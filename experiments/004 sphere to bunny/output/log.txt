gd loss = 113744.1824672875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113528.4595861247
gradient descent iteration = 12
gd loss = 113528.4595861247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113313.6223035255
gradient descent iteration = 13
gd loss = 113313.6223035255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113099.664141214
gradient descent iteration = 14
gd loss = 113099.664141214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112886.5787018731
gradient descent iteration = 15
gd loss = 112886.5787018731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112674.3596665423
gradient descent iteration = 16
gd loss = 112674.3596665423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112463.0007894388
gradient descent iteration = 17
gd loss = 112463.0007894388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112252.4958953859
gradient descent iteration = 18
gd loss = 112252.4958953859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112042.8388778077
gradient descent iteration = 19
gd loss = 112042.8388778077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111834.0237019962
gradient descent iteration = 20
gd loss = 111834.0237019962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111626.0444032306
gradient descent iteration = 21
gd loss = 111626.0444032306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111418.8950841294
gradient descent iteration = 22
gd loss = 111418.8950841294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111212.5699132721
gradient descent iteration = 23
gd loss = 111212.5699132721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111007.0631256738
gradient descent iteration = 24
gd loss = 111007.0631256738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110802.3690180837
Initial loss = 155942.3934061751
Final loss = 110802.3690180837
Deformation gradient control sequence optimization finished.
Animation interval 2 took 1208 seconds.
Full animation took 3689 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 3************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 133957.2812276076
initial norm = 8800.485809317639
convergence norm = 8.800485809317639
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 133957.2812276076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133078.7201020716
gradient descent iteration = 1
gd loss = 133078.7201020716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132203.7359243789
gradient descent iteration = 2
gd loss = 132203.7359243789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131332.3638645176
gradient descent iteration = 3
gd loss = 131332.3638645176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130464.6397441959
gradient descent iteration = 4
gd loss = 130464.6397441959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129600.6003493388
gradient descent iteration = 5
gd loss = 129600.6003493388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128740.283142967
gradient descent iteration = 6
gd loss = 128740.283142967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 127883.7261745606
gradient descent iteration = 7
gd loss = 127883.7261745606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 127030.9684424399
gradient descent iteration = 8
gd loss = 127030.9684424399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 126182.0492263346
gradient descent iteration = 9
gd loss = 126182.0492263346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125337.0083338048
gradient descent iteration = 10
gd loss = 125337.0083338048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124495.8859543032
gradient descent iteration = 11
gd loss = 124495.8859543032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123658.7230207562
gradient descent iteration = 12
gd loss = 123658.7230207562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122825.5613698373
gradient descent iteration = 13
gd loss = 122825.5613698373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121996.4434629661
gradient descent iteration = 14
gd loss = 121996.4434629661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121171.4121463449
gradient descent iteration = 15
gd loss = 121171.4121463449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120350.5109698026
gradient descent iteration = 16
gd loss = 120350.5109698026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119533.7843893937
gradient descent iteration = 17
gd loss = 119533.7843893937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118721.2772225934
gradient descent iteration = 18
gd loss = 118721.2772225934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117913.0347840552
gradient descent iteration = 19
gd loss = 117913.0347840552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117109.1031095959
gradient descent iteration = 20
gd loss = 117109.1031095959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116309.5290419087
gradient descent iteration = 21
gd loss = 116309.5290419087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115514.3600363586
gradient descent iteration = 22
gd loss = 115514.3600363586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114723.6437477905
gradient descent iteration = 23
gd loss = 114723.6437477905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113937.4282639802
gradient descent iteration = 24
gd loss = 113937.4282639802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113155.7617098983
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 113155.7617098983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112503.6606638092
gradient descent iteration = 1
gd loss = 112503.6606638092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111858.3647970768
gradient descent iteration = 2
gd loss = 111858.3647970768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111219.843839739
gradient descent iteration = 3
gd loss = 111219.843839739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110588.0655471255
gradient descent iteration = 4
gd loss = 110588.0655471255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109962.995891981
gradient descent iteration = 5
gd loss = 109962.995891981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109344.5993437542
gradient descent iteration = 6
gd loss = 109344.5993437542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108732.8388591826
gradient descent iteration = 7
gd loss = 108732.8388591826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108127.6757273035
gradient descent iteration = 8
gd loss = 108127.6757273035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 107529.069627871
gradient descent iteration = 9
gd loss = 107529.069627871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106936.9786029721
gradient descent iteration = 10
gd loss = 106936.9786029721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106351.3589695746
gradient descent iteration = 11
gd loss = 106351.3589695746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105772.165921848
gradient descent iteration = 12
gd loss = 105772.165921848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105199.3537982417
gradient descent iteration = 13
gd loss = 105199.3537982417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104632.8759597547
gradient descent iteration = 14
gd loss = 104632.8759597547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104072.6848558764
gradient descent iteration = 15
gd loss = 104072.6848558764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103518.7319262916
gradient descent iteration = 16
gd loss = 103518.7319262916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102970.9676920574
gradient descent iteration = 17
gd loss = 102970.9676920574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102429.3420136506
gradient descent iteration = 18
gd loss = 102429.3420136506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101893.8040652759
gradient descent iteration = 19
gd loss = 101893.8040652759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101364.302603602
gradient descent iteration = 20
gd loss = 101364.302603602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100840.7863850058
gradient descent iteration = 21
gd loss = 100840.7863850058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100323.2041045565
gradient descent iteration = 22
gd loss = 100323.2041045565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99811.50397472044
gradient descent iteration = 23
gd loss = 99811.50397472044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99305.63355287105
gradient descent iteration = 24
gd loss = 99305.63355287105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98805.54007079739
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 98805.54007079739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98622.17832469891
gradient descent iteration = 1
gd loss = 98622.17832469891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98439.71496317456
gradient descent iteration = 2
gd loss = 98439.71496317456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98258.14063848631
gradient descent iteration = 3
gd loss = 98258.14063848631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98077.4461559326
gradient descent iteration = 4
gd loss = 98077.4461559326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97897.62247494624
gradient descent iteration = 5
gd loss = 97897.62247494624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97718.66070947441
gradient descent iteration = 6
gd loss = 97718.66070947441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97540.5521157747
gradient descent iteration = 7
gd loss = 97540.5521157747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97363.28808804478
gradient descent iteration = 8
gd loss = 97363.28808804478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97186.86015361232
gradient descent iteration = 9
gd loss = 97186.86015361232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97011.25997263382
gradient descent iteration = 10
gd loss = 97011.25997263382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96836.47934027913
gradient descent iteration = 11
gd loss = 96836.47934027913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96662.51017730621
gradient descent iteration = 12
gd loss = 96662.51017730621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96489.34452562129
gradient descent iteration = 13
gd loss = 96489.34452562129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96316.97454794678
gradient descent iteration = 14
gd loss = 96316.97454794678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96145.3925270201
gradient descent iteration = 15
gd loss = 96145.3925270201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95974.59086206241
gradient descent iteration = 16
gd loss = 95974.59086206241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95804.562065637
gradient descent iteration = 17
gd loss = 95804.562065637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95635.29876232719
gradient descent iteration = 18
gd loss = 95635.29876232719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95466.79368682612
gradient descent iteration = 19
gd loss = 95466.79368682612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95299.03968168283
gradient descent iteration = 20
gd loss = 95299.03968168283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95132.02969531926
gradient descent iteration = 21
gd loss = 95132.02969531926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94965.75678585739
gradient descent iteration = 22
gd loss = 94965.75678585739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94800.21412619141
gradient descent iteration = 23
gd loss = 94800.21412619141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94635.39499037589
gradient descent iteration = 24
gd loss = 94635.39499037589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94471.29274987303
Initial loss = 133957.2812276076
Final loss = 94471.29274987303
Deformation gradient control sequence optimization finished.
Animation interval 3 took 1244 seconds.
Full animation took 4934 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 4************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 99517.65011980067
initial norm = 7065.350058889606
convergence norm = 7.065350058889606
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 99517.65011980067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98813.83935839501
gradient descent iteration = 1
gd loss = 98813.83935839501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98115.62360506125
gradient descent iteration = 2
gd loss = 98115.62360506125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97423.04135717421
gradient descent iteration = 3
gd loss = 97423.04135717421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96736.1302060468
gradient descent iteration = 4
gd loss = 96736.1302060468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96054.92649655927
gradient descent iteration = 5
gd loss = 96054.92649655927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95379.46521104549
gradient descent iteration = 6
gd loss = 95379.46521104549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94709.78015638518
gradient descent iteration = 7
gd loss = 94709.78015638518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94045.90374732426
gradient descent iteration = 8
gd loss = 94045.90374732426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93387.86705399756
gradient descent iteration = 9
gd loss = 93387.86705399756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92735.69966046185
gradient descent iteration = 10
gd loss = 92735.69966046185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92089.42943350697
gradient descent iteration = 11
gd loss = 92089.42943350697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91449.08259747821
gradient descent iteration = 12
gd loss = 91449.08259747821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90814.6835904207
gradient descent iteration = 13
gd loss = 90814.6835904207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90186.25475596332
gradient descent iteration = 14
gd loss = 90186.25475596332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89563.81621321432
gradient descent iteration = 15
gd loss = 89563.81621321432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88947.3860023404
gradient descent iteration = 16
gd loss = 88947.3860023404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88336.98046736444
gradient descent iteration = 17
gd loss = 88336.98046736444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87732.61459539431
gradient descent iteration = 18
gd loss = 87732.61459539431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87134.30179177155
gradient descent iteration = 19
gd loss = 87134.30179177155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86542.05388214496
gradient descent iteration = 20
gd loss = 86542.05388214496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85955.88131578614
gradient descent iteration = 21
gd loss = 85955.88131578614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85375.79371636141
gradient descent iteration = 22
gd loss = 85375.79371636141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84801.79960676766
gradient descent iteration = 23
gd loss = 84801.79960676766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84233.90597125696
gradient descent iteration = 24
gd loss = 84233.90597125696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83672.11824669752
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 83672.11824669752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83215.71782035992
gradient descent iteration = 1
gd loss = 83215.71782035992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82766.63222032221
gradient descent iteration = 2
gd loss = 82766.63222032221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82324.72512655662
gradient descent iteration = 3
gd loss = 82324.72512655662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81889.86158710523
gradient descent iteration = 4
gd loss = 81889.86158710523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81461.90794513164
gradient descent iteration = 5
gd loss = 81461.90794513164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81040.73208313911
gradient descent iteration = 6
gd loss = 81040.73208313911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80626.20347794595
gradient descent iteration = 7
gd loss = 80626.20347794595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80218.19336707587
gradient descent iteration = 8
gd loss = 80218.19336707587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79816.57483514576
gradient descent iteration = 9
gd loss = 79816.57483514576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79421.22270620395
gradient descent iteration = 10
gd loss = 79421.22270620395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79032.01365470867
gradient descent iteration = 11
gd loss = 79032.01365470867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78648.82640779122
gradient descent iteration = 12
gd loss = 78648.82640779122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78271.54155765893
gradient descent iteration = 13
gd loss = 78271.54155765893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77900.04147051381
gradient descent iteration = 14
gd loss = 77900.04147051381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77534.21054231026
gradient descent iteration = 15
gd loss = 77534.21054231026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77173.9352651411
gradient descent iteration = 16
gd loss = 77173.9352651411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76819.10428450139
gradient descent iteration = 17
gd loss = 76819.10428450139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76469.60830302245
gradient descent iteration = 18
gd loss = 76469.60830302245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76125.34002431728
gradient descent iteration = 19
gd loss = 76125.34002431728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75786.19407534933
gradient descent iteration = 20
gd loss = 75786.19407534933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75452.06708811107
gradient descent iteration = 21
gd loss = 75452.06708811107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75122.85751411936
gradient descent iteration = 22
gd loss = 75122.85751411936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74798.46565613865
gradient descent iteration = 23
gd loss = 74798.46565613865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74478.79380943357
gradient descent iteration = 24
gd loss = 74478.79380943357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74163.74623074285
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 74163.74623074285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73994.65613044066
gradient descent iteration = 1
gd loss = 73994.65613044066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73827.24383104479
gradient descent iteration = 2
gd loss = 73827.24383104479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73661.46857208238
gradient descent iteration = 3
gd loss = 73661.46857208238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73497.29083437829
gradient descent iteration = 4
gd loss = 73497.29083437829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73334.67229801958
gradient descent iteration = 5
gd loss = 73334.67229801958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73173.57581648002
gradient descent iteration = 6
gd loss = 73173.57581648002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73013.96539106482
gradient descent iteration = 7
gd loss = 73013.96539106482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72855.80611420108
gradient descent iteration = 8
gd loss = 72855.80611420108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72699.06413749495
gradient descent iteration = 9
gd loss = 72699.06413749495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72543.70665125991
gradient descent iteration = 10
gd loss = 72543.70665125991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72389.70184932185
gradient descent iteration = 11
gd loss = 72389.70184932185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72237.01889765209
gradient descent iteration = 12
gd loss = 72237.01889765209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72085.62792495254
gradient descent iteration = 13
gd loss = 72085.62792495254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71935.49998865568
gradient descent iteration = 14
gd loss = 71935.49998865568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71786.60704026284
gradient descent iteration = 15
gd loss = 71786.60704026284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71638.92189048389
gradient descent iteration = 16
gd loss = 71638.92189048389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71492.4181767885
gradient descent iteration = 17
gd loss = 71492.4181767885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71347.07034188867
gradient descent iteration = 18
gd loss = 71347.07034188867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71202.85360395482
gradient descent iteration = 19
gd loss = 71202.85360395482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71059.74393239329
gradient descent iteration = 20
gd loss = 71059.74393239329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70917.71802703181
gradient descent iteration = 21
gd loss = 70917.71802703181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70776.75329338353
gradient descent iteration = 22
gd loss = 70776.75329338353
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70636.82781957879
gradient descent iteration = 23
gd loss = 70636.82781957879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70497.92036049892
gradient descent iteration = 24
gd loss = 70497.92036049892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70360.01031256228
Initial loss = 99517.65011980067
Final loss = 70360.01031256228
Deformation gradient control sequence optimization finished.
Animation interval 4 took 1242 seconds.
Full animation took 6177 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 5************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 82982.39779297824
initial norm = 6126.586713093818
convergence norm = 6.126586713093817
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 82982.39779297824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82372.88464178462
gradient descent iteration = 1
gd loss = 82372.88464178462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81770.18284508346
gradient descent iteration = 2
gd loss = 81770.18284508346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81174.30628653093
gradient descent iteration = 3
gd loss = 81174.30628653093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80585.2670995192
gradient descent iteration = 4
gd loss = 80585.2670995192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80003.07578314903
gradient descent iteration = 5
gd loss = 80003.07578314903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79427.74139598425
gradient descent iteration = 6
gd loss = 79427.74139598425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78859.27138338164
gradient descent iteration = 7
gd loss = 78859.27138338164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78297.67131997587
gradient descent iteration = 8
gd loss = 78297.67131997587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77742.94440634597
gradient descent iteration = 9
gd loss = 77742.94440634597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77195.09139706191
gradient descent iteration = 10
gd loss = 77195.09139706191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76654.11087627213
gradient descent iteration = 11
gd loss = 76654.11087627213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76119.99901381599
gradient descent iteration = 12
gd loss = 76119.99901381599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75592.74952179537
gradient descent iteration = 13
gd loss = 75592.74952179537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75072.35330306017
gradient descent iteration = 14
gd loss = 75072.35330306017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74558.79826246863
gradient descent iteration = 15
gd loss = 74558.79826246863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74052.06925428496
gradient descent iteration = 16
gd loss = 74052.06925428496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73552.14743571354
gradient descent iteration = 17
gd loss = 73552.14743571354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73059.01062491574
gradient descent iteration = 18
gd loss = 73059.01062491574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72572.63335995292
gradient descent iteration = 19
gd loss = 72572.63335995292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72092.98721389382
gradient descent iteration = 20
gd loss = 72092.98721389382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71620.04095248724
gradient descent iteration = 21
gd loss = 71620.04095248724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71153.76018064484
gradient descent iteration = 22
gd loss = 71153.76018064484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70694.10720482144
gradient descent iteration = 23
gd loss = 70694.10720482144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70241.0410740807
gradient descent iteration = 24
gd loss = 70241.0410740807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69794.51751376191
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 69794.51751376191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69443.22184924128
gradient descent iteration = 1
gd loss = 69443.22184924128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69098.35606905028
gradient descent iteration = 2
gd loss = 69098.35606905028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68759.75297231402
gradient descent iteration = 3
gd loss = 68759.75297231402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68427.24981477333
gradient descent iteration = 4
gd loss = 68427.24981477333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68100.68823110119
gradient descent iteration = 5
gd loss = 68100.68823110119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67779.91389118013
gradient descent iteration = 6
gd loss = 67779.91389118013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67464.77633928544
gradient descent iteration = 7
gd loss = 67464.77633928544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67155.12903279033
gradient descent iteration = 8
gd loss = 67155.12903279033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66850.8294129401
gradient descent iteration = 9
gd loss = 66850.8294129401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66551.73904294179
gradient descent iteration = 10
gd loss = 66551.73904294179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66257.72333136661
gradient descent iteration = 11
gd loss = 66257.72333136661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65968.65127276565
gradient descent iteration = 12
gd loss = 65968.65127276565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65684.39564973257
gradient descent iteration = 13
gd loss = 65684.39564973257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65404.83282717517
gradient descent iteration = 14
gd loss = 65404.83282717517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65129.84250598357
gradient descent iteration = 15
gd loss = 65129.84250598357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64859.30762977023
gradient descent iteration = 16
gd loss = 64859.30762977023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64593.11429100674
gradient descent iteration = 17
gd loss = 64593.11429100674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64331.15166386409
gradient descent iteration = 18
gd loss = 64331.15166386409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64073.31206108427
gradient descent iteration = 19
gd loss = 64073.31206108427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63819.49081512325
gradient descent iteration = 20
gd loss = 63819.49081512325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63569.58617040373
gradient descent iteration = 21
gd loss = 63569.58617040373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63323.49929374435
gradient descent iteration = 22
gd loss = 63323.49929374435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63081.13428092057
gradient descent iteration = 23
gd loss = 63081.13428092057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62842.39810283538
gradient descent iteration = 24
gd loss = 62842.39810283538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62607.20048817236
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 62607.20048817236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62445.56795350806
gradient descent iteration = 1
gd loss = 62445.56795350806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62286.37639792547
gradient descent iteration = 2
gd loss = 62286.37639792547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62129.54206840038
gradient descent iteration = 3
gd loss = 62129.54206840038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61974.98458456829
gradient descent iteration = 4
gd loss = 61974.98458456829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61822.62681294594
gradient descent iteration = 5
gd loss = 61822.62681294594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61672.39473695393
gradient descent iteration = 6
gd loss = 61672.39473695393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61524.21733620211
gradient descent iteration = 7
gd loss = 61524.21733620211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61378.02645231067
gradient descent iteration = 8
gd loss = 61378.02645231067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61233.75664487112
gradient descent iteration = 9
gd loss = 61233.75664487112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61091.34509809474
gradient descent iteration = 10
gd loss = 61091.34509809474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60950.73155153089
gradient descent iteration = 11
gd loss = 60950.73155153089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60811.85820542477
gradient descent iteration = 12
gd loss = 60811.85820542477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60674.66961713716
gradient descent iteration = 13
gd loss = 60674.66961713716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60539.11261671565
gradient descent iteration = 14
gd loss = 60539.11261671565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60405.13621677122
gradient descent iteration = 15
gd loss = 60405.13621677122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60272.69150217809
gradient descent iteration = 16
gd loss = 60272.69150217809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60141.73154601731
gradient descent iteration = 17
gd loss = 60141.73154601731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60012.21133833798
gradient descent iteration = 18
gd loss = 60012.21133833798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59884.08769811743
gradient descent iteration = 19
gd loss = 59884.08769811743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59757.31919134122
gradient descent iteration = 20
gd loss = 59757.31919134122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59631.86605721624
gradient descent iteration = 21
gd loss = 59631.86605721624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59507.69013854481
gradient descent iteration = 22
gd loss = 59507.69013854481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59384.75481905579
gradient descent iteration = 23
gd loss = 59384.75481905579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59263.02497059718
gradient descent iteration = 24
gd loss = 59263.02497059718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59142.46687878737
Initial loss = 82982.39779297824
Final loss = 59142.46687878737
Deformation gradient control sequence optimization finished.
Animation interval 5 took 1261 seconds.
Full animation took 7438 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 6************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 62991.86685369202
initial norm = 3919.474679056207
convergence norm = 3.919474679056207
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 62991.86685369202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62603.16726266503
gradient descent iteration = 1
gd loss = 62603.16726266503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62220.98904019667
gradient descent iteration = 2
gd loss = 62220.98904019667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61845.24854875037
gradient descent iteration = 3
gd loss = 61845.24854875037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61475.85890099672
gradient descent iteration = 4
gd loss = 61475.85890099672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61112.73008060046
gradient descent iteration = 5
gd loss = 61112.73008060046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60755.76961301734
gradient descent iteration = 6
gd loss = 60755.76961301734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60404.88212722657
gradient descent iteration = 7
gd loss = 60404.88212722657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60059.96890048124
gradient descent iteration = 8
gd loss = 60059.96890048124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59720.92822457413
gradient descent iteration = 9
gd loss = 59720.92822457413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59387.65583060699
gradient descent iteration = 10
gd loss = 59387.65583060699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59060.04484068843
gradient descent iteration = 11
gd loss = 59060.04484068843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58737.98577354132
gradient descent iteration = 12
gd loss = 58737.98577354132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58421.36673020876
gradient descent iteration = 13
gd loss = 58421.36673020876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58110.07344561303
gradient descent iteration = 14
gd loss = 58110.07344561303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57803.98956230671
gradient descent iteration = 15
gd loss = 57803.98956230671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57502.99660491254
gradient descent iteration = 16
gd loss = 57502.99660491254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57206.97477046457
gradient descent iteration = 17
gd loss = 57206.97477046457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56915.80323456706
gradient descent iteration = 18
gd loss = 56915.80323456706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56629.35982314235
gradient descent iteration = 19
gd loss = 56629.35982314235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56347.52104999231
gradient descent iteration = 20
gd loss = 56347.52104999231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56070.16291479336
gradient descent iteration = 21
gd loss = 56070.16291479336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55797.16094869752
gradient descent iteration = 22
gd loss = 55797.16094869752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55528.3904352327
gradient descent iteration = 23
gd loss = 55528.3904352327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55263.72667359625
gradient descent iteration = 24
gd loss = 55263.72667359625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55003.04537251613
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 55003.04537251613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54745.12766770168
gradient descent iteration = 1
gd loss = 54745.12766770168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54492.11616392936
gradient descent iteration = 2
gd loss = 54492.11616392936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54243.83739643738
gradient descent iteration = 3
gd loss = 54243.83739643738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54000.12561422346
gradient descent iteration = 4
gd loss = 54000.12561422346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53760.82210698509
gradient descent iteration = 5
gd loss = 53760.82210698509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53525.77496557595
gradient descent iteration = 6
gd loss = 53525.77496557595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53294.83884348164
gradient descent iteration = 7
gd loss = 53294.83884348164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53067.87480608967
gradient descent iteration = 8
gd loss = 53067.87480608967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52844.74966571007
gradient descent iteration = 9
gd loss = 52844.74966571007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52625.33561482666
gradient descent iteration = 10
gd loss = 52625.33561482666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52409.51025651268
gradient descent iteration = 11
gd loss = 52409.51025651268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52197.15618446578
gradient descent iteration = 12
gd loss = 52197.15618446578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51988.16063437366
gradient descent iteration = 13
gd loss = 51988.16063437366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51782.41567334694
gradient descent iteration = 14
gd loss = 51782.41567334694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51579.81810503379
gradient descent iteration = 15
gd loss = 51579.81810503379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51380.26882498381
gradient descent iteration = 16
gd loss = 51380.26882498381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51183.67259726707
gradient descent iteration = 17
gd loss = 51183.67259726707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50989.93787079008
gradient descent iteration = 18
gd loss = 50989.93787079008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50798.9766564947
gradient descent iteration = 19
gd loss = 50798.9766564947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50610.7045006862
gradient descent iteration = 20
gd loss = 50610.7045006862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50425.0403292757
gradient descent iteration = 21
gd loss = 50425.0403292757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50241.90616290949
gradient descent iteration = 22
gd loss = 50241.90616290949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50061.22695791013
gradient descent iteration = 23
gd loss = 50061.22695791013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49882.93037198374
gradient descent iteration = 24
gd loss = 49882.93037198374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49706.94669348167
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 49706.94669348167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49514.38742980816
gradient descent iteration = 1
gd loss = 49514.38742980816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49327.79111917524
gradient descent iteration = 2
gd loss = 49327.79111917524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49146.77127399622
gradient descent iteration = 3
gd loss = 49146.77127399622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48970.96982902604
gradient descent iteration = 4
gd loss = 48970.96982902604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48800.05506876301
gradient descent iteration = 5
gd loss = 48800.05506876301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48633.71971086024
gradient descent iteration = 6
gd loss = 48633.71971086024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48471.67913054238
gradient descent iteration = 7
gd loss = 48471.67913054238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48313.66969342152
gradient descent iteration = 8
gd loss = 48313.66969342152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48159.44720454502
gradient descent iteration = 9
gd loss = 48159.44720454502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48008.78544851937
gradient descent iteration = 10
gd loss = 48008.78544851937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47861.47483229428
gradient descent iteration = 11
gd loss = 47861.47483229428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47717.32112393706
gradient descent iteration = 12
gd loss = 47717.32112393706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47576.14434557444
gradient descent iteration = 13
gd loss = 47576.14434557444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47437.77767927566
gradient descent iteration = 14
gd loss = 47437.77767927566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47302.06646543818
gradient descent iteration = 15
gd loss = 47302.06646543818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47168.86726271007
gradient descent iteration = 16
gd loss = 47168.86726271007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47038.04696948202
gradient descent iteration = 17
gd loss = 47038.04696948202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46909.48202208257
gradient descent iteration = 18
gd loss = 46909.48202208257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46783.05765668975
gradient descent iteration = 19
gd loss = 46783.05765668975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46658.6672554489
gradient descent iteration = 20
gd loss = 46658.6672554489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46536.21172304621
gradient descent iteration = 21
gd loss = 46536.21172304621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46415.5988890946
gradient descent iteration = 22
gd loss = 46415.5988890946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46296.74297287422
gradient descent iteration = 23
gd loss = 46296.74297287422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46179.56407373928
gradient descent iteration = 24
gd loss = 46179.56407373928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46063.98771521595
Initial loss = 62991.86685369202
Final loss = 46063.98771521595
Deformation gradient control sequence optimization finished.
Animation interval 6 took 1265 seconds.
Full animation took 8704 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 7************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 51124.39323664062
initial norm = 3143.644076811353
convergence norm = 3.143644076811353
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 51124.39323664062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50813.61781994325
gradient descent iteration = 1
gd loss = 50813.61781994325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50510.07969909722
gradient descent iteration = 2
gd loss = 50510.07969909722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50213.63077652459
gradient descent iteration = 3
gd loss = 50213.63077652459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49924.11796061732
gradient descent iteration = 4
gd loss = 49924.11796061732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49641.38228048554
gradient descent iteration = 5
gd loss = 49641.38228048554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49365.25889639909
gradient descent iteration = 6
gd loss = 49365.25889639909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49095.57717766392
gradient descent iteration = 7
gd loss = 49095.57717766392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48832.1614269831
gradient descent iteration = 8
gd loss = 48832.1614269831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48574.83206221018
gradient descent iteration = 9
gd loss = 48574.83206221018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48323.40587000264
gradient descent iteration = 10
gd loss = 48323.40587000264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48077.69607015936
gradient descent iteration = 11
gd loss = 48077.69607015936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47837.51261613507
gradient descent iteration = 12
gd loss = 47837.51261613507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47602.66257979096
gradient descent iteration = 13
gd loss = 47602.66257979096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47372.95124071146
gradient descent iteration = 14
gd loss = 47372.95124071146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47148.18240906125
gradient descent iteration = 15
gd loss = 47148.18240906125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46928.15958236495
gradient descent iteration = 16
gd loss = 46928.15958236495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46712.68681283565
gradient descent iteration = 17
gd loss = 46712.68681283565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46501.56967450752
gradient descent iteration = 18
gd loss = 46501.56967450752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46294.6165483122
gradient descent iteration = 19
gd loss = 46294.6165483122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46091.63895597939
gradient descent iteration = 20
gd loss = 46091.63895597939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45892.45195190455
gradient descent iteration = 21
gd loss = 45892.45195190455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45696.87482810528
gradient descent iteration = 22
gd loss = 45696.87482810528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45504.73165897519
gradient descent iteration = 23
gd loss = 45504.73165897519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45315.85203026829
gradient descent iteration = 24
gd loss = 45315.85203026829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45130.07116857115
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 45130.07116857115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44920.63107728207
gradient descent iteration = 1
gd loss = 44920.63107728207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44715.70733956955
gradient descent iteration = 2
gd loss = 44715.70733956955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44515.08845356838
gradient descent iteration = 3
gd loss = 44515.08845356838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44318.57488310209
gradient descent iteration = 4
gd loss = 44318.57488310209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44125.97818268877
gradient descent iteration = 5
gd loss = 44125.97818268877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43937.12027934317
gradient descent iteration = 6
gd loss = 43937.12027934317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43751.83294613965
gradient descent iteration = 7
gd loss = 43751.83294613965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43569.95739418667
gradient descent iteration = 8
gd loss = 43569.95739418667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43391.3434671478
gradient descent iteration = 9
gd loss = 43391.3434671478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43215.84949616162
gradient descent iteration = 10
gd loss = 43215.84949616162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43043.34163178949
gradient descent iteration = 11
gd loss = 43043.34163178949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42873.69359030083
gradient descent iteration = 12
gd loss = 42873.69359030083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42706.78613120568
gradient descent iteration = 13
gd loss = 42706.78613120568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42542.50654090823
gradient descent iteration = 14
gd loss = 42542.50654090823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42380.74829234201
gradient descent iteration = 15
gd loss = 42380.74829234201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42221.41049625374
gradient descent iteration = 16
gd loss = 42221.41049625374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42064.39759988798
gradient descent iteration = 17
gd loss = 42064.39759988798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41909.61892705513
gradient descent iteration = 18
gd loss = 41909.61892705513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41756.98846884766
gradient descent iteration = 19
gd loss = 41756.98846884766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41606.42470661757
gradient descent iteration = 20
gd loss = 41606.42470661757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41457.85059918738
gradient descent iteration = 21
gd loss = 41457.85059918738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41311.19319052799
gradient descent iteration = 22
gd loss = 41311.19319052799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41166.3831607069
gradient descent iteration = 23
gd loss = 41166.3831607069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41023.35473842354
gradient descent iteration = 24
gd loss = 41023.35473842354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40882.04535821021
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40882.04535821021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40720.9446556192
gradient descent iteration = 1
gd loss = 40720.9446556192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40566.32380481256
gradient descent iteration = 2
gd loss = 40566.32380481256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40417.57042668756
gradient descent iteration = 3
gd loss = 40417.57042668756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40274.13988036519
gradient descent iteration = 4
gd loss = 40274.13988036519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40135.54770649906
gradient descent iteration = 5
gd loss = 40135.54770649906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40001.36287267377
gradient descent iteration = 6
gd loss = 40001.36287267377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39871.20172939882
gradient descent iteration = 7
gd loss = 39871.20172939882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39744.72255680747
gradient descent iteration = 8
gd loss = 39744.72255680747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39621.6208171817
gradient descent iteration = 9
gd loss = 39621.6208171817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39501.62494446422
gradient descent iteration = 10
gd loss = 39501.62494446422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39384.49256705634
gradient descent iteration = 11
gd loss = 39384.49256705634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39270.00715390537
gradient descent iteration = 12
gd loss = 39270.00715390537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39157.97504551481
gradient descent iteration = 13
gd loss = 39157.97504551481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39048.22283524759
gradient descent iteration = 14
gd loss = 39048.22283524759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38940.59505767727
gradient descent iteration = 15
gd loss = 38940.59505767727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38834.95214000689
gradient descent iteration = 16
gd loss = 38834.95214000689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38731.16857610874
gradient descent iteration = 17
gd loss = 38731.16857610874
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38629.13132410256
gradient descent iteration = 18
gd loss = 38629.13132410256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38528.73839786846
gradient descent iteration = 19
gd loss = 38528.73839786846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38429.89764300759
gradient descent iteration = 20
gd loss = 38429.89764300759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38332.52563989389
gradient descent iteration = 21
gd loss = 38332.52563989389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38236.54675048295
gradient descent iteration = 22
gd loss = 38236.54675048295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38141.89223258765
gradient descent iteration = 23
gd loss = 38141.89223258765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38048.49945940559
gradient descent iteration = 24
gd loss = 38048.49945940559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37956.31128001382
Initial loss = 51124.39323664062
Final loss = 37956.31128001382
Deformation gradient control sequence optimization finished.
Animation interval 7 took 1262 seconds.
Full animation took 9966 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 8************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 40028.59288172533
initial norm = 1744.999168985146
convergence norm = 1.744999168985146
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 40028.59288172533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39856.17380503521
gradient descent iteration = 1
gd loss = 39856.17380503521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39687.77912493249
gradient descent iteration = 2
gd loss = 39687.77912493249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39523.20271299065
gradient descent iteration = 3
gd loss = 39523.20271299065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39362.24453300523
gradient descent iteration = 4
gd loss = 39362.24453300523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39204.71093427607
gradient descent iteration = 5
gd loss = 39204.71093427607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39050.41466655904
gradient descent iteration = 6
gd loss = 39050.41466655904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38899.17546754083
gradient descent iteration = 7
gd loss = 38899.17546754083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38750.82098527843
gradient descent iteration = 8
gd loss = 38750.82098527843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38605.18793876738
gradient descent iteration = 9
gd loss = 38605.18793876738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38462.12218620563
gradient descent iteration = 10
gd loss = 38462.12218620563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38321.47860293696
gradient descent iteration = 11
gd loss = 38321.47860293696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38183.12024145981
gradient descent iteration = 12
gd loss = 38183.12024145981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38046.91907504541
gradient descent iteration = 13
gd loss = 38046.91907504541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37912.7554744951
gradient descent iteration = 14
gd loss = 37912.7554744951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37780.51738872002
gradient descent iteration = 15
gd loss = 37780.51738872002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37650.10115327162
gradient descent iteration = 16
gd loss = 37650.10115327162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37521.41154913409
gradient descent iteration = 17
gd loss = 37521.41154913409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37394.36006912462
gradient descent iteration = 18
gd loss = 37394.36006912462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37268.86420527993
gradient descent iteration = 19
gd loss = 37268.86420527993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37144.84755028004
gradient descent iteration = 20
gd loss = 37144.84755028004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37022.23952924475
gradient descent iteration = 21
gd loss = 37022.23952924475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36900.97556172258
gradient descent iteration = 22
gd loss = 36900.97556172258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36780.99637502426
gradient descent iteration = 23
gd loss = 36780.99637502426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36662.24705093607
gradient descent iteration = 24
gd loss = 36662.24705093607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36544.67649777143
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 36544.67649777143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36358.563147177
gradient descent iteration = 1
gd loss = 36358.563147177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36177.562726551
gradient descent iteration = 2
gd loss = 36177.562726551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36001.32292374082
gradient descent iteration = 3
gd loss = 36001.32292374082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35829.5234758661
gradient descent iteration = 4
gd loss = 35829.5234758661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35661.87221460939
gradient descent iteration = 5
gd loss = 35661.87221460939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35498.10261953255
gradient descent iteration = 6
gd loss = 35498.10261953255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35337.97284062837
gradient descent iteration = 7
gd loss = 35337.97284062837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35181.26187602049
gradient descent iteration = 8
gd loss = 35181.26187602049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35027.76764945783
gradient descent iteration = 9
gd loss = 35027.76764945783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34877.30599657951
gradient descent iteration = 10
gd loss = 34877.30599657951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34729.70846013985
gradient descent iteration = 11
gd loss = 34729.70846013985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34584.82044625014
gradient descent iteration = 12
gd loss = 34584.82044625014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34442.49964369661
gradient descent iteration = 13
gd loss = 34442.49964369661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34302.61539117588
gradient descent iteration = 14
gd loss = 34302.61539117588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34165.04686326367
gradient descent iteration = 15
gd loss = 34165.04686326367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34029.68188363601
gradient descent iteration = 16
gd loss = 34029.68188363601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33896.41673667316
gradient descent iteration = 17
gd loss = 33896.41673667316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33765.15556329623
gradient descent iteration = 18
gd loss = 33765.15556329623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33635.80944798705
gradient descent iteration = 19
gd loss = 33635.80944798705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33508.29517105959
gradient descent iteration = 20
gd loss = 33508.29517105959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33382.53387779447
gradient descent iteration = 21
gd loss = 33382.53387779447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33258.4510187784
gradient descent iteration = 22
gd loss = 33258.4510187784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33135.97517886537
gradient descent iteration = 23
gd loss = 33135.97517886537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33015.03727078425
gradient descent iteration = 24
gd loss = 33015.03727078425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32895.57051937435
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 32895.57051937435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32760.41939690418
gradient descent iteration = 1
gd loss = 32760.41939690418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32632.47327731322
gradient descent iteration = 2
gd loss = 32632.47327731322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32510.67523698252
gradient descent iteration = 3
gd loss = 32510.67523698252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32394.16217264588
gradient descent iteration = 4
gd loss = 32394.16217264588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32282.22789599952
gradient descent iteration = 5
gd loss = 32282.22789599952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32174.29311589176
gradient descent iteration = 6
gd loss = 32174.29311589176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32069.88108702295
gradient descent iteration = 7
gd loss = 32069.88108702295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31968.59788548953
gradient descent iteration = 8
gd loss = 31968.59788548953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31870.11655002815
gradient descent iteration = 9
gd loss = 31870.11655002815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31774.16451793973
gradient descent iteration = 10
gd loss = 31774.16451793973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31680.51325674603
gradient descent iteration = 11
gd loss = 31680.51325674603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31588.96996863965
gradient descent iteration = 12
gd loss = 31588.96996863965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31499.37099186865
gradient descent iteration = 13
gd loss = 31499.37099186865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31411.57640077807
gradient descent iteration = 14
gd loss = 31411.57640077807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31325.46571143053
gradient descent iteration = 15
gd loss = 31325.46571143053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31240.93451559429
gradient descent iteration = 16
gd loss = 31240.93451559429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31157.89162176928
gradient descent iteration = 17
gd loss = 31157.89162176928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31076.25667303163
gradient descent iteration = 18
gd loss = 31076.25667303163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30995.95834344066
gradient descent iteration = 19
gd loss = 30995.95834344066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30916.9328427382
gradient descent iteration = 20
gd loss = 30916.9328427382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30839.12276780203
gradient descent iteration = 21
gd loss = 30839.12276780203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30762.47619944189
gradient descent iteration = 22
gd loss = 30762.47619944189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30686.94591557323
gradient descent iteration = 23
gd loss = 30686.94591557323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30612.48871362013
gradient descent iteration = 24
gd loss = 30612.48871362013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30539.0648278066
Initial loss = 40028.59288172533
Final loss = 30539.0648278066
Deformation gradient control sequence optimization finished.
Animation interval 8 took 1269 seconds.
Full animation took 11236 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 9************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 32229.52915968923
initial norm = 1376.806688574826
convergence norm = 1.376806688574826
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 32229.52915968923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32095.07528798089
gradient descent iteration = 1
gd loss = 32095.07528798089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31966.71575276337
gradient descent iteration = 2
gd loss = 31966.71575276337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31843.9545323286
gradient descent iteration = 3
gd loss = 31843.9545323286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31726.29388870385
gradient descent iteration = 4
gd loss = 31726.29388870385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31613.24269253418
gradient descent iteration = 5
gd loss = 31613.24269253418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31504.32595004528
gradient descent iteration = 6
gd loss = 31504.32595004528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31399.09211764994
gradient descent iteration = 7
gd loss = 31399.09211764994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31297.11938633456
gradient descent iteration = 8
gd loss = 31297.11938633456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31198.02117378751
gradient descent iteration = 9
gd loss = 31198.02117378751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31101.44928414208
gradient descent iteration = 10
gd loss = 31101.44928414208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31007.09506327436
gradient descent iteration = 11
gd loss = 31007.09506327436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30914.68847139578
gradient descent iteration = 12
gd loss = 30914.68847139578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30823.99570693179
gradient descent iteration = 13
gd loss = 30823.99570693179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30734.81623944303
gradient descent iteration = 14
gd loss = 30734.81623944303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30646.97916417196
gradient descent iteration = 15
gd loss = 30646.97916417196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30560.3391764543
gradient descent iteration = 16
gd loss = 30560.3391764543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30474.77280146094
gradient descent iteration = 17
gd loss = 30474.77280146094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30390.17502191545
gradient descent iteration = 18
gd loss = 30390.17502191545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30306.45614892273
gradient descent iteration = 19
gd loss = 30306.45614892273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30223.53904189246
gradient descent iteration = 20
gd loss = 30223.53904189246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30141.3570191889
gradient descent iteration = 21
gd loss = 30141.3570191889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30059.85208164161
gradient descent iteration = 22
gd loss = 30059.85208164161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29978.97346759881
gradient descent iteration = 23
gd loss = 29978.97346759881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29898.67643693487
gradient descent iteration = 24
gd loss = 29898.67643693487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29818.92125328038
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 29818.92125328038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29657.38698069884
gradient descent iteration = 1
gd loss = 29657.38698069884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29501.69658554205
gradient descent iteration = 2
gd loss = 29501.69658554205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29351.26309181791
gradient descent iteration = 3
gd loss = 29351.26309181791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29205.57314810231
gradient descent iteration = 4
gd loss = 29205.57314810231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29064.17642597542
gradient descent iteration = 5
gd loss = 29064.17642597542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28926.67668632349
gradient descent iteration = 6
gd loss = 28926.67668632349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28792.72403819982
gradient descent iteration = 7
gd loss = 28792.72403819982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28662.00836181567
gradient descent iteration = 8
gd loss = 28662.00836181567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28534.25609169218
gradient descent iteration = 9
gd loss = 28534.25609169218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28409.22505159146
gradient descent iteration = 10
gd loss = 28409.22505159146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28286.70004543233
gradient descent iteration = 11
gd loss = 28286.70004543233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28166.48849811259
gradient descent iteration = 12
gd loss = 28166.48849811259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28048.41692611553
gradient descent iteration = 13
gd loss = 28048.41692611553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27932.32858092609
gradient descent iteration = 14
gd loss = 27932.32858092609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27818.08229095249
gradient descent iteration = 15
gd loss = 27818.08229095249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27705.54935148879
gradient descent iteration = 16
gd loss = 27705.54935148879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27594.61280599835
gradient descent iteration = 17
gd loss = 27594.61280599835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27485.16640374706
gradient descent iteration = 18
gd loss = 27485.16640374706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27377.11356772342
gradient descent iteration = 19
gd loss = 27377.11356772342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27270.36669976111
gradient descent iteration = 20
gd loss = 27270.36669976111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27164.84631054299
gradient descent iteration = 21
gd loss = 27164.84631054299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27060.48015110109
gradient descent iteration = 22
gd loss = 27060.48015110109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26957.20352535487
gradient descent iteration = 23
gd loss = 26957.20352535487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26854.95813104595
gradient descent iteration = 24
gd loss = 26854.95813104595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26753.69142258076
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 26753.69142258076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26655.23455937185
gradient descent iteration = 1
gd loss = 26655.23455937185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26563.52195428932
gradient descent iteration = 2
gd loss = 26563.52195428932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26477.15218540447
gradient descent iteration = 3
gd loss = 26477.15218540447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26395.10246198595
gradient descent iteration = 4
gd loss = 26395.10246198595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26316.61988824025
gradient descent iteration = 5
gd loss = 26316.61988824025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26241.14422239187
gradient descent iteration = 6
gd loss = 26241.14422239187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26168.25319239765
gradient descent iteration = 7
gd loss = 26168.25319239765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26097.62351404923
gradient descent iteration = 8
gd loss = 26097.62351404923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26029.0034139157
gradient descent iteration = 9
gd loss = 26029.0034139157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25962.1931684737
gradient descent iteration = 10
gd loss = 25962.1931684737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25897.03131711475
gradient descent iteration = 11
gd loss = 25897.03131711475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25833.38489809402
gradient descent iteration = 12
gd loss = 25833.38489809402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25771.14243615996
gradient descent iteration = 13
gd loss = 25771.14243615996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25710.20897722863
gradient descent iteration = 14
gd loss = 25710.20897722863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25650.50239789996
gradient descent iteration = 15
gd loss = 25650.50239789996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25591.95066141223
gradient descent iteration = 16
gd loss = 25591.95066141223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25534.48991742223
gradient descent iteration = 17
gd loss = 25534.48991742223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25478.06299093093
gradient descent iteration = 18
gd loss = 25478.06299093093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25422.61822756687
gradient descent iteration = 19
gd loss = 25422.61822756687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25368.10864987035
gradient descent iteration = 20
gd loss = 25368.10864987035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25314.49127117477
gradient descent iteration = 21
gd loss = 25314.49127117477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25261.72657535206
gradient descent iteration = 22
gd loss = 25261.72657535206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25209.77809836946
gradient descent iteration = 23
gd loss = 25209.77809836946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25158.61206916241
gradient descent iteration = 24
gd loss = 25158.61206916241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25108.19711233806
Initial loss = 32229.52915968923
Final loss = 25108.19711233806
Deformation gradient control sequence optimization finished.
Animation interval 9 took 1249 seconds.
Full animation took 12485 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 10************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 26419.28028811742
initial norm = 934.0868648897442
convergence norm = 0.9340868648897442
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 26419.28028811742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26328.16472659697
gradient descent iteration = 1
gd loss = 26328.16472659697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26241.20639122907
gradient descent iteration = 2
gd loss = 26241.20639122907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26157.80523112501
gradient descent iteration = 3
gd loss = 26157.80523112501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26077.41086173141
gradient descent iteration = 4
gd loss = 26077.41086173141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25999.53339677593
gradient descent iteration = 5
gd loss = 25999.53339677593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25923.74859683722
gradient descent iteration = 6
gd loss = 25923.74859683722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25849.69751467065
gradient descent iteration = 7
gd loss = 25849.69751467065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25777.08202836629
gradient descent iteration = 8
gd loss = 25777.08202836629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25705.65807213601
gradient descent iteration = 9
gd loss = 25705.65807213601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25635.22783523109
gradient descent iteration = 10
gd loss = 25635.22783523109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25565.63195781428
gradient descent iteration = 11
gd loss = 25565.63195781428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25496.74231648138
gradient descent iteration = 12
gd loss = 25496.74231648138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25428.45580930753
gradient descent iteration = 13
gd loss = 25428.45580930753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25360.68923474707
gradient descent iteration = 14
gd loss = 25360.68923474707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25293.37522555771
gradient descent iteration = 15
gd loss = 25293.37522555771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25226.458802205
gradient descent iteration = 16
gd loss = 25226.458802205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25159.8946808959
gradient descent iteration = 17
gd loss = 25159.8946808959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25093.64520254247
gradient descent iteration = 18
gd loss = 25093.64520254247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25027.67854217341
gradient descent iteration = 19
gd loss = 25027.67854217341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24961.96725274955
gradient descent iteration = 20
gd loss = 24961.96725274955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24896.48707901912
gradient descent iteration = 21
gd loss = 24896.48707901912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24831.21621604147
gradient descent iteration = 22
gd loss = 24831.21621604147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24766.13474216636
gradient descent iteration = 23
gd loss = 24766.13474216636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24701.22416842951
gradient descent iteration = 24
gd loss = 24701.22416842951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24636.46703127493
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 24636.46703127493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24513.86183687623
gradient descent iteration = 1
gd loss = 24513.86183687623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24397.09550097989
gradient descent iteration = 2
gd loss = 24397.09550097989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24285.38554015287
gradient descent iteration = 3
gd loss = 24285.38554015287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24178.08717002487
gradient descent iteration = 4
gd loss = 24178.08717002487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24074.66479411682
gradient descent iteration = 5
gd loss = 24074.66479411682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23974.67247449144
gradient descent iteration = 6
gd loss = 23974.67247449144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23877.73574058073
gradient descent iteration = 7
gd loss = 23877.73574058073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23783.53853223898
gradient descent iteration = 8
gd loss = 23783.53853223898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23691.81254435432
gradient descent iteration = 9
gd loss = 23691.81254435432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23602.32836398321
gradient descent iteration = 10
gd loss = 23602.32836398321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23514.88907602818
gradient descent iteration = 11
gd loss = 23514.88907602818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23429.32698149513
gradient descent iteration = 12
gd loss = 23429.32698149513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23345.49929889841
gradient descent iteration = 13
gd loss = 23345.49929889841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23263.28411049381
gradient descent iteration = 14
gd loss = 23263.28411049381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23182.57609885281
gradient descent iteration = 15
gd loss = 23182.57609885281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23103.28499814328
gradient descent iteration = 16
gd loss = 23103.28499814328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23025.33493921055
gradient descent iteration = 17
gd loss = 23025.33493921055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22948.66058249805
gradient descent iteration = 18
gd loss = 22948.66058249805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22873.20460950294
gradient descent iteration = 19
gd loss = 22873.20460950294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22798.91489740148
gradient descent iteration = 20
gd loss = 22798.91489740148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22725.74346489408
gradient descent iteration = 21
gd loss = 22725.74346489408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22653.64462821455
gradient descent iteration = 22
gd loss = 22653.64462821455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22582.5732595984
gradient descent iteration = 23
gd loss = 22582.5732595984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22512.48385521068
gradient descent iteration = 24
gd loss = 22512.48385521068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22443.33107137765
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 22443.33107137765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22386.06292625377
gradient descent iteration = 1
gd loss = 22386.06292625377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22333.37909766333
gradient descent iteration = 2
gd loss = 22333.37909766333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22284.03990799055
gradient descent iteration = 3
gd loss = 22284.03990799055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22237.22637052715
gradient descent iteration = 4
gd loss = 22237.22637052715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22192.38979784445
gradient descent iteration = 5
gd loss = 22192.38979784445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22149.15572828603
gradient descent iteration = 6
gd loss = 22149.15572828603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22107.26267939289
gradient descent iteration = 7
gd loss = 22107.26267939289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22066.52307408216
gradient descent iteration = 8
gd loss = 22066.52307408216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22026.79827214149
gradient descent iteration = 9
gd loss = 22026.79827214149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21987.98255587662
gradient descent iteration = 10
gd loss = 21987.98255587662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21949.99279110904
gradient descent iteration = 11
gd loss = 21949.99279110904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21912.76168487014
gradient descent iteration = 12
gd loss = 21912.76168487014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21876.23335088251
gradient descent iteration = 13
gd loss = 21876.23335088251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21840.36035187093
gradient descent iteration = 14
gd loss = 21840.36035187093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21805.10169736117
gradient descent iteration = 15
gd loss = 21805.10169736117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21770.42145959024
gradient descent iteration = 16
gd loss = 21770.42145959024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21736.28777028915
gradient descent iteration = 17
gd loss = 21736.28777028915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21702.67214704376
gradient descent iteration = 18
gd loss = 21702.67214704376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21669.54895078376
gradient descent iteration = 19
gd loss = 21669.54895078376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21636.89500453976
gradient descent iteration = 20
gd loss = 21636.89500453976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21604.68926007447
gradient descent iteration = 21
gd loss = 21604.68926007447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21572.91244738799
gradient descent iteration = 22
gd loss = 21572.91244738799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21541.54684909365
gradient descent iteration = 23
gd loss = 21541.54684909365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21510.5761225488
gradient descent iteration = 24
gd loss = 21510.5761225488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21479.98514570391
Initial loss = 26419.28028811742
Final loss = 21479.98514570391
Deformation gradient control sequence optimization finished.
Animation interval 10 took 1238 seconds.
Full animation took 13724 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 11************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 22274.16562043194
initial norm = 790.6858163289513
convergence norm = 0.7906858163289513
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 22274.16562043194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22197.63182796412
gradient descent iteration = 1
gd loss = 22197.63182796412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22125.53044680479
gradient descent iteration = 2
gd loss = 22125.53044680479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22057.00042145481
gradient descent iteration = 3
gd loss = 22057.00042145481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21991.28796223063
gradient descent iteration = 4
gd loss = 21991.28796223063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21927.76679339782
gradient descent iteration = 5
gd loss = 21927.76679339782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21865.93861300195
gradient descent iteration = 6
gd loss = 21865.93861300195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21805.41912407488
gradient descent iteration = 7
gd loss = 21805.41912407488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21745.91697525595
gradient descent iteration = 8
gd loss = 21745.91697525595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21687.21212683303
gradient descent iteration = 9
gd loss = 21687.21212683303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21629.13709442927
gradient descent iteration = 10
gd loss = 21629.13709442927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21571.56227147887
gradient descent iteration = 11
gd loss = 21571.56227147887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21514.38528765674
gradient descent iteration = 12
gd loss = 21514.38528765674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21457.52376205358
gradient descent iteration = 13
gd loss = 21457.52376205358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21400.91113362736
gradient descent iteration = 14
gd loss = 21400.91113362736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21344.49537051234
gradient descent iteration = 15
gd loss = 21344.49537051234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21288.24001981855
gradient descent iteration = 16
gd loss = 21288.24001981855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21232.12647205427
gradient descent iteration = 17
gd loss = 21232.12647205427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21176.1543559085
gradient descent iteration = 18
gd loss = 21176.1543559085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21120.33928720327
gradient descent iteration = 19
gd loss = 21120.33928720327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21064.7062046298
gradient descent iteration = 20
gd loss = 21064.7062046298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21009.2784885494
gradient descent iteration = 21
gd loss = 21009.2784885494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20954.06924955075
gradient descent iteration = 22
gd loss = 20954.06924955075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20899.07881755413
gradient descent iteration = 23
gd loss = 20899.07881755413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20844.29777918587
gradient descent iteration = 24
gd loss = 20844.29777918587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20789.71150451383
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 20789.71150451383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20719.07144700932
gradient descent iteration = 1
gd loss = 20719.07144700932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20651.83914759178
gradient descent iteration = 2
gd loss = 20651.83914759178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20587.44187309779
gradient descent iteration = 3
gd loss = 20587.44187309779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20525.43437933711
gradient descent iteration = 4
gd loss = 20525.43437933711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20465.46681957971
gradient descent iteration = 5
gd loss = 20465.46681957971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20407.26131981369
gradient descent iteration = 6
gd loss = 20407.26131981369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20350.59522298559
gradient descent iteration = 7
gd loss = 20350.59522298559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20295.28833386034
gradient descent iteration = 8
gd loss = 20295.28833386034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20241.19367283429
gradient descent iteration = 9
gd loss = 20241.19367283429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20188.19033998183
gradient descent iteration = 10
gd loss = 20188.19033998183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20136.17782669171
gradient descent iteration = 11
gd loss = 20136.17782669171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20085.07133917884
gradient descent iteration = 12
gd loss = 20085.07133917884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20034.79861385424
gradient descent iteration = 13
gd loss = 20034.79861385424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19985.29766921989
gradient descent iteration = 14
gd loss = 19985.29766921989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19936.51511053024
gradient descent iteration = 15
gd loss = 19936.51511053024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19888.40436627821
gradient descent iteration = 16
gd loss = 19888.40436627821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19840.9240320826
gradient descent iteration = 17
gd loss = 19840.9240320826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19794.0369882259
gradient descent iteration = 18
gd loss = 19794.0369882259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19747.70945430246
gradient descent iteration = 19
gd loss = 19747.70945430246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19701.91070035643
gradient descent iteration = 20
gd loss = 19701.91070035643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19656.61320825313
gradient descent iteration = 21
gd loss = 19656.61320825313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19611.79243636152
gradient descent iteration = 22
gd loss = 19611.79243636152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19567.42709625731
gradient descent iteration = 23
gd loss = 19567.42709625731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19523.49914767488
gradient descent iteration = 24
gd loss = 19523.49914767488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19479.99317785193
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 19479.99317785193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19446.24878357795
gradient descent iteration = 1
gd loss = 19446.24878357795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19415.51763120236
gradient descent iteration = 2
gd loss = 19415.51763120236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19386.78384295501
gradient descent iteration = 3
gd loss = 19386.78384295501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19359.44557514998
gradient descent iteration = 4
gd loss = 19359.44557514998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19333.13942252543
gradient descent iteration = 5
gd loss = 19333.13942252543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19307.63997828359
gradient descent iteration = 6
gd loss = 19307.63997828359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19282.8024320927
gradient descent iteration = 7
gd loss = 19282.8024320927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19258.5297033233
gradient descent iteration = 8
gd loss = 19258.5297033233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19234.75353624556
gradient descent iteration = 9
gd loss = 19234.75353624556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19211.423545716
gradient descent iteration = 10
gd loss = 19211.423545716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19188.50079999044
gradient descent iteration = 11
gd loss = 19188.50079999044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19165.95399618462
gradient descent iteration = 12
gd loss = 19165.95399618462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19143.75712967871
gradient descent iteration = 13
gd loss = 19143.75712967871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19121.88804514746
gradient descent iteration = 14
gd loss = 19121.88804514746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19100.3274947992
gradient descent iteration = 15
gd loss = 19100.3274947992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19079.05850985109
gradient descent iteration = 16
gd loss = 19079.05850985109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19058.06596742132
gradient descent iteration = 17
gd loss = 19058.06596742132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19037.33628101221
gradient descent iteration = 18
gd loss = 19037.33628101221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19016.8571604877
gradient descent iteration = 19
gd loss = 19016.8571604877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18996.61742859771
gradient descent iteration = 20
gd loss = 18996.61742859771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18976.6068749851
gradient descent iteration = 21
gd loss = 18976.6068749851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18956.81613223443
gradient descent iteration = 22
gd loss = 18956.81613223443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18937.23657595682
gradient descent iteration = 23
gd loss = 18937.23657595682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18917.86023741486
gradient descent iteration = 24
gd loss = 18917.86023741486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18898.67973244402
Initial loss = 22274.16562043194
Final loss = 18898.67973244402
Deformation gradient control sequence optimization finished.
Animation interval 11 took 1242 seconds.
Full animation took 14966 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 12************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 19327.64927588335
initial norm = 790.0643541633782
convergence norm = 0.7900643541633782
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 19327.64927588335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19252.08977837439
gradient descent iteration = 1
gd loss = 19252.08977837439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19182.66475633009
gradient descent iteration = 2
gd loss = 19182.66475633009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19118.33866130795
gradient descent iteration = 3
gd loss = 19118.33866130795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19058.11521756406
gradient descent iteration = 4
gd loss = 19058.11521756406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19001.10161086201
gradient descent iteration = 5
gd loss = 19001.10161086201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18946.5524232653
gradient descent iteration = 6
gd loss = 18946.5524232653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18893.8835642175
gradient descent iteration = 7
gd loss = 18893.8835642175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18842.66020479961
gradient descent iteration = 8
gd loss = 18842.66020479961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18792.56973193253
gradient descent iteration = 9
gd loss = 18792.56973193253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18743.38878501314
gradient descent iteration = 10
gd loss = 18743.38878501314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18694.95431223435
gradient descent iteration = 11
gd loss = 18694.95431223435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18647.14255652212
gradient descent iteration = 12
gd loss = 18647.14255652212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18599.85601399157
gradient descent iteration = 13
gd loss = 18599.85601399157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18553.01642844209
gradient descent iteration = 14
gd loss = 18553.01642844209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18506.55975320949
gradient descent iteration = 15
gd loss = 18506.55975320949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18460.43590200162
gradient descent iteration = 16
gd loss = 18460.43590200162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18414.61660100415
gradient descent iteration = 17
gd loss = 18414.61660100415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18369.09356443798
gradient descent iteration = 18
gd loss = 18369.09356443798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18323.86933519857
gradient descent iteration = 19
gd loss = 18323.86933519857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18278.94983186568
gradient descent iteration = 20
gd loss = 18278.94983186568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18234.3383421562
gradient descent iteration = 21
gd loss = 18234.3383421562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18190.03337595394
gradient descent iteration = 22
gd loss = 18190.03337595394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18146.02387907884
gradient descent iteration = 23
gd loss = 18146.02387907884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18102.28875971195
gradient descent iteration = 24
gd loss = 18102.28875971195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18058.79937154675
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 18058.79937154675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18017.27953568144
gradient descent iteration = 1
gd loss = 18017.27953568144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17977.56781470769
gradient descent iteration = 2
gd loss = 17977.56781470769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17939.29251578448
gradient descent iteration = 3
gd loss = 17939.29251578448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17902.18839813131
gradient descent iteration = 4
gd loss = 17902.18839813131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17866.06237434646
gradient descent iteration = 5
gd loss = 17866.06237434646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17830.77127085326
gradient descent iteration = 6
gd loss = 17830.77127085326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17796.2076989431
gradient descent iteration = 7
gd loss = 17796.2076989431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17762.28918645348
gradient descent iteration = 8
gd loss = 17762.28918645348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17728.9505867534
gradient descent iteration = 9
gd loss = 17728.9505867534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17696.1392611091
gradient descent iteration = 10
gd loss = 17696.1392611091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17663.81218885267
gradient descent iteration = 11
gd loss = 17663.81218885267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17631.93379537504
gradient descent iteration = 12
gd loss = 17631.93379537504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17600.47411285948
gradient descent iteration = 13
gd loss = 17600.47411285948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17569.407532932
gradient descent iteration = 14
gd loss = 17569.407532932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17538.71216779019
gradient descent iteration = 15
gd loss = 17538.71216779019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17508.36962864206
gradient descent iteration = 16
gd loss = 17508.36962864206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17478.36399261317
gradient descent iteration = 17
gd loss = 17478.36399261317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17448.68153941346
gradient descent iteration = 18
gd loss = 17448.68153941346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17419.31078416446
gradient descent iteration = 19
gd loss = 17419.31078416446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17390.24194553474
gradient descent iteration = 20
gd loss = 17390.24194553474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17361.46690501973
gradient descent iteration = 21
gd loss = 17361.46690501973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17332.978815403
gradient descent iteration = 22
gd loss = 17332.978815403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17304.77218007636
gradient descent iteration = 23
gd loss = 17304.77218007636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17276.84269532226
gradient descent iteration = 24
gd loss = 17276.84269532226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17249.18700676068
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 17249.18700676068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17227.46871926097
gradient descent iteration = 1
gd loss = 17227.46871926097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17207.68252143998
gradient descent iteration = 2
gd loss = 17207.68252143998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17189.02338644989
gradient descent iteration = 3
gd loss = 17189.02338644989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17171.08955772176
gradient descent iteration = 4
gd loss = 17171.08955772176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17153.67295123161
gradient descent iteration = 5
gd loss = 17153.67295123161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17136.65967744096
gradient descent iteration = 6
gd loss = 17136.65967744096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17119.98268279242
gradient descent iteration = 7
gd loss = 17119.98268279242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17103.59902038037
gradient descent iteration = 8
gd loss = 17103.59902038037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17087.47877742525
gradient descent iteration = 9
gd loss = 17087.47877742525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17071.59953784711
gradient descent iteration = 10
gd loss = 17071.59953784711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17055.94352477715
gradient descent iteration = 11
gd loss = 17055.94352477715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17040.4960562488
gradient descent iteration = 12
gd loss = 17040.4960562488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17025.24466254718
gradient descent iteration = 13
gd loss = 17025.24466254718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17010.1785370585
gradient descent iteration = 14
gd loss = 17010.1785370585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16995.28817479547
gradient descent iteration = 15
gd loss = 16995.28817479547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16980.56512722455
gradient descent iteration = 16
gd loss = 16980.56512722455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16966.0018212287
gradient descent iteration = 17
gd loss = 16966.0018212287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16951.59141886078
gradient descent iteration = 18
gd loss = 16951.59141886078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16937.32770779104
gradient descent iteration = 19
gd loss = 16937.32770779104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16923.20501597521
gradient descent iteration = 20
gd loss = 16923.20501597521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16909.21814030114
gradient descent iteration = 21
gd loss = 16909.21814030114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16895.36228511551
gradient descent iteration = 22
gd loss = 16895.36228511551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16881.63301284777
gradient descent iteration = 23
gd loss = 16881.63301284777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16868.02620269162
gradient descent iteration = 24
gd loss = 16868.02620269162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16854.53802088165
Initial loss = 19327.64927588335
Final loss = 16854.53802088165
Deformation gradient control sequence optimization finished.
Animation interval 12 took 1238 seconds.
Full animation took 16205 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 13************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 17062.42738930627
initial norm = 806.6306363481227
convergence norm = 0.8066306363481227
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 17062.42738930627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16985.51077621503
gradient descent iteration = 1
gd loss = 16985.51077621503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16915.59531771185
gradient descent iteration = 2
gd loss = 16915.59531771185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16851.96552170132
gradient descent iteration = 3
gd loss = 16851.96552170132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16793.84860731071
gradient descent iteration = 4
gd loss = 16793.84860731071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16740.44069613381
gradient descent iteration = 5
gd loss = 16740.44069613381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16690.94372862191
gradient descent iteration = 6
gd loss = 16690.94372862191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16644.60864995092
gradient descent iteration = 7
gd loss = 16644.60864995092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16600.77704636235
gradient descent iteration = 8
gd loss = 16600.77704636235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16558.9077011222
gradient descent iteration = 9
gd loss = 16558.9077011222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16518.58030997545
gradient descent iteration = 10
gd loss = 16518.58030997545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16479.47472361671
gradient descent iteration = 11
gd loss = 16479.47472361671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16441.3416845664
gradient descent iteration = 12
gd loss = 16441.3416845664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16403.98583779902
gradient descent iteration = 13
gd loss = 16403.98583779902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16367.25701265057
gradient descent iteration = 14
gd loss = 16367.25701265057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16331.04315334913
gradient descent iteration = 15
gd loss = 16331.04315334913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16295.2629598545
gradient descent iteration = 16
gd loss = 16295.2629598545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16259.8593985574
gradient descent iteration = 17
gd loss = 16259.8593985574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16224.79039442162
gradient descent iteration = 18
gd loss = 16224.79039442162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16190.02408464246
gradient descent iteration = 19
gd loss = 16190.02408464246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16155.53982611639
gradient descent iteration = 20
gd loss = 16155.53982611639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16121.33417975968
gradient descent iteration = 21
gd loss = 16121.33417975968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16087.42050652735
gradient descent iteration = 22
gd loss = 16087.42050652735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16053.81501936096
gradient descent iteration = 23
gd loss = 16053.81501936096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16020.52062488699
gradient descent iteration = 24
gd loss = 16020.52062488699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15987.52286444543
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 15987.52286444543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15960.52278432557
gradient descent iteration = 1
gd loss = 15960.52278432557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15934.83653477488
gradient descent iteration = 2
gd loss = 15934.83653477488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15910.14353339447
gradient descent iteration = 3
gd loss = 15910.14353339447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15886.23275361696
gradient descent iteration = 4
gd loss = 15886.23275361696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15862.95915506188
gradient descent iteration = 5
gd loss = 15862.95915506188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15840.21894908953
gradient descent iteration = 6
gd loss = 15840.21894908953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15817.93512717673
gradient descent iteration = 7
gd loss = 15817.93512717673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15796.04896100767
gradient descent iteration = 8
gd loss = 15796.04896100767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15774.5147223123
gradient descent iteration = 9
gd loss = 15774.5147223123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15753.29580451857
gradient descent iteration = 10
gd loss = 15753.29580451857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15732.36241942396
gradient descent iteration = 11
gd loss = 15732.36241942396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15711.69036589398
gradient descent iteration = 12
gd loss = 15711.69036589398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15691.25970460422
gradient descent iteration = 13
gd loss = 15691.25970460422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15671.05381935686
gradient descent iteration = 14
gd loss = 15671.05381935686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15651.05866361931
gradient descent iteration = 15
gd loss = 15651.05866361931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15631.26209537923
gradient descent iteration = 16
gd loss = 15631.26209537923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15611.65349825481
gradient descent iteration = 17
gd loss = 15611.65349825481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15592.22361816515
gradient descent iteration = 18
gd loss = 15592.22361816515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15572.96473021139
gradient descent iteration = 19
gd loss = 15572.96473021139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15553.87027661588
gradient descent iteration = 20
gd loss = 15553.87027661588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15534.93444504551
gradient descent iteration = 21
gd loss = 15534.93444504551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15516.15230598499
gradient descent iteration = 22
gd loss = 15516.15230598499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15497.51966661251
gradient descent iteration = 23
gd loss = 15497.51966661251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15479.03264810751
gradient descent iteration = 24
gd loss = 15479.03264810751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15460.68752797884
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 15460.68752797884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15444.19058443538
gradient descent iteration = 1
gd loss = 15444.19058443538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15429.27284007915
gradient descent iteration = 2
gd loss = 15429.27284007915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15415.14770607389
gradient descent iteration = 3
gd loss = 15415.14770607389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15401.50848014954
gradient descent iteration = 4
gd loss = 15401.50848014954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15388.22197055737
gradient descent iteration = 5
gd loss = 15388.22197055737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15375.22104409253
gradient descent iteration = 6
gd loss = 15375.22104409253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15362.46595908729
gradient descent iteration = 7
gd loss = 15362.46595908729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15349.92977021214
gradient descent iteration = 8
gd loss = 15349.92977021214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15337.59238925768
gradient descent iteration = 9
gd loss = 15337.59238925768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15325.43790711639
gradient descent iteration = 10
gd loss = 15325.43790711639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15313.45323468384
gradient descent iteration = 11
gd loss = 15313.45323468384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15301.627314385
gradient descent iteration = 12
gd loss = 15301.627314385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15289.95062619898
gradient descent iteration = 13
gd loss = 15289.95062619898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15278.41485280267
gradient descent iteration = 14
gd loss = 15278.41485280267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15267.01264341021
gradient descent iteration = 15
gd loss = 15267.01264341021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15255.73743501682
gradient descent iteration = 16
gd loss = 15255.73743501682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15244.5833187495
gradient descent iteration = 17
gd loss = 15244.5833187495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15233.54493182901
gradient descent iteration = 18
gd loss = 15233.54493182901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15222.61737577455
gradient descent iteration = 19
gd loss = 15222.61737577455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15211.79615793561
gradient descent iteration = 20
gd loss = 15211.79615793561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15201.07713857871
gradient descent iteration = 21
gd loss = 15201.07713857871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15190.45647451549
gradient descent iteration = 22
gd loss = 15190.45647451549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15179.93058001737
gradient descent iteration = 23
gd loss = 15179.93058001737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15169.49609638635
gradient descent iteration = 24
gd loss = 15169.49609638635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15159.14986841062
Initial loss = 17062.42738930627
Final loss = 15159.14986841062
Deformation gradient control sequence optimization finished.
Animation interval 13 took 1237 seconds.
Full animation took 17443 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 14************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 15243.19559216103
initial norm = 613.1689206567702
convergence norm = 0.6131689206567702
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 15243.19559216103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15186.6650890715
gradient descent iteration = 1
gd loss = 15186.6650890715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15138.57497691986
gradient descent iteration = 2
gd loss = 15138.57497691986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15097.23257804949
gradient descent iteration = 3
gd loss = 15097.23257804949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15060.85747496291
gradient descent iteration = 4
gd loss = 15060.85747496291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15027.86058788083
gradient descent iteration = 5
gd loss = 15027.86058788083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14997.05322046496
gradient descent iteration = 6
gd loss = 14997.05322046496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14967.65986334655
gradient descent iteration = 7
gd loss = 14967.65986334655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14939.20970109753
gradient descent iteration = 8
gd loss = 14939.20970109753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14911.42324447783
gradient descent iteration = 9
gd loss = 14911.42324447783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14884.1335640612
gradient descent iteration = 10
gd loss = 14884.1335640612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14857.2374952774
gradient descent iteration = 11
gd loss = 14857.2374952774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14830.66927913446
gradient descent iteration = 12
gd loss = 14830.66927913446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14804.3858331445
gradient descent iteration = 13
gd loss = 14804.3858331445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14778.35816916749
gradient descent iteration = 14
gd loss = 14778.35816916749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14752.56424427934
gradient descent iteration = 15
gd loss = 14752.56424427934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14726.98541873637
gradient descent iteration = 16
gd loss = 14726.98541873637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14701.6047312305
gradient descent iteration = 17
gd loss = 14701.6047312305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14676.40657391602
gradient descent iteration = 18
gd loss = 14676.40657391602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14651.37654792221
gradient descent iteration = 19
gd loss = 14651.37654792221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14626.50099566013
gradient descent iteration = 20
gd loss = 14626.50099566013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14601.76663491206
gradient descent iteration = 21
gd loss = 14601.76663491206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14577.16104563313
gradient descent iteration = 22
gd loss = 14577.16104563313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14552.67292911647
gradient descent iteration = 23
gd loss = 14552.67292911647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14528.29280512417
gradient descent iteration = 24
gd loss = 14528.29280512417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14504.01148000756
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 14504.01148000756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14484.89984832095
gradient descent iteration = 1
gd loss = 14484.89984832095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14466.97030440402
gradient descent iteration = 2
gd loss = 14466.97030440402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14449.8084234902
gradient descent iteration = 3
gd loss = 14449.8084234902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14433.18419923803
gradient descent iteration = 4
gd loss = 14433.18419923803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14416.95855346042
gradient descent iteration = 5
gd loss = 14416.95855346042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14401.04190436394
gradient descent iteration = 6
gd loss = 14401.04190436394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14385.37345411102
gradient descent iteration = 7
gd loss = 14385.37345411102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14369.9101212425
gradient descent iteration = 8
gd loss = 14369.9101212425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14354.62023811574
gradient descent iteration = 9
gd loss = 14354.62023811574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14339.47976803048
gradient descent iteration = 10
gd loss = 14339.47976803048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14324.47001820854
gradient descent iteration = 11
gd loss = 14324.47001820854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14309.57602684816
gradient descent iteration = 12
gd loss = 14309.57602684816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14294.78548648994
gradient descent iteration = 13
gd loss = 14294.78548648994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14280.08810242432
gradient descent iteration = 14
gd loss = 14280.08810242432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14265.47513285494
gradient descent iteration = 15
gd loss = 14265.47513285494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14250.93898170836
gradient descent iteration = 16
gd loss = 14250.93898170836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14236.47310068509
gradient descent iteration = 17
gd loss = 14236.47310068509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14222.07214782085
gradient descent iteration = 18
gd loss = 14222.07214782085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14207.73189274593
gradient descent iteration = 19
gd loss = 14207.73189274593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14193.44911485564
gradient descent iteration = 20
gd loss = 14193.44911485564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14179.22137642852
gradient descent iteration = 21
gd loss = 14179.22137642852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14165.04692242359
gradient descent iteration = 22
gd loss = 14165.04692242359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14150.92466102342
gradient descent iteration = 23
gd loss = 14150.92466102342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14136.85403658669
gradient descent iteration = 24
gd loss = 14136.85403658669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14122.83506874103
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 14122.83506874103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14110.40158565413
gradient descent iteration = 1
gd loss = 14110.40158565413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14099.21378690648
gradient descent iteration = 2
gd loss = 14099.21378690648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14088.53821252705
gradient descent iteration = 3
gd loss = 14088.53821252705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14078.17345463052
gradient descent iteration = 4
gd loss = 14078.17345463052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14068.04133321046
gradient descent iteration = 5
gd loss = 14068.04133321046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14058.10008676203
gradient descent iteration = 6
gd loss = 14058.10008676203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14048.32258064277
gradient descent iteration = 7
gd loss = 14048.32258064277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14038.68926378847
gradient descent iteration = 8
gd loss = 14038.68926378847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14029.18517894597
gradient descent iteration = 9
gd loss = 14029.18517894597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14019.79839746404
gradient descent iteration = 10
gd loss = 14019.79839746404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14010.51912032828
gradient descent iteration = 11
gd loss = 14010.51912032828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14001.33911257003
gradient descent iteration = 12
gd loss = 14001.33911257003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13992.25132757674
gradient descent iteration = 13
gd loss = 13992.25132757674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13983.24964779712
gradient descent iteration = 14
gd loss = 13983.24964779712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13974.32870420773
gradient descent iteration = 15
gd loss = 13974.32870420773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13965.48375490445
gradient descent iteration = 16
gd loss = 13965.48375490445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13956.71056723138
gradient descent iteration = 17
gd loss = 13956.71056723138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13948.00533331932
gradient descent iteration = 18
gd loss = 13948.00533331932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13939.36460370863
gradient descent iteration = 19
gd loss = 13939.36460370863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13930.78523796418
gradient descent iteration = 20
gd loss = 13930.78523796418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13922.26436526436
gradient descent iteration = 21
gd loss = 13922.26436526436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13913.79934997321
gradient descent iteration = 22
gd loss = 13913.79934997321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13905.3877639033
gradient descent iteration = 23
gd loss = 13905.3877639033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13897.02736518582
gradient descent iteration = 24
gd loss = 13897.02736518582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13888.71608040442
Initial loss = 15243.19559216103
Final loss = 13888.71608040442
Deformation gradient control sequence optimization finished.
Animation interval 14 took 1243 seconds.
Full animation took 18686 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 15************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 13795.31917730545
initial norm = 412.1081469510337
convergence norm = 0.4121081469510337
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 13795.31917730545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13757.33794917215
gradient descent iteration = 1
gd loss = 13757.33794917215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13724.96390990907
gradient descent iteration = 2
gd loss = 13724.96390990907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13696.9751786115
gradient descent iteration = 3
gd loss = 13696.9751786115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13672.12384198102
gradient descent iteration = 4
gd loss = 13672.12384198102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13649.33250841936
gradient descent iteration = 5
gd loss = 13649.33250841936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13627.83124119201
gradient descent iteration = 6
gd loss = 13627.83124119201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13607.14522247024
gradient descent iteration = 7
gd loss = 13607.14522247024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13586.99827874656
gradient descent iteration = 8
gd loss = 13586.99827874656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13567.22546690757
gradient descent iteration = 9
gd loss = 13567.22546690757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13547.72212519572
gradient descent iteration = 10
gd loss = 13547.72212519572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13528.41765934124
gradient descent iteration = 11
gd loss = 13528.41765934124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13509.26226000408
gradient descent iteration = 12
gd loss = 13509.26226000408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13490.21950622583
gradient descent iteration = 13
gd loss = 13490.21950622583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13471.26163852258
gradient descent iteration = 14
gd loss = 13471.26163852258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13452.36737947462
gradient descent iteration = 15
gd loss = 13452.36737947462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13433.51990918436
gradient descent iteration = 16
gd loss = 13433.51990918436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13414.70597230441
gradient descent iteration = 17
gd loss = 13414.70597230441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13395.91486824803
gradient descent iteration = 18
gd loss = 13395.91486824803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13377.13708975109
gradient descent iteration = 19
gd loss = 13377.13708975109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13358.36381997092
gradient descent iteration = 20
gd loss = 13358.36381997092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13339.5874122073
gradient descent iteration = 21
gd loss = 13339.5874122073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13320.80162964278
gradient descent iteration = 22
gd loss = 13320.80162964278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13302.00166204621
gradient descent iteration = 23
gd loss = 13302.00166204621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13283.18339154566
gradient descent iteration = 24
gd loss = 13283.18339154566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13264.34370736881
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 13264.34370736881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13250.13531779639
gradient descent iteration = 1
gd loss = 13250.13531779639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13236.93792441748
gradient descent iteration = 2
gd loss = 13236.93792441748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13224.3168354626
gradient descent iteration = 3
gd loss = 13224.3168354626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13212.05903901855
gradient descent iteration = 4
gd loss = 13212.05903901855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13200.04534513958
gradient descent iteration = 5
gd loss = 13200.04534513958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13188.20313552617
gradient descent iteration = 6
gd loss = 13188.20313552617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13176.48509005301
gradient descent iteration = 7
gd loss = 13176.48509005301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13164.85870079931
gradient descent iteration = 8
gd loss = 13164.85870079931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13153.30064681497
gradient descent iteration = 9
gd loss = 13153.30064681497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13141.79340025549
gradient descent iteration = 10
gd loss = 13141.79340025549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13130.32342835831
gradient descent iteration = 11
gd loss = 13130.32342835831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13118.88054582623
gradient descent iteration = 12
gd loss = 13118.88054582623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13107.4567057006
gradient descent iteration = 13
gd loss = 13107.4567057006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13096.04528746119
gradient descent iteration = 14
gd loss = 13096.04528746119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13084.64071440699
gradient descent iteration = 15
gd loss = 13084.64071440699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13073.23817383004
gradient descent iteration = 16
gd loss = 13073.23817383004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13061.83350160596
gradient descent iteration = 17
gd loss = 13061.83350160596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13050.42319017009
gradient descent iteration = 18
gd loss = 13050.42319017009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13039.00436268808
gradient descent iteration = 19
gd loss = 13039.00436268808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13027.57474660089
gradient descent iteration = 20
gd loss = 13027.57474660089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13016.13273348226
gradient descent iteration = 21
gd loss = 13016.13273348226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13004.67717155544
gradient descent iteration = 22
gd loss = 13004.67717155544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12993.20708387603
gradient descent iteration = 23
gd loss = 12993.20708387603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12981.72132144783
gradient descent iteration = 24
gd loss = 12981.72132144783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12970.21814660747
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 12970.21814660747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12961.24142450151
gradient descent iteration = 1
gd loss = 12961.24142450151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12953.07232432194
gradient descent iteration = 2
gd loss = 12953.07232432194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12945.21148446034
gradient descent iteration = 3
gd loss = 12945.21148446034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12937.54798742377
gradient descent iteration = 4
gd loss = 12937.54798742377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12930.03439563241
gradient descent iteration = 5
gd loss = 12930.03439563241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12922.64330095169
gradient descent iteration = 6
gd loss = 12922.64330095169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12915.35654377219
gradient descent iteration = 7
gd loss = 12915.35654377219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12908.16109165725
gradient descent iteration = 8
gd loss = 12908.16109165725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12901.04708768727
gradient descent iteration = 9
gd loss = 12901.04708768727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12894.00679420706
gradient descent iteration = 10
gd loss = 12894.00679420706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12887.03396377333
gradient descent iteration = 11
gd loss = 12887.03396377333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12880.12344048136
gradient descent iteration = 12
gd loss = 12880.12344048136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12873.2708954582
gradient descent iteration = 13
gd loss = 12873.2708954582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12866.47262563699
gradient descent iteration = 14
gd loss = 12866.47262563699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12859.72541061674
gradient descent iteration = 15
gd loss = 12859.72541061674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12853.02640775143
gradient descent iteration = 16
gd loss = 12853.02640775143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12846.37307562425
gradient descent iteration = 17
gd loss = 12846.37307562425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12839.76311940282
gradient descent iteration = 18
gd loss = 12839.76311940282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12833.19448371768
gradient descent iteration = 19
gd loss = 12833.19448371768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12826.66536495569
gradient descent iteration = 20
gd loss = 12826.66536495569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12820.17413096744
gradient descent iteration = 21
gd loss = 12820.17413096744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12813.71928701956
gradient descent iteration = 22
gd loss = 12813.71928701956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12807.29945994197
gradient descent iteration = 23
gd loss = 12807.29945994197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12800.91339024901
gradient descent iteration = 24
gd loss = 12800.91339024901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12794.5599177976
Initial loss = 13795.31917730545
Final loss = 12794.5599177976
Deformation gradient control sequence optimization finished.
Animation interval 15 took 1246 seconds.
Full animation took 19932 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 16************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 12668.16481085744
initial norm = 498.6559075882751
convergence norm = 0.498655907588275
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 12668.16481085744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12622.53072540287
gradient descent iteration = 1
gd loss = 12622.53072540287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12584.44055342307
gradient descent iteration = 2
gd loss = 12584.44055342307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12552.692447583
gradient descent iteration = 3
gd loss = 12552.692447583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12526.08784818004
gradient descent iteration = 4
gd loss = 12526.08784818004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12503.4294142954
gradient descent iteration = 5
gd loss = 12503.4294142954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12483.55777185686
gradient descent iteration = 6
gd loss = 12483.55777185686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12465.47778863111
gradient descent iteration = 7
gd loss = 12465.47778863111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12448.47194788077
gradient descent iteration = 8
gd loss = 12448.47194788077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12432.08377486859
gradient descent iteration = 9
gd loss = 12432.08377486859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12416.03098139083
gradient descent iteration = 10
gd loss = 12416.03098139083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12400.13628392459
gradient descent iteration = 11
gd loss = 12400.13628392459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12384.28545373983
gradient descent iteration = 12
gd loss = 12384.28545373983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12368.40700211398
gradient descent iteration = 13
gd loss = 12368.40700211398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12352.46263924066
gradient descent iteration = 14
gd loss = 12352.46263924066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12336.4453274543
gradient descent iteration = 15
gd loss = 12336.4453274543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12320.37537198197
gradient descent iteration = 16
gd loss = 12320.37537198197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12304.2826074122
gradient descent iteration = 17
gd loss = 12304.2826074122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12288.18842967671
gradient descent iteration = 18
gd loss = 12288.18842967671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12272.10214995305
gradient descent iteration = 19
gd loss = 12272.10214995305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12256.03074842707
gradient descent iteration = 20
gd loss = 12256.03074842707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12240.00161528441
gradient descent iteration = 21
gd loss = 12240.00161528441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12224.06082394406
gradient descent iteration = 22
gd loss = 12224.06082394406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12208.24231269301
gradient descent iteration = 23
gd loss = 12208.24231269301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12192.5558912704
gradient descent iteration = 24
gd loss = 12192.5558912704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12176.99501782519
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 12176.99501782519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12166.2003191603
gradient descent iteration = 1
gd loss = 12166.2003191603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12156.38637716209
gradient descent iteration = 2
gd loss = 12156.38637716209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12147.09746066232
gradient descent iteration = 3
gd loss = 12147.09746066232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12138.12527644318
gradient descent iteration = 4
gd loss = 12138.12527644318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12129.36064265109
gradient descent iteration = 5
gd loss = 12129.36064265109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12120.74014493013
gradient descent iteration = 6
gd loss = 12120.74014493013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12112.2235536318
gradient descent iteration = 7
gd loss = 12112.2235536318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12103.78332187691
gradient descent iteration = 8
gd loss = 12103.78332187691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12095.39922833587
gradient descent iteration = 9
gd loss = 12095.39922833587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12087.05543099925
gradient descent iteration = 10
gd loss = 12087.05543099925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12078.73875854886
gradient descent iteration = 11
gd loss = 12078.73875854886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12070.4377125433
gradient descent iteration = 12
gd loss = 12070.4377125433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12062.14183601534
gradient descent iteration = 13
gd loss = 12062.14183601534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12053.84157297623
gradient descent iteration = 14
gd loss = 12053.84157297623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12045.5286371384
gradient descent iteration = 15
gd loss = 12045.5286371384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12037.19688566525
gradient descent iteration = 16
gd loss = 12037.19688566525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12028.84234503311
gradient descent iteration = 17
gd loss = 12028.84234503311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12020.46299027844
gradient descent iteration = 18
gd loss = 12020.46299027844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12012.05853841223
gradient descent iteration = 19
gd loss = 12012.05853841223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12003.6305529179
gradient descent iteration = 20
gd loss = 12003.6305529179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11995.18191960636
gradient descent iteration = 21
gd loss = 11995.18191960636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11986.71641842718
gradient descent iteration = 22
gd loss = 11986.71641842718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11978.23869534786
gradient descent iteration = 23
gd loss = 11978.23869534786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11969.754295609
gradient descent iteration = 24
gd loss = 11969.754295609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11961.26937455709
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 11961.26937455709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11955.28386755295
gradient descent iteration = 1
gd loss = 11955.28386755295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11949.87659167089
gradient descent iteration = 2
gd loss = 11949.87659167089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11944.63792932708
gradient descent iteration = 3
gd loss = 11944.63792932708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11939.50621419501
gradient descent iteration = 4
gd loss = 11939.50621419501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11934.45865732212
gradient descent iteration = 5
gd loss = 11934.45865732212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11929.48297324323
gradient descent iteration = 6
gd loss = 11929.48297324323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11924.57107247296
gradient descent iteration = 7
gd loss = 11924.57107247296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11919.71697896983
gradient descent iteration = 8
gd loss = 11919.71697896983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11914.91597470818
gradient descent iteration = 9
gd loss = 11914.91597470818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11910.16417875791
gradient descent iteration = 10
gd loss = 11910.16417875791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11905.45831642864
gradient descent iteration = 11
gd loss = 11905.45831642864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11900.79558358627
gradient descent iteration = 12
gd loss = 11900.79558358627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11896.17353647306
gradient descent iteration = 13
gd loss = 11896.17353647306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11891.59000664233
gradient descent iteration = 14
gd loss = 11891.59000664233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11887.04305503324
gradient descent iteration = 15
gd loss = 11887.04305503324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11882.53093445883
gradient descent iteration = 16
gd loss = 11882.53093445883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11878.0520603991
gradient descent iteration = 17
gd loss = 11878.0520603991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11873.60499188331
gradient descent iteration = 18
gd loss = 11873.60499188331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11869.18841554726
gradient descent iteration = 19
gd loss = 11869.18841554726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11864.80111409723
gradient descent iteration = 20
gd loss = 11864.80111409723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11860.44195211425
gradient descent iteration = 21
gd loss = 11860.44195211425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11856.10986521466
gradient descent iteration = 22
gd loss = 11856.10986521466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11851.80385795263
gradient descent iteration = 23
gd loss = 11851.80385795263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11847.52303357414
gradient descent iteration = 24
gd loss = 11847.52303357414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11843.26658921867
Initial loss = 12668.16481085744
Final loss = 11843.26658921867
Deformation gradient control sequence optimization finished.
Animation interval 16 took 1236 seconds.
Full animation took 21169 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 17************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 11722.30598348486
initial norm = 581.4153328902134
convergence norm = 0.5814153328902134
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 11722.30598348486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11668.3464258135
gradient descent iteration = 1
gd loss = 11668.3464258135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11622.31426798779
gradient descent iteration = 2
gd loss = 11622.31426798779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11583.57506237974
gradient descent iteration = 3
gd loss = 11583.57506237974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11551.33640608599
gradient descent iteration = 4
gd loss = 11551.33640608599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11524.63376616051
gradient descent iteration = 5
gd loss = 11524.63376616051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11502.37498718084
gradient descent iteration = 6
gd loss = 11502.37498718084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11483.46621790077
gradient descent iteration = 7
gd loss = 11483.46621790077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11466.96592806438
gradient descent iteration = 8
gd loss = 11466.96592806438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11452.14354467234
gradient descent iteration = 9
gd loss = 11452.14354467234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11438.44378756863
gradient descent iteration = 10
gd loss = 11438.44378756863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11425.45197796048
gradient descent iteration = 11
gd loss = 11425.45197796048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11412.87892457715
gradient descent iteration = 12
gd loss = 11412.87892457715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11400.5394565132
gradient descent iteration = 13
gd loss = 11400.5394565132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11388.32184163327
gradient descent iteration = 14
gd loss = 11388.32184163327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11376.16006273965
gradient descent iteration = 15
gd loss = 11376.16006273965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11364.01558602966
gradient descent iteration = 16
gd loss = 11364.01558602966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11351.86479841616
gradient descent iteration = 17
gd loss = 11351.86479841616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11339.68918501508
gradient descent iteration = 18
gd loss = 11339.68918501508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11327.47068161118
gradient descent iteration = 19
gd loss = 11327.47068161118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11315.18967548928
gradient descent iteration = 20
gd loss = 11315.18967548928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11302.83262502056
gradient descent iteration = 21
gd loss = 11302.83262502056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11290.41093885301
gradient descent iteration = 22
gd loss = 11290.41093885301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11277.95973216193
gradient descent iteration = 23
gd loss = 11277.95973216193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11265.51002374767
gradient descent iteration = 24
gd loss = 11265.51002374767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11253.05499874359
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 11253.05499874359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11243.83761581083
gradient descent iteration = 1
gd loss = 11243.83761581083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11235.80961183354
gradient descent iteration = 2
gd loss = 11235.80961183354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11228.31717936291
gradient descent iteration = 3
gd loss = 11228.31717936291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11221.11962445185
gradient descent iteration = 4
gd loss = 11221.11962445185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11214.10411894185
gradient descent iteration = 5
gd loss = 11214.10411894185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11207.20929775293
gradient descent iteration = 6
gd loss = 11207.20929775293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11200.39907063157
gradient descent iteration = 7
gd loss = 11200.39907063157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11193.65294242486
gradient descent iteration = 8
gd loss = 11193.65294242486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11186.95980431153
gradient descent iteration = 9
gd loss = 11186.95980431153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11180.31416624203
gradient descent iteration = 10
gd loss = 11180.31416624203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11173.71355551262
gradient descent iteration = 11
gd loss = 11173.71355551262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11167.15622127142
gradient descent iteration = 12
gd loss = 11167.15622127142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11160.63956833063
gradient descent iteration = 13
gd loss = 11160.63956833063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11154.15953795511
gradient descent iteration = 14
gd loss = 11154.15953795511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11147.71124729508
gradient descent iteration = 15
gd loss = 11147.71124729508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11141.2889791669
gradient descent iteration = 16
gd loss = 11141.2889791669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11134.88562965674
gradient descent iteration = 17
gd loss = 11134.88562965674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11128.49270480687
gradient descent iteration = 18
gd loss = 11128.49270480687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11122.10123328009
gradient descent iteration = 19
gd loss = 11122.10123328009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11115.70235028303
gradient descent iteration = 20
gd loss = 11115.70235028303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11109.28641070307
gradient descent iteration = 21
gd loss = 11109.28641070307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11102.84362711683
gradient descent iteration = 22
gd loss = 11102.84362711683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11096.36524348439
gradient descent iteration = 23
gd loss = 11096.36524348439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11089.84322387893
gradient descent iteration = 24
gd loss = 11089.84322387893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11083.27145144697
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 11083.27145144697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11078.68414002256
gradient descent iteration = 1
gd loss = 11078.68414002256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11074.62869341395
gradient descent iteration = 2
gd loss = 11074.62869341395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11070.690453622
gradient descent iteration = 3
gd loss = 11070.690453622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11066.83213484121
gradient descent iteration = 4
gd loss = 11066.83213484121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11063.03960185584
gradient descent iteration = 5
gd loss = 11063.03960185584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11059.30436657901
gradient descent iteration = 6
gd loss = 11059.30436657901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11055.62036177326
gradient descent iteration = 7
gd loss = 11055.62036177326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11051.98288934824
gradient descent iteration = 8
gd loss = 11051.98288934824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11048.38814221613
gradient descent iteration = 9
gd loss = 11048.38814221613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11044.8329441381
gradient descent iteration = 10
gd loss = 11044.8329441381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11041.31459695128
gradient descent iteration = 11
gd loss = 11041.31459695128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11037.83077508098
gradient descent iteration = 12
gd loss = 11037.83077508098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11034.37944149826
gradient descent iteration = 13
gd loss = 11034.37944149826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11030.95879444275
gradient descent iteration = 14
gd loss = 11030.95879444275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11027.56722691431
gradient descent iteration = 15
gd loss = 11027.56722691431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11024.20328839555
gradient descent iteration = 16
gd loss = 11024.20328839555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11020.86565967206
gradient descent iteration = 17
gd loss = 11020.86565967206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11017.55313315511
gradient descent iteration = 18
gd loss = 11017.55313315511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11014.26459667272
gradient descent iteration = 19
gd loss = 11014.26459667272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11010.9990205894
gradient descent iteration = 20
gd loss = 11010.9990205894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11007.75544720049
gradient descent iteration = 21
gd loss = 11007.75544720049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11004.53298225857
gradient descent iteration = 22
gd loss = 11004.53298225857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11001.3307873316
gradient descent iteration = 23
gd loss = 11001.3307873316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10998.14807410095
gradient descent iteration = 24
gd loss = 10998.14807410095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10994.98411070698
Initial loss = 11722.30598348486
Final loss = 10994.98411070698
Deformation gradient control sequence optimization finished.
Animation interval 17 took 1247 seconds.
Full animation took 22416 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 18************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 10798.46481134651
initial norm = 620.6647995109124
convergence norm = 0.6206647995109125
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 10798.46481134651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10741.74554702115
gradient descent iteration = 1
gd loss = 10741.74554702115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10695.11035315983
gradient descent iteration = 2
gd loss = 10695.11035315983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10657.64555816511
gradient descent iteration = 3
gd loss = 10657.64555816511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10628.20300518553
gradient descent iteration = 4
gd loss = 10628.20300518553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10605.32557651177
gradient descent iteration = 5
gd loss = 10605.32557651177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10587.27108250881
gradient descent iteration = 6
gd loss = 10587.27108250881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10572.31984208968
gradient descent iteration = 7
gd loss = 10572.31984208968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10559.22935308445
gradient descent iteration = 8
gd loss = 10559.22935308445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10547.28600360147
gradient descent iteration = 9
gd loss = 10547.28600360147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10536.08750359773
gradient descent iteration = 10
gd loss = 10536.08750359773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10525.3983949965
gradient descent iteration = 11
gd loss = 10525.3983949965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10515.07613404401
gradient descent iteration = 12
gd loss = 10515.07613404401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10505.02901420398
gradient descent iteration = 13
gd loss = 10505.02901420398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10495.19325876607
gradient descent iteration = 14
gd loss = 10495.19325876607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10485.52137442381
gradient descent iteration = 15
gd loss = 10485.52137442381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10475.97649914612
gradient descent iteration = 16
gd loss = 10475.97649914612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10466.52978672365
gradient descent iteration = 17
gd loss = 10466.52978672365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10457.15863542476
gradient descent iteration = 18
gd loss = 10457.15863542476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10447.84535017841
gradient descent iteration = 19
gd loss = 10447.84535017841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10438.57619832181
gradient descent iteration = 20
gd loss = 10438.57619832181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10429.34096655566
gradient descent iteration = 21
gd loss = 10429.34096655566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10420.13501053671
gradient descent iteration = 22
gd loss = 10420.13501053671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10410.9591612403
gradient descent iteration = 23
gd loss = 10410.9591612403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10401.81725023122
gradient descent iteration = 24
gd loss = 10401.81725023122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10392.71444260678
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 10392.71444260678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10384.10259025263
gradient descent iteration = 1
gd loss = 10384.10259025263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10377.10145205057
gradient descent iteration = 2
gd loss = 10377.10145205057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10370.72975540891
gradient descent iteration = 3
gd loss = 10370.72975540891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10364.71987045706
gradient descent iteration = 4
gd loss = 10364.71987045706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10358.95455664724
gradient descent iteration = 5
gd loss = 10358.95455664724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10353.3703829168
gradient descent iteration = 6
gd loss = 10353.3703829168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10347.92829877116
gradient descent iteration = 7
gd loss = 10347.92829877116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10342.60192853581
gradient descent iteration = 8
gd loss = 10342.60192853581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10337.37221110751
gradient descent iteration = 9
gd loss = 10337.37221110751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10332.22466184895
gradient descent iteration = 10
gd loss = 10332.22466184895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10327.14781981318
gradient descent iteration = 11
gd loss = 10327.14781981318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10322.13230732751
gradient descent iteration = 12
gd loss = 10322.13230732751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10317.17021923346
gradient descent iteration = 13
gd loss = 10317.17021923346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10312.25471237908
gradient descent iteration = 14
gd loss = 10312.25471237908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10307.37971948417
gradient descent iteration = 15
gd loss = 10307.37971948417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10302.53976012709
gradient descent iteration = 16
gd loss = 10302.53976012709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10297.72986267511
gradient descent iteration = 17
gd loss = 10297.72986267511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10292.94546183806
gradient descent iteration = 18
gd loss = 10292.94546183806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10288.18237731927
gradient descent iteration = 19
gd loss = 10288.18237731927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10283.43672348856
gradient descent iteration = 20
gd loss = 10283.43672348856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10278.70488583634
gradient descent iteration = 21
gd loss = 10278.70488583634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10273.98355524908
gradient descent iteration = 22
gd loss = 10273.98355524908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10269.27040240055
gradient descent iteration = 23
gd loss = 10269.27040240055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10264.56404495508
gradient descent iteration = 24
gd loss = 10264.56404495508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10259.86339637917
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 10259.86339637917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10255.64650963431
gradient descent iteration = 1
gd loss = 10255.64650963431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10251.96179557555
gradient descent iteration = 2
gd loss = 10251.96179557555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10248.42843871839
gradient descent iteration = 3
gd loss = 10248.42843871839
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10244.99512587602
gradient descent iteration = 4
gd loss = 10244.99512587602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10241.639974229
gradient descent iteration = 5
gd loss = 10241.639974229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10238.3497590922
gradient descent iteration = 6
gd loss = 10238.3497590922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10235.11539910603
gradient descent iteration = 7
gd loss = 10235.11539910603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10231.93022332523
gradient descent iteration = 8
gd loss = 10231.93022332523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10228.78911723502
gradient descent iteration = 9
gd loss = 10228.78911723502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10225.68802586125
gradient descent iteration = 10
gd loss = 10225.68802586125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10222.62364901947
gradient descent iteration = 11
gd loss = 10222.62364901947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10219.59324672348
gradient descent iteration = 12
gd loss = 10219.59324672348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10216.59450893971
gradient descent iteration = 13
gd loss = 10216.59450893971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10213.62546008437
gradient descent iteration = 14
gd loss = 10213.62546008437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10210.68439096133
gradient descent iteration = 15
gd loss = 10210.68439096133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10207.76980804514
gradient descent iteration = 16
gd loss = 10207.76980804514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10204.88039485325
gradient descent iteration = 17
gd loss = 10204.88039485325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10202.01498197041
gradient descent iteration = 18
gd loss = 10202.01498197041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10199.17252377361
gradient descent iteration = 19
gd loss = 10199.17252377361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10196.35207804289
gradient descent iteration = 20
gd loss = 10196.35207804289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10193.55279032393
gradient descent iteration = 21
gd loss = 10193.55279032393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10190.77388078816
gradient descent iteration = 22
gd loss = 10190.77388078816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10188.01463317365
gradient descent iteration = 23
gd loss = 10188.01463317365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10185.27438552727
gradient descent iteration = 24
gd loss = 10185.27438552727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10182.55252297507
Initial loss = 10798.46481134651
Final loss = 10182.55252297507
Deformation gradient control sequence optimization finished.
Animation interval 18 took 1251 seconds.
Full animation took 23667 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 19************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 10077.36012279345
initial norm = 765.1058815789277
convergence norm = 0.7651058815789277
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 10077.36012279345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10006.24757912133
gradient descent iteration = 1
gd loss = 10006.24757912133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9945.545857528916
gradient descent iteration = 2
gd loss = 9945.545857528916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9894.691998748514
gradient descent iteration = 3
gd loss = 9894.691998748514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9852.973682799511
gradient descent iteration = 4
gd loss = 9852.973682799511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9819.48742693285
gradient descent iteration = 5
gd loss = 9819.48742693285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9793.099626217765
gradient descent iteration = 6
gd loss = 9793.099626217765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9772.449806143646
gradient descent iteration = 7
gd loss = 9772.449806143646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9756.070976467976
gradient descent iteration = 8
gd loss = 9756.070976467976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9742.634652025647
gradient descent iteration = 9
gd loss = 9742.634652025647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9731.143915823581
gradient descent iteration = 10
gd loss = 9731.143915823581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9720.934582147815
gradient descent iteration = 11
gd loss = 9720.934582147815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9711.586717552689
gradient descent iteration = 12
gd loss = 9711.586717552689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9702.839758270375
gradient descent iteration = 13
gd loss = 9702.839758270375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9694.529870224538
gradient descent iteration = 14
gd loss = 9694.529870224538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9686.549844645646
gradient descent iteration = 15
gd loss = 9686.549844645646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9678.825780331506
gradient descent iteration = 16
gd loss = 9678.825780331506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9671.304498200405
gradient descent iteration = 17
gd loss = 9671.304498200405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9663.946510779631
gradient descent iteration = 18
gd loss = 9663.946510779631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9656.721669435585
gradient descent iteration = 19
gd loss = 9656.721669435585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9649.606211308705
gradient descent iteration = 20
gd loss = 9649.606211308705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9642.581281224795
gradient descent iteration = 21
gd loss = 9642.581281224795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9635.634341492847
gradient descent iteration = 22
gd loss = 9635.634341492847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9628.774574709872
gradient descent iteration = 23
gd loss = 9628.774574709872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9622.106982542469
gradient descent iteration = 24
gd loss = 9622.106982542469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9616.072798390298
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 9616.072798390298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9608.233798900237
gradient descent iteration = 1
gd loss = 9608.233798900237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9602.204929285341
gradient descent iteration = 2
gd loss = 9602.204929285341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9596.937335883167
gradient descent iteration = 3
gd loss = 9596.937335883167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9592.18643718724
gradient descent iteration = 4
gd loss = 9592.18643718724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9587.932638497841
gradient descent iteration = 5
gd loss = 9587.932638497841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9584.168721909538
gradient descent iteration = 6
gd loss = 9584.168721909538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9581.082282917179
gradient descent iteration = 7
gd loss = 9581.082282917179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9578.709411273769
gradient descent iteration = 8
gd loss = 9578.709411273769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9577.553698044027
gradient descent iteration = 9
gd loss = 9577.553698044027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9577.549998000974
gradient descent iteration = 10
gd loss = 9577.549998000974
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 9560.655895335545
gradient descent iteration = 11
gd loss = 9560.655895335545
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9558.381931568118
gradient descent iteration = 12
gd loss = 9558.381931568118
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9556.283385928706
gradient descent iteration = 13
gd loss = 9556.283385928706
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9554.204167675513
gradient descent iteration = 14
gd loss = 9554.204167675513
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9552.14180991401
gradient descent iteration = 15
gd loss = 9552.14180991401
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9550.095503821451
gradient descent iteration = 16
gd loss = 9550.095503821451
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9548.064521901455
gradient descent iteration = 17
gd loss = 9548.064521901455
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9546.048192100914
gradient descent iteration = 18
gd loss = 9546.048192100914
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9544.045891987998
gradient descent iteration = 19
gd loss = 9544.045891987998
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9542.057044679699
gradient descent iteration = 20
gd loss = 9542.057044679699
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9540.081116915218
gradient descent iteration = 21
gd loss = 9540.081116915218
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9538.117615211797
gradient descent iteration = 22
gd loss = 9538.117615211797
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9536.166081460115
gradient descent iteration = 23
gd loss = 9536.166081460115
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9534.226089758205
gradient descent iteration = 24
gd loss = 9534.226089758205
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 9532.29724322798
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 9532.29724322798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9528.200985033558
gradient descent iteration = 1
gd loss = 9528.200985033558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9524.575242027138
gradient descent iteration = 2
gd loss = 9524.575242027138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9521.154192307589
gradient descent iteration = 3
gd loss = 9521.154192307589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9517.86511103068
gradient descent iteration = 4
gd loss = 9517.86511103068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9514.672930991956
gradient descent iteration = 5
gd loss = 9514.672930991956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9511.557605757302
gradient descent iteration = 6
gd loss = 9511.557605757302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9508.506637656428
gradient descent iteration = 7
gd loss = 9508.506637656428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9505.511377493227
gradient descent iteration = 8
gd loss = 9505.511377493227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9502.565618831561
gradient descent iteration = 9
gd loss = 9502.565618831561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9499.66453685273
gradient descent iteration = 10
gd loss = 9499.66453685273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9496.804382807662
gradient descent iteration = 11
gd loss = 9496.804382807662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9493.982035303234
gradient descent iteration = 12
gd loss = 9493.982035303234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9491.19495121957
gradient descent iteration = 13
gd loss = 9491.19495121957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9488.44091639838
gradient descent iteration = 14
gd loss = 9488.44091639838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9485.718065895306
gradient descent iteration = 15
gd loss = 9485.718065895306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9483.024721984164
gradient descent iteration = 16
gd loss = 9483.024721984164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9480.359435117603
gradient descent iteration = 17
gd loss = 9480.359435117603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9477.720870918178
gradient descent iteration = 18
gd loss = 9477.720870918178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9475.107849055597
gradient descent iteration = 19
gd loss = 9475.107849055597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9472.519258444348
gradient descent iteration = 20
gd loss = 9472.519258444348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9469.954096577838
gradient descent iteration = 21
gd loss = 9469.954096577838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9467.411405376068
gradient descent iteration = 22
gd loss = 9467.411405376068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9464.89030602853
gradient descent iteration = 23
gd loss = 9464.89030602853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9462.389949564542
gradient descent iteration = 24
gd loss = 9462.389949564542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9459.909547457293
Initial loss = 10077.36012279345
Final loss = 9459.909547457293
Deformation gradient control sequence optimization finished.
Animation interval 19 took 1180 seconds.
Full animation took 24847 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 20************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9302.46730129207
initial norm = 604.2629041026721
convergence norm = 0.6042629041026721
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9302.46730129207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9247.361299637041
gradient descent iteration = 1
gd loss = 9247.361299637041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9202.157809943203
gradient descent iteration = 2
gd loss = 9202.157809943203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9165.765846594448
gradient descent iteration = 3
gd loss = 9165.765846594448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9136.936649952992
gradient descent iteration = 4
gd loss = 9136.936649952992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9114.300898429423
gradient descent iteration = 5
gd loss = 9114.300898429423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9096.435239545772
gradient descent iteration = 6
gd loss = 9096.435239545772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9081.967038149065
gradient descent iteration = 7
gd loss = 9081.967038149065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9069.75319236197
gradient descent iteration = 8
gd loss = 9069.75319236197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9059.036317805783
gradient descent iteration = 9
gd loss = 9059.036317805783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9049.389115937209
gradient descent iteration = 10
gd loss = 9049.389115937209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9040.553256131348
gradient descent iteration = 11
gd loss = 9040.553256131348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9032.343846885737
gradient descent iteration = 12
gd loss = 9032.343846885737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9024.618845235285
gradient descent iteration = 13
gd loss = 9024.618845235285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9017.269462851429
gradient descent iteration = 14
gd loss = 9017.269462851429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9010.214053518745
gradient descent iteration = 15
gd loss = 9010.214053518745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9003.3923483245
gradient descent iteration = 16
gd loss = 9003.3923483245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8996.760484514845
gradient descent iteration = 17
gd loss = 8996.760484514845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8990.288499893599
gradient descent iteration = 18
gd loss = 8990.288499893599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8983.970776431956
gradient descent iteration = 19
gd loss = 8983.970776431956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8977.911014474528
gradient descent iteration = 20
gd loss = 8977.911014474528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8972.770978932072
gradient descent iteration = 21
gd loss = 8972.770978932072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8969.694146172455
gradient descent iteration = 22
gd loss = 8969.694146172455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8966.382889956354
gradient descent iteration = 23
gd loss = 8966.382889956354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8963.259616837657
gradient descent iteration = 24
gd loss = 8963.259616837657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8960.075913753311
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8960.075913753311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8954.013457646888
gradient descent iteration = 1
gd loss = 8954.013457646888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8949.855153773269
gradient descent iteration = 2
gd loss = 8949.855153773269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8946.329686140791
gradient descent iteration = 3
gd loss = 8946.329686140791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8943.102300748173
gradient descent iteration = 4
gd loss = 8943.102300748173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8940.057483306829
gradient descent iteration = 5
gd loss = 8940.057483306829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8937.142745937323
gradient descent iteration = 6
gd loss = 8937.142745937323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8934.328637906445
gradient descent iteration = 7
gd loss = 8934.328637906445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8931.596176053863
gradient descent iteration = 8
gd loss = 8931.596176053863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8928.932073103366
gradient descent iteration = 9
gd loss = 8928.932073103366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8926.326523426967
gradient descent iteration = 10
gd loss = 8926.326523426967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8923.772016059464
gradient descent iteration = 11
gd loss = 8923.772016059464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8921.262630428797
gradient descent iteration = 12
gd loss = 8921.262630428797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8918.793591868091
gradient descent iteration = 13
gd loss = 8918.793591868091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8916.360975568867
gradient descent iteration = 14
gd loss = 8916.360975568867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8913.961501961039
gradient descent iteration = 15
gd loss = 8913.961501961039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8911.59239109581
gradient descent iteration = 16
gd loss = 8911.59239109581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8909.251256769827
gradient descent iteration = 17
gd loss = 8909.251256769827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8906.936027773632
gradient descent iteration = 18
gd loss = 8906.936027773632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8904.64488833535
gradient descent iteration = 19
gd loss = 8904.64488833535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8902.37623270917
gradient descent iteration = 20
gd loss = 8902.37623270917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8900.128632479289
gradient descent iteration = 21
gd loss = 8900.128632479289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8897.900812203645
gradient descent iteration = 22
gd loss = 8897.900812203645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8895.691624906563
gradient descent iteration = 23
gd loss = 8895.691624906563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8893.500033610464
gradient descent iteration = 24
gd loss = 8893.500033610464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8891.325094201708
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8891.325094201708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8888.790461778541
gradient descent iteration = 1
gd loss = 8888.790461778541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8886.611497820195
gradient descent iteration = 2
gd loss = 8886.611497820195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8884.540755111715
gradient descent iteration = 3
gd loss = 8884.540755111715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8882.546612504724
gradient descent iteration = 4
gd loss = 8882.546612504724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8880.611910782995
gradient descent iteration = 5
gd loss = 8880.611910782995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8878.725424921677
gradient descent iteration = 6
gd loss = 8878.725424921677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8876.87936640591
gradient descent iteration = 7
gd loss = 8876.87936640591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8875.068100440079
gradient descent iteration = 8
gd loss = 8875.068100440079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8873.287402409665
gradient descent iteration = 9
gd loss = 8873.287402409665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8871.534005249332
gradient descent iteration = 10
gd loss = 8871.534005249332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8869.805314109091
gradient descent iteration = 11
gd loss = 8869.805314109091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8868.099220768265
gradient descent iteration = 12
gd loss = 8868.099220768265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8866.413979301347
gradient descent iteration = 13
gd loss = 8866.413979301347
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8864.748120363314
gradient descent iteration = 14
gd loss = 8864.748120363314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8863.10039036315
gradient descent iteration = 15
gd loss = 8863.10039036315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8861.469707529572
gradient descent iteration = 16
gd loss = 8861.469707529572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8859.855129689697
gradient descent iteration = 17
gd loss = 8859.855129689697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8858.25582844495
gradient descent iteration = 18
gd loss = 8858.25582844495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8856.6710694014
gradient descent iteration = 19
gd loss = 8856.6710694014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8855.100196844329
gradient descent iteration = 20
gd loss = 8855.100196844329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8853.542621536099
gradient descent iteration = 21
gd loss = 8853.542621536099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8851.997810831044
gradient descent iteration = 22
gd loss = 8851.997810831044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8850.465280616894
gradient descent iteration = 23
gd loss = 8850.465280616894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8848.944588668301
gradient descent iteration = 24
gd loss = 8848.944588668301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8847.435329054839
Initial loss = 9302.46730129207
Final loss = 8847.435329054839
Deformation gradient control sequence optimization finished.
Animation interval 20 took 1156 seconds.
Full animation took 26003 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 21************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8755.764802902202
initial norm = 618.9360059593637
convergence norm = 0.6189360059593637
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8755.764802902202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8699.748241977137
gradient descent iteration = 1
gd loss = 8699.748241977137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8654.589638336251
gradient descent iteration = 2
gd loss = 8654.589638336251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8618.846915060794
gradient descent iteration = 3
gd loss = 8618.846915060794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8590.778329895467
gradient descent iteration = 4
gd loss = 8590.778329895467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8568.555348307491
gradient descent iteration = 5
gd loss = 8568.555348307491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8550.594623199431
gradient descent iteration = 6
gd loss = 8550.594623199431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8535.702565965034
gradient descent iteration = 7
gd loss = 8535.702565965034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8523.008791291015
gradient descent iteration = 8
gd loss = 8523.008791291015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8511.911957382421
gradient descent iteration = 9
gd loss = 8511.911957382421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8502.010237163615
gradient descent iteration = 10
gd loss = 8502.010237163615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8493.017362611676
gradient descent iteration = 11
gd loss = 8493.017362611676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8484.716069268516
gradient descent iteration = 12
gd loss = 8484.716069268516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8476.940449666525
gradient descent iteration = 13
gd loss = 8476.940449666525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8469.566528800055
gradient descent iteration = 14
gd loss = 8469.566528800055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8462.503738875595
gradient descent iteration = 15
gd loss = 8462.503738875595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8455.686798614452
gradient descent iteration = 16
gd loss = 8455.686798614452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8449.068984283083
gradient descent iteration = 17
gd loss = 8449.068984283083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8442.618340821638
gradient descent iteration = 18
gd loss = 8442.618340821638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8436.327066383845
gradient descent iteration = 19
gd loss = 8436.327066383845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8430.360369608092
gradient descent iteration = 20
gd loss = 8430.360369608092
line search decrease found at ls_iter = 2, alpha = 0.025, loss = 8430.291521727126
gradient descent iteration = 21
gd loss = 8430.291521727126
line search decrease found at ls_iter = 0, alpha = 0.025, loss = 8428.741079521325
gradient descent iteration = 22
gd loss = 8428.741079521325
line search decrease found at ls_iter = 0, alpha = 0.025, loss = 8427.213935104812
gradient descent iteration = 23
gd loss = 8427.213935104812
line search decrease found at ls_iter = 0, alpha = 0.025, loss = 8425.692847283994
gradient descent iteration = 24
gd loss = 8425.692847283994
line search decrease found at ls_iter = 0, alpha = 0.025, loss = 8424.177522503163
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8424.177522503163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8415.426542778221
gradient descent iteration = 1
gd loss = 8415.426542778221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8408.862432532631
gradient descent iteration = 2
gd loss = 8408.862432532631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8403.097789204583
gradient descent iteration = 3
gd loss = 8403.097789204583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8397.885618728325
gradient descent iteration = 4
gd loss = 8397.885618728325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8393.308333982075
gradient descent iteration = 5
gd loss = 8393.308333982075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8389.969530067521
gradient descent iteration = 6
gd loss = 8389.969530067521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8389.889828775313
gradient descent iteration = 7
gd loss = 8389.889828775313
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 8381.892565071537
gradient descent iteration = 8
gd loss = 8381.892565071537
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8378.847073245184
gradient descent iteration = 9
gd loss = 8378.847073245184
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8376.550845658165
gradient descent iteration = 10
gd loss = 8376.550845658165
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8374.387249058638
gradient descent iteration = 11
gd loss = 8374.387249058638
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8372.267037136027
gradient descent iteration = 12
gd loss = 8372.267037136027
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8370.175721459575
gradient descent iteration = 13
gd loss = 8370.175721459575
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8368.109896303984
gradient descent iteration = 14
gd loss = 8368.109896303984
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8366.067862180093
gradient descent iteration = 15
gd loss = 8366.067862180093
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8364.048269094048
gradient descent iteration = 16
gd loss = 8364.048269094048
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8362.049896888937
gradient descent iteration = 17
gd loss = 8362.049896888937
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8360.071614363535
gradient descent iteration = 18
gd loss = 8360.071614363535
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8358.112361803089
gradient descent iteration = 19
gd loss = 8358.112361803089
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8356.171140517563
gradient descent iteration = 20
gd loss = 8356.171140517563
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8354.247004209881
gradient descent iteration = 21
gd loss = 8354.247004209881
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8352.339051836576
gradient descent iteration = 22
gd loss = 8352.339051836576
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8350.446421666584
gradient descent iteration = 23
gd loss = 8350.446421666584
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8348.568286544583
gradient descent iteration = 24
gd loss = 8348.568286544583
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8346.703850335443
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8346.703850335443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8342.581352583875
gradient descent iteration = 1
gd loss = 8342.581352583875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8338.988920827849
gradient descent iteration = 2
gd loss = 8338.988920827849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8335.660937530542
gradient descent iteration = 3
gd loss = 8335.660937530542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8332.506852197654
gradient descent iteration = 4
gd loss = 8332.506852197654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8329.486888177344
gradient descent iteration = 5
gd loss = 8329.486888177344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8326.583125097728
gradient descent iteration = 6
gd loss = 8326.583125097728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8323.789482562941
gradient descent iteration = 7
gd loss = 8323.789482562941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8321.112493610804
gradient descent iteration = 8
gd loss = 8321.112493610804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8318.569622433068
gradient descent iteration = 9
gd loss = 8318.569622433068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8316.20274525989
gradient descent iteration = 10
gd loss = 8316.20274525989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8314.073090761654
gradient descent iteration = 11
gd loss = 8314.073090761654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8312.311185060893
gradient descent iteration = 12
gd loss = 8312.311185060893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8311.078863118464
gradient descent iteration = 13
gd loss = 8311.078863118464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8310.758651775346
gradient descent iteration = 14
gd loss = 8310.758651775346
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 8304.126856397414
gradient descent iteration = 15
gd loss = 8304.126856397414
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8302.822139705475
gradient descent iteration = 16
gd loss = 8302.822139705475
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8301.622973239335
gradient descent iteration = 17
gd loss = 8301.622973239335
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8300.434933575465
gradient descent iteration = 18
gd loss = 8300.434933575465
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8299.255944361828
gradient descent iteration = 19
gd loss = 8299.255944361828
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8298.085759457537
gradient descent iteration = 20
gd loss = 8298.085759457537
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8296.924179246824
gradient descent iteration = 21
gd loss = 8296.924179246824
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8295.771014982463
gradient descent iteration = 22
gd loss = 8295.771014982463
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8294.626087100498
gradient descent iteration = 23
gd loss = 8294.626087100498
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8293.489224458066
gradient descent iteration = 24
gd loss = 8293.489224458066
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 8292.360263680837
Initial loss = 8755.764802902202
Final loss = 8292.360263680837
Deformation gradient control sequence optimization finished.
Animation interval 21 took 1160 seconds.
Full animation took 27163 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 22************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8248.123505156374
initial norm = 668.5474845236938
convergence norm = 0.6685474845236938
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8248.123505156374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8188.197163476965
gradient descent iteration = 1
gd loss = 8188.197163476965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8141.212132410549
gradient descent iteration = 2
gd loss = 8141.212132410549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8105.491360747419
gradient descent iteration = 3
gd loss = 8105.491360747419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8078.694344275051
gradient descent iteration = 4
gd loss = 8078.694344275051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8058.189765888534
gradient descent iteration = 5
gd loss = 8058.189765888534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8041.947710883326
gradient descent iteration = 6
gd loss = 8041.947710883326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8028.728657720825
gradient descent iteration = 7
gd loss = 8028.728657720825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8017.647232054232
gradient descent iteration = 8
gd loss = 8017.647232054232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8008.061986846978
gradient descent iteration = 9
gd loss = 8008.061986846978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7999.530963563251
gradient descent iteration = 10
gd loss = 7999.530963563251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7991.749766455663
gradient descent iteration = 11
gd loss = 7991.749766455663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7984.511193007371
gradient descent iteration = 12
gd loss = 7984.511193007371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7977.677500172204
gradient descent iteration = 13
gd loss = 7977.677500172204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7971.157420832786
gradient descent iteration = 14
gd loss = 7971.157420832786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7964.889285569808
gradient descent iteration = 15
gd loss = 7964.889285569808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7958.831011429143
gradient descent iteration = 16
gd loss = 7958.831011429143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7952.964364321485
gradient descent iteration = 17
gd loss = 7952.964364321485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7947.390120033184
gradient descent iteration = 18
gd loss = 7947.390120033184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7943.064290496492
gradient descent iteration = 19
gd loss = 7943.064290496492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7941.375544950301
gradient descent iteration = 20
gd loss = 7941.375544950301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7938.263431949033
gradient descent iteration = 21
gd loss = 7938.263431949033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7936.099322199494
gradient descent iteration = 22
gd loss = 7936.099322199494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7933.443135882011
gradient descent iteration = 23
gd loss = 7933.443135882011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7931.169381019099
gradient descent iteration = 24
gd loss = 7931.169381019099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7928.699871108746
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 7928.699871108746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7923.320427941727
gradient descent iteration = 1
gd loss = 7923.320427941727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7919.9757785386
gradient descent iteration = 2
gd loss = 7919.9757785386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7917.226367630968
gradient descent iteration = 3
gd loss = 7917.226367630968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7914.740592829307
gradient descent iteration = 4
gd loss = 7914.740592829307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7912.414479609964
gradient descent iteration = 5
gd loss = 7912.414479609964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7910.202729384501
gradient descent iteration = 6
gd loss = 7910.202729384501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7908.080148123804
gradient descent iteration = 7
gd loss = 7908.080148123804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7906.030518739956
gradient descent iteration = 8
gd loss = 7906.030518739956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7904.042495437255
gradient descent iteration = 9
gd loss = 7904.042495437255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7902.10770379224
gradient descent iteration = 10
gd loss = 7902.10770379224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7900.219724103331
gradient descent iteration = 11
gd loss = 7900.219724103331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7898.37348816005
gradient descent iteration = 12
gd loss = 7898.37348816005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7896.564899230003
gradient descent iteration = 13
gd loss = 7896.564899230003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7894.790580496722
gradient descent iteration = 14
gd loss = 7894.790580496722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7893.04770261088
gradient descent iteration = 15
gd loss = 7893.04770261088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7891.333861596328
gradient descent iteration = 16
gd loss = 7891.333861596328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7889.646989658555
gradient descent iteration = 17
gd loss = 7889.646989658555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7887.985289023421
gradient descent iteration = 18
gd loss = 7887.985289023421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7886.347182130682
gradient descent iteration = 19
gd loss = 7886.347182130682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7884.731273203301
gradient descent iteration = 20
gd loss = 7884.731273203301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7883.136318393206
gradient descent iteration = 21
gd loss = 7883.136318393206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7881.561202014756
gradient descent iteration = 22
gd loss = 7881.561202014756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7880.004917138218
gradient descent iteration = 23
gd loss = 7880.004917138218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7878.466550152236
gradient descent iteration = 24
gd loss = 7878.466550152236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7876.945268250351
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 7876.945268250351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7874.986356925913
gradient descent iteration = 1
gd loss = 7874.986356925913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7873.286050851897
gradient descent iteration = 2
gd loss = 7873.286050851897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7871.684173275793
gradient descent iteration = 3
gd loss = 7871.684173275793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7870.152907680822
gradient descent iteration = 4
gd loss = 7870.152907680822
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7868.676366458583
gradient descent iteration = 5
gd loss = 7868.676366458583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7867.244117081745
gradient descent iteration = 6
gd loss = 7867.244117081745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7865.848919976474
gradient descent iteration = 7
gd loss = 7865.848919976474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7864.485538183399
gradient descent iteration = 8
gd loss = 7864.485538183399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7863.150045203483
gradient descent iteration = 9
gd loss = 7863.150045203483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7861.839406235342
gradient descent iteration = 10
gd loss = 7861.839406235342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7860.551211323498
gradient descent iteration = 11
gd loss = 7860.551211323498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7859.283502439099
gradient descent iteration = 12
gd loss = 7859.283502439099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7858.03465832615
gradient descent iteration = 13
gd loss = 7858.03465832615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7856.803315093004
gradient descent iteration = 14
gd loss = 7856.803315093004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7855.58830975501
gradient descent iteration = 15
gd loss = 7855.58830975501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7854.388639061642
gradient descent iteration = 16
gd loss = 7854.388639061642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7853.203428770855
gradient descent iteration = 17
gd loss = 7853.203428770855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7852.031910272685
gradient descent iteration = 18
gd loss = 7852.031910272685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7850.873402485471
gradient descent iteration = 19
gd loss = 7850.873402485471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7849.727297604924
gradient descent iteration = 20
gd loss = 7849.727297604924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7848.5930497311
gradient descent iteration = 21
gd loss = 7848.5930497311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7847.470165708444
gradient descent iteration = 22
gd loss = 7847.470165708444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7846.358197651511
gradient descent iteration = 23
gd loss = 7846.358197651511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7845.256736798511
gradient descent iteration = 24
gd loss = 7845.256736798511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7844.165408417346
Initial loss = 8248.123505156374
Final loss = 7844.165408417346
Deformation gradient control sequence optimization finished.
Animation interval 22 took 1155 seconds.
Full animation took 28318 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 23************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7766.540117354305
initial norm = 503.9507293322737
convergence norm = 0.5039507293322737
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7766.540117354305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7722.605046587941
gradient descent iteration = 1
gd loss = 7722.605046587941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7690.163940659413
gradient descent iteration = 2
gd loss = 7690.163940659413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7666.747342497456
gradient descent iteration = 3
gd loss = 7666.747342497456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7649.507035349679
gradient descent iteration = 4
gd loss = 7649.507035349679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7636.209893546878
gradient descent iteration = 5
gd loss = 7636.209893546878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7625.477384532462
gradient descent iteration = 6
gd loss = 7625.477384532462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7616.414981880836
gradient descent iteration = 7
gd loss = 7616.414981880836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7608.469545220791
gradient descent iteration = 8
gd loss = 7608.469545220791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7601.290351827482
gradient descent iteration = 9
gd loss = 7601.290351827482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7594.647686901863
gradient descent iteration = 10
gd loss = 7594.647686901863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7588.411442104012
gradient descent iteration = 11
gd loss = 7588.411442104012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7582.63894594869
gradient descent iteration = 12
gd loss = 7582.63894594869
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7578.325419986565
gradient descent iteration = 13
gd loss = 7578.325419986565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7576.533406865543
gradient descent iteration = 14
gd loss = 7576.533406865543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7573.418802088655
gradient descent iteration = 15
gd loss = 7573.418802088655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7571.228060776251
gradient descent iteration = 16
gd loss = 7571.228060776251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7568.597681005665
gradient descent iteration = 17
gd loss = 7568.597681005665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7566.349449710035
gradient descent iteration = 18
gd loss = 7566.349449710035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7563.936116244463
gradient descent iteration = 19
gd loss = 7563.936116244463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7561.728706817326
gradient descent iteration = 20
gd loss = 7561.728706817326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7559.444955833664
gradient descent iteration = 21
gd loss = 7559.444955833664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7557.302648830236
gradient descent iteration = 22
gd loss = 7557.302648830236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7555.11234855912
gradient descent iteration = 23
gd loss = 7555.11234855912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7553.03736910441
gradient descent iteration = 24
gd loss = 7553.03736910441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7550.922164089885
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 7550.922164089885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7545.756177789916
gradient descent iteration = 1
gd loss = 7545.756177789916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7542.622030728338
gradient descent iteration = 2
gd loss = 7542.622030728338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7540.077518476401
gradient descent iteration = 3
gd loss = 7540.077518476401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7537.785962957853
gradient descent iteration = 4
gd loss = 7537.785962957853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7535.643444555817
gradient descent iteration = 5
gd loss = 7535.643444555817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7533.606324269925
gradient descent iteration = 6
gd loss = 7533.606324269925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7531.651038189243
gradient descent iteration = 7
gd loss = 7531.651038189243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7529.762638117363
gradient descent iteration = 8
gd loss = 7529.762638117363
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7527.930733967689
gradient descent iteration = 9
gd loss = 7527.930733967689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7526.147678015263
gradient descent iteration = 10
gd loss = 7526.147678015263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7524.407617887313
gradient descent iteration = 11
gd loss = 7524.407617887313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7522.705939732213
gradient descent iteration = 12
gd loss = 7522.705939732213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7521.038920050579
gradient descent iteration = 13
gd loss = 7521.038920050579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7519.403495196414
gradient descent iteration = 14
gd loss = 7519.403495196414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7517.797103596747
gradient descent iteration = 15
gd loss = 7517.797103596747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7516.217573780777
gradient descent iteration = 16
gd loss = 7516.217573780777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7514.663042994791
gradient descent iteration = 17
gd loss = 7514.663042994791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7513.131896702087
gradient descent iteration = 18
gd loss = 7513.131896702087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7511.622722754415
gradient descent iteration = 19
gd loss = 7511.622722754415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7510.13427602213
gradient descent iteration = 20
gd loss = 7510.13427602213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7508.665450781858
gradient descent iteration = 21
gd loss = 7508.665450781858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7507.215258790057
gradient descent iteration = 22
gd loss = 7507.215258790057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7505.78281147873
gradient descent iteration = 23
gd loss = 7505.78281147873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7504.3673058042
gradient descent iteration = 24
gd loss = 7504.3673058042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7502.968012729876
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 7502.968012729876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7501.04944222371
gradient descent iteration = 1
gd loss = 7501.04944222371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7499.392358157571
gradient descent iteration = 2
gd loss = 7499.392358157571
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7497.833930028736
gradient descent iteration = 3
gd loss = 7497.833930028736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7496.34543516507
gradient descent iteration = 4
gd loss = 7496.34543516507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7494.910647072144
gradient descent iteration = 5
gd loss = 7494.910647072144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7493.519111788929
gradient descent iteration = 6
gd loss = 7493.519111788929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7492.1636946174
gradient descent iteration = 7
gd loss = 7492.1636946174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7490.839303306341
gradient descent iteration = 8
gd loss = 7490.839303306341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7489.542160094567
gradient descent iteration = 9
gd loss = 7489.542160094567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7488.269367455938
gradient descent iteration = 10
gd loss = 7488.269367455938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7487.018639230318
gradient descent iteration = 11
gd loss = 7487.018639230318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7485.78812820036
gradient descent iteration = 12
gd loss = 7485.78812820036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7484.576311711226
gradient descent iteration = 13
gd loss = 7484.576311711226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7483.381913306218
gradient descent iteration = 14
gd loss = 7483.381913306218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7482.203847467367
gradient descent iteration = 15
gd loss = 7482.203847467367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7481.041179524284
gradient descent iteration = 16
gd loss = 7481.041179524284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7479.893095886428
gradient descent iteration = 17
gd loss = 7479.893095886428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7478.758881511088
gradient descent iteration = 18
gd loss = 7478.758881511088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7477.637902545611
gradient descent iteration = 19
gd loss = 7477.637902545611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7476.529592732811
gradient descent iteration = 20
gd loss = 7476.529592732811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7475.433442657807
gradient descent iteration = 21
gd loss = 7475.433442657807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7474.348991106859
gradient descent iteration = 22
gd loss = 7474.348991106859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7473.275818084168
gradient descent iteration = 23
gd loss = 7473.275818084168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7472.213540023476
gradient descent iteration = 24
gd loss = 7472.213540023476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7471.161807044589
Initial loss = 7766.540117354305
Final loss = 7471.161807044589
Deformation gradient control sequence optimization finished.
Animation interval 23 took 1154 seconds.
Full animation took 29473 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 24************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7420.698874868246
initial norm = 454.179453165671
convergence norm = 0.454179453165671
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7420.698874868246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7381.517314804119
gradient descent iteration = 1
gd loss = 7381.517314804119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7352.978463100334
gradient descent iteration = 2
gd loss = 7352.978463100334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7332.21768014432
gradient descent iteration = 3
gd loss = 7332.21768014432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7316.625066184591
gradient descent iteration = 4
gd loss = 7316.625066184591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7304.509312626615
gradient descent iteration = 5
gd loss = 7304.509312626615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7294.700417106596
gradient descent iteration = 6
gd loss = 7294.700417106596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7286.407142917823
gradient descent iteration = 7
gd loss = 7286.407142917823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7279.136462383867
gradient descent iteration = 8
gd loss = 7279.136462383867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7272.556130078836
gradient descent iteration = 9
gd loss = 7272.556130078836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7266.447591002518
gradient descent iteration = 10
gd loss = 7266.447591002518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7260.68670437557
gradient descent iteration = 11
gd loss = 7260.68670437557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7255.267109953304
gradient descent iteration = 12
gd loss = 7255.267109953304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7250.707258804737
gradient descent iteration = 13
gd loss = 7250.707258804737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7248.787761554132
gradient descent iteration = 14
gd loss = 7248.787761554132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7246.38588604267
gradient descent iteration = 15
gd loss = 7246.38588604267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7244.4388136646
gradient descent iteration = 16
gd loss = 7244.4388136646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7242.302109034441
gradient descent iteration = 17
gd loss = 7242.302109034441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7240.384939674019
gradient descent iteration = 18
gd loss = 7240.384939674019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7238.376194870169
gradient descent iteration = 19
gd loss = 7238.376194870169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7236.512056680207
gradient descent iteration = 20
gd loss = 7236.512056680207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7234.592961639895
gradient descent iteration = 21
gd loss = 7234.592961639895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7232.788596517405
gradient descent iteration = 22
gd loss = 7232.788596517405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7230.941270227831
gradient descent iteration = 23
gd loss = 7230.941270227831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7229.195242271452
gradient descent iteration = 24
gd loss = 7229.195242271452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7227.409146415865
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 7227.409146415865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7222.599773737359
gradient descent iteration = 1
gd loss = 7222.599773737359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7219.858129956627
gradient descent iteration = 2
gd loss = 7219.858129956627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7217.666287637346
gradient descent iteration = 3
gd loss = 7217.666287637346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7215.696281202412
gradient descent iteration = 4
gd loss = 7215.696281202412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7213.85355612072
gradient descent iteration = 5
gd loss = 7213.85355612072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7212.100372272193
gradient descent iteration = 6
gd loss = 7212.100372272193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7210.416857657802
gradient descent iteration = 7
gd loss = 7210.416857657802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7208.790533219127
gradient descent iteration = 8
gd loss = 7208.790533219127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7207.212751022366
gradient descent iteration = 9
gd loss = 7207.212751022366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7205.677145596987
gradient descent iteration = 10
gd loss = 7205.677145596987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7204.178835783273
gradient descent iteration = 11
gd loss = 7204.178835783273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7202.713960864996
gradient descent iteration = 12
gd loss = 7202.713960864996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7201.27939258267
gradient descent iteration = 13
gd loss = 7201.27939258267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7199.872546026884
gradient descent iteration = 14
gd loss = 7199.872546026884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7198.491249279516
gradient descent iteration = 15
gd loss = 7198.491249279516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7197.133651848249
gradient descent iteration = 16
gd loss = 7197.133651848249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7195.798158492114
gradient descent iteration = 17
gd loss = 7195.798158492114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7194.483380043436
gradient descent iteration = 18
gd loss = 7194.483380043436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7193.188095710781
gradient descent iteration = 19
gd loss = 7193.188095710781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7191.911224265607
gradient descent iteration = 20
gd loss = 7191.911224265607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7190.651801405138
gradient descent iteration = 21
gd loss = 7190.651801405138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7189.408961789292
gradient descent iteration = 22
gd loss = 7189.408961789292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7188.181924552657
gradient descent iteration = 23
gd loss = 7188.181924552657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7186.969981506114
gradient descent iteration = 24
gd loss = 7186.969981506114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7185.772487402787
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 7185.772487402787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7184.074598720374
gradient descent iteration = 1
gd loss = 7184.074598720374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7182.615598660448
gradient descent iteration = 2
gd loss = 7182.615598660448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7181.244653131782
gradient descent iteration = 3
gd loss = 7181.244653131782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7179.93557278783
gradient descent iteration = 4
gd loss = 7179.93557278783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7178.673733540048
gradient descent iteration = 5
gd loss = 7178.673733540048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7177.449859125565
gradient descent iteration = 6
gd loss = 7177.449859125565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7176.257689614487
gradient descent iteration = 7
gd loss = 7176.257689614487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7175.092787517911
gradient descent iteration = 8
gd loss = 7175.092787517911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7173.951870840762
gradient descent iteration = 9
gd loss = 7173.951870840762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7172.832422916847
gradient descent iteration = 10
gd loss = 7172.832422916847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7171.732454808266
gradient descent iteration = 11
gd loss = 7171.732454808266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7170.65035488533
gradient descent iteration = 12
gd loss = 7170.65035488533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7169.58479001866
gradient descent iteration = 13
gd loss = 7169.58479001866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7168.534638335854
gradient descent iteration = 14
gd loss = 7168.534638335854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7167.498941960646
gradient descent iteration = 15
gd loss = 7167.498941960646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7166.476872836715
gradient descent iteration = 16
gd loss = 7166.476872836715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7165.467707356102
gradient descent iteration = 17
gd loss = 7165.467707356102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7164.470807196827
gradient descent iteration = 18
gd loss = 7164.470807196827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7163.485604994077
gradient descent iteration = 19
gd loss = 7163.485604994077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7162.511592931033
gradient descent iteration = 20
gd loss = 7162.511592931033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7161.548312858959
gradient descent iteration = 21
gd loss = 7161.548312858959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7160.595348881344
gradient descent iteration = 22
gd loss = 7160.595348881344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7159.652321368352
gradient descent iteration = 23
gd loss = 7159.652321368352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7158.718882053089
gradient descent iteration = 24
gd loss = 7158.718882053089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7157.794709977535
Initial loss = 7420.698874868246
Final loss = 7157.794709977535
Deformation gradient control sequence optimization finished.
Animation interval 24 took 1154 seconds.
Full animation took 30628 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 25************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7116.883961397284
initial norm = 432.9721633021041
convergence norm = 0.4329721633021041
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7116.883961397284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7080.436721143679
gradient descent iteration = 1
gd loss = 7080.436721143679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7055.4328357724
gradient descent iteration = 2
gd loss = 7055.4328357724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7038.160337211578
gradient descent iteration = 3
gd loss = 7038.160337211578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7025.558474463177
gradient descent iteration = 4
gd loss = 7025.558474463177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7015.924123789569
gradient descent iteration = 5
gd loss = 7015.924123789569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7008.108691950907
gradient descent iteration = 6
gd loss = 7008.108691950907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7001.441396409253
gradient descent iteration = 7
gd loss = 7001.441396409253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6995.559629916018
gradient descent iteration = 8
gd loss = 6995.559629916018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6990.732709196845
gradient descent iteration = 9
gd loss = 6990.732709196845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6989.196635214396
gradient descent iteration = 10
gd loss = 6989.196635214396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6986.703750723804
gradient descent iteration = 11
gd loss = 6986.703750723804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6984.900482367531
gradient descent iteration = 12
gd loss = 6984.900482367531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6982.786678443244
gradient descent iteration = 13
gd loss = 6982.786678443244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6980.976205730288
gradient descent iteration = 14
gd loss = 6980.976205730288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6979.073661587992
gradient descent iteration = 15
gd loss = 6979.073661587992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6977.308437036902
gradient descent iteration = 16
gd loss = 6977.308437036902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6975.543893070722
gradient descent iteration = 17
gd loss = 6975.543893070722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6973.838354451072
gradient descent iteration = 18
gd loss = 6973.838354451072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6972.174507550792
gradient descent iteration = 19
gd loss = 6972.174507550792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6970.529735913798
gradient descent iteration = 20
gd loss = 6970.529735913798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6968.945103769431
gradient descent iteration = 21
gd loss = 6968.945103769431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6967.357668700549
gradient descent iteration = 22
gd loss = 6967.357668700549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6965.83855551002
gradient descent iteration = 23
gd loss = 6965.83855551002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6964.303789126595
gradient descent iteration = 24
gd loss = 6964.303789126595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6962.840721381524
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6962.840721381524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6958.045922000606
gradient descent iteration = 1
gd loss = 6958.045922000606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6955.676174704291
gradient descent iteration = 2
gd loss = 6955.676174704291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6953.817804556529
gradient descent iteration = 3
gd loss = 6953.817804556529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6952.143256481265
gradient descent iteration = 4
gd loss = 6952.143256481265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6950.570581401717
gradient descent iteration = 5
gd loss = 6950.570581401717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6949.070205788252
gradient descent iteration = 6
gd loss = 6949.070205788252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6947.626932756112
gradient descent iteration = 7
gd loss = 6947.626932756112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6946.231098909687
gradient descent iteration = 8
gd loss = 6946.231098909687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6944.875861241146
gradient descent iteration = 9
gd loss = 6944.875861241146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6943.556086334909
gradient descent iteration = 10
gd loss = 6943.556086334909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6942.267773771382
gradient descent iteration = 11
gd loss = 6942.267773771382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6941.007718728909
gradient descent iteration = 12
gd loss = 6941.007718728909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6939.773297116457
gradient descent iteration = 13
gd loss = 6939.773297116457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6938.562322286316
gradient descent iteration = 14
gd loss = 6938.562322286316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6937.372945175913
gradient descent iteration = 15
gd loss = 6937.372945175913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6936.20358290074
gradient descent iteration = 16
gd loss = 6936.20358290074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6935.052866211
gradient descent iteration = 17
gd loss = 6935.052866211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6933.919600289428
gradient descent iteration = 18
gd loss = 6933.919600289428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6932.802735043166
gradient descent iteration = 19
gd loss = 6932.802735043166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6931.701340484376
gradient descent iteration = 20
gd loss = 6931.701340484376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6930.614587613881
gradient descent iteration = 21
gd loss = 6930.614587613881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6929.541733340045
gradient descent iteration = 22
gd loss = 6929.541733340045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6928.48210817007
gradient descent iteration = 23
gd loss = 6928.48210817007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6927.435106241107
gradient descent iteration = 24
gd loss = 6927.435106241107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6926.40017698604
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6926.40017698604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6924.923440966893
gradient descent iteration = 1
gd loss = 6924.923440966893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6923.61567519548
gradient descent iteration = 2
gd loss = 6923.61567519548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6922.385725971882
gradient descent iteration = 3
gd loss = 6922.385725971882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6921.210696096881
gradient descent iteration = 4
gd loss = 6921.210696096881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6920.077704560806
gradient descent iteration = 5
gd loss = 6920.077704560806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6918.978590422529
gradient descent iteration = 6
gd loss = 6918.978590422529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6917.907841273204
gradient descent iteration = 7
gd loss = 6917.907841273204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6916.861536631507
gradient descent iteration = 8
gd loss = 6916.861536631507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6915.836763752308
gradient descent iteration = 9
gd loss = 6915.836763752308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6914.831278557499
gradient descent iteration = 10
gd loss = 6914.831278557499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6913.84330009085
gradient descent iteration = 11
gd loss = 6913.84330009085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6912.871380400275
gradient descent iteration = 12
gd loss = 6912.871380400275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6911.914318778201
gradient descent iteration = 13
gd loss = 6911.914318778201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6910.971103112372
gradient descent iteration = 14
gd loss = 6910.971103112372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6910.040868385786
gradient descent iteration = 15
gd loss = 6910.040868385786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6909.122866467013
gradient descent iteration = 16
gd loss = 6909.122866467013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6908.216443571515
gradient descent iteration = 17
gd loss = 6908.216443571515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6907.321023101546
gradient descent iteration = 18
gd loss = 6907.321023101546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6906.436092355537
gradient descent iteration = 19
gd loss = 6906.436092355537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6905.561192083178
gradient descent iteration = 20
gd loss = 6905.561192083178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6904.695908175362
gradient descent iteration = 21
gd loss = 6904.695908175362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6903.839864977933
gradient descent iteration = 22
gd loss = 6903.839864977933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6902.992719858551
gradient descent iteration = 23
gd loss = 6902.992719858551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6902.15415876049
gradient descent iteration = 24
gd loss = 6902.15415876049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6901.323892515098
Initial loss = 7116.883961397284
Final loss = 6901.323892515098
Deformation gradient control sequence optimization finished.
Animation interval 25 took 1154 seconds.
Full animation took 31782 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 26************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6883.350588380145
initial norm = 438.1119240297457
convergence norm = 0.4381119240297457
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6883.350588380145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6847.520152769858
gradient descent iteration = 1
gd loss = 6847.520152769858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6824.565086703657
gradient descent iteration = 2
gd loss = 6824.565086703657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6809.122982547728
gradient descent iteration = 3
gd loss = 6809.122982547728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6797.936463536861
gradient descent iteration = 4
gd loss = 6797.936463536861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6789.444408688983
gradient descent iteration = 5
gd loss = 6789.444408688983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6782.598913773883
gradient descent iteration = 6
gd loss = 6782.598913773883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6777.073498905923
gradient descent iteration = 7
gd loss = 6777.073498905923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6774.475319040746
gradient descent iteration = 8
gd loss = 6774.475319040746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6772.926817851313
gradient descent iteration = 9
gd loss = 6772.926817851313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6770.588741572925
gradient descent iteration = 10
gd loss = 6770.588741572925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6768.971021970669
gradient descent iteration = 11
gd loss = 6768.971021970669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6766.994700712987
gradient descent iteration = 12
gd loss = 6766.994700712987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6765.404229112987
gradient descent iteration = 13
gd loss = 6765.404229112987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6763.63790513114
gradient descent iteration = 14
gd loss = 6763.63790513114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6762.102933423811
gradient descent iteration = 15
gd loss = 6762.102933423811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6760.475681710195
gradient descent iteration = 16
gd loss = 6760.475681710195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6759.001579257632
gradient descent iteration = 17
gd loss = 6759.001579257632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6757.47522831002
gradient descent iteration = 18
gd loss = 6757.47522831002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6756.059644801973
gradient descent iteration = 19
gd loss = 6756.059644801973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6754.611409446906
gradient descent iteration = 20
gd loss = 6754.611409446906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6753.24965748705
gradient descent iteration = 21
gd loss = 6753.24965748705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6751.864781438368
gradient descent iteration = 22
gd loss = 6751.864781438368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6750.551798737067
gradient descent iteration = 23
gd loss = 6750.551798737067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6749.220082650677
gradient descent iteration = 24
gd loss = 6749.220082650677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6747.951124786826
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6747.951124786826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6743.251370245661
gradient descent iteration = 1
gd loss = 6743.251370245661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6741.165375468587
gradient descent iteration = 2
gd loss = 6741.165375468587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6739.543656029046
gradient descent iteration = 3
gd loss = 6739.543656029046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6738.07965692383
gradient descent iteration = 4
gd loss = 6738.07965692383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6736.703388799567
gradient descent iteration = 5
gd loss = 6736.703388799567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6735.389977168508
gradient descent iteration = 6
gd loss = 6735.389977168508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6734.12637462035
gradient descent iteration = 7
gd loss = 6734.12637462035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6732.904160090601
gradient descent iteration = 8
gd loss = 6732.904160090601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6731.717345382274
gradient descent iteration = 9
gd loss = 6731.717345382274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6730.561440508377
gradient descent iteration = 10
gd loss = 6730.561440508377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6729.43295371667
gradient descent iteration = 11
gd loss = 6729.43295371667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6728.329093446348
gradient descent iteration = 12
gd loss = 6728.329093446348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6727.247577894144
gradient descent iteration = 13
gd loss = 6727.247577894144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6726.186508014689
gradient descent iteration = 14
gd loss = 6726.186508014689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6725.144279480367
gradient descent iteration = 15
gd loss = 6725.144279480367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6724.119519784753
gradient descent iteration = 16
gd loss = 6724.119519784753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6723.11104204592
gradient descent iteration = 17
gd loss = 6723.11104204592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6722.117810359025
gradient descent iteration = 18
gd loss = 6722.117810359025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6721.138913311962
gradient descent iteration = 19
gd loss = 6721.138913311962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6720.173543461416
gradient descent iteration = 20
gd loss = 6720.173543461416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6719.220980814443
gradient descent iteration = 21
gd loss = 6719.220980814443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6718.280579640083
gradient descent iteration = 22
gd loss = 6718.280579640083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6717.35175782215
gradient descent iteration = 23
gd loss = 6717.35175782215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6716.433988161762
gradient descent iteration = 24
gd loss = 6716.433988161762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6715.526791244949
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6715.526791244949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6714.22706629523
gradient descent iteration = 1
gd loss = 6714.22706629523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6713.068161692225
gradient descent iteration = 2
gd loss = 6713.068161692225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6711.976925207353
gradient descent iteration = 3
gd loss = 6711.976925207353
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6710.933212277883
gradient descent iteration = 4
gd loss = 6710.933212277883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6709.925756243684
gradient descent iteration = 5
gd loss = 6709.925756243684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6708.947439401159
gradient descent iteration = 6
gd loss = 6708.947439401159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6707.993462122759
gradient descent iteration = 7
gd loss = 6707.993462122759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6707.060418087021
gradient descent iteration = 8
gd loss = 6707.060418087021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6706.145784114867
gradient descent iteration = 9
gd loss = 6706.145784114867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6705.247623726817
gradient descent iteration = 10
gd loss = 6705.247623726817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6704.364406865672
gradient descent iteration = 11
gd loss = 6704.364406865672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6703.494895363079
gradient descent iteration = 12
gd loss = 6703.494895363079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6702.638067181295
gradient descent iteration = 13
gd loss = 6702.638067181295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6701.79306443682
gradient descent iteration = 14
gd loss = 6701.79306443682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6700.959156597341
gradient descent iteration = 15
gd loss = 6700.959156597341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6700.135713724339
gradient descent iteration = 16
gd loss = 6700.135713724339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6699.322186568386
gradient descent iteration = 17
gd loss = 6699.322186568386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6698.518091486256
gradient descent iteration = 18
gd loss = 6698.518091486256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6697.72299882589
gradient descent iteration = 19
gd loss = 6697.72299882589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6696.936523863593
gradient descent iteration = 20
gd loss = 6696.936523863593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6696.158319639267
gradient descent iteration = 21
gd loss = 6696.158319639267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6695.388071222319
gradient descent iteration = 22
gd loss = 6695.388071222319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6694.625491106133
gradient descent iteration = 23
gd loss = 6694.625491106133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6693.870315449414
gradient descent iteration = 24
gd loss = 6693.870315449414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6693.122300986175
Initial loss = 6883.350588380145
Final loss = 6693.122300986175
Deformation gradient control sequence optimization finished.
Animation interval 26 took 1154 seconds.
Full animation took 32937 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 27************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6675.629425534239
initial norm = 390.8571925544983
convergence norm = 0.3908571925544984
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6675.629425534239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6645.135760281089
gradient descent iteration = 1
gd loss = 6645.135760281089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6627.301005699534
gradient descent iteration = 2
gd loss = 6627.301005699534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6615.435647970519
gradient descent iteration = 3
gd loss = 6615.435647970519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6607.043085107483
gradient descent iteration = 4
gd loss = 6607.043085107483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6600.719702989339
gradient descent iteration = 5
gd loss = 6600.719702989339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6597.039018503457
gradient descent iteration = 6
gd loss = 6597.039018503457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6596.565751775216
gradient descent iteration = 7
gd loss = 6596.565751775216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6593.535415648255
gradient descent iteration = 8
gd loss = 6593.535415648255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6592.564217378517
gradient descent iteration = 9
gd loss = 6592.564217378517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6590.283205708015
gradient descent iteration = 10
gd loss = 6590.283205708015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6589.119728988142
gradient descent iteration = 11
gd loss = 6589.119728988142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6587.233567450413
gradient descent iteration = 12
gd loss = 6587.233567450413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6586.002726953005
gradient descent iteration = 13
gd loss = 6586.002726953005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6584.353525477569
gradient descent iteration = 14
gd loss = 6584.353525477569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6583.109734804096
gradient descent iteration = 15
gd loss = 6583.109734804096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6581.616288000152
gradient descent iteration = 16
gd loss = 6581.616288000152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6580.384131079429
gradient descent iteration = 17
gd loss = 6580.384131079429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6579.000608206455
gradient descent iteration = 18
gd loss = 6579.000608206455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6577.79103149268
gradient descent iteration = 19
gd loss = 6577.79103149268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6576.489638570488
gradient descent iteration = 20
gd loss = 6576.489638570488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6575.307041933567
gradient descent iteration = 21
gd loss = 6575.307041933567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6574.069896143073
gradient descent iteration = 22
gd loss = 6574.069896143073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6572.915461567472
gradient descent iteration = 23
gd loss = 6572.915461567472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6571.730466782104
gradient descent iteration = 24
gd loss = 6571.730466782104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6570.603799852567
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6570.603799852567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6566.369186925323
gradient descent iteration = 1
gd loss = 6566.369186925323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6564.452935242247
gradient descent iteration = 2
gd loss = 6564.452935242247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6562.97605445883
gradient descent iteration = 3
gd loss = 6562.97605445883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6561.654331572377
gradient descent iteration = 4
gd loss = 6561.654331572377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6560.418813103533
gradient descent iteration = 5
gd loss = 6560.418813103533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6559.243667013741
gradient descent iteration = 6
gd loss = 6559.243667013741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6558.115332949787
gradient descent iteration = 7
gd loss = 6558.115332949787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6557.025246745104
gradient descent iteration = 8
gd loss = 6557.025246745104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6555.967464197114
gradient descent iteration = 9
gd loss = 6555.967464197114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6554.937617421072
gradient descent iteration = 10
gd loss = 6554.937617421072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6553.932366567306
gradient descent iteration = 11
gd loss = 6553.932366567306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6552.949078337263
gradient descent iteration = 12
gd loss = 6552.949078337263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6551.985625018939
gradient descent iteration = 13
gd loss = 6551.985625018939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6551.040252641148
gradient descent iteration = 14
gd loss = 6551.040252641148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6550.111491247332
gradient descent iteration = 15
gd loss = 6550.111491247332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6549.198092055944
gradient descent iteration = 16
gd loss = 6549.198092055944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6548.298981700348
gradient descent iteration = 17
gd loss = 6548.298981700348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6547.413227984116
gradient descent iteration = 18
gd loss = 6547.413227984116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6546.540014254871
gradient descent iteration = 19
gd loss = 6546.540014254871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6545.678619586472
gradient descent iteration = 20
gd loss = 6545.678619586472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6544.828403235912
gradient descent iteration = 21
gd loss = 6544.828403235912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6543.988792271272
gradient descent iteration = 22
gd loss = 6543.988792271272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6543.159271576361
gradient descent iteration = 23
gd loss = 6543.159271576361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6542.339375688108
gradient descent iteration = 24
gd loss = 6542.339375688108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6541.528682108056
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6541.528682108056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6540.349056815468
gradient descent iteration = 1
gd loss = 6540.349056815468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6539.306520137337
gradient descent iteration = 2
gd loss = 6539.306520137337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6538.321916511872
gradient descent iteration = 3
gd loss = 6538.321916511872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6537.377986908733
gradient descent iteration = 4
gd loss = 6537.377986908733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6536.46510705245
gradient descent iteration = 5
gd loss = 6536.46510705245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6535.577194123128
gradient descent iteration = 6
gd loss = 6535.577194123128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6534.710145495354
gradient descent iteration = 7
gd loss = 6534.710145495354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6533.861052609102
gradient descent iteration = 8
gd loss = 6533.861052609102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6533.027766940933
gradient descent iteration = 9
gd loss = 6533.027766940933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6532.208646497623
gradient descent iteration = 10
gd loss = 6532.208646497623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6531.402400508217
gradient descent iteration = 11
gd loss = 6531.402400508217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6530.607990031379
gradient descent iteration = 12
gd loss = 6530.607990031379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6529.824561852402
gradient descent iteration = 13
gd loss = 6529.824561852402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6529.051403008361
gradient descent iteration = 14
gd loss = 6529.051403008361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6528.287908504437
gradient descent iteration = 15
gd loss = 6528.287908504437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6527.533557994446
gradient descent iteration = 16
gd loss = 6527.533557994446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6526.787898562119
gradient descent iteration = 17
gd loss = 6526.787898562119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6526.050531699355
gradient descent iteration = 18
gd loss = 6526.050531699355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6525.321103360756
gradient descent iteration = 19
gd loss = 6525.321103360756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6524.599296263731
gradient descent iteration = 20
gd loss = 6524.599296263731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6523.884823857004
gradient descent iteration = 21
gd loss = 6523.884823857004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6523.17742554842
gradient descent iteration = 22
gd loss = 6523.17742554842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6522.476862888979
gradient descent iteration = 23
gd loss = 6522.476862888979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6521.782916478241
gradient descent iteration = 24
gd loss = 6521.782916478241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6521.095383444916
Initial loss = 6675.629425534239
Final loss = 6521.095383444916
Deformation gradient control sequence optimization finished.
Animation interval 27 took 1155 seconds.
Full animation took 34092 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 28************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6507.831181955691
initial norm = 320.8761559079378
convergence norm = 0.3208761559079378
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6507.831181955691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6483.027454963258
gradient descent iteration = 1
gd loss = 6483.027454963258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6467.607857060928
gradient descent iteration = 2
gd loss = 6467.607857060928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6457.279500501525
gradient descent iteration = 3
gd loss = 6457.279500501525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6450.140064010239
gradient descent iteration = 4
gd loss = 6450.140064010239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6445.487032333432
gradient descent iteration = 5
gd loss = 6445.487032333432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6445.429248666291
gradient descent iteration = 6
gd loss = 6445.429248666291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6442.277689374761
gradient descent iteration = 7
gd loss = 6442.277689374761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6441.542205517448
gradient descent iteration = 8
gd loss = 6441.542205517448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6439.282587016479
gradient descent iteration = 9
gd loss = 6439.282587016479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6438.237567951279
gradient descent iteration = 10
gd loss = 6438.237567951279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6436.444301720106
gradient descent iteration = 11
gd loss = 6436.444301720106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6435.287508129889
gradient descent iteration = 12
gd loss = 6435.287508129889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6433.765826291418
gradient descent iteration = 13
gd loss = 6433.765826291418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6432.592719845738
gradient descent iteration = 14
gd loss = 6432.592719845738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6431.239722579847
gradient descent iteration = 15
gd loss = 6431.239722579847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6430.088739195035
gradient descent iteration = 16
gd loss = 6430.088739195035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6428.847070055146
gradient descent iteration = 17
gd loss = 6428.847070055146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6427.729944492131
gradient descent iteration = 18
gd loss = 6427.729944492131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6426.566257053719
gradient descent iteration = 19
gd loss = 6426.566257053719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6425.483882597702
gradient descent iteration = 20
gd loss = 6425.483882597702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6424.377204172864
gradient descent iteration = 21
gd loss = 6424.377204172864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6423.326548138461
gradient descent iteration = 22
gd loss = 6423.326548138461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6422.262414993006
gradient descent iteration = 23
gd loss = 6422.262414993006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6421.239889663386
gradient descent iteration = 24
gd loss = 6421.239889663386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6420.208481682708
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6420.208481682708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6416.171002164757
gradient descent iteration = 1
gd loss = 6416.171002164757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6414.494067484907
gradient descent iteration = 2
gd loss = 6414.494067484907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6413.212236294009
gradient descent iteration = 3
gd loss = 6413.212236294009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6412.06400065645
gradient descent iteration = 4
gd loss = 6412.06400065645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6410.989596554179
gradient descent iteration = 5
gd loss = 6410.989596554179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6409.967042598988
gradient descent iteration = 6
gd loss = 6409.967042598988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6408.984751809815
gradient descent iteration = 7
gd loss = 6408.984751809815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6408.035365962744
gradient descent iteration = 8
gd loss = 6408.035365962744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6407.113763550921
gradient descent iteration = 9
gd loss = 6407.113763550921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6406.216179421925
gradient descent iteration = 10
gd loss = 6406.216179421925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6405.339736755012
gradient descent iteration = 11
gd loss = 6405.339736755012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6404.482170435484
gradient descent iteration = 12
gd loss = 6404.482170435484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6403.641653262715
gradient descent iteration = 13
gd loss = 6403.641653262715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6402.81668158316
gradient descent iteration = 14
gd loss = 6402.81668158316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6402.005997264444
gradient descent iteration = 15
gd loss = 6402.005997264444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6401.208532755964
gradient descent iteration = 16
gd loss = 6401.208532755964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6400.423371331873
gradient descent iteration = 17
gd loss = 6400.423371331873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6399.649717657764
gradient descent iteration = 18
gd loss = 6399.649717657764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6398.886875515614
gradient descent iteration = 19
gd loss = 6398.886875515614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6398.134230640761
gradient descent iteration = 20
gd loss = 6398.134230640761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6397.391237296934
gradient descent iteration = 21
gd loss = 6397.391237296934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6396.657407620373
gradient descent iteration = 22
gd loss = 6396.657407620373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6395.932303006742
gradient descent iteration = 23
gd loss = 6395.932303006742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6395.215527093983
gradient descent iteration = 24
gd loss = 6395.215527093983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6394.506720089526
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6394.506720089526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6393.469408368309
gradient descent iteration = 1
gd loss = 6393.469408368309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6392.544942145993
gradient descent iteration = 2
gd loss = 6392.544942145993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6391.669481587948
gradient descent iteration = 3
gd loss = 6391.669481587948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6390.828862965573
gradient descent iteration = 4
gd loss = 6390.828862965573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6390.015045549733
gradient descent iteration = 5
gd loss = 6390.015045549733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6389.222863024389
gradient descent iteration = 6
gd loss = 6389.222863024389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6388.448795437022
gradient descent iteration = 7
gd loss = 6388.448795437022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6387.690337969781
gradient descent iteration = 8
gd loss = 6387.690337969781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6386.945642782009
gradient descent iteration = 9
gd loss = 6386.945642782009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6386.213304051795
gradient descent iteration = 10
gd loss = 6386.213304051795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6385.49222320749
gradient descent iteration = 11
gd loss = 6385.49222320749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6384.781521263871
gradient descent iteration = 12
gd loss = 6384.781521263871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6384.080479987834
gradient descent iteration = 13
gd loss = 6384.080479987834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6383.388501349154
gradient descent iteration = 14
gd loss = 6383.388501349154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6382.705078923927
gradient descent iteration = 15
gd loss = 6382.705078923927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6382.02977733143
gradient descent iteration = 16
gd loss = 6382.02977733143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6381.362217173445
gradient descent iteration = 17
gd loss = 6381.362217173445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6380.702063848435
gradient descent iteration = 18
gd loss = 6380.702063848435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6380.049019112255
gradient descent iteration = 19
gd loss = 6380.049019112255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6379.402814630799
gradient descent iteration = 20
gd loss = 6379.402814630799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6378.76320698309
gradient descent iteration = 21
gd loss = 6378.76320698309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6378.129973746981
gradient descent iteration = 22
gd loss = 6378.129973746981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6377.502910402446
gradient descent iteration = 23
gd loss = 6377.502910402446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6376.881827838685
gradient descent iteration = 24
gd loss = 6376.881827838685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6376.266550339428
Initial loss = 6507.831181955691
Final loss = 6376.266550339428
Deformation gradient control sequence optimization finished.
Animation interval 28 took 1156 seconds.
Full animation took 35249 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 29************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6366.851136524088
initial norm = 312.386636744747
convergence norm = 0.312386636744747
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6366.851136524088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6343.803542242907
gradient descent iteration = 1
gd loss = 6343.803542242907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6330.523896410095
gradient descent iteration = 2
gd loss = 6330.523896410095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6321.804473464443
gradient descent iteration = 3
gd loss = 6321.804473464443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6316.281990390208
gradient descent iteration = 4
gd loss = 6316.281990390208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6315.517121246558
gradient descent iteration = 5
gd loss = 6315.517121246558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6313.212574939993
gradient descent iteration = 6
gd loss = 6313.212574939993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6312.2722111503
gradient descent iteration = 7
gd loss = 6312.2722111503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6310.18479074076
gradient descent iteration = 8
gd loss = 6310.18479074076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6309.202177250015
gradient descent iteration = 9
gd loss = 6309.202177250015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6307.391838048087
gradient descent iteration = 10
gd loss = 6307.391838048087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6306.414717151856
gradient descent iteration = 11
gd loss = 6306.414717151856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6304.843504813528
gradient descent iteration = 12
gd loss = 6304.843504813528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6303.887561980354
gradient descent iteration = 13
gd loss = 6303.887561980354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6302.513270710895
gradient descent iteration = 14
gd loss = 6302.513270710895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6301.59435354203
gradient descent iteration = 15
gd loss = 6301.59435354203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6300.376592667025
gradient descent iteration = 16
gd loss = 6300.376592667025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6299.491434940604
gradient descent iteration = 17
gd loss = 6299.491434940604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6298.384961816302
gradient descent iteration = 18
gd loss = 6298.384961816302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6297.518600263178
gradient descent iteration = 19
gd loss = 6297.518600263178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6296.487536328539
gradient descent iteration = 20
gd loss = 6296.487536328539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6295.631511196024
gradient descent iteration = 21
gd loss = 6295.631511196024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6294.655532947128
gradient descent iteration = 22
gd loss = 6294.655532947128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6293.808327377969
gradient descent iteration = 23
gd loss = 6293.808327377969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6292.8762094372
gradient descent iteration = 24
gd loss = 6292.8762094372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6292.038547361856
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6292.038547361856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6288.223406111031
gradient descent iteration = 1
gd loss = 6288.223406111031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6286.737150193696
gradient descent iteration = 2
gd loss = 6286.737150193696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6285.636838688134
gradient descent iteration = 3
gd loss = 6285.636838688134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6284.659638016619
gradient descent iteration = 4
gd loss = 6284.659638016619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6283.746656288995
gradient descent iteration = 5
gd loss = 6283.746656288995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6282.877478065555
gradient descent iteration = 6
gd loss = 6282.877478065555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6282.041862806403
gradient descent iteration = 7
gd loss = 6282.041862806403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6281.233489112438
gradient descent iteration = 8
gd loss = 6281.233489112438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6280.448027920499
gradient descent iteration = 9
gd loss = 6280.448027920499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6279.682327271978
gradient descent iteration = 10
gd loss = 6279.682327271978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6278.933992765114
gradient descent iteration = 11
gd loss = 6278.933992765114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6278.201145246539
gradient descent iteration = 12
gd loss = 6278.201145246539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6277.482271416313
gradient descent iteration = 13
gd loss = 6277.482271416313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6276.776126851973
gradient descent iteration = 14
gd loss = 6276.776126851973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6276.081670519719
gradient descent iteration = 15
gd loss = 6276.081670519719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6275.398019022588
gradient descent iteration = 16
gd loss = 6275.398019022588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6274.724413721249
gradient descent iteration = 17
gd loss = 6274.724413721249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6274.060196319702
gradient descent iteration = 18
gd loss = 6274.060196319702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6273.404790574088
gradient descent iteration = 19
gd loss = 6273.404790574088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6272.757688054838
gradient descent iteration = 20
gd loss = 6272.757688054838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6272.118437084279
gradient descent iteration = 21
gd loss = 6272.118437084279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6271.486633912221
gradient descent iteration = 22
gd loss = 6271.486633912221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6270.861915635092
gradient descent iteration = 23
gd loss = 6270.861915635092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6270.243954420194
gradient descent iteration = 24
gd loss = 6270.243954420194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6269.632452774742
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6269.632452774742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6268.713569977356
gradient descent iteration = 1
gd loss = 6268.713569977356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6267.894704805471
gradient descent iteration = 2
gd loss = 6267.894704805471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6267.119377376832
gradient descent iteration = 3
gd loss = 6267.119377376832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6266.374833096899
gradient descent iteration = 4
gd loss = 6266.374833096899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6265.653714579991
gradient descent iteration = 5
gd loss = 6265.653714579991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6264.95130533206
gradient descent iteration = 6
gd loss = 6264.95130533206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6264.264433784032
gradient descent iteration = 7
gd loss = 6264.264433784032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6263.590884488482
gradient descent iteration = 8
gd loss = 6263.590884488482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6262.929054854503
gradient descent iteration = 9
gd loss = 6262.929054854503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6262.27774689349
gradient descent iteration = 10
gd loss = 6262.27774689349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6261.636037129309
gradient descent iteration = 11
gd loss = 6261.636037129309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6261.003193257347
gradient descent iteration = 12
gd loss = 6261.003193257347
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6260.378619519013
gradient descent iteration = 13
gd loss = 6260.378619519013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6259.761820101809
gradient descent iteration = 14
gd loss = 6259.761820101809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6259.152374085274
gradient descent iteration = 15
gd loss = 6259.152374085274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6258.549917937708
gradient descent iteration = 16
gd loss = 6258.549917937708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6257.954133040765
gradient descent iteration = 17
gd loss = 6257.954133040765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6257.364736611165
gradient descent iteration = 18
gd loss = 6257.364736611165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6256.781474976706
gradient descent iteration = 19
gd loss = 6256.781474976706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6256.204118503894
gradient descent iteration = 20
gd loss = 6256.204118503894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6255.632457688052
gradient descent iteration = 21
gd loss = 6255.632457688052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6255.066300115654
gradient descent iteration = 22
gd loss = 6255.066300115654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6254.505468058409
gradient descent iteration = 23
gd loss = 6254.505468058409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6253.949796532046
gradient descent iteration = 24
gd loss = 6253.949796532046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6253.399131711677
Initial loss = 6366.851136524088
Final loss = 6253.399131711677
Deformation gradient control sequence optimization finished.
Animation interval 29 took 1157 seconds.
Full animation took 36406 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 30************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6244.25087465764
initial norm = 255.5571900922674
convergence norm = 0.2555571900922675
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6244.25087465764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6225.631919934645
gradient descent iteration = 1
gd loss = 6225.631919934645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6214.342696111295
gradient descent iteration = 2
gd loss = 6214.342696111295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6207.158415888175
gradient descent iteration = 3
gd loss = 6207.158415888175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6202.508263906198
gradient descent iteration = 4
gd loss = 6202.508263906198
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 6200.887289441858
gradient descent iteration = 5
gd loss = 6200.887289441858
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6199.560252897521
gradient descent iteration = 6
gd loss = 6199.560252897521
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6198.415470108582
gradient descent iteration = 7
gd loss = 6198.415470108582
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6197.270545809202
gradient descent iteration = 8
gd loss = 6197.270545809202
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6196.237581345386
gradient descent iteration = 9
gd loss = 6196.237581345386
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6195.165401078666
gradient descent iteration = 10
gd loss = 6195.165401078666
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6194.193110288575
gradient descent iteration = 11
gd loss = 6194.193110288575
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6193.178600928613
gradient descent iteration = 12
gd loss = 6193.178600928613
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6192.249196801689
gradient descent iteration = 13
gd loss = 6192.249196801689
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6191.282264626252
gradient descent iteration = 14
gd loss = 6191.282264626252
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6190.387426227155
gradient descent iteration = 15
gd loss = 6190.387426227155
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6189.460816757044
gradient descent iteration = 16
gd loss = 6189.460816757044
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6188.595735569722
gradient descent iteration = 17
gd loss = 6188.595735569722
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6187.704349221559
gradient descent iteration = 18
gd loss = 6187.704349221559
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6186.865809382058
gradient descent iteration = 19
gd loss = 6186.865809382058
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6186.005912499199
gradient descent iteration = 20
gd loss = 6186.005912499199
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6185.191498496296
gradient descent iteration = 21
gd loss = 6185.191498496296
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6184.360135046523
gradient descent iteration = 22
gd loss = 6184.360135046523
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6183.567837264
gradient descent iteration = 23
gd loss = 6183.567837264
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6182.762448203319
gradient descent iteration = 24
gd loss = 6182.762448203319
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6181.990458248273
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6181.990458248273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6180.149388734164
gradient descent iteration = 1
gd loss = 6180.149388734164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6180.102517749273
gradient descent iteration = 2
gd loss = 6180.102517749273
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 6176.974945233382
gradient descent iteration = 3
gd loss = 6176.974945233382
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6175.914910041955
gradient descent iteration = 4
gd loss = 6175.914910041955
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6175.141935162164
gradient descent iteration = 5
gd loss = 6175.141935162164
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6174.424757105663
gradient descent iteration = 6
gd loss = 6174.424757105663
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6173.729656828909
gradient descent iteration = 7
gd loss = 6173.729656828909
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6173.050313445042
gradient descent iteration = 8
gd loss = 6173.050313445042
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6172.384492855824
gradient descent iteration = 9
gd loss = 6172.384492855824
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6171.730769013629
gradient descent iteration = 10
gd loss = 6171.730769013629
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6171.088013508804
gradient descent iteration = 11
gd loss = 6171.088013508804
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6170.455284593499
gradient descent iteration = 12
gd loss = 6170.455284593499
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6169.831781315397
gradient descent iteration = 13
gd loss = 6169.831781315397
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6169.21681475686
gradient descent iteration = 14
gd loss = 6169.21681475686
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6168.609786911975
gradient descent iteration = 15
gd loss = 6168.609786911975
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6168.010174544977
gradient descent iteration = 16
gd loss = 6168.010174544977
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6167.417516550907
gradient descent iteration = 17
gd loss = 6167.417516550907
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6166.831403999605
gradient descent iteration = 18
gd loss = 6166.831403999605
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6166.251472886821
gradient descent iteration = 19
gd loss = 6166.251472886821
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6165.677398273855
gradient descent iteration = 20
gd loss = 6165.677398273855
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6165.108887669403
gradient descent iteration = 21
gd loss = 6165.108887669403
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6164.54567649613
gradient descent iteration = 22
gd loss = 6164.54567649613
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6163.987524445312
gradient descent iteration = 23
gd loss = 6163.987524445312
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6163.43421241848
gradient descent iteration = 24
gd loss = 6163.43421241848
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6162.885539953283
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6162.885539953283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6161.274024969941
gradient descent iteration = 1
gd loss = 6161.274024969941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6159.85585174137
gradient descent iteration = 2
gd loss = 6159.85585174137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6158.523539554712
gradient descent iteration = 3
gd loss = 6158.523539554712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6157.245645314491
gradient descent iteration = 4
gd loss = 6157.245645314491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6156.009033791901
gradient descent iteration = 5
gd loss = 6156.009033791901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6154.806704833192
gradient descent iteration = 6
gd loss = 6154.806704833192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6153.634213255604
gradient descent iteration = 7
gd loss = 6153.634213255604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6152.488377296567
gradient descent iteration = 8
gd loss = 6152.488377296567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6151.366788351479
gradient descent iteration = 9
gd loss = 6151.366788351479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6150.267498495276
gradient descent iteration = 10
gd loss = 6150.267498495276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6149.188927355114
gradient descent iteration = 11
gd loss = 6149.188927355114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6148.129718656764
gradient descent iteration = 12
gd loss = 6148.129718656764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6147.088734897696
gradient descent iteration = 13
gd loss = 6147.088734897696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6146.0649610456
gradient descent iteration = 14
gd loss = 6146.0649610456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6145.05753006643
gradient descent iteration = 15
gd loss = 6145.05753006643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6144.065649849078
gradient descent iteration = 16
gd loss = 6144.065649849078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6143.088640528723
gradient descent iteration = 17
gd loss = 6143.088640528723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6142.12587482355
gradient descent iteration = 18
gd loss = 6142.12587482355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6141.176811030304
gradient descent iteration = 19
gd loss = 6141.176811030304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6140.240953254787
gradient descent iteration = 20
gd loss = 6140.240953254787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6139.317876716718
gradient descent iteration = 21
gd loss = 6139.317876716718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6138.407216735839
gradient descent iteration = 22
gd loss = 6138.407216735839
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6137.508693186863
gradient descent iteration = 23
gd loss = 6137.508693186863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6136.622151227291
gradient descent iteration = 24
gd loss = 6136.622151227291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6135.747719412668
Initial loss = 6244.25087465764
Final loss = 6135.747719412668
Deformation gradient control sequence optimization finished.
Animation interval 30 took 1159 seconds.
Full animation took 37566 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 31************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6138.488536134411
initial norm = 341.4600624424258
convergence norm = 0.3414600624424258
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6138.488536134411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6115.892870723942
gradient descent iteration = 1
gd loss = 6115.892870723942
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6104.573760305435
gradient descent iteration = 2
gd loss = 6104.573760305435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6099.131285523222
gradient descent iteration = 3
gd loss = 6099.131285523222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6098.26562362703
gradient descent iteration = 4
gd loss = 6098.26562362703
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6095.027939750218
gradient descent iteration = 5
gd loss = 6095.027939750218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6094.103343606769
gradient descent iteration = 6
gd loss = 6094.103343606769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6092.075802481087
gradient descent iteration = 7
gd loss = 6092.075802481087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6091.150038250204
gradient descent iteration = 8
gd loss = 6091.150038250204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6089.632954639696
gradient descent iteration = 9
gd loss = 6089.632954639696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6088.702241313937
gradient descent iteration = 10
gd loss = 6088.702241313937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6087.43547785897
gradient descent iteration = 11
gd loss = 6087.43547785897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6086.508902345252
gradient descent iteration = 12
gd loss = 6086.508902345252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6085.39724517144
gradient descent iteration = 13
gd loss = 6085.39724517144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6084.483541698358
gradient descent iteration = 14
gd loss = 6084.483541698358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6083.479777185551
gradient descent iteration = 15
gd loss = 6083.479777185551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6082.590200201133
gradient descent iteration = 16
gd loss = 6082.590200201133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6081.674635813643
gradient descent iteration = 17
gd loss = 6081.674635813643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6080.824777190724
gradient descent iteration = 18
gd loss = 6080.824777190724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6079.994233268617
gradient descent iteration = 19
gd loss = 6079.994233268617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6079.202382364206
gradient descent iteration = 20
gd loss = 6079.202382364206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6078.453315162432
gradient descent iteration = 21
gd loss = 6078.453315162432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6077.717517204834
gradient descent iteration = 22
gd loss = 6077.717517204834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6077.016109047501
gradient descent iteration = 23
gd loss = 6077.016109047501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6076.296033078053
gradient descent iteration = 24
gd loss = 6076.296033078053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6075.60653418411
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6075.60653418411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6072.019719584112
gradient descent iteration = 1
gd loss = 6072.019719584112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6070.769273165691
gradient descent iteration = 2
gd loss = 6070.769273165691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6069.869378253984
gradient descent iteration = 3
gd loss = 6069.869378253984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6069.076629110652
gradient descent iteration = 4
gd loss = 6069.076629110652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6068.335252828186
gradient descent iteration = 5
gd loss = 6068.335252828186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6067.626596887094
gradient descent iteration = 6
gd loss = 6067.626596887094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6066.942037744312
gradient descent iteration = 7
gd loss = 6066.942037744312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6066.276616381341
gradient descent iteration = 8
gd loss = 6066.276616381341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6065.627085152511
gradient descent iteration = 9
gd loss = 6065.627085152511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6064.991141287584
gradient descent iteration = 10
gd loss = 6064.991141287584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6064.367065137152
gradient descent iteration = 11
gd loss = 6064.367065137152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6063.753524654513
gradient descent iteration = 12
gd loss = 6063.753524654513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6063.149459263482
gradient descent iteration = 13
gd loss = 6063.149459263482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6062.554005992818
gradient descent iteration = 14
gd loss = 6062.554005992818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6061.966450088202
gradient descent iteration = 15
gd loss = 6061.966450088202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6061.386190718797
gradient descent iteration = 16
gd loss = 6061.386190718797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6060.812716487941
gradient descent iteration = 17
gd loss = 6060.812716487941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6060.245587443319
gradient descent iteration = 18
gd loss = 6060.245587443319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6059.684422066409
gradient descent iteration = 19
gd loss = 6059.684422066409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6059.128886623742
gradient descent iteration = 20
gd loss = 6059.128886623742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6058.57868666025
gradient descent iteration = 21
gd loss = 6058.57868666025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6058.033560624354
gradient descent iteration = 22
gd loss = 6058.033560624354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6057.493274761523
gradient descent iteration = 23
gd loss = 6057.493274761523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6056.957618991327
gradient descent iteration = 24
gd loss = 6056.957618991327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6056.426403537704
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6056.426403537704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6055.672585895771
gradient descent iteration = 1
gd loss = 6055.672585895771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6054.998603009276
gradient descent iteration = 2
gd loss = 6054.998603009276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6054.357148757755
gradient descent iteration = 3
gd loss = 6054.357148757755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6053.73810196941
gradient descent iteration = 4
gd loss = 6053.73810196941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6053.136077112597
gradient descent iteration = 5
gd loss = 6053.136077112597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6052.547775665284
gradient descent iteration = 6
gd loss = 6052.547775665284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6051.971029701501
gradient descent iteration = 7
gd loss = 6051.971029701501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6051.40433356697
gradient descent iteration = 8
gd loss = 6051.40433356697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6050.846589737318
gradient descent iteration = 9
gd loss = 6050.846589737318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6050.296963205422
gradient descent iteration = 10
gd loss = 6050.296963205422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6049.75479472265
gradient descent iteration = 11
gd loss = 6049.75479472265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6049.219547316394
gradient descent iteration = 12
gd loss = 6049.219547316394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6048.690772244118
gradient descent iteration = 13
gd loss = 6048.690772244118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6048.168086644638
gradient descent iteration = 14
gd loss = 6048.168086644638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6047.651158404253
gradient descent iteration = 15
gd loss = 6047.651158404253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6047.139695515924
gradient descent iteration = 16
gd loss = 6047.139695515924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6046.633438378055
gradient descent iteration = 17
gd loss = 6046.633438378055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6046.132154084256
gradient descent iteration = 18
gd loss = 6046.132154084256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6045.635632070576
gradient descent iteration = 19
gd loss = 6045.635632070576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6045.143680715863
gradient descent iteration = 20
gd loss = 6045.143680715863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6044.656124648646
gradient descent iteration = 21
gd loss = 6044.656124648646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6044.172802565977
gradient descent iteration = 22
gd loss = 6044.172802565977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6043.693565446589
gradient descent iteration = 23
gd loss = 6043.693565446589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6043.218275073737
gradient descent iteration = 24
gd loss = 6043.218275073737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6042.746802806915
Initial loss = 6138.488536134411
Final loss = 6042.746802806915
Deformation gradient control sequence optimization finished.
Animation interval 31 took 1155 seconds.
Full animation took 38721 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 32************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6032.26037908018
initial norm = 184.0621565166025
convergence norm = 0.1840621565166025
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6032.26037908018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6018.817507256411
gradient descent iteration = 1
gd loss = 6018.817507256411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6010.570555652147
gradient descent iteration = 2
gd loss = 6010.570555652147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6006.169829526965
gradient descent iteration = 3
gd loss = 6006.169829526965
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 6004.339335425339
gradient descent iteration = 4
gd loss = 6004.339335425339
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6002.995283743099
gradient descent iteration = 5
gd loss = 6002.995283743099
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6001.910147819573
gradient descent iteration = 6
gd loss = 6001.910147819573
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 6000.820258819101
gradient descent iteration = 7
gd loss = 6000.820258819101
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5999.91510724368
gradient descent iteration = 8
gd loss = 5999.91510724368
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5998.933047363964
gradient descent iteration = 9
gd loss = 5998.933047363964
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5998.107123311451
gradient descent iteration = 10
gd loss = 5998.107123311451
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5997.212132740755
gradient descent iteration = 11
gd loss = 5997.212132740755
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5996.431831911843
gradient descent iteration = 12
gd loss = 5996.431831911843
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5995.592386047044
gradient descent iteration = 13
gd loss = 5995.592386047044
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5994.845146396679
gradient descent iteration = 14
gd loss = 5994.845146396679
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5994.046074491406
gradient descent iteration = 15
gd loss = 5994.046074491406
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5993.324337832386
gradient descent iteration = 16
gd loss = 5993.324337832386
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5992.556567185203
gradient descent iteration = 17
gd loss = 5992.556567185203
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5991.855463993585
gradient descent iteration = 18
gd loss = 5991.855463993585
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5991.113094338211
gradient descent iteration = 19
gd loss = 5991.113094338211
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5990.429287573537
gradient descent iteration = 20
gd loss = 5990.429287573537
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5989.708182174697
gradient descent iteration = 21
gd loss = 5989.708182174697
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5989.039270201502
gradient descent iteration = 22
gd loss = 5989.039270201502
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5988.336385664257
gradient descent iteration = 23
gd loss = 5988.336385664257
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5987.680569396757
gradient descent iteration = 24
gd loss = 5987.680569396757
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5986.993586010331
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5986.993586010331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5985.53386680647
gradient descent iteration = 1
gd loss = 5985.53386680647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5985.410085914642
gradient descent iteration = 2
gd loss = 5985.410085914642
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5982.576596252018
gradient descent iteration = 3
gd loss = 5982.576596252018
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5981.725139498198
gradient descent iteration = 4
gd loss = 5981.725139498198
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5981.071908476894
gradient descent iteration = 5
gd loss = 5981.071908476894
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5980.45078356786
gradient descent iteration = 6
gd loss = 5980.45078356786
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5979.843893410609
gradient descent iteration = 7
gd loss = 5979.843893410609
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5979.248188610149
gradient descent iteration = 8
gd loss = 5979.248188610149
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5978.662333498018
gradient descent iteration = 9
gd loss = 5978.662333498018
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5978.08535040729
gradient descent iteration = 10
gd loss = 5978.08535040729
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5977.516439578695
gradient descent iteration = 11
gd loss = 5977.516439578695
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5976.954929426664
gradient descent iteration = 12
gd loss = 5976.954929426664
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5976.400248205435
gradient descent iteration = 13
gd loss = 5976.400248205435
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5975.851903999132
gradient descent iteration = 14
gd loss = 5975.851903999132
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5975.309469730948
gradient descent iteration = 15
gd loss = 5975.309469730948
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5974.772571651675
gradient descent iteration = 16
gd loss = 5974.772571651675
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5974.240880369513
gradient descent iteration = 17
gd loss = 5974.240880369513
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5973.714103717359
gradient descent iteration = 18
gd loss = 5973.714103717359
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5973.191981115875
gradient descent iteration = 19
gd loss = 5973.191981115875
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5972.674278934064
gradient descent iteration = 20
gd loss = 5972.674278934064
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5972.160786725742
gradient descent iteration = 21
gd loss = 5972.160786725742
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5971.651314121516
gradient descent iteration = 22
gd loss = 5971.651314121516
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5971.145688236423
gradient descent iteration = 23
gd loss = 5971.145688236423
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5970.643751501887
gradient descent iteration = 24
gd loss = 5970.643751501887
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5970.145359827537
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5970.145359827537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5968.846336614317
gradient descent iteration = 1
gd loss = 5968.846336614317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5967.678871782407
gradient descent iteration = 2
gd loss = 5967.678871782407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5966.568122806728
gradient descent iteration = 3
gd loss = 5966.568122806728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5965.493896186095
gradient descent iteration = 4
gd loss = 5965.493896186095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5964.447709958466
gradient descent iteration = 5
gd loss = 5964.447709958466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5963.424941276665
gradient descent iteration = 6
gd loss = 5963.424941276665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5962.422600828208
gradient descent iteration = 7
gd loss = 5962.422600828208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5961.438526362763
gradient descent iteration = 8
gd loss = 5961.438526362763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5960.471063758907
gradient descent iteration = 9
gd loss = 5960.471063758907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5959.518882475259
gradient descent iteration = 10
gd loss = 5959.518882475259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5958.580891578315
gradient descent iteration = 11
gd loss = 5958.580891578315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5957.656167196254
gradient descent iteration = 12
gd loss = 5957.656167196254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5956.743922825896
gradient descent iteration = 13
gd loss = 5956.743922825896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5955.843476724236
gradient descent iteration = 14
gd loss = 5955.843476724236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5954.95425232813
gradient descent iteration = 15
gd loss = 5954.95425232813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5954.075748557913
gradient descent iteration = 16
gd loss = 5954.075748557913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5953.20752144545
gradient descent iteration = 17
gd loss = 5953.20752144545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5952.349167995904
gradient descent iteration = 18
gd loss = 5952.349167995904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5951.500326115965
gradient descent iteration = 19
gd loss = 5951.500326115965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5950.660662539906
gradient descent iteration = 20
gd loss = 5950.660662539906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5949.829874378512
gradient descent iteration = 21
gd loss = 5949.829874378512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5949.007679260332
gradient descent iteration = 22
gd loss = 5949.007679260332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5948.193818127103
gradient descent iteration = 23
gd loss = 5948.193818127103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5947.38804785477
gradient descent iteration = 24
gd loss = 5947.38804785477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5946.590144379668
Initial loss = 6032.26037908018
Final loss = 5946.590144379668
Deformation gradient control sequence optimization finished.
Animation interval 32 took 1158 seconds.
Full animation took 39879 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 33************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5960.397303450994
initial norm = 371.5944425771608
convergence norm = 0.3715944425771608
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5960.397303450994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5935.666876903231
gradient descent iteration = 1
gd loss = 5935.666876903231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5924.369826857522
gradient descent iteration = 2
gd loss = 5924.369826857522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5917.723819809598
gradient descent iteration = 3
gd loss = 5917.723819809598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5916.534235990609
gradient descent iteration = 4
gd loss = 5916.534235990609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5914.812075765679
gradient descent iteration = 5
gd loss = 5914.812075765679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5913.862569279022
gradient descent iteration = 6
gd loss = 5913.862569279022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5912.586623888436
gradient descent iteration = 7
gd loss = 5912.586623888436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5911.762987373781
gradient descent iteration = 8
gd loss = 5911.762987373781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5910.696976583266
gradient descent iteration = 9
gd loss = 5910.696976583266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5909.930982420953
gradient descent iteration = 10
gd loss = 5909.930982420953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5908.991178542772
gradient descent iteration = 11
gd loss = 5908.991178542772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5908.268490410709
gradient descent iteration = 12
gd loss = 5908.268490410709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5907.428085325117
gradient descent iteration = 13
gd loss = 5907.428085325117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5906.756995683101
gradient descent iteration = 14
gd loss = 5906.756995683101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5906.001775030799
gradient descent iteration = 15
gd loss = 5906.001775030799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5905.341068028182
gradient descent iteration = 16
gd loss = 5905.341068028182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5904.629621829949
gradient descent iteration = 17
gd loss = 5904.629621829949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5903.952835595182
gradient descent iteration = 18
gd loss = 5903.952835595182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5903.282974977955
gradient descent iteration = 19
gd loss = 5903.282974977955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5902.604187525197
gradient descent iteration = 20
gd loss = 5902.604187525197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5901.964843852236
gradient descent iteration = 21
gd loss = 5901.964843852236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5901.287848231417
gradient descent iteration = 22
gd loss = 5901.287848231417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5900.671787808426
gradient descent iteration = 23
gd loss = 5900.671787808426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5900.001526960699
gradient descent iteration = 24
gd loss = 5900.001526960699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5899.403763423423
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5899.403763423423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5895.773892737825
gradient descent iteration = 1
gd loss = 5895.773892737825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5894.704185665337
gradient descent iteration = 2
gd loss = 5894.704185665337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5893.935301178582
gradient descent iteration = 3
gd loss = 5893.935301178582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5893.255051130335
gradient descent iteration = 4
gd loss = 5893.255051130335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5892.617644117824
gradient descent iteration = 5
gd loss = 5892.617644117824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5892.007631065619
gradient descent iteration = 6
gd loss = 5892.007631065619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5891.417789962924
gradient descent iteration = 7
gd loss = 5891.417789962924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5890.843978994503
gradient descent iteration = 8
gd loss = 5890.843978994503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5890.283509171583
gradient descent iteration = 9
gd loss = 5890.283509171583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5889.734490675715
gradient descent iteration = 10
gd loss = 5889.734490675715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5889.195522541824
gradient descent iteration = 11
gd loss = 5889.195522541824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5888.665525796445
gradient descent iteration = 12
gd loss = 5888.665525796445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5888.143645105331
gradient descent iteration = 13
gd loss = 5888.143645105331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5887.629186732448
gradient descent iteration = 14
gd loss = 5887.629186732448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5887.121577379554
gradient descent iteration = 15
gd loss = 5887.121577379554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5886.620335817073
gradient descent iteration = 16
gd loss = 5886.620335817073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5886.12505269491
gradient descent iteration = 17
gd loss = 5886.12505269491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5885.635375803729
gradient descent iteration = 18
gd loss = 5885.635375803729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5885.150999080392
gradient descent iteration = 19
gd loss = 5885.150999080392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5884.671654247198
gradient descent iteration = 20
gd loss = 5884.671654247198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5884.19710429866
gradient descent iteration = 21
gd loss = 5884.19710429866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5883.727138390484
gradient descent iteration = 22
gd loss = 5883.727138390484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5883.261567773289
gradient descent iteration = 23
gd loss = 5883.261567773289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5882.800222502244
gradient descent iteration = 24
gd loss = 5882.800222502244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5882.342948758498
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5882.342948758498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5881.683087600967
gradient descent iteration = 1
gd loss = 5881.683087600967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5881.080500468136
gradient descent iteration = 2
gd loss = 5881.080500468136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5880.502616118082
gradient descent iteration = 3
gd loss = 5880.502616118082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5879.942125308142
gradient descent iteration = 4
gd loss = 5879.942125308142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5879.395161581845
gradient descent iteration = 5
gd loss = 5879.395161581845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5878.85935605835
gradient descent iteration = 6
gd loss = 5878.85935605835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5878.333150501542
gradient descent iteration = 7
gd loss = 5878.333150501542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5877.815458598331
gradient descent iteration = 8
gd loss = 5877.815458598331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5877.305482325919
gradient descent iteration = 9
gd loss = 5877.305482325919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5876.802607470205
gradient descent iteration = 10
gd loss = 5876.802607470205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5876.306342008816
gradient descent iteration = 11
gd loss = 5876.306342008816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5875.816278591038
gradient descent iteration = 12
gd loss = 5875.816278591038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5875.332070960595
gradient descent iteration = 13
gd loss = 5875.332070960595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5874.853418648219
gradient descent iteration = 14
gd loss = 5874.853418648219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5874.380056702586
gradient descent iteration = 15
gd loss = 5874.380056702586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5873.911748546854
gradient descent iteration = 16
gd loss = 5873.911748546854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5873.448280836225
gradient descent iteration = 17
gd loss = 5873.448280836225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5872.989459647002
gradient descent iteration = 18
gd loss = 5872.989459647002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5872.535107559172
gradient descent iteration = 19
gd loss = 5872.535107559172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5872.085061370792
gradient descent iteration = 20
gd loss = 5872.085061370792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5871.639170269017
gradient descent iteration = 21
gd loss = 5871.639170269017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5871.197294331982
gradient descent iteration = 22
gd loss = 5871.197294331982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5870.759303290151
gradient descent iteration = 23
gd loss = 5870.759303290151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5870.325075483779
gradient descent iteration = 24
gd loss = 5870.325075483779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5869.894496978935
Initial loss = 5960.397303450994
Final loss = 5869.894496978935
Deformation gradient control sequence optimization finished.
Animation interval 33 took 1155 seconds.
Full animation took 41035 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 34************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5860.473335987826
initial norm = 173.7228699939305
convergence norm = 0.1737228699939305
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5860.473335987826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5850.109168691266
gradient descent iteration = 1
gd loss = 5850.109168691266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5845.326403635301
gradient descent iteration = 2
gd loss = 5845.326403635301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5845.232889977838
gradient descent iteration = 3
gd loss = 5845.232889977838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5842.719989517635
gradient descent iteration = 4
gd loss = 5842.719989517635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5842.581835956608
gradient descent iteration = 5
gd loss = 5842.581835956608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5840.759913281413
gradient descent iteration = 6
gd loss = 5840.759913281413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5840.547045743689
gradient descent iteration = 7
gd loss = 5840.547045743689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5839.088187439918
gradient descent iteration = 8
gd loss = 5839.088187439918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5838.835031302802
gradient descent iteration = 9
gd loss = 5838.835031302802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5837.630867644182
gradient descent iteration = 10
gd loss = 5837.630867644182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5837.391280130199
gradient descent iteration = 11
gd loss = 5837.391280130199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5836.358238057212
gradient descent iteration = 12
gd loss = 5836.358238057212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5836.069634466501
gradient descent iteration = 13
gd loss = 5836.069634466501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5835.092978020482
gradient descent iteration = 14
gd loss = 5835.092978020482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5834.75531789843
gradient descent iteration = 15
gd loss = 5834.75531789843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5833.850974222026
gradient descent iteration = 16
gd loss = 5833.850974222026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5833.479068717341
gradient descent iteration = 17
gd loss = 5833.479068717341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5832.62773300167
gradient descent iteration = 18
gd loss = 5832.62773300167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5832.231259240352
gradient descent iteration = 19
gd loss = 5832.231259240352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5831.439906326862
gradient descent iteration = 20
gd loss = 5831.439906326862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5831.027540887212
gradient descent iteration = 21
gd loss = 5831.027540887212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5830.276045818897
gradient descent iteration = 22
gd loss = 5830.276045818897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5829.853356554895
gradient descent iteration = 23
gd loss = 5829.853356554895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5829.142061692964
gradient descent iteration = 24
gd loss = 5829.142061692964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5828.713440141473
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5828.713440141473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5825.112999602375
gradient descent iteration = 1
gd loss = 5825.112999602375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5824.134308783448
gradient descent iteration = 2
gd loss = 5824.134308783448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5823.451341628272
gradient descent iteration = 3
gd loss = 5823.451341628272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5822.851693328699
gradient descent iteration = 4
gd loss = 5822.851693328699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5822.29019544611
gradient descent iteration = 5
gd loss = 5822.29019544611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5821.752625523083
gradient descent iteration = 6
gd loss = 5821.752625523083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5821.232645782763
gradient descent iteration = 7
gd loss = 5821.232645782763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5820.726678527785
gradient descent iteration = 8
gd loss = 5820.726678527785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5820.232404601426
gradient descent iteration = 9
gd loss = 5820.232404601426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5819.748189741068
gradient descent iteration = 10
gd loss = 5819.748189741068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5819.272818262853
gradient descent iteration = 11
gd loss = 5819.272818262853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5818.805350599379
gradient descent iteration = 12
gd loss = 5818.805350599379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5818.345039283494
gradient descent iteration = 13
gd loss = 5818.345039283494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5817.89127585825
gradient descent iteration = 14
gd loss = 5817.89127585825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5817.443555618869
gradient descent iteration = 15
gd loss = 5817.443555618869
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5817.00145330515
gradient descent iteration = 16
gd loss = 5817.00145330515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5816.564605822287
gradient descent iteration = 17
gd loss = 5816.564605822287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5816.132699628637
gradient descent iteration = 18
gd loss = 5816.132699628637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5815.705461324953
gradient descent iteration = 19
gd loss = 5815.705461324953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5815.282650488137
gradient descent iteration = 20
gd loss = 5815.282650488137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5814.864054113386
gradient descent iteration = 21
gd loss = 5814.864054113386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5814.449482232409
gradient descent iteration = 22
gd loss = 5814.449482232409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5814.038764420253
gradient descent iteration = 23
gd loss = 5814.038764420253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5813.63174696618
gradient descent iteration = 24
gd loss = 5813.63174696618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5813.228290560319
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5813.228290560319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5812.599398826029
gradient descent iteration = 1
gd loss = 5812.599398826029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5812.023343291728
gradient descent iteration = 2
gd loss = 5812.023343291728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5811.470806606028
gradient descent iteration = 3
gd loss = 5811.470806606028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5810.93544416499
gradient descent iteration = 4
gd loss = 5810.93544416499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5810.413854832816
gradient descent iteration = 5
gd loss = 5810.413854832816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5809.903922020271
gradient descent iteration = 6
gd loss = 5809.903922020271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5809.404223722788
gradient descent iteration = 7
gd loss = 5809.404223722788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5808.913742904383
gradient descent iteration = 8
gd loss = 5808.913742904383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5808.431711369657
gradient descent iteration = 9
gd loss = 5808.431711369657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5807.957521227311
gradient descent iteration = 10
gd loss = 5807.957521227311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5807.490672737209
gradient descent iteration = 11
gd loss = 5807.490672737209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5807.030742511179
gradient descent iteration = 12
gd loss = 5807.030742511179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5806.577363439989
gradient descent iteration = 13
gd loss = 5806.577363439989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5806.130211560096
gradient descent iteration = 14
gd loss = 5806.130211560096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5805.688997134167
gradient descent iteration = 15
gd loss = 5805.688997134167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5805.253458362894
gradient descent iteration = 16
gd loss = 5805.253458362894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5804.823356786121
gradient descent iteration = 17
gd loss = 5804.823356786121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5804.398473810723
gradient descent iteration = 18
gd loss = 5804.398473810723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5803.978608004072
gradient descent iteration = 19
gd loss = 5803.978608004072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5803.563572933653
gradient descent iteration = 20
gd loss = 5803.563572933653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5803.153195403564
gradient descent iteration = 21
gd loss = 5803.153195403564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5802.747313989194
gradient descent iteration = 22
gd loss = 5802.747313989194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5802.345777803402
gradient descent iteration = 23
gd loss = 5802.345777803402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5801.94844544258
gradient descent iteration = 24
gd loss = 5801.94844544258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5801.555184080011
Initial loss = 5860.473335987826
Final loss = 5801.555184080011
Deformation gradient control sequence optimization finished.
Animation interval 34 took 1155 seconds.
Full animation took 42190 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 35************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5803.251580929791
initial norm = 231.2365946395004
convergence norm = 0.2312365946395004
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5803.251580929791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5789.44899585758
gradient descent iteration = 1
gd loss = 5789.44899585758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5782.193693970392
gradient descent iteration = 2
gd loss = 5782.193693970392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5780.817557875564
gradient descent iteration = 3
gd loss = 5780.817557875564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5779.63921960217
gradient descent iteration = 4
gd loss = 5779.63921960217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5778.934189727946
gradient descent iteration = 5
gd loss = 5778.934189727946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5777.782361952066
gradient descent iteration = 6
gd loss = 5777.782361952066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5777.339225100668
gradient descent iteration = 7
gd loss = 5777.339225100668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5776.375640775258
gradient descent iteration = 8
gd loss = 5776.375640775258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5775.960017309108
gradient descent iteration = 9
gd loss = 5775.960017309108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5775.116475924684
gradient descent iteration = 10
gd loss = 5775.116475924684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5774.707006401736
gradient descent iteration = 11
gd loss = 5774.707006401736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5773.94592980896
gradient descent iteration = 12
gd loss = 5773.94592980896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5773.535907529118
gradient descent iteration = 13
gd loss = 5773.535907529118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5772.836876037394
gradient descent iteration = 14
gd loss = 5772.836876037394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5772.424732114956
gradient descent iteration = 15
gd loss = 5772.424732114956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5771.774823136149
gradient descent iteration = 16
gd loss = 5771.774823136149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5771.360646279667
gradient descent iteration = 17
gd loss = 5771.360646279667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5770.750884236688
gradient descent iteration = 18
gd loss = 5770.750884236688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5770.335302982417
gradient descent iteration = 19
gd loss = 5770.335302982417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5769.759088215346
gradient descent iteration = 20
gd loss = 5769.759088215346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5769.34286919762
gradient descent iteration = 21
gd loss = 5769.34286919762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5768.79516810865
gradient descent iteration = 22
gd loss = 5768.79516810865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5768.379062198355
gradient descent iteration = 23
gd loss = 5768.379062198355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5767.855936380262
gradient descent iteration = 24
gd loss = 5767.855936380262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5767.440620134837
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5767.440620134837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5763.728755798728
gradient descent iteration = 1
gd loss = 5763.728755798728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5762.997654893986
gradient descent iteration = 2
gd loss = 5762.997654893986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5762.4706495832
gradient descent iteration = 3
gd loss = 5762.4706495832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5761.993286895477
gradient descent iteration = 4
gd loss = 5761.993286895477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5761.539683604814
gradient descent iteration = 5
gd loss = 5761.539683604814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5761.102266519362
gradient descent iteration = 6
gd loss = 5761.102266519362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5760.677515182092
gradient descent iteration = 7
gd loss = 5760.677515182092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5760.263304528938
gradient descent iteration = 8
gd loss = 5760.263304528938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5759.858171788736
gradient descent iteration = 9
gd loss = 5759.858171788736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5759.461033789989
gradient descent iteration = 10
gd loss = 5759.461033789989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5759.07105047143
gradient descent iteration = 11
gd loss = 5759.07105047143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5758.687548995599
gradient descent iteration = 12
gd loss = 5758.687548995599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5758.309977365174
gradient descent iteration = 13
gd loss = 5758.309977365174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5757.937874153277
gradient descent iteration = 14
gd loss = 5757.937874153277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5757.570847752427
gradient descent iteration = 15
gd loss = 5757.570847752427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5757.208561618695
gradient descent iteration = 16
gd loss = 5757.208561618695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5756.850723487242
gradient descent iteration = 17
gd loss = 5756.850723487242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5756.49707725698
gradient descent iteration = 18
gd loss = 5756.49707725698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5756.147396756067
gradient descent iteration = 19
gd loss = 5756.147396756067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5755.801480871827
gradient descent iteration = 20
gd loss = 5755.801480871827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5755.459149679916
gradient descent iteration = 21
gd loss = 5755.459149679916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5755.120241328622
gradient descent iteration = 22
gd loss = 5755.120241328622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5754.784609495269
gradient descent iteration = 23
gd loss = 5754.784609495269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5754.452121293097
gradient descent iteration = 24
gd loss = 5754.452121293097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5754.122655526592
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5754.122655526592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5753.652513720603
gradient descent iteration = 1
gd loss = 5753.652513720603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5753.212243679032
gradient descent iteration = 2
gd loss = 5753.212243679032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5752.788449139331
gradient descent iteration = 3
gd loss = 5752.788449139331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5752.376829569579
gradient descent iteration = 4
gd loss = 5752.376829569579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5751.97495904718
gradient descent iteration = 5
gd loss = 5751.97495904718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5751.581292211743
gradient descent iteration = 6
gd loss = 5751.581292211743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5751.194777367297
gradient descent iteration = 7
gd loss = 5751.194777367297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5750.814659213157
gradient descent iteration = 8
gd loss = 5750.814659213157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5750.440368958518
gradient descent iteration = 9
gd loss = 5750.440368958518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5750.071460215214
gradient descent iteration = 10
gd loss = 5750.071460215214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5749.707570261683
gradient descent iteration = 11
gd loss = 5749.707570261683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5749.348395871837
gradient descent iteration = 12
gd loss = 5749.348395871837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5748.993677737105
gradient descent iteration = 13
gd loss = 5748.993677737105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5748.643190087397
gradient descent iteration = 14
gd loss = 5748.643190087397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5748.296733541888
gradient descent iteration = 15
gd loss = 5748.296733541888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5747.954130024694
gradient descent iteration = 16
gd loss = 5747.954130024694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5747.615219031954
gradient descent iteration = 17
gd loss = 5747.615219031954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5747.279854805659
gradient descent iteration = 18
gd loss = 5747.279854805659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5746.947904137921
gradient descent iteration = 19
gd loss = 5746.947904137921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5746.619244631033
gradient descent iteration = 20
gd loss = 5746.619244631033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5746.293763289002
gradient descent iteration = 21
gd loss = 5746.293763289002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5745.971355361145
gradient descent iteration = 22
gd loss = 5745.971355361145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5745.651923374136
gradient descent iteration = 23
gd loss = 5745.651923374136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5745.335376319064
gradient descent iteration = 24
gd loss = 5745.335376319064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5745.021628963821
Initial loss = 5803.251580929791
Final loss = 5745.021628963821
Deformation gradient control sequence optimization finished.
Animation interval 35 took 1155 seconds.
Full animation took 43345 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 36************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5742.355300380566
initial norm = 232.1342857219434
convergence norm = 0.2321342857219434
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5742.355300380566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5731.184299599308
gradient descent iteration = 1
gd loss = 5731.184299599308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5728.156027724519
gradient descent iteration = 2
gd loss = 5728.156027724519
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5725.950597730534
gradient descent iteration = 3
gd loss = 5725.950597730534
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5725.128497800536
gradient descent iteration = 4
gd loss = 5725.128497800536
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5724.520122353758
gradient descent iteration = 5
gd loss = 5724.520122353758
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5723.883763867896
gradient descent iteration = 6
gd loss = 5723.883763867896
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5723.32946116232
gradient descent iteration = 7
gd loss = 5723.32946116232
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5722.801016197919
gradient descent iteration = 8
gd loss = 5722.801016197919
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5722.287253278109
gradient descent iteration = 9
gd loss = 5722.287253278109
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5721.814101753499
gradient descent iteration = 10
gd loss = 5721.814101753499
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5721.330881848167
gradient descent iteration = 11
gd loss = 5721.330881848167
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5720.890466907588
gradient descent iteration = 12
gd loss = 5720.890466907588
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5720.430854698696
gradient descent iteration = 13
gd loss = 5720.430854698696
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5720.0123955147
gradient descent iteration = 14
gd loss = 5720.0123955147
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5719.571615171149
gradient descent iteration = 15
gd loss = 5719.571615171149
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5719.169344705228
gradient descent iteration = 16
gd loss = 5719.169344705228
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5718.744026294981
gradient descent iteration = 17
gd loss = 5718.744026294981
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5718.354533221642
gradient descent iteration = 18
gd loss = 5718.354533221642
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5717.942222311906
gradient descent iteration = 19
gd loss = 5717.942222311906
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5717.563310644984
gradient descent iteration = 20
gd loss = 5717.563310644984
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5717.162166396897
gradient descent iteration = 21
gd loss = 5717.162166396897
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5716.792321795821
gradient descent iteration = 22
gd loss = 5716.792321795821
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5716.400928524472
gradient descent iteration = 23
gd loss = 5716.400928524472
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5716.039047557274
gradient descent iteration = 24
gd loss = 5716.039047557274
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5715.656293112492
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5715.656293112492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5714.890752343823
gradient descent iteration = 1
gd loss = 5714.890752343823
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5713.609847415135
gradient descent iteration = 2
gd loss = 5713.609847415135
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5713.175667188132
gradient descent iteration = 3
gd loss = 5713.175667188132
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5712.807944613578
gradient descent iteration = 4
gd loss = 5712.807944613578
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5712.455320525933
gradient descent iteration = 5
gd loss = 5712.455320525933
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5712.111472516292
gradient descent iteration = 6
gd loss = 5712.111472516292
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5711.774701838811
gradient descent iteration = 7
gd loss = 5711.774701838811
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5711.444022954018
gradient descent iteration = 8
gd loss = 5711.444022954018
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5711.118701318858
gradient descent iteration = 9
gd loss = 5711.118701318858
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5710.798156098318
gradient descent iteration = 10
gd loss = 5710.798156098318
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5710.481916265157
gradient descent iteration = 11
gd loss = 5710.481916265157
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5710.169593099225
gradient descent iteration = 12
gd loss = 5710.169593099225
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5709.860861235094
gradient descent iteration = 13
gd loss = 5709.860861235094
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5709.555445112186
gradient descent iteration = 14
gd loss = 5709.555445112186
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5709.253109003525
gradient descent iteration = 15
gd loss = 5709.253109003525
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5708.953649514541
gradient descent iteration = 16
gd loss = 5708.953649514541
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5708.656889823705
gradient descent iteration = 17
gd loss = 5708.656889823705
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5708.362675186215
gradient descent iteration = 18
gd loss = 5708.362675186215
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5708.070869369016
gradient descent iteration = 19
gd loss = 5708.070869369016
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5707.781351790701
gradient descent iteration = 20
gd loss = 5707.781351790701
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5707.494015198513
gradient descent iteration = 21
gd loss = 5707.494015198513
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5707.208764686827
gradient descent iteration = 22
gd loss = 5707.208764686827
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5706.9255205722
gradient descent iteration = 23
gd loss = 5706.9255205722
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5706.644214010702
gradient descent iteration = 24
gd loss = 5706.644214010702
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5706.364783370192
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5706.364783370192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5705.587527581777
gradient descent iteration = 1
gd loss = 5705.587527581777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5704.874036807316
gradient descent iteration = 2
gd loss = 5704.874036807316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5704.190715168828
gradient descent iteration = 3
gd loss = 5704.190715168828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5703.527516069716
gradient descent iteration = 4
gd loss = 5703.527516069716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5702.879853603941
gradient descent iteration = 5
gd loss = 5702.879853603941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5702.245043490465
gradient descent iteration = 6
gd loss = 5702.245043490465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5701.621260819921
gradient descent iteration = 7
gd loss = 5701.621260819921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5701.007149760187
gradient descent iteration = 8
gd loss = 5701.007149760187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5700.401656506109
gradient descent iteration = 9
gd loss = 5700.401656506109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5699.803932944406
gradient descent iteration = 10
gd loss = 5699.803932944406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5699.213286439205
gradient descent iteration = 11
gd loss = 5699.213286439205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5698.62914096256
gradient descent iteration = 12
gd loss = 5698.62914096256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5698.05101661136
gradient descent iteration = 13
gd loss = 5698.05101661136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5697.478509832674
gradient descent iteration = 14
gd loss = 5697.478509832674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5696.911283901912
gradient descent iteration = 15
gd loss = 5696.911283901912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5696.349057316638
gradient descent iteration = 16
gd loss = 5696.349057316638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5695.791598929823
gradient descent iteration = 17
gd loss = 5695.791598929823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5695.238720212074
gradient descent iteration = 18
gd loss = 5695.238720212074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5694.690272384394
gradient descent iteration = 19
gd loss = 5694.690272384394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5694.146140619141
gradient descent iteration = 20
gd loss = 5694.146140619141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5693.606241922415
gradient descent iteration = 21
gd loss = 5693.606241922415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5693.070520246256
gradient descent iteration = 22
gd loss = 5693.070520246256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5692.538944565631
gradient descent iteration = 23
gd loss = 5692.538944565631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5692.011504496506
gradient descent iteration = 24
gd loss = 5692.011504496506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5691.48820832505
Initial loss = 5742.355300380566
Final loss = 5691.48820832505
Deformation gradient control sequence optimization finished.
Animation interval 36 took 1158 seconds.
Full animation took 44504 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 37************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5688.768692770769
initial norm = 190.6512239126538
convergence norm = 0.1906512239126538
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5688.768692770769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5680.023173537814
gradient descent iteration = 1
gd loss = 5680.023173537814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5678.440578832578
gradient descent iteration = 2
gd loss = 5678.440578832578
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5675.333844501981
gradient descent iteration = 3
gd loss = 5675.333844501981
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5674.443470019509
gradient descent iteration = 4
gd loss = 5674.443470019509
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5674.037927977233
gradient descent iteration = 5
gd loss = 5674.037927977233
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5673.390351518865
gradient descent iteration = 6
gd loss = 5673.390351518865
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5672.945116098237
gradient descent iteration = 7
gd loss = 5672.945116098237
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5672.455739975255
gradient descent iteration = 8
gd loss = 5672.455739975255
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5672.020355817547
gradient descent iteration = 9
gd loss = 5672.020355817547
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5671.577963805397
gradient descent iteration = 10
gd loss = 5671.577963805397
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5671.158089276822
gradient descent iteration = 11
gd loss = 5671.158089276822
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5670.743598902444
gradient descent iteration = 12
gd loss = 5670.743598902444
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5670.338446252406
gradient descent iteration = 13
gd loss = 5670.338446252406
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5669.943605271411
gradient descent iteration = 14
gd loss = 5669.943605271411
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5669.551232402211
gradient descent iteration = 15
gd loss = 5669.551232402211
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5669.171648350628
gradient descent iteration = 16
gd loss = 5669.171648350628
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5668.790490525849
gradient descent iteration = 17
gd loss = 5668.790490525849
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5668.423505105142
gradient descent iteration = 18
gd loss = 5668.423505105142
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5668.052365405057
gradient descent iteration = 19
gd loss = 5668.052365405057
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5667.696210486063
gradient descent iteration = 20
gd loss = 5667.696210486063
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5667.334147671741
gradient descent iteration = 21
gd loss = 5667.334147671741
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5666.987563854669
gradient descent iteration = 22
gd loss = 5666.987563854669
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5666.633812543727
gradient descent iteration = 23
gd loss = 5666.633812543727
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5666.29585371812
gradient descent iteration = 24
gd loss = 5666.29585371812
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5665.949774201679
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5665.949774201679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5665.1379907339
gradient descent iteration = 1
gd loss = 5665.1379907339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5665.087614262165
gradient descent iteration = 2
gd loss = 5665.087614262165
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5663.388267822007
gradient descent iteration = 3
gd loss = 5663.388267822007
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5662.97102416888
gradient descent iteration = 4
gd loss = 5662.97102416888
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5662.651609642249
gradient descent iteration = 5
gd loss = 5662.651609642249
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5662.34641823645
gradient descent iteration = 6
gd loss = 5662.34641823645
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5662.047711711067
gradient descent iteration = 7
gd loss = 5662.047711711067
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5661.75429058552
gradient descent iteration = 8
gd loss = 5661.75429058552
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5661.465615420685
gradient descent iteration = 9
gd loss = 5661.465615420685
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5661.181277869397
gradient descent iteration = 10
gd loss = 5661.181277869397
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5660.900937710454
gradient descent iteration = 11
gd loss = 5660.900937710454
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5660.624304982152
gradient descent iteration = 12
gd loss = 5660.624304982152
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5660.351129403907
gradient descent iteration = 13
gd loss = 5660.351129403907
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5660.081192735963
gradient descent iteration = 14
gd loss = 5660.081192735963
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5659.814303004045
gradient descent iteration = 15
gd loss = 5659.814303004045
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5659.550290040943
gradient descent iteration = 16
gd loss = 5659.550290040943
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5659.289001984745
gradient descent iteration = 17
gd loss = 5659.289001984745
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5659.030302489932
gradient descent iteration = 18
gd loss = 5659.030302489932
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5658.774068478183
gradient descent iteration = 19
gd loss = 5658.774068478183
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5658.520188302599
gradient descent iteration = 20
gd loss = 5658.520188302599
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5658.26856023925
gradient descent iteration = 21
gd loss = 5658.26856023925
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5658.019091232055
gradient descent iteration = 22
gd loss = 5658.019091232055
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5657.771695841835
gradient descent iteration = 23
gd loss = 5657.771695841835
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5657.526295358564
gradient descent iteration = 24
gd loss = 5657.526295358564
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5657.282817047369
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5657.282817047369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5656.5519500685
gradient descent iteration = 1
gd loss = 5656.5519500685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5655.883539659172
gradient descent iteration = 2
gd loss = 5655.883539659172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5655.249719591563
gradient descent iteration = 3
gd loss = 5655.249719591563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5654.641188257209
gradient descent iteration = 4
gd loss = 5654.641188257209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5654.053328458464
gradient descent iteration = 5
gd loss = 5654.053328458464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5653.48326256476
gradient descent iteration = 6
gd loss = 5653.48326256476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5652.928947686438
gradient descent iteration = 7
gd loss = 5652.928947686438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5652.388820611382
gradient descent iteration = 8
gd loss = 5652.388820611382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5651.861633440445
gradient descent iteration = 9
gd loss = 5651.861633440445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5651.346357448084
gradient descent iteration = 10
gd loss = 5651.346357448084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5650.842127174215
gradient descent iteration = 11
gd loss = 5650.842127174215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5650.348198337791
gradient descent iteration = 12
gd loss = 5650.348198337791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5649.863922356182
gradient descent iteration = 13
gd loss = 5649.863922356182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5649.388726898657
gradient descent iteration = 14
gd loss = 5649.388726898657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5648.922103057551
gradient descent iteration = 15
gd loss = 5648.922103057551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5648.463593327077
gradient descent iteration = 16
gd loss = 5648.463593327077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5648.012784277003
gradient descent iteration = 17
gd loss = 5648.012784277003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5647.569299054324
gradient descent iteration = 18
gd loss = 5647.569299054324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5647.132793027432
gradient descent iteration = 19
gd loss = 5647.132793027432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5646.702948899313
gradient descent iteration = 20
gd loss = 5646.702948899313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5646.279474240599
gradient descent iteration = 21
gd loss = 5646.279474240599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5645.862098434785
gradient descent iteration = 22
gd loss = 5645.862098434785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5645.450570339493
gradient descent iteration = 23
gd loss = 5645.450570339493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5645.044655779928
gradient descent iteration = 24
gd loss = 5645.044655779928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5644.644136271939
Initial loss = 5688.768692770769
Final loss = 5644.644136271939
Deformation gradient control sequence optimization finished.
Animation interval 37 took 1158 seconds.
Full animation took 45662 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 38************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5641.012880118808
initial norm = 185.5110420888038
convergence norm = 0.1855110420888038
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5641.012880118808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5634.39713384122
gradient descent iteration = 1
gd loss = 5634.39713384122
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5632.193452323184
gradient descent iteration = 2
gd loss = 5632.193452323184
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5631.118194728988
gradient descent iteration = 3
gd loss = 5631.118194728988
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5630.55323630866
gradient descent iteration = 4
gd loss = 5630.55323630866
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5629.927638680013
gradient descent iteration = 5
gd loss = 5629.927638680013
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5629.589858465093
gradient descent iteration = 6
gd loss = 5629.589858465093
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5629.106592916451
gradient descent iteration = 7
gd loss = 5629.106592916451
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5628.777031397763
gradient descent iteration = 8
gd loss = 5628.777031397763
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5628.370375759476
gradient descent iteration = 9
gd loss = 5628.370375759476
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5628.048742041348
gradient descent iteration = 10
gd loss = 5628.048742041348
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5627.687628585119
gradient descent iteration = 11
gd loss = 5627.687628585119
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5627.373222739865
gradient descent iteration = 12
gd loss = 5627.373222739865
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5627.039816167077
gradient descent iteration = 13
gd loss = 5627.039816167077
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5626.732092660353
gradient descent iteration = 14
gd loss = 5626.732092660353
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5626.416453021376
gradient descent iteration = 15
gd loss = 5626.416453021376
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5626.11485070094
gradient descent iteration = 16
gd loss = 5626.11485070094
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5625.811162226424
gradient descent iteration = 17
gd loss = 5625.811162226424
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5625.515069207057
gradient descent iteration = 18
gd loss = 5625.515069207057
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5625.219744783454
gradient descent iteration = 19
gd loss = 5625.219744783454
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5624.928524500631
gradient descent iteration = 20
gd loss = 5624.928524500631
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5624.639237907233
gradient descent iteration = 21
gd loss = 5624.639237907233
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5624.352263086276
gradient descent iteration = 22
gd loss = 5624.352263086276
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5624.067435440197
gradient descent iteration = 23
gd loss = 5624.067435440197
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5623.78411413385
gradient descent iteration = 24
gd loss = 5623.78411413385
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5623.502630071497
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5623.502630071497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5622.883799564108
gradient descent iteration = 1
gd loss = 5622.883799564108
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5621.748002293546
gradient descent iteration = 2
gd loss = 5621.748002293546
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5621.424949331715
gradient descent iteration = 3
gd loss = 5621.424949331715
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5621.149393858411
gradient descent iteration = 4
gd loss = 5621.149393858411
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5620.883119872718
gradient descent iteration = 5
gd loss = 5620.883119872718
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5620.622130674456
gradient descent iteration = 6
gd loss = 5620.622130674456
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5620.365339286752
gradient descent iteration = 7
gd loss = 5620.365339286752
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5620.112079310746
gradient descent iteration = 8
gd loss = 5620.112079310746
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5619.861846497332
gradient descent iteration = 9
gd loss = 5619.861846497332
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5619.614240971553
gradient descent iteration = 10
gd loss = 5619.614240971553
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5619.368938346074
gradient descent iteration = 11
gd loss = 5619.368938346074
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5619.125670981563
gradient descent iteration = 12
gd loss = 5619.125670981563
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5618.88421495521
gradient descent iteration = 13
gd loss = 5618.88421495521
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5618.64438069501
gradient descent iteration = 14
gd loss = 5618.64438069501
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5618.40600607165
gradient descent iteration = 15
gd loss = 5618.40600607165
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5618.168951191564
gradient descent iteration = 16
gd loss = 5618.168951191564
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5617.933094400084
gradient descent iteration = 17
gd loss = 5617.933094400084
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5617.698329166452
gradient descent iteration = 18
gd loss = 5617.698329166452
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5617.464561629186
gradient descent iteration = 19
gd loss = 5617.464561629186
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5617.231708641931
gradient descent iteration = 20
gd loss = 5617.231708641931
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5616.99969620786
gradient descent iteration = 21
gd loss = 5616.99969620786
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5616.768458217382
gradient descent iteration = 22
gd loss = 5616.768458217382
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5616.537935430823
gradient descent iteration = 23
gd loss = 5616.537935430823
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5616.30807465692
gradient descent iteration = 24
gd loss = 5616.30807465692
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5616.078828090102
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5616.078828090102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5615.514789770225
gradient descent iteration = 1
gd loss = 5615.514789770225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5614.993017308701
gradient descent iteration = 2
gd loss = 5614.993017308701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5614.493104828111
gradient descent iteration = 3
gd loss = 5614.493104828111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5614.008144521034
gradient descent iteration = 4
gd loss = 5614.008144521034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5613.534749976859
gradient descent iteration = 5
gd loss = 5613.534749976859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5613.070858814814
gradient descent iteration = 6
gd loss = 5613.070858814814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5612.615043851335
gradient descent iteration = 7
gd loss = 5612.615043851335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5612.166238459778
gradient descent iteration = 8
gd loss = 5612.166238459778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5611.723610049404
gradient descent iteration = 9
gd loss = 5611.723610049404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5611.28648636948
gradient descent iteration = 10
gd loss = 5611.28648636948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5610.854313366812
gradient descent iteration = 11
gd loss = 5610.854313366812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5610.426624507283
gradient descent iteration = 12
gd loss = 5610.426624507283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5610.003025117942
gradient descent iteration = 13
gd loss = 5610.003025117942
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5609.583198493152
gradient descent iteration = 14
gd loss = 5609.583198493152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5609.166888857718
gradient descent iteration = 15
gd loss = 5609.166888857718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5608.753876086659
gradient descent iteration = 16
gd loss = 5608.753876086659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5608.343970434455
gradient descent iteration = 17
gd loss = 5608.343970434455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5607.937007409234
gradient descent iteration = 18
gd loss = 5607.937007409234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5607.532844758609
gradient descent iteration = 19
gd loss = 5607.532844758609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5607.131359098855
gradient descent iteration = 20
gd loss = 5607.131359098855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5606.732444022852
gradient descent iteration = 21
gd loss = 5606.732444022852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5606.336007981389
gradient descent iteration = 22
gd loss = 5606.336007981389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5605.941973041709
gradient descent iteration = 23
gd loss = 5605.941973041709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5605.550273237543
gradient descent iteration = 24
gd loss = 5605.550273237543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5605.160853645502
Initial loss = 5641.012880118808
Final loss = 5605.160853645502
Deformation gradient control sequence optimization finished.
Animation interval 38 took 1157 seconds.
Full animation took 46820 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 39************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5600.23499943082
initial norm = 149.1984826631648
convergence norm = 0.1491984826631648
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5600.23499943082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5595.696325650814
gradient descent iteration = 1
gd loss = 5595.696325650814
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5592.951930536467
gradient descent iteration = 2
gd loss = 5592.951930536467
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5591.790554859912
gradient descent iteration = 3
gd loss = 5591.790554859912
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5591.581038645798
gradient descent iteration = 4
gd loss = 5591.581038645798
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5590.839798570546
gradient descent iteration = 5
gd loss = 5590.839798570546
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5590.583799426532
gradient descent iteration = 6
gd loss = 5590.583799426532
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5590.029914899401
gradient descent iteration = 7
gd loss = 5590.029914899401
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5589.747876673675
gradient descent iteration = 8
gd loss = 5589.747876673675
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5589.287389654136
gradient descent iteration = 9
gd loss = 5589.287389654136
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5588.991965561939
gradient descent iteration = 10
gd loss = 5588.991965561939
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5588.586211340126
gradient descent iteration = 11
gd loss = 5588.586211340126
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5588.284852920926
gradient descent iteration = 12
gd loss = 5588.284852920926
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5587.914383503758
gradient descent iteration = 13
gd loss = 5587.914383503758
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5587.611652082084
gradient descent iteration = 14
gd loss = 5587.611652082084
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5587.26559253333
gradient descent iteration = 15
gd loss = 5587.26559253333
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5586.964521175345
gradient descent iteration = 16
gd loss = 5586.964521175345
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5586.636237978892
gradient descent iteration = 17
gd loss = 5586.636237978892
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5586.339332411694
gradient descent iteration = 18
gd loss = 5586.339332411694
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5586.023645415721
gradient descent iteration = 19
gd loss = 5586.023645415721
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5585.732968721679
gradient descent iteration = 20
gd loss = 5585.732968721679
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5585.422882532712
gradient descent iteration = 21
gd loss = 5585.422882532712
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5585.138841978538
gradient descent iteration = 22
gd loss = 5585.138841978538
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5584.829022233375
gradient descent iteration = 23
gd loss = 5584.829022233375
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5584.552982035373
gradient descent iteration = 24
gd loss = 5584.552982035373
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5584.247891959997
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5584.247891959997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5583.690835609505
gradient descent iteration = 1
gd loss = 5583.690835609505
line search decrease found at ls_iter = 1, alpha = 0.05, loss = 5582.485350553407
gradient descent iteration = 2
gd loss = 5582.485350553407
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5582.152689852952
gradient descent iteration = 3
gd loss = 5582.152689852952
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5581.86534175057
gradient descent iteration = 4
gd loss = 5581.86534175057
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5581.588274353389
gradient descent iteration = 5
gd loss = 5581.588274353389
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5581.317751913142
gradient descent iteration = 6
gd loss = 5581.317751913142
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5581.052726173151
gradient descent iteration = 7
gd loss = 5581.052726173151
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5580.792542687297
gradient descent iteration = 8
gd loss = 5580.792542687297
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5580.536698058161
gradient descent iteration = 9
gd loss = 5580.536698058161
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5580.284786261012
gradient descent iteration = 10
gd loss = 5580.284786261012
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5580.036472165754
gradient descent iteration = 11
gd loss = 5580.036472165754
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5579.791474296911
gradient descent iteration = 12
gd loss = 5579.791474296911
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5579.549552795967
gradient descent iteration = 13
gd loss = 5579.549552795967
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5579.310500743031
gradient descent iteration = 14
gd loss = 5579.310500743031
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5579.074137748186
gradient descent iteration = 15
gd loss = 5579.074137748186
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5578.840305114572
gradient descent iteration = 16
gd loss = 5578.840305114572
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5578.608862119097
gradient descent iteration = 17
gd loss = 5578.608862119097
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5578.379683108134
gradient descent iteration = 18
gd loss = 5578.379683108134
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5578.152655191794
gradient descent iteration = 19
gd loss = 5578.152655191794
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5577.927676392505
gradient descent iteration = 20
gd loss = 5577.927676392505
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5577.704654141093
gradient descent iteration = 21
gd loss = 5577.704654141093
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5577.483504039727
gradient descent iteration = 22
gd loss = 5577.483504039727
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5577.264148838411
gradient descent iteration = 23
gd loss = 5577.264148838411
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5577.0465175775
gradient descent iteration = 24
gd loss = 5577.0465175775
line search decrease found at ls_iter = 0, alpha = 0.05, loss = 5576.830544864737
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5576.830544864737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5575.982049405943
gradient descent iteration = 1
gd loss = 5575.982049405943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5575.223719132413
gradient descent iteration = 2
gd loss = 5575.223719132413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5574.523148911851
gradient descent iteration = 3
gd loss = 5574.523148911851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5573.865566508575
gradient descent iteration = 4
gd loss = 5573.865566508575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5573.242045112045
gradient descent iteration = 5
gd loss = 5573.242045112045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5572.646510112867
gradient descent iteration = 6
gd loss = 5572.646510112867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5572.074568562214
gradient descent iteration = 7
gd loss = 5572.074568562214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5571.522920908267
gradient descent iteration = 8
gd loss = 5571.522920908267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5570.98902301047
gradient descent iteration = 9
gd loss = 5570.98902301047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5570.470867996012
gradient descent iteration = 10
gd loss = 5570.470867996012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5569.966843251901
gradient descent iteration = 11
gd loss = 5569.966843251901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5569.475628799446
gradient descent iteration = 12
gd loss = 5569.475628799446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5568.996127635249
gradient descent iteration = 13
gd loss = 5568.996127635249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5568.527413562046
gradient descent iteration = 14
gd loss = 5568.527413562046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5568.068694726153
gradient descent iteration = 15
gd loss = 5568.068694726153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5567.619285049236
gradient descent iteration = 16
gd loss = 5567.619285049236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5567.178584021364
gradient descent iteration = 17
gd loss = 5567.178584021364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5566.746060210136
gradient descent iteration = 18
gd loss = 5566.746060210136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5566.321239497046
gradient descent iteration = 19
gd loss = 5566.321239497046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5565.903695067582
gradient descent iteration = 20
gd loss = 5565.903695067582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5565.493040219705
gradient descent iteration = 21
gd loss = 5565.493040219705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5565.088921990435
gradient descent iteration = 22
gd loss = 5565.088921990435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5564.691016528574
gradient descent iteration = 23
gd loss = 5564.691016528574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5564.299024828597
gradient descent iteration = 24
gd loss = 5564.299024828597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5563.91266958646
Initial loss = 5600.23499943082
Final loss = 5563.91266958646
Deformation gradient control sequence optimization finished.
Animation interval 39 took 1157 seconds.
Full animation took 47977 seconds so far.