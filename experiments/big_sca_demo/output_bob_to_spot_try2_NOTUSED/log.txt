line search decrease found at ls_iter = 0, alpha = 0.1, loss = 361392.6514692405
gradient descent iteration = 13
gd loss = 361392.6514692405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360701.7838499203
gradient descent iteration = 14
gd loss = 360701.7838499203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360013.2341857207
gradient descent iteration = 15
gd loss = 360013.2341857207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 359326.9967255698
gradient descent iteration = 16
gd loss = 359326.9967255698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358643.0656830614
gradient descent iteration = 17
gd loss = 358643.0656830614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357961.4352220262
gradient descent iteration = 18
gd loss = 357961.4352220262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357282.0994557826
gradient descent iteration = 19
gd loss = 357282.0994557826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356605.0524481469
gradient descent iteration = 20
gd loss = 356605.0524481469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355930.2882133591
gradient descent iteration = 21
gd loss = 355930.2882133591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355257.800717982
gradient descent iteration = 22
gd loss = 355257.800717982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 354587.5838763205
gradient descent iteration = 23
gd loss = 354587.5838763205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353919.6315579417
gradient descent iteration = 24
gd loss = 353919.6315579417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353253.9375906184
Initial loss = 443427.980227154
Final loss = 353253.9375906184
Deformation gradient control sequence optimization finished.
Animation interval 2 took 1334 seconds.
Full animation took 4010 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 3************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 388895.0704339534
initial norm = 18195.94369707441
convergence norm = 18.19594369707441
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 388895.0704339534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 387078.8543690785
gradient descent iteration = 1
gd loss = 387078.8543690785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 385269.6898818379
gradient descent iteration = 2
gd loss = 385269.6898818379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 383467.5388499146
gradient descent iteration = 3
gd loss = 383467.5388499146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 381672.3599336755
gradient descent iteration = 4
gd loss = 381672.3599336755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 379884.1099799303
gradient descent iteration = 5
gd loss = 379884.1099799303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 378102.7457060109
gradient descent iteration = 6
gd loss = 378102.7457060109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 376328.2258443139
gradient descent iteration = 7
gd loss = 376328.2258443139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 374560.5115197388
gradient descent iteration = 8
gd loss = 374560.5115197388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 372799.5652107836
gradient descent iteration = 9
gd loss = 372799.5652107836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 371045.3504531098
gradient descent iteration = 10
gd loss = 371045.3504531098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 369297.8324682504
gradient descent iteration = 11
gd loss = 369297.8324682504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 367556.9795280383
gradient descent iteration = 12
gd loss = 367556.9795280383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 365822.7637376848
gradient descent iteration = 13
gd loss = 365822.7637376848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 364095.1630518744
gradient descent iteration = 14
gd loss = 364095.1630518744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 362374.161693881
gradient descent iteration = 15
gd loss = 362374.161693881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360659.7494690188
gradient descent iteration = 16
gd loss = 360659.7494690188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358951.9206936547
gradient descent iteration = 17
gd loss = 358951.9206936547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357250.6746978116
gradient descent iteration = 18
gd loss = 357250.6746978116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355556.0171142427
gradient descent iteration = 19
gd loss = 355556.0171142427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353867.9601915502
gradient descent iteration = 20
gd loss = 353867.9601915502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 352186.5240168492
gradient descent iteration = 21
gd loss = 352186.5240168492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 350511.7375231988
gradient descent iteration = 22
gd loss = 350511.7375231988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 348843.6381512813
gradient descent iteration = 23
gd loss = 348843.6381512813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 347182.2720027466
gradient descent iteration = 24
gd loss = 347182.2720027466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 345527.6933392289
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 345527.6933392289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 344443.2546247754
gradient descent iteration = 1
gd loss = 344443.2546247754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 343363.1558431411
gradient descent iteration = 2
gd loss = 343363.1558431411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 342287.4272083189
gradient descent iteration = 3
gd loss = 342287.4272083189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 341216.0986154005
gradient descent iteration = 4
gd loss = 341216.0986154005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 340149.1999722279
gradient descent iteration = 5
gd loss = 340149.1999722279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 339086.7620617324
gradient descent iteration = 6
gd loss = 339086.7620617324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 338028.8157455124
gradient descent iteration = 7
gd loss = 338028.8157455124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 336975.3919930895
gradient descent iteration = 8
gd loss = 336975.3919930895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 335926.5219435642
gradient descent iteration = 9
gd loss = 335926.5219435642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 334882.2372614894
gradient descent iteration = 10
gd loss = 334882.2372614894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 333842.5697612799
gradient descent iteration = 11
gd loss = 333842.5697612799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 332807.5516671197
gradient descent iteration = 12
gd loss = 332807.5516671197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 331777.2155803849
gradient descent iteration = 13
gd loss = 331777.2155803849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 330751.5941103341
gradient descent iteration = 14
gd loss = 330751.5941103341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 329730.718612315
gradient descent iteration = 15
gd loss = 329730.718612315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 328714.6184593922
gradient descent iteration = 16
gd loss = 328714.6184593922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 327703.3209589563
gradient descent iteration = 17
gd loss = 327703.3209589563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 326696.8521599604
gradient descent iteration = 18
gd loss = 326696.8521599604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 325695.2367271529
gradient descent iteration = 19
gd loss = 325695.2367271529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324698.4976732006
gradient descent iteration = 20
gd loss = 324698.4976732006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 323706.6566841558
gradient descent iteration = 21
gd loss = 323706.6566841558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322719.7342856512
gradient descent iteration = 22
gd loss = 322719.7342856512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 321737.7497779669
gradient descent iteration = 23
gd loss = 321737.7497779669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320760.7211200667
gradient descent iteration = 24
gd loss = 320760.7211200667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319788.6648720074
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 319788.6648720074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319104.0700274603
gradient descent iteration = 1
gd loss = 319104.0700274603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 318422.3414007891
gradient descent iteration = 2
gd loss = 318422.3414007891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317743.4677413407
gradient descent iteration = 3
gd loss = 317743.4677413407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317067.4377749252
gradient descent iteration = 4
gd loss = 317067.4377749252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 316394.2402133543
gradient descent iteration = 5
gd loss = 316394.2402133543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315723.8637451457
gradient descent iteration = 6
gd loss = 315723.8637451457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315056.2970297337
gradient descent iteration = 7
gd loss = 315056.2970297337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 314391.5287022296
gradient descent iteration = 8
gd loss = 314391.5287022296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313729.5473700716
gradient descent iteration = 9
gd loss = 313729.5473700716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313070.3416148619
gradient descent iteration = 10
gd loss = 313070.3416148619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 312413.8999952886
gradient descent iteration = 11
gd loss = 312413.8999952886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311760.2110547539
gradient descent iteration = 12
gd loss = 311760.2110547539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311109.2633183829
gradient descent iteration = 13
gd loss = 311109.2633183829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 310461.0452888382
gradient descent iteration = 14
gd loss = 310461.0452888382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309815.5454467923
gradient descent iteration = 15
gd loss = 309815.5454467923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309172.7522588962
gradient descent iteration = 16
gd loss = 309172.7522588962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308532.6541849843
gradient descent iteration = 17
gd loss = 308532.6541849843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 307895.2396876389
gradient descent iteration = 18
gd loss = 307895.2396876389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 307260.49723317
gradient descent iteration = 19
gd loss = 307260.49723317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306628.4152852276
gradient descent iteration = 20
gd loss = 306628.4152852276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305998.9823039313
gradient descent iteration = 21
gd loss = 305998.9823039313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305372.1867437056
gradient descent iteration = 22
gd loss = 305372.1867437056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304748.0170482488
gradient descent iteration = 23
gd loss = 304748.0170482488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304126.4616550659
gradient descent iteration = 24
gd loss = 304126.4616550659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303507.5089989024
Initial loss = 388895.0704339534
Final loss = 303507.5089989024
Deformation gradient control sequence optimization finished.
Animation interval 3 took 1364 seconds.
Full animation took 5375 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 4************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 324281.6695293045
initial norm = 16543.29200854048
convergence norm = 16.54329200854048
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 324281.6695293045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322631.8282817417
gradient descent iteration = 1
gd loss = 322631.8282817417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320990.2008196791
gradient descent iteration = 2
gd loss = 320990.2008196791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319356.9507443344
gradient descent iteration = 3
gd loss = 319356.9507443344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317732.2459526
gradient descent iteration = 4
gd loss = 317732.2459526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 316116.2579078175
gradient descent iteration = 5
gd loss = 316116.2579078175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 314509.1607489357
gradient descent iteration = 6
gd loss = 314509.1607489357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 312911.1302400014
gradient descent iteration = 7
gd loss = 312911.1302400014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311322.3422251592
gradient descent iteration = 8
gd loss = 311322.3422251592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309742.9713190206
gradient descent iteration = 9
gd loss = 309742.9713190206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308173.1895289994
gradient descent iteration = 10
gd loss = 308173.1895289994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306613.1639141143
gradient descent iteration = 11
gd loss = 306613.1639141143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305063.0550335341
gradient descent iteration = 12
gd loss = 305063.0550335341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303523.0166747193
gradient descent iteration = 13
gd loss = 303523.0166747193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 301993.1956412908
gradient descent iteration = 14
gd loss = 301993.1956412908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300473.7310428669
gradient descent iteration = 15
gd loss = 300473.7310428669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 298964.7526291122
gradient descent iteration = 16
gd loss = 298964.7526291122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297466.3810707842
gradient descent iteration = 17
gd loss = 297466.3810707842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 295978.727917363
gradient descent iteration = 18
gd loss = 295978.727917363
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 294501.893747706
gradient descent iteration = 19
gd loss = 294501.893747706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 293035.9676646977
gradient descent iteration = 20
gd loss = 293035.9676646977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 291581.0265823614
gradient descent iteration = 21
gd loss = 291581.0265823614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 290137.1347446375
gradient descent iteration = 22
gd loss = 290137.1347446375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 288704.3425064323
gradient descent iteration = 23
gd loss = 288704.3425064323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 287282.6869439775
gradient descent iteration = 24
gd loss = 287282.6869439775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 285872.1943695645
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 285872.1943695645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 284805.5972366211
gradient descent iteration = 1
gd loss = 284805.5972366211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 283747.4834663828
gradient descent iteration = 2
gd loss = 283747.4834663828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 282697.8947907659
gradient descent iteration = 3
gd loss = 282697.8947907659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281656.8696114868
gradient descent iteration = 4
gd loss = 281656.8696114868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 280624.4435601709
gradient descent iteration = 5
gd loss = 280624.4435601709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279600.6491980091
gradient descent iteration = 6
gd loss = 279600.6491980091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 278585.5153378095
gradient descent iteration = 7
gd loss = 278585.5153378095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277579.0675485887
gradient descent iteration = 8
gd loss = 277579.0675485887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276581.3267551115
gradient descent iteration = 9
gd loss = 276581.3267551115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 275592.3088837492
gradient descent iteration = 10
gd loss = 275592.3088837492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274612.0238666158
gradient descent iteration = 11
gd loss = 274612.0238666158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 273640.4749708045
gradient descent iteration = 12
gd loss = 273640.4749708045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 272677.6601165303
gradient descent iteration = 13
gd loss = 272677.6601165303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 271723.5724112195
gradient descent iteration = 14
gd loss = 271723.5724112195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270778.2000046918
gradient descent iteration = 15
gd loss = 270778.2000046918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269841.526143281
gradient descent iteration = 16
gd loss = 269841.526143281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268913.5283753396
gradient descent iteration = 17
gd loss = 268913.5283753396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267994.1777200134
gradient descent iteration = 18
gd loss = 267994.1777200134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267083.4392505308
gradient descent iteration = 19
gd loss = 267083.4392505308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266181.2729661164
gradient descent iteration = 20
gd loss = 266181.2729661164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265287.6334723837
gradient descent iteration = 21
gd loss = 265287.6334723837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264402.4714705317
gradient descent iteration = 22
gd loss = 264402.4714705317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263525.7331348538
gradient descent iteration = 23
gd loss = 263525.7331348538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 262657.3592404292
gradient descent iteration = 24
gd loss = 262657.3592404292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261797.2857890712
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 261797.2857890712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261171.9427513288
gradient descent iteration = 1
gd loss = 261171.9427513288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260550.2597625792
gradient descent iteration = 2
gd loss = 260550.2597625792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259932.2086889665
gradient descent iteration = 3
gd loss = 259932.2086889665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259317.7615313044
gradient descent iteration = 4
gd loss = 259317.7615313044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258706.8904264423
gradient descent iteration = 5
gd loss = 258706.8904264423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258099.567657634
gradient descent iteration = 6
gd loss = 258099.567657634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257495.7656554072
gradient descent iteration = 7
gd loss = 257495.7656554072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256895.4569910308
gradient descent iteration = 8
gd loss = 256895.4569910308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256298.6143827965
gradient descent iteration = 9
gd loss = 256298.6143827965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255705.2106969284
gradient descent iteration = 10
gd loss = 255705.2106969284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255115.2189479339
gradient descent iteration = 11
gd loss = 255115.2189479339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 254528.6123055918
gradient descent iteration = 12
gd loss = 254528.6123055918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253945.3640978088
gradient descent iteration = 13
gd loss = 253945.3640978088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253365.4478136647
gradient descent iteration = 14
gd loss = 253365.4478136647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252788.8370969906
gradient descent iteration = 15
gd loss = 252788.8370969906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252215.5057456943
gradient descent iteration = 16
gd loss = 252215.5057456943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251645.4277157276
gradient descent iteration = 17
gd loss = 251645.4277157276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251078.5771191231
gradient descent iteration = 18
gd loss = 251078.5771191231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250514.9282335794
gradient descent iteration = 19
gd loss = 250514.9282335794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249954.455500115
gradient descent iteration = 20
gd loss = 249954.455500115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249397.1335236208
gradient descent iteration = 21
gd loss = 249397.1335236208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248842.9370677369
gradient descent iteration = 22
gd loss = 248842.9370677369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248291.8410523362
gradient descent iteration = 23
gd loss = 248291.8410523362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247743.8205542314
gradient descent iteration = 24
gd loss = 247743.8205542314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247198.8508102562
Initial loss = 324281.6695293045
Final loss = 247198.8508102562
Deformation gradient control sequence optimization finished.
Animation interval 4 took 1402 seconds.
Full animation took 6777 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 5************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 275668.4462760107
initial norm = 13845.08778240389
convergence norm = 13.84508778240389
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 275668.4462760107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274291.7730814847
gradient descent iteration = 1
gd loss = 274291.7730814847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 272928.9859125745
gradient descent iteration = 2
gd loss = 272928.9859125745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 271579.85078996
gradient descent iteration = 3
gd loss = 271579.85078996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270244.1325475091
gradient descent iteration = 4
gd loss = 270244.1325475091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268921.5952925191
gradient descent iteration = 5
gd loss = 268921.5952925191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267612.0039708843
gradient descent iteration = 6
gd loss = 267612.0039708843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266315.1263451139
gradient descent iteration = 7
gd loss = 266315.1263451139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265030.73338162
gradient descent iteration = 8
gd loss = 265030.73338162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263758.5987899628
gradient descent iteration = 9
gd loss = 263758.5987899628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 262498.4984638477
gradient descent iteration = 10
gd loss = 262498.4984638477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261250.2123663884
gradient descent iteration = 11
gd loss = 261250.2123663884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260013.5256830213
gradient descent iteration = 12
gd loss = 260013.5256830213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258788.22792702
gradient descent iteration = 13
gd loss = 258788.22792702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257574.1131343509
gradient descent iteration = 14
gd loss = 257574.1131343509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256370.9796358018
gradient descent iteration = 15
gd loss = 256370.9796358018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255178.6296149704
gradient descent iteration = 16
gd loss = 255178.6296149704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253996.8688667252
gradient descent iteration = 17
gd loss = 253996.8688667252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252825.5069154721
gradient descent iteration = 18
gd loss = 252825.5069154721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251664.3579577475
gradient descent iteration = 19
gd loss = 251664.3579577475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250513.2407921619
gradient descent iteration = 20
gd loss = 250513.2407921619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249371.9790208256
gradient descent iteration = 21
gd loss = 249371.9790208256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248240.4010433824
gradient descent iteration = 22
gd loss = 248240.4010433824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247118.3399030176
gradient descent iteration = 23
gd loss = 247118.3399030176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246005.6329574614
gradient descent iteration = 24
gd loss = 246005.6329574614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 244902.121815254
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 244902.121815254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 243782.3772739756
gradient descent iteration = 1
gd loss = 243782.3772739756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242679.135746169
gradient descent iteration = 2
gd loss = 242679.135746169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241592.0537698482
gradient descent iteration = 3
gd loss = 241592.0537698482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240520.7888614864
gradient descent iteration = 4
gd loss = 240520.7888614864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239465.0009580564
gradient descent iteration = 5
gd loss = 239465.0009580564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 238424.3540676634
gradient descent iteration = 6
gd loss = 238424.3540676634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 237398.513860159
gradient descent iteration = 7
gd loss = 237398.513860159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 236387.1486969981
gradient descent iteration = 8
gd loss = 236387.1486969981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 235389.9338302861
gradient descent iteration = 9
gd loss = 235389.9338302861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234406.5514519194
gradient descent iteration = 10
gd loss = 234406.5514519194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233436.6899381765
gradient descent iteration = 11
gd loss = 233436.6899381765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232480.0452687809
gradient descent iteration = 12
gd loss = 232480.0452687809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231536.3213571199
gradient descent iteration = 13
gd loss = 231536.3213571199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230605.2289221116
gradient descent iteration = 14
gd loss = 230605.2289221116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 229686.4884228102
gradient descent iteration = 15
gd loss = 229686.4884228102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228779.8300258657
gradient descent iteration = 16
gd loss = 228779.8300258657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227884.9930027922
gradient descent iteration = 17
gd loss = 227884.9930027922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227001.7246015442
gradient descent iteration = 18
gd loss = 227001.7246015442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226129.7795430874
gradient descent iteration = 19
gd loss = 226129.7795430874
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225268.9199722479
gradient descent iteration = 20
gd loss = 225268.9199722479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224418.9157157204
gradient descent iteration = 21
gd loss = 224418.9157157204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223579.5447849431
gradient descent iteration = 22
gd loss = 223579.5447849431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222750.5918237128
gradient descent iteration = 23
gd loss = 222750.5918237128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221931.848897394
gradient descent iteration = 24
gd loss = 221931.848897394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221123.1159967375
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 221123.1159967375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220505.4938232712
gradient descent iteration = 1
gd loss = 220505.4938232712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219892.5775518016
gradient descent iteration = 2
gd loss = 219892.5775518016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219284.3082174515
gradient descent iteration = 3
gd loss = 219284.3082174515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218680.6278081897
gradient descent iteration = 4
gd loss = 218680.6278081897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218081.4792189372
gradient descent iteration = 5
gd loss = 218081.4792189372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217486.8062436141
gradient descent iteration = 6
gd loss = 217486.8062436141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216896.5535428031
gradient descent iteration = 7
gd loss = 216896.5535428031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216310.6666537285
gradient descent iteration = 8
gd loss = 216310.6666537285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215729.0919710924
gradient descent iteration = 9
gd loss = 215729.0919710924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215151.7767299255
gradient descent iteration = 10
gd loss = 215151.7767299255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214578.6689837177
gradient descent iteration = 11
gd loss = 214578.6689837177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214009.7175704018
gradient descent iteration = 12
gd loss = 214009.7175704018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213444.8721039364
gradient descent iteration = 13
gd loss = 213444.8721039364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212884.0829835877
gradient descent iteration = 14
gd loss = 212884.0829835877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212327.3013905606
gradient descent iteration = 15
gd loss = 212327.3013905606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211774.479268604
gradient descent iteration = 16
gd loss = 211774.479268604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211225.5693212522
gradient descent iteration = 17
gd loss = 211225.5693212522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210680.5249758753
gradient descent iteration = 18
gd loss = 210680.5249758753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210139.3003652141
gradient descent iteration = 19
gd loss = 210139.3003652141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209601.8503118923
gradient descent iteration = 20
gd loss = 209601.8503118923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209068.1303351792
gradient descent iteration = 21
gd loss = 209068.1303351792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208538.096619644
gradient descent iteration = 22
gd loss = 208538.096619644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208011.7060045128
gradient descent iteration = 23
gd loss = 208011.7060045128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207488.9159768493
gradient descent iteration = 24
gd loss = 207488.9159768493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206969.6846694617
Initial loss = 275668.4462760107
Final loss = 206969.6846694617
Deformation gradient control sequence optimization finished.
Animation interval 5 took 1402 seconds.
Full animation took 8180 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 6************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 226934.0045078187
initial norm = 10199.54197576039
convergence norm = 10.19954197576039
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 226934.0045078187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225919.1261264155
gradient descent iteration = 1
gd loss = 225919.1261264155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224912.9149783041
gradient descent iteration = 2
gd loss = 224912.9149783041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223915.2140429635
gradient descent iteration = 3
gd loss = 223915.2140429635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222925.8711931108
gradient descent iteration = 4
gd loss = 222925.8711931108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221944.7400163886
gradient descent iteration = 5
gd loss = 221944.7400163886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220971.679310022
gradient descent iteration = 6
gd loss = 220971.679310022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220006.552490138
gradient descent iteration = 7
gd loss = 220006.552490138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219049.2275595412
gradient descent iteration = 8
gd loss = 219049.2275595412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218099.5768497366
gradient descent iteration = 9
gd loss = 218099.5768497366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217157.4766731131
gradient descent iteration = 10
gd loss = 217157.4766731131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216222.8072742214
gradient descent iteration = 11
gd loss = 216222.8072742214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215295.452772223
gradient descent iteration = 12
gd loss = 215295.452772223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214375.3009652219
gradient descent iteration = 13
gd loss = 214375.3009652219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213462.2428452552
gradient descent iteration = 14
gd loss = 213462.2428452552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212556.1726029484
gradient descent iteration = 15
gd loss = 212556.1726029484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211656.987371324
gradient descent iteration = 16
gd loss = 211656.987371324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210764.5873477479
gradient descent iteration = 17
gd loss = 210764.5873477479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209878.875714611
gradient descent iteration = 18
gd loss = 209878.875714611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208999.7586326178
gradient descent iteration = 19
gd loss = 208999.7586326178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208127.1450278637
gradient descent iteration = 20
gd loss = 208127.1450278637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207260.94663761
gradient descent iteration = 21
gd loss = 207260.94663761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206401.0775737321
gradient descent iteration = 22
gd loss = 206401.0775737321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205547.4542070403
gradient descent iteration = 23
gd loss = 205547.4542070403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204699.995298326
gradient descent iteration = 24
gd loss = 204699.995298326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203858.6216270504
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 203858.6216270504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202885.7061423064
gradient descent iteration = 1
gd loss = 202885.7061423064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201929.0932848391
gradient descent iteration = 2
gd loss = 201929.0932848391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200988.3145614868
gradient descent iteration = 3
gd loss = 200988.3145614868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200062.9205128179
gradient descent iteration = 4
gd loss = 200062.9205128179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199152.4764666295
gradient descent iteration = 5
gd loss = 199152.4764666295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198256.5618788724
gradient descent iteration = 6
gd loss = 198256.5618788724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197374.7716307595
gradient descent iteration = 7
gd loss = 197374.7716307595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196506.7136161072
gradient descent iteration = 8
gd loss = 196506.7136161072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195652.0078487193
gradient descent iteration = 9
gd loss = 195652.0078487193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194810.2864262574
gradient descent iteration = 10
gd loss = 194810.2864262574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193981.1920787962
gradient descent iteration = 11
gd loss = 193981.1920787962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193164.3773753588
gradient descent iteration = 12
gd loss = 193164.3773753588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192359.5019488212
gradient descent iteration = 13
gd loss = 192359.5019488212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191566.2346227244
gradient descent iteration = 14
gd loss = 191566.2346227244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190784.2552020283
gradient descent iteration = 15
gd loss = 190784.2552020283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190013.253884558
gradient descent iteration = 16
gd loss = 190013.253884558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189252.9286617843
gradient descent iteration = 17
gd loss = 189252.9286617843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188502.9846477471
gradient descent iteration = 18
gd loss = 188502.9846477471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187763.1341393825
gradient descent iteration = 19
gd loss = 187763.1341393825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187033.0971964631
gradient descent iteration = 20
gd loss = 187033.0971964631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186312.6011231968
gradient descent iteration = 21
gd loss = 186312.6011231968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185601.3804666901
gradient descent iteration = 22
gd loss = 185601.3804666901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184899.1772582019
gradient descent iteration = 23
gd loss = 184899.1772582019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184205.7421079379
gradient descent iteration = 24
gd loss = 184205.7421079379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183520.8339564969
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 183520.8339564969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182896.2473978176
gradient descent iteration = 1
gd loss = 182896.2473978176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182278.6009901641
gradient descent iteration = 2
gd loss = 182278.6009901641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181667.7448428163
gradient descent iteration = 3
gd loss = 181667.7448428163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181063.5336144996
gradient descent iteration = 4
gd loss = 181063.5336144996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180465.8263111845
gradient descent iteration = 5
gd loss = 180465.8263111845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179874.4861345552
gradient descent iteration = 6
gd loss = 179874.4861345552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179289.3802940841
gradient descent iteration = 7
gd loss = 179289.3802940841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178710.3798841602
gradient descent iteration = 8
gd loss = 178710.3798841602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178137.3597457817
gradient descent iteration = 9
gd loss = 178137.3597457817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177570.1983877053
gradient descent iteration = 10
gd loss = 177570.1983877053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177008.7778715287
gradient descent iteration = 11
gd loss = 177008.7778715287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176452.9836466665
gradient descent iteration = 12
gd loss = 176452.9836466665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175902.7044360597
gradient descent iteration = 13
gd loss = 175902.7044360597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175357.8320983935
gradient descent iteration = 14
gd loss = 175357.8320983935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174818.2615132592
gradient descent iteration = 15
gd loss = 174818.2615132592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174283.8904891394
gradient descent iteration = 16
gd loss = 174283.8904891394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173754.6196788142
gradient descent iteration = 17
gd loss = 173754.6196788142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173230.3524992371
gradient descent iteration = 18
gd loss = 173230.3524992371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172710.9949735455
gradient descent iteration = 19
gd loss = 172710.9949735455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172196.4556521036
gradient descent iteration = 20
gd loss = 172196.4556521036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171686.645513561
gradient descent iteration = 21
gd loss = 171686.645513561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171181.4778965707
gradient descent iteration = 22
gd loss = 171181.4778965707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170680.8684414479
gradient descent iteration = 23
gd loss = 170680.8684414479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170184.735002028
gradient descent iteration = 24
gd loss = 170184.735002028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169692.9975891591
Initial loss = 226934.0045078187
Final loss = 169692.9975891591
Deformation gradient control sequence optimization finished.
Animation interval 6 took 1398 seconds.
Full animation took 9579 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 7************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 186799.0879991831
initial norm = 7922.701091863947
convergence norm = 7.922701091863948
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 186799.0879991831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186010.8692743299
gradient descent iteration = 1
gd loss = 186010.8692743299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185229.4737605138
gradient descent iteration = 2
gd loss = 185229.4737605138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184454.7846930891
gradient descent iteration = 3
gd loss = 184454.7846930891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183686.6879119779
gradient descent iteration = 4
gd loss = 183686.6879119779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182925.0717661834
gradient descent iteration = 5
gd loss = 182925.0717661834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182169.826984027
gradient descent iteration = 6
gd loss = 182169.826984027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181420.8465263453
gradient descent iteration = 7
gd loss = 181420.8465263453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180678.0258034788
gradient descent iteration = 8
gd loss = 180678.0258034788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179941.2624148475
gradient descent iteration = 9
gd loss = 179941.2624148475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179210.4563743383
gradient descent iteration = 10
gd loss = 179210.4563743383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178485.5099868983
gradient descent iteration = 11
gd loss = 178485.5099868983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177766.3273877632
gradient descent iteration = 12
gd loss = 177766.3273877632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177052.8143134497
gradient descent iteration = 13
gd loss = 177052.8143134497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176344.8779632854
gradient descent iteration = 14
gd loss = 176344.8779632854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175642.4271638695
gradient descent iteration = 15
gd loss = 175642.4271638695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174945.3722525597
gradient descent iteration = 16
gd loss = 174945.3722525597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174253.6250387963
gradient descent iteration = 17
gd loss = 174253.6250387963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173567.0989589217
gradient descent iteration = 18
gd loss = 173567.0989589217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172885.7092248743
gradient descent iteration = 19
gd loss = 172885.7092248743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172209.3726710469
gradient descent iteration = 20
gd loss = 172209.3726710469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171538.0075082199
gradient descent iteration = 21
gd loss = 171538.0075082199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170871.5331372497
gradient descent iteration = 22
gd loss = 170871.5331372497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170209.8700453101
gradient descent iteration = 23
gd loss = 170209.8700453101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169552.9398682308
gradient descent iteration = 24
gd loss = 169552.9398682308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168900.6654586934
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 168900.6654586934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168031.8927753216
gradient descent iteration = 1
gd loss = 168031.8927753216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167178.50954697
gradient descent iteration = 2
gd loss = 167178.50954697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166339.8920927863
gradient descent iteration = 3
gd loss = 166339.8920927863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165515.4473176837
gradient descent iteration = 4
gd loss = 165515.4473176837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164704.6131193741
gradient descent iteration = 5
gd loss = 164704.6131193741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163906.860336257
gradient descent iteration = 6
gd loss = 163906.860336257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163121.6900994011
gradient descent iteration = 7
gd loss = 163121.6900994011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162348.6313066569
gradient descent iteration = 8
gd loss = 162348.6313066569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161587.2386834071
gradient descent iteration = 9
gd loss = 161587.2386834071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160837.0961433386
gradient descent iteration = 10
gd loss = 160837.0961433386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160097.8154374059
gradient descent iteration = 11
gd loss = 160097.8154374059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159369.0349832712
gradient descent iteration = 12
gd loss = 159369.0349832712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158650.4194257108
gradient descent iteration = 13
gd loss = 158650.4194257108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157941.653659153
gradient descent iteration = 14
gd loss = 157941.653659153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157242.4414966645
gradient descent iteration = 15
gd loss = 157242.4414966645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156552.501752875
gradient descent iteration = 16
gd loss = 156552.501752875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155871.5667126403
gradient descent iteration = 17
gd loss = 155871.5667126403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155199.38121779
gradient descent iteration = 18
gd loss = 155199.38121779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154535.7016551865
gradient descent iteration = 19
gd loss = 154535.7016551865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153880.2945653494
gradient descent iteration = 20
gd loss = 153880.2945653494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153232.9362889042
gradient descent iteration = 21
gd loss = 153232.9362889042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152593.4101152316
gradient descent iteration = 22
gd loss = 152593.4101152316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151961.5068542682
gradient descent iteration = 23
gd loss = 151961.5068542682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151337.0247559185
gradient descent iteration = 24
gd loss = 151337.0247559185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150719.7683650973
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 150719.7683650973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150107.6392849832
gradient descent iteration = 1
gd loss = 150107.6392849832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149505.2037820741
gradient descent iteration = 2
gd loss = 149505.2037820741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148912.1343053322
gradient descent iteration = 3
gd loss = 148912.1343053322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148328.1183749662
gradient descent iteration = 4
gd loss = 148328.1183749662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147752.8577779582
gradient descent iteration = 5
gd loss = 147752.8577779582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147186.0677203005
gradient descent iteration = 6
gd loss = 147186.0677203005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146627.4761454397
gradient descent iteration = 7
gd loss = 146627.4761454397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146076.8230937578
gradient descent iteration = 8
gd loss = 146076.8230937578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145533.8600068848
gradient descent iteration = 9
gd loss = 145533.8600068848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144998.3491755074
gradient descent iteration = 10
gd loss = 144998.3491755074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144470.0631941832
gradient descent iteration = 11
gd loss = 144470.0631941832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143948.7843703074
gradient descent iteration = 12
gd loss = 143948.7843703074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143434.3042341306
gradient descent iteration = 13
gd loss = 143434.3042341306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142926.4230686647
gradient descent iteration = 14
gd loss = 142926.4230686647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142424.9494716034
gradient descent iteration = 15
gd loss = 142424.9494716034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141929.6999477545
gradient descent iteration = 16
gd loss = 141929.6999477545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141440.4984806046
gradient descent iteration = 17
gd loss = 141440.4984806046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140957.1760935135
gradient descent iteration = 18
gd loss = 140957.1760935135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140479.5705360626
gradient descent iteration = 19
gd loss = 140479.5705360626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140007.526024436
gradient descent iteration = 20
gd loss = 140007.526024436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139540.8929240988
gradient descent iteration = 21
gd loss = 139540.8929240988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139079.5274117308
gradient descent iteration = 22
gd loss = 139079.5274117308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138623.2912049388
gradient descent iteration = 23
gd loss = 138623.2912049388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138172.0513381928
gradient descent iteration = 24
gd loss = 138172.0513381928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137725.6798999874
Initial loss = 186799.0879991831
Final loss = 137725.6798999874
Deformation gradient control sequence optimization finished.
Animation interval 7 took 1400 seconds.
Full animation took 10980 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 8************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 152812.4378127404
initial norm = 6273.144662410345
convergence norm = 6.273144662410345
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 152812.4378127404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152188.7328258351
gradient descent iteration = 1
gd loss = 152188.7328258351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151571.044788656
gradient descent iteration = 2
gd loss = 151571.044788656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150959.2322843023
gradient descent iteration = 3
gd loss = 150959.2322843023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150353.1567761696
gradient descent iteration = 4
gd loss = 150353.1567761696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149752.6825115738
gradient descent iteration = 5
gd loss = 149752.6825115738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149157.6767650449
gradient descent iteration = 6
gd loss = 149157.6767650449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148568.0097832126
gradient descent iteration = 7
gd loss = 148568.0097832126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147983.5546286218
gradient descent iteration = 8
gd loss = 147983.5546286218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147404.187575082
gradient descent iteration = 9
gd loss = 147404.187575082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146829.787916949
gradient descent iteration = 10
gd loss = 146829.787916949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146260.2376577388
gradient descent iteration = 11
gd loss = 146260.2376577388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145695.4217230062
gradient descent iteration = 12
gd loss = 145695.4217230062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145135.2277574595
gradient descent iteration = 13
gd loss = 145135.2277574595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144579.545806088
gradient descent iteration = 14
gd loss = 144579.545806088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144028.268489204
gradient descent iteration = 15
gd loss = 144028.268489204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143481.2909996774
gradient descent iteration = 16
gd loss = 143481.2909996774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142938.5110787701
gradient descent iteration = 17
gd loss = 142938.5110787701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142399.8289427748
gradient descent iteration = 18
gd loss = 142399.8289427748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141865.1472700623
gradient descent iteration = 19
gd loss = 141865.1472700623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141334.3712306895
gradient descent iteration = 20
gd loss = 141334.3712306895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140807.4086277142
gradient descent iteration = 21
gd loss = 140807.4086277142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140284.1698494009
gradient descent iteration = 22
gd loss = 140284.1698494009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139764.5676790733
gradient descent iteration = 23
gd loss = 139764.5676790733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139248.5172839505
gradient descent iteration = 24
gd loss = 139248.5172839505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138735.9360073767
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 138735.9360073767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137940.3551568043
gradient descent iteration = 1
gd loss = 137940.3551568043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137158.8697099208
gradient descent iteration = 2
gd loss = 137158.8697099208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136390.9207436851
gradient descent iteration = 3
gd loss = 136390.9207436851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135635.9797549276
gradient descent iteration = 4
gd loss = 135635.9797549276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134893.5453750564
gradient descent iteration = 5
gd loss = 134893.5453750564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134163.1408887639
gradient descent iteration = 6
gd loss = 134163.1408887639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133444.3148004877
gradient descent iteration = 7
gd loss = 133444.3148004877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132736.6379049196
gradient descent iteration = 8
gd loss = 132736.6379049196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132039.7003200957
gradient descent iteration = 9
gd loss = 132039.7003200957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131353.1105672571
gradient descent iteration = 10
gd loss = 131353.1105672571
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130676.4941045324
gradient descent iteration = 11
gd loss = 130676.4941045324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130009.493586495
gradient descent iteration = 12
gd loss = 130009.493586495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129351.7676634429
gradient descent iteration = 13
gd loss = 129351.7676634429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128702.9889390784
gradient descent iteration = 14
gd loss = 128702.9889390784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128062.8435083713
gradient descent iteration = 15
gd loss = 128062.8435083713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 127431.0303715421
gradient descent iteration = 16
gd loss = 127431.0303715421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 126807.2620105007
gradient descent iteration = 17
gd loss = 126807.2620105007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 126191.2640118609
gradient descent iteration = 18
gd loss = 126191.2640118609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125582.772854624
gradient descent iteration = 19
gd loss = 125582.772854624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124981.5363300563
gradient descent iteration = 20
gd loss = 124981.5363300563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124387.3140991088
gradient descent iteration = 21
gd loss = 124387.3140991088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123799.8779735361
gradient descent iteration = 22
gd loss = 123799.8779735361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123219.0105312693
gradient descent iteration = 23
gd loss = 123219.0105312693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122644.5045228143
gradient descent iteration = 24
gd loss = 122644.5045228143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122076.1622199463
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 122076.1622199463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121528.1130124069
gradient descent iteration = 1
gd loss = 121528.1130124069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120990.4595101441
gradient descent iteration = 2
gd loss = 120990.4595101441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120462.7281343854
gradient descent iteration = 3
gd loss = 120462.7281343854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119944.4749422895
gradient descent iteration = 4
gd loss = 119944.4749422895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119435.2834892287
gradient descent iteration = 5
gd loss = 119435.2834892287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118934.7628506214
gradient descent iteration = 6
gd loss = 118934.7628506214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118442.5458372958
gradient descent iteration = 7
gd loss = 118442.5458372958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117958.2872357006
gradient descent iteration = 8
gd loss = 117958.2872357006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117481.6622950409
gradient descent iteration = 9
gd loss = 117481.6622950409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117012.365301715
gradient descent iteration = 10
gd loss = 117012.365301715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116550.1083032897
gradient descent iteration = 11
gd loss = 116550.1083032897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116094.6199630235
gradient descent iteration = 12
gd loss = 116094.6199630235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115645.6443877891
gradient descent iteration = 13
gd loss = 115645.6443877891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115202.9400977052
gradient descent iteration = 14
gd loss = 115202.9400977052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114766.2791217063
gradient descent iteration = 15
gd loss = 114766.2791217063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114335.4461319344
gradient descent iteration = 16
gd loss = 114335.4461319344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113910.2375174236
gradient descent iteration = 17
gd loss = 113910.2375174236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113490.4606084803
gradient descent iteration = 18
gd loss = 113490.4606084803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113075.9330018726
gradient descent iteration = 19
gd loss = 113075.9330018726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112666.4818350585
gradient descent iteration = 20
gd loss = 112666.4818350585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112261.9431628506
gradient descent iteration = 21
gd loss = 112261.9431628506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111862.1613693748
gradient descent iteration = 22
gd loss = 111862.1613693748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111466.9886709492
gradient descent iteration = 23
gd loss = 111466.9886709492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111076.28475291
gradient descent iteration = 24
gd loss = 111076.28475291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110689.9163368677
Initial loss = 152812.4378127404
Final loss = 110689.9163368677
Deformation gradient control sequence optimization finished.
Animation interval 8 took 1398 seconds.
Full animation took 12378 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 9************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 121718.4196289538
initial norm = 4765.164832117403
convergence norm = 4.765164832117403
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 121718.4196289538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121244.4978752286
gradient descent iteration = 1
gd loss = 121244.4978752286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120774.7911952964
gradient descent iteration = 2
gd loss = 120774.7911952964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120309.1599273986
gradient descent iteration = 3
gd loss = 120309.1599273986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119847.4696478661
gradient descent iteration = 4
gd loss = 119847.4696478661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119389.5909746082
gradient descent iteration = 5
gd loss = 119389.5909746082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118935.3995295987
gradient descent iteration = 6
gd loss = 118935.3995295987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118484.7758746893
gradient descent iteration = 7
gd loss = 118484.7758746893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118037.6055473551
gradient descent iteration = 8
gd loss = 118037.6055473551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117593.7791694609
gradient descent iteration = 9
gd loss = 117593.7791694609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117153.1919758159
gradient descent iteration = 10
gd loss = 117153.1919758159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116715.7435985244
gradient descent iteration = 11
gd loss = 116715.7435985244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116281.3378101136
gradient descent iteration = 12
gd loss = 116281.3378101136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115849.8825423556
gradient descent iteration = 13
gd loss = 115849.8825423556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115421.2896804554
gradient descent iteration = 14
gd loss = 115421.2896804554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114995.4749389865
gradient descent iteration = 15
gd loss = 114995.4749389865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114572.3576842075
gradient descent iteration = 16
gd loss = 114572.3576842075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114151.8608050558
gradient descent iteration = 17
gd loss = 114151.8608050558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113733.9106336463
gradient descent iteration = 18
gd loss = 113733.9106336463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113318.4367898842
gradient descent iteration = 19
gd loss = 113318.4367898842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112905.3720404824
gradient descent iteration = 20
gd loss = 112905.3720404824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112494.6521707455
gradient descent iteration = 21
gd loss = 112494.6521707455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112086.2157804683
gradient descent iteration = 22
gd loss = 112086.2157804683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111680.0041438979
gradient descent iteration = 23
gd loss = 111680.0041438979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111275.9610859777
gradient descent iteration = 24
gd loss = 111275.9610859777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110874.0328484085
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 110874.0328484085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110169.3734192201
gradient descent iteration = 1
gd loss = 110169.3734192201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109476.9614445535
gradient descent iteration = 2
gd loss = 109476.9614445535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108796.2909750253
gradient descent iteration = 3
gd loss = 108796.2909750253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108126.8875655821
gradient descent iteration = 4
gd loss = 108126.8875655821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 107468.3058518219
gradient descent iteration = 5
gd loss = 107468.3058518219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106820.1279082718
gradient descent iteration = 6
gd loss = 106820.1279082718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106181.9614983111
gradient descent iteration = 7
gd loss = 106181.9614983111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105553.4386444018
gradient descent iteration = 8
gd loss = 105553.4386444018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104934.2137136445
gradient descent iteration = 9
gd loss = 104934.2137136445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104323.9599577786
gradient descent iteration = 10
gd loss = 104323.9599577786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103722.3675772456
gradient descent iteration = 11
gd loss = 103722.3675772456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103129.1442183191
gradient descent iteration = 12
gd loss = 103129.1442183191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102544.0147705652
gradient descent iteration = 13
gd loss = 102544.0147705652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101966.7193914393
gradient descent iteration = 14
gd loss = 101966.7193914393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101397.0127527135
gradient descent iteration = 15
gd loss = 101397.0127527135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100834.6629883107
gradient descent iteration = 16
gd loss = 100834.6629883107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100279.4511979087
gradient descent iteration = 17
gd loss = 100279.4511979087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99731.17167917477
gradient descent iteration = 18
gd loss = 99731.17167917477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99189.630207528
gradient descent iteration = 19
gd loss = 99189.630207528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98654.64312700412
gradient descent iteration = 20
gd loss = 98654.64312700412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98126.03748561701
gradient descent iteration = 21
gd loss = 98126.03748561701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97603.65008339086
gradient descent iteration = 22
gd loss = 97603.65008339086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97087.326504987
gradient descent iteration = 23
gd loss = 97087.326504987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96576.92046860405
gradient descent iteration = 24
gd loss = 96576.92046860405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96072.29264261077
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 96072.29264261077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95617.24537415763
gradient descent iteration = 1
gd loss = 95617.24537415763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95170.89166225139
gradient descent iteration = 2
gd loss = 95170.89166225139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94732.8016064985
gradient descent iteration = 3
gd loss = 94732.8016064985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94302.57764196814
gradient descent iteration = 4
gd loss = 94302.57764196814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93879.85163529127
gradient descent iteration = 5
gd loss = 93879.85163529127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93464.28231921405
gradient descent iteration = 6
gd loss = 93464.28231921405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93055.55281881531
gradient descent iteration = 7
gd loss = 93055.55281881531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92653.36850782244
gradient descent iteration = 8
gd loss = 92653.36850782244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92257.45495269015
gradient descent iteration = 9
gd loss = 92257.45495269015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91867.55624801341
gradient descent iteration = 10
gd loss = 91867.55624801341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91483.43354138454
gradient descent iteration = 11
gd loss = 91483.43354138454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91104.86355771325
gradient descent iteration = 12
gd loss = 91104.86355771325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90731.63728528573
gradient descent iteration = 13
gd loss = 90731.63728528573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90363.55881294206
gradient descent iteration = 14
gd loss = 90363.55881294206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90000.44437305992
gradient descent iteration = 15
gd loss = 90000.44437305992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89642.12135653541
gradient descent iteration = 16
gd loss = 89642.12135653541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89288.42739090046
gradient descent iteration = 17
gd loss = 89288.42739090046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88939.20954284001
gradient descent iteration = 18
gd loss = 88939.20954284001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88594.32356966111
gradient descent iteration = 19
gd loss = 88594.32356966111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88253.63325058305
gradient descent iteration = 20
gd loss = 88253.63325058305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87917.00989879943
gradient descent iteration = 21
gd loss = 87917.00989879943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87584.33188889769
gradient descent iteration = 22
gd loss = 87584.33188889769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87255.48402600392
gradient descent iteration = 23
gd loss = 87255.48402600392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86930.35704355304
gradient descent iteration = 24
gd loss = 86930.35704355304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86608.84722696317
Initial loss = 121718.4196289538
Final loss = 86608.84722696317
Deformation gradient control sequence optimization finished.
Animation interval 9 took 1398 seconds.
Full animation took 13777 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 10************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 94811.93313300177
initial norm = 3921.015749318362
convergence norm = 3.921015749318362
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 94811.93313300177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94422.60837401151
gradient descent iteration = 1
gd loss = 94422.60837401151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94038.06124455745
gradient descent iteration = 2
gd loss = 94038.06124455745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93658.05439532676
gradient descent iteration = 3
gd loss = 93658.05439532676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93282.3624095093
gradient descent iteration = 4
gd loss = 93282.3624095093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92910.77192255555
gradient descent iteration = 5
gd loss = 92910.77192255555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92543.08150185824
gradient descent iteration = 6
gd loss = 92543.08150185824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92179.10126433242
gradient descent iteration = 7
gd loss = 92179.10126433242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91818.65269054635
gradient descent iteration = 8
gd loss = 91818.65269054635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91461.5683323705
gradient descent iteration = 9
gd loss = 91461.5683323705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91107.69146377649
gradient descent iteration = 10
gd loss = 91107.69146377649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90756.87563264341
gradient descent iteration = 11
gd loss = 90756.87563264341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90408.98415349251
gradient descent iteration = 12
gd loss = 90408.98415349251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90063.88959302328
gradient descent iteration = 13
gd loss = 90063.88959302328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89721.47320928842
gradient descent iteration = 14
gd loss = 89721.47320928842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89381.624443894
gradient descent iteration = 15
gd loss = 89381.624443894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89044.24047609285
gradient descent iteration = 16
gd loss = 89044.24047609285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88709.22574526889
gradient descent iteration = 17
gd loss = 88709.22574526889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88376.49146427224
gradient descent iteration = 18
gd loss = 88376.49146427224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88045.95505045156
gradient descent iteration = 19
gd loss = 88045.95505045156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87717.53973104803
gradient descent iteration = 20
gd loss = 87717.53973104803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87391.17419143954
gradient descent iteration = 21
gd loss = 87391.17419143954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87066.79216077825
gradient descent iteration = 22
gd loss = 87066.79216077825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86744.33197659279
gradient descent iteration = 23
gd loss = 86744.33197659279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86423.73616407384
gradient descent iteration = 24
gd loss = 86423.73616407384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86104.951067106
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 86104.951067106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85525.1586474989
gradient descent iteration = 1
gd loss = 85525.1586474989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84956.23099415119
gradient descent iteration = 2
gd loss = 84956.23099415119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84397.76547022493
gradient descent iteration = 3
gd loss = 84397.76547022493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83849.38169956587
gradient descent iteration = 4
gd loss = 83849.38169956587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83310.7208800045
gradient descent iteration = 5
gd loss = 83310.7208800045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82781.44330351426
gradient descent iteration = 6
gd loss = 82781.44330351426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82261.22629066078
gradient descent iteration = 7
gd loss = 82261.22629066078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81749.76293991278
gradient descent iteration = 8
gd loss = 81749.76293991278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81246.76239885426
gradient descent iteration = 9
gd loss = 81246.76239885426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80751.94900959225
gradient descent iteration = 10
gd loss = 80751.94900959225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80265.06113294962
gradient descent iteration = 11
gd loss = 80265.06113294962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79785.84953910953
gradient descent iteration = 12
gd loss = 79785.84953910953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79314.07783741239
gradient descent iteration = 13
gd loss = 79314.07783741239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78849.52270715203
gradient descent iteration = 14
gd loss = 78849.52270715203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78391.97285555241
gradient descent iteration = 15
gd loss = 78391.97285555241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77941.22843667014
gradient descent iteration = 16
gd loss = 77941.22843667014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77497.10047700057
gradient descent iteration = 17
gd loss = 77497.10047700057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77059.41007212683
gradient descent iteration = 18
gd loss = 77059.41007212683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76627.9880710874
gradient descent iteration = 19
gd loss = 76627.9880710874
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76202.67432084872
gradient descent iteration = 20
gd loss = 76202.67432084872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75783.31697200904
gradient descent iteration = 21
gd loss = 75783.31697200904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75369.77245225548
gradient descent iteration = 22
gd loss = 75369.77245225548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74961.90469465926
gradient descent iteration = 23
gd loss = 74961.90469465926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74559.58461918181
gradient descent iteration = 24
gd loss = 74559.58461918181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74162.68987235543
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 74162.68987235543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73810.85122673849
gradient descent iteration = 1
gd loss = 73810.85122673849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73465.27665970016
gradient descent iteration = 2
gd loss = 73465.27665970016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73125.70618665984
gradient descent iteration = 3
gd loss = 73125.70618665984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72791.89742106947
gradient descent iteration = 4
gd loss = 72791.89742106947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72463.62397952488
gradient descent iteration = 5
gd loss = 72463.62397952488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72140.67416221836
gradient descent iteration = 6
gd loss = 72140.67416221836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71822.84972151218
gradient descent iteration = 7
gd loss = 71822.84972151218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71509.96456180162
gradient descent iteration = 8
gd loss = 71509.96456180162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71201.84377976703
gradient descent iteration = 9
gd loss = 71201.84377976703
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70898.32278386722
gradient descent iteration = 10
gd loss = 70898.32278386722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70599.24649817197
gradient descent iteration = 11
gd loss = 70599.24649817197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70304.4685528886
gradient descent iteration = 12
gd loss = 70304.4685528886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70013.85052893707
gradient descent iteration = 13
gd loss = 70013.85052893707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69727.26144886606
gradient descent iteration = 14
gd loss = 69727.26144886606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69444.57724854483
gradient descent iteration = 15
gd loss = 69444.57724854483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69165.68022586621
gradient descent iteration = 16
gd loss = 69165.68022586621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68890.45859670389
gradient descent iteration = 17
gd loss = 68890.45859670389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68618.80610709375
gradient descent iteration = 18
gd loss = 68618.80610709375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68350.62167535636
gradient descent iteration = 19
gd loss = 68350.62167535636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68085.80901959006
gradient descent iteration = 20
gd loss = 68085.80901959006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67824.27636609523
gradient descent iteration = 21
gd loss = 67824.27636609523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67565.9361557825
gradient descent iteration = 22
gd loss = 67565.9361557825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67310.70474800561
gradient descent iteration = 23
gd loss = 67310.70474800561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67058.50214308701
gradient descent iteration = 24
gd loss = 67058.50214308701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66809.25176633398
Initial loss = 94811.93313300177
Final loss = 66809.25176633398
Deformation gradient control sequence optimization finished.
Animation interval 10 took 1407 seconds.
Full animation took 15184 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 11************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 73078.53494180841
initial norm = 3084.843652230154
convergence norm = 3.084843652230155
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 73078.53494180841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72772.224680195
gradient descent iteration = 1
gd loss = 72772.224680195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72469.72575340598
gradient descent iteration = 2
gd loss = 72469.72575340598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72170.84455926163
gradient descent iteration = 3
gd loss = 72170.84455926163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71875.39991042932
gradient descent iteration = 4
gd loss = 71875.39991042932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71583.22256429534
gradient descent iteration = 5
gd loss = 71583.22256429534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71294.1547788459
gradient descent iteration = 6
gd loss = 71294.1547788459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71008.04975333191
gradient descent iteration = 7
gd loss = 71008.04975333191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70724.77092563777
gradient descent iteration = 8
gd loss = 70724.77092563777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70444.19138757167
gradient descent iteration = 9
gd loss = 70444.19138757167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70166.19321234204
gradient descent iteration = 10
gd loss = 70166.19321234204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69890.66693815215
gradient descent iteration = 11
gd loss = 69890.66693815215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69617.51117955518
gradient descent iteration = 12
gd loss = 69617.51117955518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69346.63200599133
gradient descent iteration = 13
gd loss = 69346.63200599133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69077.94237462866
gradient descent iteration = 14
gd loss = 69077.94237462866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68811.36161753448
gradient descent iteration = 15
gd loss = 68811.36161753448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68546.81489664201
gradient descent iteration = 16
gd loss = 68546.81489664201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68284.23278302541
gradient descent iteration = 17
gd loss = 68284.23278302541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68023.55085092116
gradient descent iteration = 18
gd loss = 68023.55085092116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67764.70934407388
gradient descent iteration = 19
gd loss = 67764.70934407388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67507.65265846891
gradient descent iteration = 20
gd loss = 67507.65265846891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67252.32901006071
gradient descent iteration = 21
gd loss = 67252.32901006071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66998.69017628836
gradient descent iteration = 22
gd loss = 66998.69017628836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66746.69121645164
gradient descent iteration = 23
gd loss = 66746.69121645164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66496.29013793672
gradient descent iteration = 24
gd loss = 66496.29013793672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66247.44761826812
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 66247.44761826812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65782.37092883411
gradient descent iteration = 1
gd loss = 65782.37092883411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65327.66033068814
gradient descent iteration = 2
gd loss = 65327.66033068814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64882.93500579667
gradient descent iteration = 3
gd loss = 64882.93500579667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64447.83550751027
gradient descent iteration = 4
gd loss = 64447.83550751027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64022.02210181642
gradient descent iteration = 5
gd loss = 64022.02210181642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63605.17336950819
gradient descent iteration = 6
gd loss = 63605.17336950819
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63196.9848319926
gradient descent iteration = 7
gd loss = 63196.9848319926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62797.16753801884
gradient descent iteration = 8
gd loss = 62797.16753801884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62405.44709559763
gradient descent iteration = 9
gd loss = 62405.44709559763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62021.5624740628
gradient descent iteration = 10
gd loss = 62021.5624740628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61645.26471728438
gradient descent iteration = 11
gd loss = 61645.26471728438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61276.31667561019
gradient descent iteration = 12
gd loss = 61276.31667561019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60914.49241368325
gradient descent iteration = 13
gd loss = 60914.49241368325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60559.57602689163
gradient descent iteration = 14
gd loss = 60559.57602689163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60211.36086109907
gradient descent iteration = 15
gd loss = 60211.36086109907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59869.64877095054
gradient descent iteration = 16
gd loss = 59869.64877095054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59534.2497761546
gradient descent iteration = 17
gd loss = 59534.2497761546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59204.98163449582
gradient descent iteration = 18
gd loss = 59204.98163449582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58881.66949824659
gradient descent iteration = 19
gd loss = 58881.66949824659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58564.14516252466
gradient descent iteration = 20
gd loss = 58564.14516252466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58252.24672712149
gradient descent iteration = 21
gd loss = 58252.24672712149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57945.81803751955
gradient descent iteration = 22
gd loss = 57945.81803751955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57644.7085451368
gradient descent iteration = 23
gd loss = 57644.7085451368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57348.77285484817
gradient descent iteration = 24
gd loss = 57348.77285484817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57057.87026051634
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 57057.87026051634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56785.33231498548
gradient descent iteration = 1
gd loss = 56785.33231498548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56517.95873710285
gradient descent iteration = 2
gd loss = 56517.95873710285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56255.54740234721
gradient descent iteration = 3
gd loss = 56255.54740234721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55997.90724127767
gradient descent iteration = 4
gd loss = 55997.90724127767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55744.8574997158
gradient descent iteration = 5
gd loss = 55744.8574997158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55496.22708130773
gradient descent iteration = 6
gd loss = 55496.22708130773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55251.85393044416
gradient descent iteration = 7
gd loss = 55251.85393044416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55011.58449283798
gradient descent iteration = 8
gd loss = 55011.58449283798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54775.27313706355
gradient descent iteration = 9
gd loss = 54775.27313706355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54542.78161204356
gradient descent iteration = 10
gd loss = 54542.78161204356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54313.97864029356
gradient descent iteration = 11
gd loss = 54313.97864029356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54088.73947683503
gradient descent iteration = 12
gd loss = 54088.73947683503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53866.94553758067
gradient descent iteration = 13
gd loss = 53866.94553758067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53648.48411081947
gradient descent iteration = 14
gd loss = 53648.48411081947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53433.24800176878
gradient descent iteration = 15
gd loss = 53433.24800176878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53221.13516904559
gradient descent iteration = 16
gd loss = 53221.13516904559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53012.04838239273
gradient descent iteration = 17
gd loss = 53012.04838239273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52805.8949608348
gradient descent iteration = 18
gd loss = 52805.8949608348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52602.58647439058
gradient descent iteration = 19
gd loss = 52602.58647439058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52402.03851875875
gradient descent iteration = 20
gd loss = 52402.03851875875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52204.17051029909
gradient descent iteration = 21
gd loss = 52204.17051029909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52008.90543104595
gradient descent iteration = 22
gd loss = 52008.90543104595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51816.16963540552
gradient descent iteration = 23
gd loss = 51816.16963540552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51625.89267582615
gradient descent iteration = 24
gd loss = 51625.89267582615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51438.00710504071
Initial loss = 73078.53494180841
Final loss = 51438.00710504071
Deformation gradient control sequence optimization finished.
Animation interval 11 took 1408 seconds.
Full animation took 16593 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 12************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 56371.69777954004
initial norm = 2517.302819723274
convergence norm = 2.517302819723275
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 56371.69777954004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56122.33615843697
gradient descent iteration = 1
gd loss = 56122.33615843697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55877.2513016462
gradient descent iteration = 2
gd loss = 55877.2513016462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55636.17170507836
gradient descent iteration = 3
gd loss = 55636.17170507836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55398.84631323335
gradient descent iteration = 4
gd loss = 55398.84631323335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55165.04361554619
gradient descent iteration = 5
gd loss = 55165.04361554619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54934.55078280042
gradient descent iteration = 6
gd loss = 54934.55078280042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54707.17270434763
gradient descent iteration = 7
gd loss = 54707.17270434763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54482.73082830419
gradient descent iteration = 8
gd loss = 54482.73082830419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54261.06195056707
gradient descent iteration = 9
gd loss = 54261.06195056707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54042.01702163343
gradient descent iteration = 10
gd loss = 54042.01702163343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53825.46000278222
gradient descent iteration = 11
gd loss = 53825.46000278222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53611.26677039488
gradient descent iteration = 12
gd loss = 53611.26677039488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53399.32410572213
gradient descent iteration = 13
gd loss = 53399.32410572213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53189.52871046604
gradient descent iteration = 14
gd loss = 53189.52871046604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52981.78626872519
gradient descent iteration = 15
gd loss = 52981.78626872519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52776.01046390222
gradient descent iteration = 16
gd loss = 52776.01046390222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52572.12228939659
gradient descent iteration = 17
gd loss = 52572.12228939659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52370.04929039497
gradient descent iteration = 18
gd loss = 52370.04929039497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52169.72484120683
gradient descent iteration = 19
gd loss = 52169.72484120683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51971.08754091502
gradient descent iteration = 20
gd loss = 51971.08754091502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51774.08063863579
gradient descent iteration = 21
gd loss = 51774.08063863579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51578.6515049451
gradient descent iteration = 22
gd loss = 51578.6515049451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51384.75116103662
gradient descent iteration = 23
gd loss = 51384.75116103662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51192.33392866159
gradient descent iteration = 24
gd loss = 51192.33392866159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51001.35703904986
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 51001.35703904986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50646.42266317196
gradient descent iteration = 1
gd loss = 50646.42266317196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50301.46115060141
gradient descent iteration = 2
gd loss = 50301.46115060141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49965.97673945079
gradient descent iteration = 3
gd loss = 49965.97673945079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49639.50377960163
gradient descent iteration = 4
gd loss = 49639.50377960163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49321.60425347786
gradient descent iteration = 5
gd loss = 49321.60425347786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49011.86622200975
gradient descent iteration = 6
gd loss = 49011.86622200975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48709.9019371605
gradient descent iteration = 7
gd loss = 48709.9019371605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48415.34578369682
gradient descent iteration = 8
gd loss = 48415.34578369682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48127.85279672682
gradient descent iteration = 9
gd loss = 48127.85279672682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47847.09759816054
gradient descent iteration = 10
gd loss = 47847.09759816054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47572.77284468966
gradient descent iteration = 11
gd loss = 47572.77284468966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47304.58786928702
gradient descent iteration = 12
gd loss = 47304.58786928702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47042.26744737609
gradient descent iteration = 13
gd loss = 47042.26744737609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46785.55078579412
gradient descent iteration = 14
gd loss = 46785.55078579412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46534.19105496267
gradient descent iteration = 15
gd loss = 46534.19105496267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46287.95484787376
gradient descent iteration = 16
gd loss = 46287.95484787376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46046.62121855591
gradient descent iteration = 17
gd loss = 46046.62121855591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45809.98099885452
gradient descent iteration = 18
gd loss = 45809.98099885452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45577.83596373437
gradient descent iteration = 19
gd loss = 45577.83596373437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45349.99812016586
gradient descent iteration = 20
gd loss = 45349.99812016586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45126.28916768936
gradient descent iteration = 21
gd loss = 45126.28916768936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44906.53988399259
gradient descent iteration = 22
gd loss = 44906.53988399259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44690.58969538286
gradient descent iteration = 23
gd loss = 44690.58969538286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44478.28634365007
gradient descent iteration = 24
gd loss = 44478.28634365007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44269.4855127887
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 44269.4855127887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44049.71268028743
gradient descent iteration = 1
gd loss = 44049.71268028743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43835.22504584058
gradient descent iteration = 2
gd loss = 43835.22504584058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43625.70355452959
gradient descent iteration = 3
gd loss = 43625.70355452959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43420.85842669135
gradient descent iteration = 4
gd loss = 43420.85842669135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43220.42588517895
gradient descent iteration = 5
gd loss = 43220.42588517895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43024.16532516205
gradient descent iteration = 6
gd loss = 43024.16532516205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42831.8567812663
gradient descent iteration = 7
gd loss = 42831.8567812663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42643.29870281238
gradient descent iteration = 8
gd loss = 42643.29870281238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42458.30597687057
gradient descent iteration = 9
gd loss = 42458.30597687057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42276.70821061375
gradient descent iteration = 10
gd loss = 42276.70821061375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42098.34824063275
gradient descent iteration = 11
gd loss = 42098.34824063275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41923.08082426283
gradient descent iteration = 12
gd loss = 41923.08082426283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41750.77143128411
gradient descent iteration = 13
gd loss = 41750.77143128411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41581.29518082189
gradient descent iteration = 14
gd loss = 41581.29518082189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41414.5359086339
gradient descent iteration = 15
gd loss = 41414.5359086339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41250.38534643962
gradient descent iteration = 16
gd loss = 41250.38534643962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41088.74239037215
gradient descent iteration = 17
gd loss = 41088.74239037215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40929.51246403681
gradient descent iteration = 18
gd loss = 40929.51246403681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40772.6069716575
gradient descent iteration = 19
gd loss = 40772.6069716575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40617.94277214865
gradient descent iteration = 20
gd loss = 40617.94277214865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40465.4417332575
gradient descent iteration = 21
gd loss = 40465.4417332575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40315.03031255511
gradient descent iteration = 22
gd loss = 40315.03031255511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40166.63921324319
gradient descent iteration = 23
gd loss = 40166.63921324319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40020.20304721071
gradient descent iteration = 24
gd loss = 40020.20304721071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39875.65998746571
Initial loss = 56371.69777954004
Final loss = 39875.65998746571
Deformation gradient control sequence optimization finished.
Animation interval 12 took 1397 seconds.
Full animation took 17991 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 13************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 43664.9282079062
initial norm = 2073.41883640126
convergence norm = 2.07341883640126
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 43664.9282079062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43460.54943364954
gradient descent iteration = 1
gd loss = 43460.54943364954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43261.54084382984
gradient descent iteration = 2
gd loss = 43261.54084382984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43067.3941223223
gradient descent iteration = 3
gd loss = 43067.3941223223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42877.65541062813
gradient descent iteration = 4
gd loss = 42877.65541062813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42691.92290457983
gradient descent iteration = 5
gd loss = 42691.92290457983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42509.84309988
gradient descent iteration = 6
gd loss = 42509.84309988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42331.10627317515
gradient descent iteration = 7
gd loss = 42331.10627317515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42155.4416472642
gradient descent iteration = 8
gd loss = 42155.4416472642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41982.61271414092
gradient descent iteration = 9
gd loss = 41982.61271414092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41812.41266089669
gradient descent iteration = 10
gd loss = 41812.41266089669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41644.66009287848
gradient descent iteration = 11
gd loss = 41644.66009287848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41479.19535305483
gradient descent iteration = 12
gd loss = 41479.19535305483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41315.87732500672
gradient descent iteration = 13
gd loss = 41315.87732500672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41154.58061830424
gradient descent iteration = 14
gd loss = 41154.58061830424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40995.19318969818
gradient descent iteration = 15
gd loss = 40995.19318969818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40837.61437207317
gradient descent iteration = 16
gd loss = 40837.61437207317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40681.75317088289
gradient descent iteration = 17
gd loss = 40681.75317088289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40527.52676209973
gradient descent iteration = 18
gd loss = 40527.52676209973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40374.85945049226
gradient descent iteration = 19
gd loss = 40374.85945049226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40223.68175827572
gradient descent iteration = 20
gd loss = 40223.68175827572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40073.929574411
gradient descent iteration = 21
gd loss = 40073.929574411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39925.54346890928
gradient descent iteration = 22
gd loss = 39925.54346890928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39778.46822903725
gradient descent iteration = 23
gd loss = 39778.46822903725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39632.652364408
gradient descent iteration = 24
gd loss = 39632.652364408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39488.04762067835
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 39488.04762067835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39217.11066392049
gradient descent iteration = 1
gd loss = 39217.11066392049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38954.58999403891
gradient descent iteration = 2
gd loss = 38954.58999403891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38699.88627235251
gradient descent iteration = 3
gd loss = 38699.88627235251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38452.45733345011
gradient descent iteration = 4
gd loss = 38452.45733345011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38211.8119819448
gradient descent iteration = 5
gd loss = 38211.8119819448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37977.50383227117
gradient descent iteration = 6
gd loss = 37977.50383227117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37749.12614963442
gradient descent iteration = 7
gd loss = 37749.12614963442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37526.30816259049
gradient descent iteration = 8
gd loss = 37526.30816259049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37308.71121023324
gradient descent iteration = 9
gd loss = 37308.71121023324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37096.02504476511
gradient descent iteration = 10
gd loss = 37096.02504476511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36887.96495135235
gradient descent iteration = 11
gd loss = 36887.96495135235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36684.26941546609
gradient descent iteration = 12
gd loss = 36684.26941546609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36484.69791087374
gradient descent iteration = 13
gd loss = 36484.69791087374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36289.02871231406
gradient descent iteration = 14
gd loss = 36289.02871231406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36097.05713685787
gradient descent iteration = 15
gd loss = 36097.05713685787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35908.593752944
gradient descent iteration = 16
gd loss = 35908.593752944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35723.4630252104
gradient descent iteration = 17
gd loss = 35723.4630252104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35541.50207703507
gradient descent iteration = 18
gd loss = 35541.50207703507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35362.55941865584
gradient descent iteration = 19
gd loss = 35362.55941865584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35186.49400580618
gradient descent iteration = 20
gd loss = 35186.49400580618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35013.17433946113
gradient descent iteration = 21
gd loss = 35013.17433946113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34842.47764646796
gradient descent iteration = 22
gd loss = 34842.47764646796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34674.28939192283
gradient descent iteration = 23
gd loss = 34674.28939192283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34508.50267749788
gradient descent iteration = 24
gd loss = 34508.50267749788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34345.01752758119
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 34345.01752758119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34159.18210462885
gradient descent iteration = 1
gd loss = 34159.18210462885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33979.29474752786
gradient descent iteration = 2
gd loss = 33979.29474752786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33804.78075736823
gradient descent iteration = 3
gd loss = 33804.78075736823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33635.15075113238
gradient descent iteration = 4
gd loss = 33635.15075113238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33469.9861048234
gradient descent iteration = 5
gd loss = 33469.9861048234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33308.92696551923
gradient descent iteration = 6
gd loss = 33308.92696551923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33151.66236391306
gradient descent iteration = 7
gd loss = 33151.66236391306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32997.92214907081
gradient descent iteration = 8
gd loss = 32997.92214907081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32847.47026884482
gradient descent iteration = 9
gd loss = 32847.47026884482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32700.09925991818
gradient descent iteration = 10
gd loss = 32700.09925991818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32555.62577993981
gradient descent iteration = 11
gd loss = 32555.62577993981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32413.88685374123
gradient descent iteration = 12
gd loss = 32413.88685374123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32274.73682684309
gradient descent iteration = 13
gd loss = 32274.73682684309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32138.04485243182
gradient descent iteration = 14
gd loss = 32138.04485243182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32003.6927733524
gradient descent iteration = 15
gd loss = 32003.6927733524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31871.57338565828
gradient descent iteration = 16
gd loss = 31871.57338565828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31741.58900849732
gradient descent iteration = 17
gd loss = 31741.58900849732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31613.65022905501
gradient descent iteration = 18
gd loss = 31613.65022905501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31487.67485006073
gradient descent iteration = 19
gd loss = 31487.67485006073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31363.58700423357
gradient descent iteration = 20
gd loss = 31363.58700423357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31241.31640757346
gradient descent iteration = 21
gd loss = 31241.31640757346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31120.79777365087
gradient descent iteration = 22
gd loss = 31120.79777365087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31001.97038372613
gradient descent iteration = 23
gd loss = 31001.97038372613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30884.77757506984
gradient descent iteration = 24
gd loss = 30884.77757506984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30769.16628037967
Initial loss = 43664.9282079062
Final loss = 30769.16628037967
Deformation gradient control sequence optimization finished.
Animation interval 13 took 1401 seconds.
Full animation took 19392 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 14************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 33767.95312618365
initial norm = 1650.948104383033
convergence norm = 1.650948104383033
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 33767.95312618365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33605.65764351693
gradient descent iteration = 1
gd loss = 33605.65764351693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33448.37557349302
gradient descent iteration = 2
gd loss = 33448.37557349302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33295.52841737262
gradient descent iteration = 3
gd loss = 33295.52841737262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33146.62768848362
gradient descent iteration = 4
gd loss = 33146.62768848362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33001.2637623104
gradient descent iteration = 5
gd loss = 33001.2637623104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32859.0933898804
gradient descent iteration = 6
gd loss = 32859.0933898804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32719.82761115934
gradient descent iteration = 7
gd loss = 32719.82761115934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32583.22099781566
gradient descent iteration = 8
gd loss = 32583.22099781566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32449.06255056366
gradient descent iteration = 9
gd loss = 32449.06255056366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32317.16838230998
gradient descent iteration = 10
gd loss = 32317.16838230998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32187.37596286911
gradient descent iteration = 11
gd loss = 32187.37596286911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32059.53977749966
gradient descent iteration = 12
gd loss = 32059.53977749966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31933.52801840159
gradient descent iteration = 13
gd loss = 31933.52801840159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31809.22012088486
gradient descent iteration = 14
gd loss = 31809.22012088486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31686.50502211655
gradient descent iteration = 15
gd loss = 31686.50502211655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31565.27988563214
gradient descent iteration = 16
gd loss = 31565.27988563214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31445.44912270297
gradient descent iteration = 17
gd loss = 31445.44912270297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31326.92372742745
gradient descent iteration = 18
gd loss = 31326.92372742745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31209.62075190006
gradient descent iteration = 19
gd loss = 31209.62075190006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31093.46289102578
gradient descent iteration = 20
gd loss = 31093.46289102578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30978.3781833268
gradient descent iteration = 21
gd loss = 30978.3781833268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30864.29971358697
gradient descent iteration = 22
gd loss = 30864.29971358697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30751.16534164378
gradient descent iteration = 23
gd loss = 30751.16534164378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30638.91747813194
gradient descent iteration = 24
gd loss = 30638.91747813194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30527.50284862499
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 30527.50284862499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30302.06384474759
gradient descent iteration = 1
gd loss = 30302.06384474759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30084.56452521715
gradient descent iteration = 2
gd loss = 30084.56452521715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29874.2510167361
gradient descent iteration = 3
gd loss = 29874.2510167361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29670.47472175796
gradient descent iteration = 4
gd loss = 29670.47472175796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29472.67518539084
gradient descent iteration = 5
gd loss = 29472.67518539084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29280.36594763408
gradient descent iteration = 6
gd loss = 29280.36594763408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29093.12216912604
gradient descent iteration = 7
gd loss = 29093.12216912604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28910.57081674466
gradient descent iteration = 8
gd loss = 28910.57081674466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28732.38276221319
gradient descent iteration = 9
gd loss = 28732.38276221319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28558.26633317393
gradient descent iteration = 10
gd loss = 28558.26633317393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28387.96194956281
gradient descent iteration = 11
gd loss = 28387.96194956281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28221.23751424887
gradient descent iteration = 12
gd loss = 28221.23751424887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28057.88469673411
gradient descent iteration = 13
gd loss = 28057.88469673411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27897.71597196023
gradient descent iteration = 14
gd loss = 27897.71597196023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27740.56188785428
gradient descent iteration = 15
gd loss = 27740.56188785428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27586.26864223754
gradient descent iteration = 16
gd loss = 27586.26864223754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27434.69610709834
gradient descent iteration = 17
gd loss = 27434.69610709834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27285.71626035004
gradient descent iteration = 18
gd loss = 27285.71626035004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27139.21179384489
gradient descent iteration = 19
gd loss = 27139.21179384489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26995.07509295275
gradient descent iteration = 20
gd loss = 26995.07509295275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26853.20701012414
gradient descent iteration = 21
gd loss = 26853.20701012414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26713.51580471032
gradient descent iteration = 22
gd loss = 26713.51580471032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26575.91643010545
gradient descent iteration = 23
gd loss = 26575.91643010545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26440.32988462378
gradient descent iteration = 24
gd loss = 26440.32988462378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26306.68260819863
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 26306.68260819863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26150.63228502444
gradient descent iteration = 1
gd loss = 26150.63228502444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26001.43810395643
gradient descent iteration = 2
gd loss = 26001.43810395643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25858.15020482966
gradient descent iteration = 3
gd loss = 25858.15020482966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25720.01305242478
gradient descent iteration = 4
gd loss = 25720.01305242478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25586.42133154109
gradient descent iteration = 5
gd loss = 25586.42133154109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25456.88597194786
gradient descent iteration = 6
gd loss = 25456.88597194786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25331.00808160255
gradient descent iteration = 7
gd loss = 25331.00808160255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25208.45898043982
gradient descent iteration = 8
gd loss = 25208.45898043982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25088.96491623172
gradient descent iteration = 9
gd loss = 25088.96491623172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24972.29541598728
gradient descent iteration = 10
gd loss = 24972.29541598728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24858.25428535595
gradient descent iteration = 11
gd loss = 24858.25428535595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24746.67271358191
gradient descent iteration = 12
gd loss = 24746.67271358191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24637.40395332854
gradient descent iteration = 13
gd loss = 24637.40395332854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24530.3191989658
gradient descent iteration = 14
gd loss = 24530.3191989658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24425.30433601576
gradient descent iteration = 15
gd loss = 24425.30433601576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24322.25732996962
gradient descent iteration = 16
gd loss = 24322.25732996962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24221.0862124533
gradient descent iteration = 17
gd loss = 24221.0862124533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24121.70748794232
gradient descent iteration = 18
gd loss = 24121.70748794232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24024.04486578816
gradient descent iteration = 19
gd loss = 24024.04486578816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23928.02825732807
gradient descent iteration = 20
gd loss = 23928.02825732807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23833.59295120748
gradient descent iteration = 21
gd loss = 23833.59295120748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23740.67893834866
gradient descent iteration = 22
gd loss = 23740.67893834866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23649.23034776752
gradient descent iteration = 23
gd loss = 23649.23034776752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23559.19493690887
gradient descent iteration = 24
gd loss = 23559.19493690887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23470.52369265492
Initial loss = 33767.95312618365
Final loss = 23470.52369265492
Deformation gradient control sequence optimization finished.
Animation interval 14 took 1402 seconds.
Full animation took 20794 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 15************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 25998.57810277581
initial norm = 1425.834003107942
convergence norm = 1.425834003107942
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 25998.57810277581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25859.17697948065
gradient descent iteration = 1
gd loss = 25859.17697948065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25725.47278824662
gradient descent iteration = 2
gd loss = 25725.47278824662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25596.77193248547
gradient descent iteration = 3
gd loss = 25596.77193248547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25472.48168519833
gradient descent iteration = 4
gd loss = 25472.48168519833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25352.0974500926
gradient descent iteration = 5
gd loss = 25352.0974500926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25235.18837431553
gradient descent iteration = 6
gd loss = 25235.18837431553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25121.38372586982
gradient descent iteration = 7
gd loss = 25121.38372586982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25010.36116002073
gradient descent iteration = 8
gd loss = 25010.36116002073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24901.83743961423
gradient descent iteration = 9
gd loss = 24901.83743961423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24795.56153135422
gradient descent iteration = 10
gd loss = 24795.56153135422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24691.30938678044
gradient descent iteration = 11
gd loss = 24691.30938678044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24588.88028382953
gradient descent iteration = 12
gd loss = 24588.88028382953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24488.09425194867
gradient descent iteration = 13
gd loss = 24488.09425194867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24388.79016910675
gradient descent iteration = 14
gd loss = 24388.79016910675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24290.8242586097
gradient descent iteration = 15
gd loss = 24290.8242586097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24194.06871284725
gradient descent iteration = 16
gd loss = 24194.06871284725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24098.41030871201
gradient descent iteration = 17
gd loss = 24098.41030871201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24003.7491095855
gradient descent iteration = 18
gd loss = 24003.7491095855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23909.9972590066
gradient descent iteration = 19
gd loss = 23909.9972590066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23817.07777130244
gradient descent iteration = 20
gd loss = 23817.07777130244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23724.92334882989
gradient descent iteration = 21
gd loss = 23724.92334882989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23633.47525705793
gradient descent iteration = 22
gd loss = 23633.47525705793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23542.68230787673
gradient descent iteration = 23
gd loss = 23542.68230787673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23452.4999237306
gradient descent iteration = 24
gd loss = 23452.4999237306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23362.88926982931
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 23362.88926982931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23179.02812441677
gradient descent iteration = 1
gd loss = 23179.02812441677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23002.58759647985
gradient descent iteration = 2
gd loss = 23002.58759647985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22832.76403922716
gradient descent iteration = 3
gd loss = 22832.76403922716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22668.89435083088
gradient descent iteration = 4
gd loss = 22668.89435083088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22510.42426386199
gradient descent iteration = 5
gd loss = 22510.42426386199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22356.88473306037
gradient descent iteration = 6
gd loss = 22356.88473306037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22207.87411654149
gradient descent iteration = 7
gd loss = 22207.87411654149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22063.04463847366
gradient descent iteration = 8
gd loss = 22063.04463847366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21922.09232924023
gradient descent iteration = 9
gd loss = 21922.09232924023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21784.74901158945
gradient descent iteration = 10
gd loss = 21784.74901158945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21650.77661214919
gradient descent iteration = 11
gd loss = 21650.77661214919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21519.96254517215
gradient descent iteration = 12
gd loss = 21519.96254517215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21392.11577077944
gradient descent iteration = 13
gd loss = 21392.11577077944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21267.06371734195
gradient descent iteration = 14
gd loss = 21267.06371734195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21144.6497616319
gradient descent iteration = 15
gd loss = 21144.6497616319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21024.73107763919
gradient descent iteration = 16
gd loss = 21024.73107763919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20907.17705874997
gradient descent iteration = 17
gd loss = 20907.17705874997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20791.86794579708
gradient descent iteration = 18
gd loss = 20791.86794579708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20678.69358069001
gradient descent iteration = 19
gd loss = 20678.69358069001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20567.55235230234
gradient descent iteration = 20
gd loss = 20567.55235230234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20458.35032972684
gradient descent iteration = 21
gd loss = 20458.35032972684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20351.00033857139
gradient descent iteration = 22
gd loss = 20351.00033857139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20245.4213647689
gradient descent iteration = 23
gd loss = 20245.4213647689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20141.53805391307
gradient descent iteration = 24
gd loss = 20141.53805391307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20039.28020583749
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 20039.28020583749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19917.88699046915
gradient descent iteration = 1
gd loss = 19917.88699046915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19803.7236866614
gradient descent iteration = 2
gd loss = 19803.7236866614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19695.44376003506
gradient descent iteration = 3
gd loss = 19695.44376003506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19592.04269843347
gradient descent iteration = 4
gd loss = 19592.04269843347
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19492.76334711312
gradient descent iteration = 5
gd loss = 19492.76334711312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19397.02794880966
gradient descent iteration = 6
gd loss = 19397.02794880966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19304.38952023463
gradient descent iteration = 7
gd loss = 19304.38952023463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19214.49703187089
gradient descent iteration = 8
gd loss = 19214.49703187089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19127.07042897496
gradient descent iteration = 9
gd loss = 19127.07042897496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19041.8826412948
gradient descent iteration = 10
gd loss = 19041.8826412948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18958.7466592939
gradient descent iteration = 11
gd loss = 18958.7466592939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18877.5061122693
gradient descent iteration = 12
gd loss = 18877.5061122693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18798.02833451232
gradient descent iteration = 13
gd loss = 18798.02833451232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18720.19923585742
gradient descent iteration = 14
gd loss = 18720.19923585742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18643.91948123039
gradient descent iteration = 15
gd loss = 18643.91948123039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18569.10161093398
gradient descent iteration = 16
gd loss = 18569.10161093398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18495.66784784022
gradient descent iteration = 17
gd loss = 18495.66784784022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18423.54841648153
gradient descent iteration = 18
gd loss = 18423.54841648153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18352.68020637687
gradient descent iteration = 19
gd loss = 18352.68020637687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18283.00575344075
gradient descent iteration = 20
gd loss = 18283.00575344075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18214.4724301644
gradient descent iteration = 21
gd loss = 18214.4724301644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18147.03178901656
gradient descent iteration = 22
gd loss = 18147.03178901656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18080.63902599829
gradient descent iteration = 23
gd loss = 18080.63902599829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18015.25255767054
gradient descent iteration = 24
gd loss = 18015.25255767054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17950.8336572578
Initial loss = 25998.57810277581
Final loss = 17950.8336572578
Deformation gradient control sequence optimization finished.
Animation interval 15 took 1386 seconds.
Full animation took 22181 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 16************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 19934.55077611117
initial norm = 1217.142591834413
convergence norm = 1.217142591834413
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 19934.55077611117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19816.81071615865
gradient descent iteration = 1
gd loss = 19816.81071615865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19705.85009938476
gradient descent iteration = 2
gd loss = 19705.85009938476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19600.45363044917
gradient descent iteration = 3
gd loss = 19600.45363044917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19499.65095620179
gradient descent iteration = 4
gd loss = 19499.65095620179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19402.6794756476
gradient descent iteration = 5
gd loss = 19402.6794756476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19308.93828321495
gradient descent iteration = 6
gd loss = 19308.93828321495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19217.94695874875
gradient descent iteration = 7
gd loss = 19217.94695874875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19129.3143493113
gradient descent iteration = 8
gd loss = 19129.3143493113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19042.716966595
gradient descent iteration = 9
gd loss = 19042.716966595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18957.88458768545
gradient descent iteration = 10
gd loss = 18957.88458768545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18874.59044909171
gradient descent iteration = 11
gd loss = 18874.59044909171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18792.64417513697
gradient descent iteration = 12
gd loss = 18792.64417513697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18711.88617027641
gradient descent iteration = 13
gd loss = 18711.88617027641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18632.18284990292
gradient descent iteration = 14
gd loss = 18632.18284990292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18553.42255250341
gradient descent iteration = 15
gd loss = 18553.42255250341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18475.51196904229
gradient descent iteration = 16
gd loss = 18475.51196904229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18398.3729519258
gradient descent iteration = 17
gd loss = 18398.3729519258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18321.93985299545
gradient descent iteration = 18
gd loss = 18321.93985299545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18246.15732539487
gradient descent iteration = 19
gd loss = 18246.15732539487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18170.97848702779
gradient descent iteration = 20
gd loss = 18170.97848702779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18096.36345090206
gradient descent iteration = 21
gd loss = 18096.36345090206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18022.27809207661
gradient descent iteration = 22
gd loss = 18022.27809207661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17948.69302067102
gradient descent iteration = 23
gd loss = 17948.69302067102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17875.58275580536
gradient descent iteration = 24
gd loss = 17875.58275580536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17802.92507119071
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 17802.92507119071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17652.87672617057
gradient descent iteration = 1
gd loss = 17652.87672617057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17510.27921398322
gradient descent iteration = 2
gd loss = 17510.27921398322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17374.16851581821
gradient descent iteration = 3
gd loss = 17374.16851581821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17243.78158959404
gradient descent iteration = 4
gd loss = 17243.78158959404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17118.50140250252
gradient descent iteration = 5
gd loss = 17118.50140250252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16997.81938636381
gradient descent iteration = 6
gd loss = 16997.81938636381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16881.30929299755
gradient descent iteration = 7
gd loss = 16881.30929299755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16768.60884380377
gradient descent iteration = 8
gd loss = 16768.60884380377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16659.40636548512
gradient descent iteration = 9
gd loss = 16659.40636548512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16553.43083560461
gradient descent iteration = 10
gd loss = 16553.43083560461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16450.4445667171
gradient descent iteration = 11
gd loss = 16450.4445667171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16350.23767182304
gradient descent iteration = 12
gd loss = 16350.23767182304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16252.6235462763
gradient descent iteration = 13
gd loss = 16252.6235462763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16157.43535573563
gradient descent iteration = 14
gd loss = 16157.43535573563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16064.52320244729
gradient descent iteration = 15
gd loss = 16064.52320244729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15973.75172785519
gradient descent iteration = 16
gd loss = 15973.75172785519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15884.99823162128
gradient descent iteration = 17
gd loss = 15884.99823162128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15798.15110594061
gradient descent iteration = 18
gd loss = 15798.15110594061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15713.10853430951
gradient descent iteration = 19
gd loss = 15713.10853430951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15629.77741589486
gradient descent iteration = 20
gd loss = 15629.77741589486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15548.07235993359
gradient descent iteration = 21
gd loss = 15548.07235993359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15467.91478975568
gradient descent iteration = 22
gd loss = 15467.91478975568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15389.23225980309
gradient descent iteration = 23
gd loss = 15389.23225980309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15311.9578680344
gradient descent iteration = 24
gd loss = 15311.9578680344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15236.02972474334
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 15236.02972474334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15145.13743740106
gradient descent iteration = 1
gd loss = 15145.13743740106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15061.01924791607
gradient descent iteration = 2
gd loss = 15061.01924791607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14982.05068694806
gradient descent iteration = 3
gd loss = 14982.05068694806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14907.10834545226
gradient descent iteration = 4
gd loss = 14907.10834545226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14835.40476360124
gradient descent iteration = 5
gd loss = 14835.40476360124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14766.37900037634
gradient descent iteration = 6
gd loss = 14766.37900037634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14699.62406307235
gradient descent iteration = 7
gd loss = 14699.62406307235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14634.83866802545
gradient descent iteration = 8
gd loss = 14634.83866802545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14571.79495672869
gradient descent iteration = 9
gd loss = 14571.79495672869
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14510.31672178614
gradient descent iteration = 10
gd loss = 14510.31672178614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14450.26460128066
gradient descent iteration = 11
gd loss = 14450.26460128066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14391.5259215097
gradient descent iteration = 12
gd loss = 14391.5259215097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14334.00765979214
gradient descent iteration = 13
gd loss = 14334.00765979214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14277.63152749053
gradient descent iteration = 14
gd loss = 14277.63152749053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14222.33045325001
gradient descent iteration = 15
gd loss = 14222.33045325001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14168.04605869879
gradient descent iteration = 16
gd loss = 14168.04605869879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14114.72682585033
gradient descent iteration = 17
gd loss = 14114.72682585033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14062.32674767745
gradient descent iteration = 18
gd loss = 14062.32674767745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14010.80432268716
gradient descent iteration = 19
gd loss = 14010.80432268716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13960.12179311518
gradient descent iteration = 20
gd loss = 13960.12179311518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13910.24455582691
gradient descent iteration = 21
gd loss = 13910.24455582691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13861.14070617014
gradient descent iteration = 22
gd loss = 13861.14070617014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13812.7806854288
gradient descent iteration = 23
gd loss = 13812.7806854288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13765.13698875619
gradient descent iteration = 24
gd loss = 13765.13698875619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13718.18393583873
Initial loss = 19934.55077611117
Final loss = 13718.18393583873
Deformation gradient control sequence optimization finished.
Animation interval 16 took 1404 seconds.
Full animation took 23585 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 17************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 15389.26264969613
initial norm = 1194.049391883441
convergence norm = 1.194049391883441
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 15389.26264969613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15276.24046393217
gradient descent iteration = 1
gd loss = 15276.24046393217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15174.26704243994
gradient descent iteration = 2
gd loss = 15174.26704243994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15081.27393419968
gradient descent iteration = 3
gd loss = 15081.27393419968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14995.38220667055
gradient descent iteration = 4
gd loss = 14995.38220667055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14915.00128862586
gradient descent iteration = 5
gd loss = 14915.00128862586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14838.8570618134
gradient descent iteration = 6
gd loss = 14838.8570618134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14765.96414366174
gradient descent iteration = 7
gd loss = 14765.96414366174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14695.57574475211
gradient descent iteration = 8
gd loss = 14695.57574475211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14627.13344657946
gradient descent iteration = 9
gd loss = 14627.13344657946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14560.22440441007
gradient descent iteration = 10
gd loss = 14560.22440441007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14494.54613131145
gradient descent iteration = 11
gd loss = 14494.54613131145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14429.87811028445
gradient descent iteration = 12
gd loss = 14429.87811028445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14366.05944573882
gradient descent iteration = 13
gd loss = 14366.05944573882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14302.97182700479
gradient descent iteration = 14
gd loss = 14302.97182700479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14240.52695052092
gradient descent iteration = 15
gd loss = 14240.52695052092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14178.6575903427
gradient descent iteration = 16
gd loss = 14178.6575903427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14117.31142890647
gradient descent iteration = 17
gd loss = 14117.31142890647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14056.44686617375
gradient descent iteration = 18
gd loss = 14056.44686617375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13996.03030836452
gradient descent iteration = 19
gd loss = 13996.03030836452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13936.03408754155
gradient descent iteration = 20
gd loss = 13936.03408754155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13876.43499131877
gradient descent iteration = 21
gd loss = 13876.43499131877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13817.21330457279
gradient descent iteration = 22
gd loss = 13817.21330457279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13758.35210226548
gradient descent iteration = 23
gd loss = 13758.35210226548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13699.83686938716
gradient descent iteration = 24
gd loss = 13699.83686938716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13641.65523540573
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 13641.65523540573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13521.16495913068
gradient descent iteration = 1
gd loss = 13521.16495913068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13408.45990582907
gradient descent iteration = 2
gd loss = 13408.45990582907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13302.31831534658
gradient descent iteration = 3
gd loss = 13302.31831534658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13201.81264754541
gradient descent iteration = 4
gd loss = 13201.81264754541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13106.21736300223
gradient descent iteration = 5
gd loss = 13106.21736300223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13014.95068276646
gradient descent iteration = 6
gd loss = 13014.95068276646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12927.5363843538
gradient descent iteration = 7
gd loss = 12927.5363843538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12843.57790775322
gradient descent iteration = 8
gd loss = 12843.57790775322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12762.74036979303
gradient descent iteration = 9
gd loss = 12762.74036979303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12684.73756772667
gradient descent iteration = 10
gd loss = 12684.73756772667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12609.32247318685
gradient descent iteration = 11
gd loss = 12609.32247318685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12536.28005106632
gradient descent iteration = 12
gd loss = 12536.28005106632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12465.42178407705
gradient descent iteration = 13
gd loss = 12465.42178407705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12396.58135452776
gradient descent iteration = 14
gd loss = 12396.58135452776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12329.61120832446
gradient descent iteration = 15
gd loss = 12329.61120832446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12264.3797909012
gradient descent iteration = 16
gd loss = 12264.3797909012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12200.76933870963
gradient descent iteration = 17
gd loss = 12200.76933870963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12138.67404814342
gradient descent iteration = 18
gd loss = 12138.67404814342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12077.99854170195
gradient descent iteration = 19
gd loss = 12077.99854170195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12018.65660767443
gradient descent iteration = 20
gd loss = 12018.65660767443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11960.57007201245
gradient descent iteration = 21
gd loss = 11960.57007201245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11903.66781762395
gradient descent iteration = 22
gd loss = 11903.66781762395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11847.88498150453
gradient descent iteration = 23
gd loss = 11847.88498150453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11793.16227326319
gradient descent iteration = 24
gd loss = 11793.16227326319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11739.44538548599
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 11739.44538548599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11672.55039932671
gradient descent iteration = 1
gd loss = 11672.55039932671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11611.95501759409
gradient descent iteration = 2
gd loss = 11611.95501759409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11555.74471142411
gradient descent iteration = 3
gd loss = 11555.74471142411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11502.72557915581
gradient descent iteration = 4
gd loss = 11502.72557915581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11452.13869125473
gradient descent iteration = 5
gd loss = 11452.13869125473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11403.49013479599
gradient descent iteration = 6
gd loss = 11403.49013479599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11356.44942470957
gradient descent iteration = 7
gd loss = 11356.44942470957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11310.78830526582
gradient descent iteration = 8
gd loss = 11310.78830526582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11266.34352329906
gradient descent iteration = 9
gd loss = 11266.34352329906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11222.99392912436
gradient descent iteration = 10
gd loss = 11222.99392912436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11180.64622275061
gradient descent iteration = 11
gd loss = 11180.64622275061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11139.22596091156
gradient descent iteration = 12
gd loss = 11139.22596091156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11098.67181306897
gradient descent iteration = 13
gd loss = 11098.67181306897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11058.93183258991
gradient descent iteration = 14
gd loss = 11058.93183258991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11019.96099338817
gradient descent iteration = 15
gd loss = 11019.96099338817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10981.71953671534
gradient descent iteration = 16
gd loss = 10981.71953671534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10944.17183610291
gradient descent iteration = 17
gd loss = 10944.17183610291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10907.2855989427
gradient descent iteration = 18
gd loss = 10907.2855989427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10871.03129395337
gradient descent iteration = 19
gd loss = 10871.03129395337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10835.38173193358
gradient descent iteration = 20
gd loss = 10835.38173193358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10800.31174777534
gradient descent iteration = 21
gd loss = 10800.31174777534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10765.79795019049
gradient descent iteration = 22
gd loss = 10765.79795019049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10731.8185207433
gradient descent iteration = 23
gd loss = 10731.8185207433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10698.35304812161
gradient descent iteration = 24
gd loss = 10698.35304812161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10665.3823927521
Initial loss = 15389.26264969613
Final loss = 10665.3823927521
Deformation gradient control sequence optimization finished.
Animation interval 17 took 1410 seconds.
Full animation took 24995 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 18************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 12043.98484930215
initial norm = 1179.642765362034
convergence norm = 1.179642765362034
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 12043.98484930215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11935.27640537273
gradient descent iteration = 1
gd loss = 11935.27640537273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11842.77703463012
gradient descent iteration = 2
gd loss = 11842.77703463012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11763.21079426992
gradient descent iteration = 3
gd loss = 11763.21079426992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11693.16659379426
gradient descent iteration = 4
gd loss = 11693.16659379426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11629.65062849568
gradient descent iteration = 5
gd loss = 11629.65062849568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11570.45242989431
gradient descent iteration = 6
gd loss = 11570.45242989431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11514.12467081623
gradient descent iteration = 7
gd loss = 11514.12467081623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11459.76835167021
gradient descent iteration = 8
gd loss = 11459.76835167021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11406.83307508527
gradient descent iteration = 9
gd loss = 11406.83307508527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11354.98162039832
gradient descent iteration = 10
gd loss = 11354.98162039832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11304.00404783166
gradient descent iteration = 11
gd loss = 11304.00404783166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11253.76498501905
gradient descent iteration = 12
gd loss = 11253.76498501905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11204.17258006225
gradient descent iteration = 13
gd loss = 11204.17258006225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11155.16078813725
gradient descent iteration = 14
gd loss = 11155.16078813725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11106.67946004441
gradient descent iteration = 15
gd loss = 11106.67946004441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11058.68879639234
gradient descent iteration = 16
gd loss = 11058.68879639234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11011.15618359674
gradient descent iteration = 17
gd loss = 11011.15618359674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10964.05425372437
gradient descent iteration = 18
gd loss = 10964.05425372437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10917.35963768945
gradient descent iteration = 19
gd loss = 10917.35963768945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10871.05221025821
gradient descent iteration = 20
gd loss = 10871.05221025821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10825.11453927551
gradient descent iteration = 21
gd loss = 10825.11453927551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10779.53129824016
gradient descent iteration = 22
gd loss = 10779.53129824016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10734.28891454265
gradient descent iteration = 23
gd loss = 10734.28891454265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10689.37528679765
gradient descent iteration = 24
gd loss = 10689.37528679765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10644.77952822579
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 10644.77952822579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10552.61734518834
gradient descent iteration = 1
gd loss = 10552.61734518834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10468.13480240223
gradient descent iteration = 2
gd loss = 10468.13480240223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10389.80189047739
gradient descent iteration = 3
gd loss = 10389.80189047739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10316.52596952893
gradient descent iteration = 4
gd loss = 10316.52596952893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10247.49629007136
gradient descent iteration = 5
gd loss = 10247.49629007136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10182.09194634037
gradient descent iteration = 6
gd loss = 10182.09194634037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10119.8248538011
gradient descent iteration = 7
gd loss = 10119.8248538011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10060.30292132641
gradient descent iteration = 8
gd loss = 10060.30292132641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10003.20544177198
gradient descent iteration = 9
gd loss = 10003.20544177198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9948.266157161523
gradient descent iteration = 10
gd loss = 9948.266157161523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9895.261303807081
gradient descent iteration = 11
gd loss = 9895.261303807081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9844.000917690175
gradient descent iteration = 12
gd loss = 9844.000917690175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9794.322331519803
gradient descent iteration = 13
gd loss = 9794.322331519803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9746.085188971885
gradient descent iteration = 14
gd loss = 9746.085188971885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9699.167599174809
gradient descent iteration = 15
gd loss = 9699.167599174809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9653.463128564208
gradient descent iteration = 16
gd loss = 9653.463128564208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9608.878394335943
gradient descent iteration = 17
gd loss = 9608.878394335943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9565.331073494412
gradient descent iteration = 18
gd loss = 9565.331073494412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9522.748326315834
gradient descent iteration = 19
gd loss = 9522.748326315834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9481.065460306834
gradient descent iteration = 20
gd loss = 9481.065460306834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9440.22481620337
gradient descent iteration = 21
gd loss = 9440.22481620337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9400.174817606328
gradient descent iteration = 22
gd loss = 9400.174817606328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9360.869192997536
gradient descent iteration = 23
gd loss = 9360.869192997536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9322.266361203245
gradient descent iteration = 24
gd loss = 9322.266361203245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9284.328840518794
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 9284.328840518794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9235.808057290313
gradient descent iteration = 1
gd loss = 9235.808057290313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9192.87753813668
gradient descent iteration = 2
gd loss = 9192.87753813668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9153.360412051303
gradient descent iteration = 3
gd loss = 9153.360412051303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9116.104305005912
gradient descent iteration = 4
gd loss = 9116.104305005912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9080.478420328733
gradient descent iteration = 5
gd loss = 9080.478420328733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9046.122096288465
gradient descent iteration = 6
gd loss = 9046.122096288465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9012.817535393704
gradient descent iteration = 7
gd loss = 9012.817535393704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8980.424425521805
gradient descent iteration = 8
gd loss = 8980.424425521805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8948.845803881864
gradient descent iteration = 9
gd loss = 8948.845803881864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8918.009912762582
gradient descent iteration = 10
gd loss = 8918.009912762582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8887.860373273194
gradient descent iteration = 11
gd loss = 8887.860373273194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8858.350714784036
gradient descent iteration = 12
gd loss = 8858.350714784036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8829.44124999455
gradient descent iteration = 13
gd loss = 8829.44124999455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8801.097230210686
gradient descent iteration = 14
gd loss = 8801.097230210686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8773.287704093673
gradient descent iteration = 15
gd loss = 8773.287704093673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8745.984773638469
gradient descent iteration = 16
gd loss = 8745.984773638469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8719.163083175552
gradient descent iteration = 17
gd loss = 8719.163083175552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8692.799451915595
gradient descent iteration = 18
gd loss = 8692.799451915595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8666.87258528956
gradient descent iteration = 19
gd loss = 8666.87258528956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8641.362850914878
gradient descent iteration = 20
gd loss = 8641.362850914878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8616.252100297492
gradient descent iteration = 21
gd loss = 8616.252100297492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8591.523507967322
gradient descent iteration = 22
gd loss = 8591.523507967322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8567.161438725261
gradient descent iteration = 23
gd loss = 8567.161438725261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8543.151339010323
gradient descent iteration = 24
gd loss = 8543.151339010323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8519.479634223153
Initial loss = 12043.98484930215
Final loss = 8519.479634223153
Deformation gradient control sequence optimization finished.
Animation interval 18 took 1402 seconds.
Full animation took 26397 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 19************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9635.199420366227
initial norm = 1139.513700122577
convergence norm = 1.139513700122577
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9635.199420366227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9533.101021129143
gradient descent iteration = 1
gd loss = 9533.101021129143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9452.303253616386
gradient descent iteration = 2
gd loss = 9452.303253616386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9388.45366689249
gradient descent iteration = 3
gd loss = 9388.45366689249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9335.764263134362
gradient descent iteration = 4
gd loss = 9335.764263134362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9288.891093596576
gradient descent iteration = 5
gd loss = 9288.891093596576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9244.842489938044
gradient descent iteration = 6
gd loss = 9244.842489938044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9202.404241508393
gradient descent iteration = 7
gd loss = 9202.404241508393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9161.068389176307
gradient descent iteration = 8
gd loss = 9161.068389176307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9120.584292124047
gradient descent iteration = 9
gd loss = 9120.584292124047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9080.806747352774
gradient descent iteration = 10
gd loss = 9080.806747352774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9041.639000040312
gradient descent iteration = 11
gd loss = 9041.639000040312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9003.009769323762
gradient descent iteration = 12
gd loss = 9003.009769323762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8964.863420222517
gradient descent iteration = 13
gd loss = 8964.863420222517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8927.155167108283
gradient descent iteration = 14
gd loss = 8927.155167108283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8889.848331397576
gradient descent iteration = 15
gd loss = 8889.848331397576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8852.912584883308
gradient descent iteration = 16
gd loss = 8852.912584883308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8816.322600276519
gradient descent iteration = 17
gd loss = 8816.322600276519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8780.057030810145
gradient descent iteration = 18
gd loss = 8780.057030810145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8744.09773331938
gradient descent iteration = 19
gd loss = 8744.09773331938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8708.4292205129
gradient descent iteration = 20
gd loss = 8708.4292205129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8673.038239037731
gradient descent iteration = 21
gd loss = 8673.038239037731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8637.91345351832
gradient descent iteration = 22
gd loss = 8637.91345351832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8603.045186925625
gradient descent iteration = 23
gd loss = 8603.045186925625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8568.425142689768
gradient descent iteration = 24
gd loss = 8568.425142689768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8534.04627406036
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8534.04627406036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8466.845540176917
gradient descent iteration = 1
gd loss = 8466.845540176917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8406.352043425321
gradient descent iteration = 2
gd loss = 8406.352043425321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8350.859200806453
gradient descent iteration = 3
gd loss = 8350.859200806453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8299.268914693024
gradient descent iteration = 4
gd loss = 8299.268914693024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8250.828707833003
gradient descent iteration = 5
gd loss = 8250.828707833003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8204.996586866982
gradient descent iteration = 6
gd loss = 8204.996586866982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8161.366473598037
gradient descent iteration = 7
gd loss = 8161.366473598037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8119.624584862068
gradient descent iteration = 8
gd loss = 8119.624584862068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8079.522498351891
gradient descent iteration = 9
gd loss = 8079.522498351891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8040.859838279228
gradient descent iteration = 10
gd loss = 8040.859838279228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8003.472579963773
gradient descent iteration = 11
gd loss = 8003.472579963773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7967.224826569609
gradient descent iteration = 12
gd loss = 7967.224826569609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7932.002802521333
gradient descent iteration = 13
gd loss = 7932.002802521333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7897.710488007988
gradient descent iteration = 14
gd loss = 7897.710488007988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7864.266311828555
gradient descent iteration = 15
gd loss = 7864.266311828555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7831.600636748502
gradient descent iteration = 16
gd loss = 7831.600636748502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7799.6537031227
gradient descent iteration = 17
gd loss = 7799.6537031227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7768.373945857406
gradient descent iteration = 18
gd loss = 7768.373945857406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7737.716659731876
gradient descent iteration = 19
gd loss = 7737.716659731876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7707.6428805134
gradient descent iteration = 20
gd loss = 7707.6428805134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7678.118493797389
gradient descent iteration = 21
gd loss = 7678.118493797389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7649.113488450652
gradient descent iteration = 22
gd loss = 7649.113488450652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7620.601333942017
gradient descent iteration = 23
gd loss = 7620.601333942017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7592.558504235702
gradient descent iteration = 24
gd loss = 7592.558504235702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7564.964033580763
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 7564.964033580763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7529.41273527341
gradient descent iteration = 1
gd loss = 7529.41273527341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7498.60538989651
gradient descent iteration = 2
gd loss = 7498.60538989651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7470.231077532648
gradient descent iteration = 3
gd loss = 7470.231077532648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7443.322978448579
gradient descent iteration = 4
gd loss = 7443.322978448579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7417.449976388349
gradient descent iteration = 5
gd loss = 7417.449976388349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7392.400818850179
gradient descent iteration = 6
gd loss = 7392.400818850179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7368.058089934151
gradient descent iteration = 7
gd loss = 7368.058089934151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7344.346743534218
gradient descent iteration = 8
gd loss = 7344.346743534218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7321.212495967327
gradient descent iteration = 9
gd loss = 7321.212495967327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7298.612407664891
gradient descent iteration = 10
gd loss = 7298.612407664891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7276.510555672194
gradient descent iteration = 11
gd loss = 7276.510555672194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7254.875884262928
gradient descent iteration = 12
gd loss = 7254.875884262928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7233.681017080319
gradient descent iteration = 13
gd loss = 7233.681017080319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7212.901521559468
gradient descent iteration = 14
gd loss = 7212.901521559468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7192.515418268386
gradient descent iteration = 15
gd loss = 7192.515418268386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7172.502811839044
gradient descent iteration = 16
gd loss = 7172.502811839044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7152.845598629071
gradient descent iteration = 17
gd loss = 7152.845598629071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7133.527227988666
gradient descent iteration = 18
gd loss = 7133.527227988666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7114.532510252593
gradient descent iteration = 19
gd loss = 7114.532510252593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7095.847458387585
gradient descent iteration = 20
gd loss = 7095.847458387585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7077.459157631825
gradient descent iteration = 21
gd loss = 7077.459157631825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7059.355645454089
gradient descent iteration = 22
gd loss = 7059.355645454089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7041.525805228453
gradient descent iteration = 23
gd loss = 7041.525805228453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7023.959276157681
gradient descent iteration = 24
gd loss = 7023.959276157681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7006.646380718556
Initial loss = 9635.199420366227
Final loss = 7006.646380718556
Deformation gradient control sequence optimization finished.
Animation interval 19 took 1404 seconds.
Full animation took 27802 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 20************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7956.623938396324
initial norm = 1054.883113639579
convergence norm = 1.054883113639579
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7956.623938396324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7863.757832771488
gradient descent iteration = 1
gd loss = 7863.757832771488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7793.621324797127
gradient descent iteration = 2
gd loss = 7793.621324797127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7741.225098439841
gradient descent iteration = 3
gd loss = 7741.225098439841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7699.450725524868
gradient descent iteration = 4
gd loss = 7699.450725524868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7662.280371767296
gradient descent iteration = 5
gd loss = 7662.280371767296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7627.197490203146
gradient descent iteration = 6
gd loss = 7627.197490203146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7593.389620692391
gradient descent iteration = 7
gd loss = 7593.389620692391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7560.532928376895
gradient descent iteration = 8
gd loss = 7560.532928376895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7528.455090394255
gradient descent iteration = 9
gd loss = 7528.455090394255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7497.040485943157
gradient descent iteration = 10
gd loss = 7497.040485943157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7466.202373367296
gradient descent iteration = 11
gd loss = 7466.202373367296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7435.872936718769
gradient descent iteration = 12
gd loss = 7435.872936718769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7405.99822173918
gradient descent iteration = 13
gd loss = 7405.99822173918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7376.53475011206
gradient descent iteration = 14
gd loss = 7376.53475011206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7347.447071998722
gradient descent iteration = 15
gd loss = 7347.447071998722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7318.70595508755
gradient descent iteration = 16
gd loss = 7318.70595508755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7290.287079140885
gradient descent iteration = 17
gd loss = 7290.287079140885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7262.170051432796
gradient descent iteration = 18
gd loss = 7262.170051432796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7234.337554969112
gradient descent iteration = 19
gd loss = 7234.337554969112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7206.774783838801
gradient descent iteration = 20
gd loss = 7206.774783838801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7179.469064875065
gradient descent iteration = 21
gd loss = 7179.469064875065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7152.409511488027
gradient descent iteration = 22
gd loss = 7152.409511488027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7125.586573342235
gradient descent iteration = 23
gd loss = 7125.586573342235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7098.991784191413
gradient descent iteration = 24
gd loss = 7098.991784191413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7072.617596966294
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 7072.617596966294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7022.601101617059
gradient descent iteration = 1
gd loss = 7022.601101617059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6978.732816626529
gradient descent iteration = 2
gd loss = 6978.732816626529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6939.101325224762
gradient descent iteration = 3
gd loss = 6939.101325224762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6902.620793033102
gradient descent iteration = 4
gd loss = 6902.620793033102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6868.603469832948
gradient descent iteration = 5
gd loss = 6868.603469832948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6836.578042627809
gradient descent iteration = 6
gd loss = 6836.578042627809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6806.202831690897
gradient descent iteration = 7
gd loss = 6806.202831690897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6777.220188921363
gradient descent iteration = 8
gd loss = 6777.220188921363
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6749.430379455296
gradient descent iteration = 9
gd loss = 6749.430379455296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6722.675411369876
gradient descent iteration = 10
gd loss = 6722.675411369876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6696.828378341748
gradient descent iteration = 11
gd loss = 6696.828378341748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6671.786119652264
gradient descent iteration = 12
gd loss = 6671.786119652264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6647.463914797628
gradient descent iteration = 13
gd loss = 6647.463914797628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6623.791495705743
gradient descent iteration = 14
gd loss = 6623.791495705743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6600.710090313325
gradient descent iteration = 15
gd loss = 6600.710090313325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6578.17015752642
gradient descent iteration = 16
gd loss = 6578.17015752642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6556.129597717199
gradient descent iteration = 17
gd loss = 6556.129597717199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6534.552372470187
gradient descent iteration = 18
gd loss = 6534.552372470187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6513.40738728829
gradient descent iteration = 19
gd loss = 6513.40738728829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6492.667610303251
gradient descent iteration = 20
gd loss = 6492.667610303251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6472.309399112677
gradient descent iteration = 21
gd loss = 6472.309399112677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6452.311980319473
gradient descent iteration = 22
gd loss = 6452.311980319473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6432.656953634595
gradient descent iteration = 23
gd loss = 6432.656953634595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6413.327917268616
gradient descent iteration = 24
gd loss = 6413.327917268616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6394.310188079045
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6394.310188079045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6369.053806084139
gradient descent iteration = 1
gd loss = 6369.053806084139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6347.790969047501
gradient descent iteration = 2
gd loss = 6347.790969047501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6328.141435196767
gradient descent iteration = 3
gd loss = 6328.141435196767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6309.404447185531
gradient descent iteration = 4
gd loss = 6309.404447185531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6291.338499417292
gradient descent iteration = 5
gd loss = 6291.338499417292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6273.835839021596
gradient descent iteration = 6
gd loss = 6273.835839021596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6256.832469526888
gradient descent iteration = 7
gd loss = 6256.832469526888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6240.281922938609
gradient descent iteration = 8
gd loss = 6240.281922938609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6224.146843538114
gradient descent iteration = 9
gd loss = 6224.146843538114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6208.395783682263
gradient descent iteration = 10
gd loss = 6208.395783682263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6193.00165966956
gradient descent iteration = 11
gd loss = 6193.00165966956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6177.940826102675
gradient descent iteration = 12
gd loss = 6177.940826102675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6163.192433965878
gradient descent iteration = 13
gd loss = 6163.192433965878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6148.737949399726
gradient descent iteration = 14
gd loss = 6148.737949399726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6134.560780049262
gradient descent iteration = 15
gd loss = 6134.560780049262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6120.645979413439
gradient descent iteration = 16
gd loss = 6120.645979413439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6106.980009345108
gradient descent iteration = 17
gd loss = 6106.980009345108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6093.55054656385
gradient descent iteration = 18
gd loss = 6093.55054656385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6080.346323709532
gradient descent iteration = 19
gd loss = 6080.346323709532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6067.356998556428
gradient descent iteration = 20
gd loss = 6067.356998556428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6054.573044925958
gradient descent iteration = 21
gd loss = 6054.573044925958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6041.985660531781
gradient descent iteration = 22
gd loss = 6041.985660531781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6029.586687818064
gradient descent iteration = 23
gd loss = 6029.586687818064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6017.368546646566
gradient descent iteration = 24
gd loss = 6017.368546646566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6005.324176955175
Initial loss = 7956.623938396324
Final loss = 6005.324176955175
Deformation gradient control sequence optimization finished.
Animation interval 20 took 1404 seconds.
Full animation took 29206 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 21************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6823.396888189019
initial norm = 962.2341648682844
convergence norm = 0.9622341648682845
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6823.396888189019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6740.324939918208
gradient descent iteration = 1
gd loss = 6740.324939918208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6680.934635868527
gradient descent iteration = 2
gd loss = 6680.934635868527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6639.450814607533
gradient descent iteration = 3
gd loss = 6639.450814607533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6607.135140200627
gradient descent iteration = 4
gd loss = 6607.135140200627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6578.010224337905
gradient descent iteration = 5
gd loss = 6578.010224337905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6550.442349228272
gradient descent iteration = 6
gd loss = 6550.442349228272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6523.959844705818
gradient descent iteration = 7
gd loss = 6523.959844705818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6498.33631888962
gradient descent iteration = 8
gd loss = 6498.33631888962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6473.41928829801
gradient descent iteration = 9
gd loss = 6473.41928829801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6449.096299042406
gradient descent iteration = 10
gd loss = 6449.096299042406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6425.282422684391
gradient descent iteration = 11
gd loss = 6425.282422684391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6401.912601938174
gradient descent iteration = 12
gd loss = 6401.912601938174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6378.936163695789
gradient descent iteration = 13
gd loss = 6378.936163695789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6356.312997415165
gradient descent iteration = 14
gd loss = 6356.312997415165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6334.011030305568
gradient descent iteration = 15
gd loss = 6334.011030305568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6312.004202647257
gradient descent iteration = 16
gd loss = 6312.004202647257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6290.270986359476
gradient descent iteration = 17
gd loss = 6290.270986359476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6268.793374402757
gradient descent iteration = 18
gd loss = 6268.793374402757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6247.55611105084
gradient descent iteration = 19
gd loss = 6247.55611105084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6226.54611779291
gradient descent iteration = 20
gd loss = 6226.54611779291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6205.752079973486
gradient descent iteration = 21
gd loss = 6205.752079973486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6185.164167515129
gradient descent iteration = 22
gd loss = 6185.164167515129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6164.773781651633
gradient descent iteration = 23
gd loss = 6164.773781651633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6144.573365513421
gradient descent iteration = 24
gd loss = 6144.573365513421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6124.556308705311
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6124.556308705311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6089.580008490279
gradient descent iteration = 1
gd loss = 6089.580008490279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6059.811431154612
gradient descent iteration = 2
gd loss = 6059.811431154612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6033.231480106256
gradient descent iteration = 3
gd loss = 6033.231480106256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6008.878084633391
gradient descent iteration = 4
gd loss = 6008.878084633391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5986.192765909555
gradient descent iteration = 5
gd loss = 5986.192765909555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5964.81068478567
gradient descent iteration = 6
gd loss = 5964.81068478567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5944.476901491154
gradient descent iteration = 7
gd loss = 5944.476901491154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5925.006138673783
gradient descent iteration = 8
gd loss = 5925.006138673783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5906.260276555968
gradient descent iteration = 9
gd loss = 5906.260276555968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5888.134360262608
gradient descent iteration = 10
gd loss = 5888.134360262608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5870.547340728227
gradient descent iteration = 11
gd loss = 5870.547340728227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5853.435714635139
gradient descent iteration = 12
gd loss = 5853.435714635139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5836.749054244689
gradient descent iteration = 13
gd loss = 5836.749054244689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5820.446800722867
gradient descent iteration = 14
gd loss = 5820.446800722867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5804.495885489096
gradient descent iteration = 15
gd loss = 5804.495885489096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5788.869025502988
gradient descent iteration = 16
gd loss = 5788.869025502988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5773.543417595713
gradient descent iteration = 17
gd loss = 5773.543417595713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5758.49975302392
gradient descent iteration = 18
gd loss = 5758.49975302392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5743.721494914486
gradient descent iteration = 19
gd loss = 5743.721494914486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5729.194329841815
gradient descent iteration = 20
gd loss = 5729.194329841815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5714.905739359867
gradient descent iteration = 21
gd loss = 5714.905739359867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5700.844653351148
gradient descent iteration = 22
gd loss = 5700.844653351148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5687.00118498418
gradient descent iteration = 23
gd loss = 5687.00118498418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5673.366427709158
gradient descent iteration = 24
gd loss = 5673.366427709158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5659.932295262258
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5659.932295262258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5642.963782776969
gradient descent iteration = 1
gd loss = 5642.963782776969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5628.498014779007
gradient descent iteration = 2
gd loss = 5628.498014779007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5614.869169983293
gradient descent iteration = 3
gd loss = 5614.869169983293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5601.778239163384
gradient descent iteration = 4
gd loss = 5601.778239163384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5589.127096103851
gradient descent iteration = 5
gd loss = 5589.127096103851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5576.858529940188
gradient descent iteration = 6
gd loss = 5576.858529940188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5564.930289749969
gradient descent iteration = 7
gd loss = 5564.930289749969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5553.308829001251
gradient descent iteration = 8
gd loss = 5553.308829001251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5541.966675823941
gradient descent iteration = 9
gd loss = 5541.966675823941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5530.880864165621
gradient descent iteration = 10
gd loss = 5530.880864165621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5520.031876020813
gradient descent iteration = 11
gd loss = 5520.031876020813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5509.402891838425
gradient descent iteration = 12
gd loss = 5509.402891838425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5498.979244301769
gradient descent iteration = 13
gd loss = 5498.979244301769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5488.748012683383
gradient descent iteration = 14
gd loss = 5488.748012683383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5478.697719331539
gradient descent iteration = 15
gd loss = 5478.697719331539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5468.818094303829
gradient descent iteration = 16
gd loss = 5468.818094303829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5459.099890308608
gradient descent iteration = 17
gd loss = 5459.099890308608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5449.534736601923
gradient descent iteration = 18
gd loss = 5449.534736601923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5440.115021834868
gradient descent iteration = 19
gd loss = 5440.115021834868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5430.833798192572
gradient descent iteration = 20
gd loss = 5430.833798192572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5421.684701333392
gradient descent iteration = 21
gd loss = 5421.684701333392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5412.661880789842
gradient descent iteration = 22
gd loss = 5412.661880789842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5403.759942816927
gradient descent iteration = 23
gd loss = 5403.759942816927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5394.973901691396
gradient descent iteration = 24
gd loss = 5394.973901691396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5386.299137843381
Initial loss = 6823.396888189019
Final loss = 5386.299137843381
Deformation gradient control sequence optimization finished.
Animation interval 21 took 1377 seconds.
Full animation took 30583 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 22************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6122.694257642204
initial norm = 934.8165798103297
convergence norm = 0.9348165798103297
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6122.694257642204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6042.96708215554
gradient descent iteration = 1
gd loss = 6042.96708215554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5988.371229649822
gradient descent iteration = 2
gd loss = 5988.371229649822
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5952.91796883584
gradient descent iteration = 3
gd loss = 5952.91796883584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5926.10326760797
gradient descent iteration = 4
gd loss = 5926.10326760797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5901.989461782797
gradient descent iteration = 5
gd loss = 5901.989461782797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5879.540927412558
gradient descent iteration = 6
gd loss = 5879.540927412558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5858.300109478996
gradient descent iteration = 7
gd loss = 5858.300109478996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5837.971377350763
gradient descent iteration = 8
gd loss = 5837.971377350763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5818.350687587427
gradient descent iteration = 9
gd loss = 5818.350687587427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5799.296596104911
gradient descent iteration = 10
gd loss = 5799.296596104911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5780.709698216396
gradient descent iteration = 11
gd loss = 5780.709698216396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5762.518705264558
gradient descent iteration = 12
gd loss = 5762.518705264558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5744.670796790287
gradient descent iteration = 13
gd loss = 5744.670796790287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5727.125758274825
gradient descent iteration = 14
gd loss = 5727.125758274825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5709.851983294652
gradient descent iteration = 15
gd loss = 5709.851983294652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5692.824306999411
gradient descent iteration = 16
gd loss = 5692.824306999411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5676.023117694645
gradient descent iteration = 17
gd loss = 5676.023117694645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5659.435247005355
gradient descent iteration = 18
gd loss = 5659.435247005355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5643.05961506831
gradient descent iteration = 19
gd loss = 5643.05961506831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5626.924946299013
gradient descent iteration = 20
gd loss = 5626.924946299013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5611.148155744039
gradient descent iteration = 21
gd loss = 5611.148155744039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5596.072637896871
gradient descent iteration = 22
gd loss = 5596.072637896871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5582.435528735618
gradient descent iteration = 23
gd loss = 5582.435528735618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5570.618400297296
gradient descent iteration = 24
gd loss = 5570.618400297296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5559.779772090377
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5559.779772090377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5538.35083160903
gradient descent iteration = 1
gd loss = 5538.35083160903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5522.072457855748
gradient descent iteration = 2
gd loss = 5522.072457855748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5507.357649754889
gradient descent iteration = 3
gd loss = 5507.357649754889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5493.750710763206
gradient descent iteration = 4
gd loss = 5493.750710763206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5480.981981209559
gradient descent iteration = 5
gd loss = 5480.981981209559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5468.870640846217
gradient descent iteration = 6
gd loss = 5468.870640846217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5457.288109489353
gradient descent iteration = 7
gd loss = 5457.288109489353
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5446.139787467159
gradient descent iteration = 8
gd loss = 5446.139787467159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5435.354545391278
gradient descent iteration = 9
gd loss = 5435.354545391278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5424.878063371176
gradient descent iteration = 10
gd loss = 5424.878063371176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5414.668296436241
gradient descent iteration = 11
gd loss = 5414.668296436241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5404.692278776953
gradient descent iteration = 12
gd loss = 5404.692278776953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5394.923851073521
gradient descent iteration = 13
gd loss = 5394.923851073521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5385.342011198859
gradient descent iteration = 14
gd loss = 5385.342011198859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5375.929703637471
gradient descent iteration = 15
gd loss = 5375.929703637471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5366.672926945102
gradient descent iteration = 16
gd loss = 5366.672926945102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5357.560060750117
gradient descent iteration = 17
gd loss = 5357.560060750117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5348.581357329582
gradient descent iteration = 18
gd loss = 5348.581357329582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5339.728566290055
gradient descent iteration = 19
gd loss = 5339.728566290055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5330.994625450629
gradient descent iteration = 20
gd loss = 5330.994625450629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5322.37342511262
gradient descent iteration = 21
gd loss = 5322.37342511262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5313.859632377545
gradient descent iteration = 22
gd loss = 5313.859632377545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5305.448558424167
gradient descent iteration = 23
gd loss = 5305.448558424167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5297.136040344419
gradient descent iteration = 24
gd loss = 5297.136040344419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5288.918361416978
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5288.918361416978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5279.17619498991
gradient descent iteration = 1
gd loss = 5279.17619498991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5270.530042443597
gradient descent iteration = 2
gd loss = 5270.530042443597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5262.306292620117
gradient descent iteration = 3
gd loss = 5262.306292620117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5254.359838885895
gradient descent iteration = 4
gd loss = 5254.359838885895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5246.639549504694
gradient descent iteration = 5
gd loss = 5246.639549504694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5239.116079585554
gradient descent iteration = 6
gd loss = 5239.116079585554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5231.768149306808
gradient descent iteration = 7
gd loss = 5231.768149306808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5224.579000610126
gradient descent iteration = 8
gd loss = 5224.579000610126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5217.534961954408
gradient descent iteration = 9
gd loss = 5217.534961954408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5210.624630720919
gradient descent iteration = 10
gd loss = 5210.624630720919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5203.838330135755
gradient descent iteration = 11
gd loss = 5203.838330135755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5197.167726945201
gradient descent iteration = 12
gd loss = 5197.167726945201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5190.60555546409
gradient descent iteration = 13
gd loss = 5190.60555546409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5184.14541378244
gradient descent iteration = 14
gd loss = 5184.14541378244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5177.781610065502
gradient descent iteration = 15
gd loss = 5177.781610065502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5171.50904489224
gradient descent iteration = 16
gd loss = 5171.50904489224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5165.323119453387
gradient descent iteration = 17
gd loss = 5165.323119453387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5159.219662918335
gradient descent iteration = 18
gd loss = 5159.219662918335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5153.194874097668
gradient descent iteration = 19
gd loss = 5153.194874097668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5147.245274387736
gradient descent iteration = 20
gd loss = 5147.245274387736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5141.367670326735
gradient descent iteration = 21
gd loss = 5141.367670326735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5135.559119534105
gradient descent iteration = 22
gd loss = 5135.559119534105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5129.816902340853
gradient descent iteration = 23
gd loss = 5129.816902340853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5124.13849824448
gradient descent iteration = 24
gd loss = 5124.13849824448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5118.521565764526
Initial loss = 6122.694257642204
Final loss = 5118.521565764526
Deformation gradient control sequence optimization finished.
Animation interval 22 took 1356 seconds.
Full animation took 31940 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 23************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5769.867205033958
initial norm = 756.9923603278572
convergence norm = 0.7569923603278572
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5769.867205033958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5708.741078073646
gradient descent iteration = 1
gd loss = 5708.741078073646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5671.673515829973
gradient descent iteration = 2
gd loss = 5671.673515829973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5646.470654614686
gradient descent iteration = 3
gd loss = 5646.470654614686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5624.436187387389
gradient descent iteration = 4
gd loss = 5624.436187387389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5604.329278238728
gradient descent iteration = 5
gd loss = 5604.329278238728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5585.582154123956
gradient descent iteration = 6
gd loss = 5585.582154123956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5567.822672915603
gradient descent iteration = 7
gd loss = 5567.822672915603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5550.801485529172
gradient descent iteration = 8
gd loss = 5550.801485529172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5534.365228348367
gradient descent iteration = 9
gd loss = 5534.365228348367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5518.446947194209
gradient descent iteration = 10
gd loss = 5518.446947194209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5503.138401579397
gradient descent iteration = 11
gd loss = 5503.138401579397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5488.918531376509
gradient descent iteration = 12
gd loss = 5488.918531376509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5476.899091723716
gradient descent iteration = 13
gd loss = 5476.899091723716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5466.979989893553
gradient descent iteration = 14
gd loss = 5466.979989893553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5457.532830500502
gradient descent iteration = 15
gd loss = 5457.532830500502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5448.083370778134
gradient descent iteration = 16
gd loss = 5448.083370778134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5438.96187865544
gradient descent iteration = 17
gd loss = 5438.96187865544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5429.815168202
gradient descent iteration = 18
gd loss = 5429.815168202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5420.979045114176
gradient descent iteration = 19
gd loss = 5420.979045114176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5412.092714185053
gradient descent iteration = 20
gd loss = 5412.092714185053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5403.506525046059
gradient descent iteration = 21
gd loss = 5403.506525046059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5394.851378510843
gradient descent iteration = 22
gd loss = 5394.851378510843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5386.488748094331
gradient descent iteration = 23
gd loss = 5386.488748094331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5378.042582081829
gradient descent iteration = 24
gd loss = 5378.042582081829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5369.883255415299
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5369.883255415299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5353.153358243311
gradient descent iteration = 1
gd loss = 5353.153358243311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5341.456932313801
gradient descent iteration = 2
gd loss = 5341.456932313801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5330.858566996932
gradient descent iteration = 3
gd loss = 5330.858566996932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5321.039111089432
gradient descent iteration = 4
gd loss = 5321.039111089432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5311.812831647999
gradient descent iteration = 5
gd loss = 5311.812831647999
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5303.054062628509
gradient descent iteration = 6
gd loss = 5303.054062628509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5294.67286623259
gradient descent iteration = 7
gd loss = 5294.67286623259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5286.602740800725
gradient descent iteration = 8
gd loss = 5286.602740800725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5278.793432098993
gradient descent iteration = 9
gd loss = 5278.793432098993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5271.206333460392
gradient descent iteration = 10
gd loss = 5271.206333460392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5263.81137427702
gradient descent iteration = 11
gd loss = 5263.81137427702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5256.584841233529
gradient descent iteration = 12
gd loss = 5256.584841233529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5249.507816057734
gradient descent iteration = 13
gd loss = 5249.507816057734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5242.565041185912
gradient descent iteration = 14
gd loss = 5242.565041185912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5235.744078826701
gradient descent iteration = 15
gd loss = 5235.744078826701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5229.034675368634
gradient descent iteration = 16
gd loss = 5229.034675368634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5222.4282874628
gradient descent iteration = 17
gd loss = 5222.4282874628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5215.917725458437
gradient descent iteration = 18
gd loss = 5215.917725458437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5209.49687935693
gradient descent iteration = 19
gd loss = 5209.49687935693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5203.160503816755
gradient descent iteration = 20
gd loss = 5203.160503816755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5196.904053279388
gradient descent iteration = 21
gd loss = 5196.904053279388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5190.723553881595
gradient descent iteration = 22
gd loss = 5190.723553881595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5184.615503755883
gradient descent iteration = 23
gd loss = 5184.615503755883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5178.576791103934
gradient descent iteration = 24
gd loss = 5178.576791103934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5172.604631085439
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5172.604631085439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5165.656832707519
gradient descent iteration = 1
gd loss = 5165.656832707519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5159.425025475112
gradient descent iteration = 2
gd loss = 5159.425025475112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5153.491719569806
gradient descent iteration = 3
gd loss = 5153.491719569806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5147.753876689743
gradient descent iteration = 4
gd loss = 5147.753876689743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5142.173789254802
gradient descent iteration = 5
gd loss = 5142.173789254802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5136.730427537756
gradient descent iteration = 6
gd loss = 5136.730427537756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5131.408892632651
gradient descent iteration = 7
gd loss = 5131.408892632651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5126.197557221206
gradient descent iteration = 8
gd loss = 5126.197557221206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5121.086962377688
gradient descent iteration = 9
gd loss = 5121.086962377688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5116.069226241637
gradient descent iteration = 10
gd loss = 5116.069226241637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5111.137664346496
gradient descent iteration = 11
gd loss = 5111.137664346496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5106.286524920238
gradient descent iteration = 12
gd loss = 5106.286524920238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5101.510797073329
gradient descent iteration = 13
gd loss = 5101.510797073329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5096.806068669147
gradient descent iteration = 14
gd loss = 5096.806068669147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5092.168419159004
gradient descent iteration = 15
gd loss = 5092.168419159004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5087.594337246478
gradient descent iteration = 16
gd loss = 5087.594337246478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5083.080656704178
gradient descent iteration = 17
gd loss = 5083.080656704178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5078.624508813842
gradient descent iteration = 18
gd loss = 5078.624508813842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5074.223293224726
gradient descent iteration = 19
gd loss = 5074.223293224726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5069.874634616206
gradient descent iteration = 20
gd loss = 5069.874634616206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5065.576349602677
gradient descent iteration = 21
gd loss = 5065.576349602677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5061.326424142731
gradient descent iteration = 22
gd loss = 5061.326424142731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5057.122994792746
gradient descent iteration = 23
gd loss = 5057.122994792746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5052.964332790503
gradient descent iteration = 24
gd loss = 5052.964332790503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5048.848830212823
Initial loss = 5769.867205033958
Final loss = 5048.848830212823
Deformation gradient control sequence optimization finished.
Animation interval 23 took 1358 seconds.
Full animation took 33299 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 24************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5731.68048741392
initial norm = 768.3365898252881
convergence norm = 0.7683365898252882
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5731.68048741392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5668.975924117956
gradient descent iteration = 1
gd loss = 5668.975924117956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5630.391224203237
gradient descent iteration = 2
gd loss = 5630.391224203237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5605.51596941654
gradient descent iteration = 3
gd loss = 5605.51596941654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5584.380864396368
gradient descent iteration = 4
gd loss = 5584.380864396368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5565.351525294697
gradient descent iteration = 5
gd loss = 5565.351525294697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5547.775751982743
gradient descent iteration = 6
gd loss = 5547.775751982743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5531.258441643584
gradient descent iteration = 7
gd loss = 5531.258441643584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5515.554340799626
gradient descent iteration = 8
gd loss = 5515.554340799626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5500.584495859562
gradient descent iteration = 9
gd loss = 5500.584495859562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5486.620901975378
gradient descent iteration = 10
gd loss = 5486.620901975378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5474.852552687599
gradient descent iteration = 11
gd loss = 5474.852552687599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5466.105339529349
gradient descent iteration = 12
gd loss = 5466.105339529349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5457.909688114991
gradient descent iteration = 13
gd loss = 5457.909688114991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5449.718288342529
gradient descent iteration = 14
gd loss = 5449.718288342529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5441.902931551629
gradient descent iteration = 15
gd loss = 5441.902931551629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5434.079935754404
gradient descent iteration = 16
gd loss = 5434.079935754404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5426.599545941296
gradient descent iteration = 17
gd loss = 5426.599545941296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5419.097601866428
gradient descent iteration = 18
gd loss = 5419.097601866428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5411.917363848556
gradient descent iteration = 19
gd loss = 5411.917363848556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5404.712094440618
gradient descent iteration = 20
gd loss = 5404.712094440618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5397.807896091966
gradient descent iteration = 21
gd loss = 5397.807896091966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5390.878633594637
gradient descent iteration = 22
gd loss = 5390.878633594637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5384.22929492446
gradient descent iteration = 23
gd loss = 5384.22929492446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5377.551921758088
gradient descent iteration = 24
gd loss = 5377.551921758088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5371.134699642696
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5371.134699642696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5356.110786889037
gradient descent iteration = 1
gd loss = 5356.110786889037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5346.677301458542
gradient descent iteration = 2
gd loss = 5346.677301458542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5338.153354989289
gradient descent iteration = 3
gd loss = 5338.153354989289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5330.273569398782
gradient descent iteration = 4
gd loss = 5330.273569398782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5322.884500076244
gradient descent iteration = 5
gd loss = 5322.884500076244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5315.883331602191
gradient descent iteration = 6
gd loss = 5315.883331602191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5309.196536273681
gradient descent iteration = 7
gd loss = 5309.196536273681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5302.769564372778
gradient descent iteration = 8
gd loss = 5302.769564372778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5296.560962467247
gradient descent iteration = 9
gd loss = 5296.560962467247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5290.538668314394
gradient descent iteration = 10
gd loss = 5290.538668314394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5284.677526464573
gradient descent iteration = 11
gd loss = 5284.677526464573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5278.957550487177
gradient descent iteration = 12
gd loss = 5278.957550487177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5273.362677169438
gradient descent iteration = 13
gd loss = 5273.362677169438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5267.879856280336
gradient descent iteration = 14
gd loss = 5267.879856280336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5262.498375472272
gradient descent iteration = 15
gd loss = 5262.498375472272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5257.209354590213
gradient descent iteration = 16
gd loss = 5257.209354590213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5252.005364259866
gradient descent iteration = 17
gd loss = 5252.005364259866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5246.880129969742
gradient descent iteration = 18
gd loss = 5246.880129969742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5241.828304355438
gradient descent iteration = 19
gd loss = 5241.828304355438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5236.845290850252
gradient descent iteration = 20
gd loss = 5236.845290850252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5231.927105643759
gradient descent iteration = 21
gd loss = 5231.927105643759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5227.070268651334
gradient descent iteration = 22
gd loss = 5227.070268651334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5222.271716676755
gradient descent iteration = 23
gd loss = 5222.271716676755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5217.528734541448
gradient descent iteration = 24
gd loss = 5217.528734541448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5212.8389020993
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5212.8389020993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5207.289858181564
gradient descent iteration = 1
gd loss = 5207.289858181564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5202.291633743648
gradient descent iteration = 2
gd loss = 5202.291633743648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5197.546749757003
gradient descent iteration = 3
gd loss = 5197.546749757003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5192.970378855525
gradient descent iteration = 4
gd loss = 5192.970378855525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5188.528924350565
gradient descent iteration = 5
gd loss = 5188.528924350565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5184.20352372673
gradient descent iteration = 6
gd loss = 5184.20352372673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5179.980985635888
gradient descent iteration = 7
gd loss = 5179.980985635888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5175.851101986129
gradient descent iteration = 8
gd loss = 5175.851101986129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5171.805599807338
gradient descent iteration = 9
gd loss = 5171.805599807338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5167.837599215703
gradient descent iteration = 10
gd loss = 5167.837599215703
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5163.941274931404
gradient descent iteration = 11
gd loss = 5163.941274931404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5160.111623362285
gradient descent iteration = 12
gd loss = 5160.111623362285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5156.344293761006
gradient descent iteration = 13
gd loss = 5156.344293761006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5152.635463492235
gradient descent iteration = 14
gd loss = 5152.635463492235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5148.981742888393
gradient descent iteration = 15
gd loss = 5148.981742888393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5145.3801023694
gradient descent iteration = 16
gd loss = 5145.3801023694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5141.827815760734
gradient descent iteration = 17
gd loss = 5141.827815760734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5138.322415521413
gradient descent iteration = 18
gd loss = 5138.322415521413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5134.861657197694
gradient descent iteration = 19
gd loss = 5134.861657197694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5131.443489865675
gradient descent iteration = 20
gd loss = 5131.443489865675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5128.066031787489
gradient descent iteration = 21
gd loss = 5128.066031787489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5124.727550592933
gradient descent iteration = 22
gd loss = 5124.727550592933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5121.426446546967
gradient descent iteration = 23
gd loss = 5121.426446546967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5118.161238056916
gradient descent iteration = 24
gd loss = 5118.161238056916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5114.930549471388
Initial loss = 5731.68048741392
Final loss = 5114.930549471388
Deformation gradient control sequence optimization finished.
Animation interval 24 took 1356 seconds.
Full animation took 34656 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 25************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5780.38996111596
initial norm = 650.7944374957888
convergence norm = 0.6507944374957888
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5780.38996111596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5730.358575632167
gradient descent iteration = 1
gd loss = 5730.358575632167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5702.024720418221
gradient descent iteration = 2
gd loss = 5702.024720418221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5680.826648695363
gradient descent iteration = 3
gd loss = 5680.826648695363
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5662.276803579641
gradient descent iteration = 4
gd loss = 5662.276803579641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5645.741668640389
gradient descent iteration = 5
gd loss = 5645.741668640389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5631.602599082926
gradient descent iteration = 6
gd loss = 5631.602599082926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5621.387895068332
gradient descent iteration = 7
gd loss = 5621.387895068332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5613.375339174598
gradient descent iteration = 8
gd loss = 5613.375339174598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5605.168419603456
gradient descent iteration = 9
gd loss = 5605.168419603456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5597.596312546286
gradient descent iteration = 10
gd loss = 5597.596312546286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5590.09269796472
gradient descent iteration = 11
gd loss = 5590.09269796472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5582.997315161746
gradient descent iteration = 12
gd loss = 5582.997315161746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5575.94288833403
gradient descent iteration = 13
gd loss = 5575.94288833403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5569.2285440855
gradient descent iteration = 14
gd loss = 5569.2285440855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5562.513017176055
gradient descent iteration = 15
gd loss = 5562.513017176055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5556.104433940253
gradient descent iteration = 16
gd loss = 5556.104433940253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5549.66198685747
gradient descent iteration = 17
gd loss = 5549.66198685747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5543.506105834167
gradient descent iteration = 18
gd loss = 5543.506105834167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5537.292355294761
gradient descent iteration = 19
gd loss = 5537.292355294761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5531.351208309061
gradient descent iteration = 20
gd loss = 5531.351208309061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5525.334285889212
gradient descent iteration = 21
gd loss = 5525.334285889212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5519.579826792094
gradient descent iteration = 22
gd loss = 5519.579826792094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5513.735855258239
gradient descent iteration = 23
gd loss = 5513.735855258239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5508.146722576394
gradient descent iteration = 24
gd loss = 5508.146722576394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5502.457235520525
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5502.457235520525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5487.997326546884
gradient descent iteration = 1
gd loss = 5487.997326546884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5479.500477665832
gradient descent iteration = 2
gd loss = 5479.500477665832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5471.914776527628
gradient descent iteration = 3
gd loss = 5471.914776527628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5464.946045013789
gradient descent iteration = 4
gd loss = 5464.946045013789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5458.439372338576
gradient descent iteration = 5
gd loss = 5458.439372338576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5452.293240115756
gradient descent iteration = 6
gd loss = 5452.293240115756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5446.436617008784
gradient descent iteration = 7
gd loss = 5446.436617008784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5440.817727714038
gradient descent iteration = 8
gd loss = 5440.817727714038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5435.397698751813
gradient descent iteration = 9
gd loss = 5435.397698751813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5430.146672257218
gradient descent iteration = 10
gd loss = 5430.146672257218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5425.041292145423
gradient descent iteration = 11
gd loss = 5425.041292145423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5420.063009088283
gradient descent iteration = 12
gd loss = 5420.063009088283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5415.196897303896
gradient descent iteration = 13
gd loss = 5415.196897303896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5410.430807353412
gradient descent iteration = 14
gd loss = 5410.430807353412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5405.754744980573
gradient descent iteration = 15
gd loss = 5405.754744980573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5401.160408775425
gradient descent iteration = 16
gd loss = 5401.160408775425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5396.640839801931
gradient descent iteration = 17
gd loss = 5396.640839801931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5392.190152807828
gradient descent iteration = 18
gd loss = 5392.190152807828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5387.803329001704
gradient descent iteration = 19
gd loss = 5387.803329001704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5383.476054380035
gradient descent iteration = 20
gd loss = 5383.476054380035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5379.204592928505
gradient descent iteration = 21
gd loss = 5379.204592928505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5374.98568760479
gradient descent iteration = 22
gd loss = 5374.98568760479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5370.81648237358
gradient descent iteration = 23
gd loss = 5370.81648237358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5366.694454150602
gradient descent iteration = 24
gd loss = 5366.694454150602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5362.617358247277
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5362.617358247277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5357.789778239684
gradient descent iteration = 1
gd loss = 5357.789778239684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5353.388675111718
gradient descent iteration = 2
gd loss = 5353.388675111718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5349.209775012509
gradient descent iteration = 3
gd loss = 5349.209775012509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5345.185298627069
gradient descent iteration = 4
gd loss = 5345.185298627069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5341.285626573775
gradient descent iteration = 5
gd loss = 5341.285626573775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5337.493545968917
gradient descent iteration = 6
gd loss = 5337.493545968917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5333.796939711382
gradient descent iteration = 7
gd loss = 5333.796939711382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5330.186398780705
gradient descent iteration = 8
gd loss = 5330.186398780705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5326.654258640893
gradient descent iteration = 9
gd loss = 5326.654258640893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5323.194107680137
gradient descent iteration = 10
gd loss = 5323.194107680137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5319.800486040641
gradient descent iteration = 11
gd loss = 5319.800486040641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5316.468679961823
gradient descent iteration = 12
gd loss = 5316.468679961823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5313.194573661755
gradient descent iteration = 13
gd loss = 5313.194573661755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5309.974539306512
gradient descent iteration = 14
gd loss = 5309.974539306512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5306.805351220399
gradient descent iteration = 15
gd loss = 5306.805351220399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5303.684120087187
gradient descent iteration = 16
gd loss = 5303.684120087187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5300.608241410408
gradient descent iteration = 17
gd loss = 5300.608241410408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5297.575354406555
gradient descent iteration = 18
gd loss = 5297.575354406555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5294.583308849389
gradient descent iteration = 19
gd loss = 5294.583308849389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5291.630138035165
gradient descent iteration = 20
gd loss = 5291.630138035165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5288.714036458188
gradient descent iteration = 21
gd loss = 5288.714036458188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5285.833341189872
gradient descent iteration = 22
gd loss = 5285.833341189872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5282.986516359777
gradient descent iteration = 23
gd loss = 5282.986516359777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5280.172139629795
gradient descent iteration = 24
gd loss = 5280.172139629795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5277.38889056452
Initial loss = 5780.38996111596
Final loss = 5277.38889056452
Deformation gradient control sequence optimization finished.
Animation interval 25 took 1356 seconds.
Full animation took 36012 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 26************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 5978.155370080927
initial norm = 663.8027271000481
convergence norm = 0.6638027271000481
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 5978.155370080927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5925.603691857925
gradient descent iteration = 1
gd loss = 5925.603691857925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5894.800573664619
gradient descent iteration = 2
gd loss = 5894.800573664619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5873.417161084098
gradient descent iteration = 3
gd loss = 5873.417161084098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5854.765682275166
gradient descent iteration = 4
gd loss = 5854.765682275166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5838.068161555033
gradient descent iteration = 5
gd loss = 5838.068161555033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5823.345051366843
gradient descent iteration = 6
gd loss = 5823.345051366843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5812.382330281399
gradient descent iteration = 7
gd loss = 5812.382330281399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5805.230762543253
gradient descent iteration = 8
gd loss = 5805.230762543253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5797.46097539054
gradient descent iteration = 9
gd loss = 5797.46097539054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5790.312248264234
gradient descent iteration = 10
gd loss = 5790.312248264234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5783.352503524924
gradient descent iteration = 11
gd loss = 5783.352503524924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5776.543740322953
gradient descent iteration = 12
gd loss = 5776.543740322953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5770.033064025239
gradient descent iteration = 13
gd loss = 5770.033064025239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5763.547657093835
gradient descent iteration = 14
gd loss = 5763.547657093835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5757.361032365938
gradient descent iteration = 15
gd loss = 5757.361032365938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5751.148299739037
gradient descent iteration = 16
gd loss = 5751.148299739037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5745.219953721544
gradient descent iteration = 17
gd loss = 5745.219953721544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5739.236923717272
gradient descent iteration = 18
gd loss = 5739.236923717272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5733.524497268351
gradient descent iteration = 19
gd loss = 5733.524497268351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5727.738419308903
gradient descent iteration = 20
gd loss = 5727.738419308903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5722.211918780928
gradient descent iteration = 21
gd loss = 5722.211918780928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5716.597969363636
gradient descent iteration = 22
gd loss = 5716.597969363636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5711.235061048781
gradient descent iteration = 23
gd loss = 5711.235061048781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5705.774124734663
gradient descent iteration = 24
gd loss = 5705.774124734663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5700.557617731391
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5700.557617731391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5686.228605442207
gradient descent iteration = 1
gd loss = 5686.228605442207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5678.174645643037
gradient descent iteration = 2
gd loss = 5678.174645643037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5670.991485011624
gradient descent iteration = 3
gd loss = 5670.991485011624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5664.379076128509
gradient descent iteration = 4
gd loss = 5664.379076128509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5658.19596263441
gradient descent iteration = 5
gd loss = 5658.19596263441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5652.349895386657
gradient descent iteration = 6
gd loss = 5652.349895386657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5646.775917297708
gradient descent iteration = 7
gd loss = 5646.775917297708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5641.42630627625
gradient descent iteration = 8
gd loss = 5641.42630627625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5636.264982834721
gradient descent iteration = 9
gd loss = 5636.264982834721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5631.264088276243
gradient descent iteration = 10
gd loss = 5631.264088276243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5626.401751335754
gradient descent iteration = 11
gd loss = 5626.401751335754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5621.660562091031
gradient descent iteration = 12
gd loss = 5621.660562091031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5617.026494132487
gradient descent iteration = 13
gd loss = 5617.026494132487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5612.488124006099
gradient descent iteration = 14
gd loss = 5612.488124006099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5608.036057310523
gradient descent iteration = 15
gd loss = 5608.036057310523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5603.66249754477
gradient descent iteration = 16
gd loss = 5603.66249754477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5599.360915496788
gradient descent iteration = 17
gd loss = 5599.360915496788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5595.125797294952
gradient descent iteration = 18
gd loss = 5595.125797294952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5590.95244925357
gradient descent iteration = 19
gd loss = 5590.95244925357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5586.83684510172
gradient descent iteration = 20
gd loss = 5586.83684510172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5582.775505536599
gradient descent iteration = 21
gd loss = 5582.775505536599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5578.765402960993
gradient descent iteration = 22
gd loss = 5578.765402960993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5574.80388513272
gradient descent iteration = 23
gd loss = 5574.80388513272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5570.888613114318
gradient descent iteration = 24
gd loss = 5570.888613114318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5567.017511507766
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5567.017511507766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5562.480330647085
gradient descent iteration = 1
gd loss = 5562.480330647085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5558.351415578356
gradient descent iteration = 2
gd loss = 5558.351415578356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5554.440023434006
gradient descent iteration = 3
gd loss = 5554.440023434006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5550.680136446991
gradient descent iteration = 4
gd loss = 5550.680136446991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5547.04228649954
gradient descent iteration = 5
gd loss = 5547.04228649954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5543.509320421557
gradient descent iteration = 6
gd loss = 5543.509320421557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5540.069219980905
gradient descent iteration = 7
gd loss = 5540.069219980905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5536.712687981809
gradient descent iteration = 8
gd loss = 5536.712687981809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5533.432166916348
gradient descent iteration = 9
gd loss = 5533.432166916348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5530.221343380831
gradient descent iteration = 10
gd loss = 5530.221343380831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5527.074848600502
gradient descent iteration = 11
gd loss = 5527.074848600502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5523.988052755364
gradient descent iteration = 12
gd loss = 5523.988052755364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5520.956917655959
gradient descent iteration = 13
gd loss = 5520.956917655959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5517.977887048167
gradient descent iteration = 14
gd loss = 5517.977887048167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5515.047802929459
gradient descent iteration = 15
gd loss = 5515.047802929459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5512.163840521847
gradient descent iteration = 16
gd loss = 5512.163840521847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5509.323457089182
gradient descent iteration = 17
gd loss = 5509.323457089182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5506.524351166375
gradient descent iteration = 18
gd loss = 5506.524351166375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5503.764429672143
gradient descent iteration = 19
gd loss = 5503.764429672143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5501.041781149549
gradient descent iteration = 20
gd loss = 5501.041781149549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5498.354653233654
gradient descent iteration = 21
gd loss = 5498.354653233654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5495.70143394258
gradient descent iteration = 22
gd loss = 5495.70143394258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5493.080635950309
gradient descent iteration = 23
gd loss = 5493.080635950309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5490.490883712062
gradient descent iteration = 24
gd loss = 5490.490883712062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5487.930904272781
Initial loss = 5978.155370080927
Final loss = 5487.930904272781
Deformation gradient control sequence optimization finished.
Animation interval 26 took 1356 seconds.
Full animation took 37369 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 27************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6206.37978099685
initial norm = 744.9550411271927
convergence norm = 0.7449550411271927
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6206.37978099685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6150.786552002533
gradient descent iteration = 1
gd loss = 6150.786552002533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6121.516161037236
gradient descent iteration = 2
gd loss = 6121.516161037236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6101.230925292771
gradient descent iteration = 3
gd loss = 6101.230925292771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6084.3779461352
gradient descent iteration = 4
gd loss = 6084.3779461352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6071.898707101073
gradient descent iteration = 5
gd loss = 6071.898707101073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6063.817944842159
gradient descent iteration = 6
gd loss = 6063.817944842159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6055.592987014919
gradient descent iteration = 7
gd loss = 6055.592987014919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6048.270963000591
gradient descent iteration = 8
gd loss = 6048.270963000591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6041.058968556666
gradient descent iteration = 9
gd loss = 6041.058968556666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6034.378541717826
gradient descent iteration = 10
gd loss = 6034.378541717826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6027.761505001439
gradient descent iteration = 11
gd loss = 6027.761505001439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6021.552392382853
gradient descent iteration = 12
gd loss = 6021.552392382853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6015.350538626033
gradient descent iteration = 13
gd loss = 6015.350538626033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6009.499063888294
gradient descent iteration = 14
gd loss = 6009.499063888294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6003.613301389028
gradient descent iteration = 15
gd loss = 6003.613301389028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5998.045413162326
gradient descent iteration = 16
gd loss = 5998.045413162326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5992.413778967459
gradient descent iteration = 17
gd loss = 5992.413778967459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5987.079304897841
gradient descent iteration = 18
gd loss = 5987.079304897841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5981.659819039824
gradient descent iteration = 19
gd loss = 5981.659819039824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5976.523204628103
gradient descent iteration = 20
gd loss = 5976.523204628103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5971.28576637525
gradient descent iteration = 21
gd loss = 5971.28576637525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5966.320790718304
gradient descent iteration = 22
gd loss = 5966.320790718304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5961.242881855001
gradient descent iteration = 23
gd loss = 5961.242881855001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5956.429549637876
gradient descent iteration = 24
gd loss = 5956.429549637876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5951.493762271482
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 5951.493762271482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5937.631328248482
gradient descent iteration = 1
gd loss = 5937.631328248482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5930.099468116594
gradient descent iteration = 2
gd loss = 5930.099468116594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5923.44026530162
gradient descent iteration = 3
gd loss = 5923.44026530162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5917.328009745217
gradient descent iteration = 4
gd loss = 5917.328009745217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5911.624783775304
gradient descent iteration = 5
gd loss = 5911.624783775304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5906.24124639506
gradient descent iteration = 6
gd loss = 5906.24124639506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5901.11492189072
gradient descent iteration = 7
gd loss = 5901.11492189072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5896.200331051112
gradient descent iteration = 8
gd loss = 5896.200331051112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5891.463382472318
gradient descent iteration = 9
gd loss = 5891.463382472318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5886.877920920734
gradient descent iteration = 10
gd loss = 5886.877920920734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5882.423486120368
gradient descent iteration = 11
gd loss = 5882.423486120368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5878.083812048935
gradient descent iteration = 12
gd loss = 5878.083812048935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5873.845786603659
gradient descent iteration = 13
gd loss = 5873.845786603659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5869.698710606453
gradient descent iteration = 14
gd loss = 5869.698710606453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5865.633758447693
gradient descent iteration = 15
gd loss = 5865.633758447693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5861.64357770577
gradient descent iteration = 16
gd loss = 5861.64357770577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5857.7219872746
gradient descent iteration = 17
gd loss = 5857.7219872746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5853.863746008084
gradient descent iteration = 18
gd loss = 5853.863746008084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5850.064373504904
gradient descent iteration = 19
gd loss = 5850.064373504904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5846.320010176871
gradient descent iteration = 20
gd loss = 5846.320010176871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5842.627306899802
gradient descent iteration = 21
gd loss = 5842.627306899802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5838.983337393702
gradient descent iteration = 22
gd loss = 5838.983337393702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5835.385527740139
gradient descent iteration = 23
gd loss = 5835.385527740139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5831.831599267711
gradient descent iteration = 24
gd loss = 5831.831599267711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5828.319522477135
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 5828.319522477135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5824.222726130269
gradient descent iteration = 1
gd loss = 5824.222726130269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5820.471035435005
gradient descent iteration = 2
gd loss = 5820.471035435005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5816.912682983748
gradient descent iteration = 3
gd loss = 5816.912682983748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5813.491403588938
gradient descent iteration = 4
gd loss = 5813.491403588938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5810.181051474949
gradient descent iteration = 5
gd loss = 5810.181051474949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5806.96622563596
gradient descent iteration = 6
gd loss = 5806.96622563596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5803.836137074763
gradient descent iteration = 7
gd loss = 5803.836137074763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5800.782445357134
gradient descent iteration = 8
gd loss = 5800.782445357134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5797.798362356637
gradient descent iteration = 9
gd loss = 5797.798362356637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5794.878202407439
gradient descent iteration = 10
gd loss = 5794.878202407439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5792.017114652159
gradient descent iteration = 11
gd loss = 5792.017114652159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5789.21090310053
gradient descent iteration = 12
gd loss = 5789.21090310053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5786.455897593455
gradient descent iteration = 13
gd loss = 5786.455897593455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5783.748857617885
gradient descent iteration = 14
gd loss = 5783.748857617885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5781.086898723212
gradient descent iteration = 15
gd loss = 5781.086898723212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5778.467435259204
gradient descent iteration = 16
gd loss = 5778.467435259204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5775.888135201556
gradient descent iteration = 17
gd loss = 5775.888135201556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5773.346883881142
gradient descent iteration = 18
gd loss = 5773.346883881142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5770.841754719244
gradient descent iteration = 19
gd loss = 5770.841754719244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5768.370985078642
gradient descent iteration = 20
gd loss = 5768.370985078642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5765.93295636516
gradient descent iteration = 21
gd loss = 5765.93295636516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5763.52617742863
gradient descent iteration = 22
gd loss = 5763.52617742863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5761.149270531478
gradient descent iteration = 23
gd loss = 5761.149270531478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5758.800959363395
gradient descent iteration = 24
gd loss = 5758.800959363395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 5756.480058777696
Initial loss = 6206.37978099685
Final loss = 5756.480058777696
Deformation gradient control sequence optimization finished.
Animation interval 27 took 1357 seconds.
Full animation took 38727 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 28************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6507.557823059018
initial norm = 697.5784601022661
convergence norm = 0.6975784601022662
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6507.557823059018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6454.297218726057
gradient descent iteration = 1
gd loss = 6454.297218726057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6424.308416077903
gradient descent iteration = 2
gd loss = 6424.308416077903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6403.36478907432
gradient descent iteration = 3
gd loss = 6403.36478907432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6385.691879518145
gradient descent iteration = 4
gd loss = 6385.691879518145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6371.542304747697
gradient descent iteration = 5
gd loss = 6371.542304747697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6362.740712058076
gradient descent iteration = 6
gd loss = 6362.740712058076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6355.402009586808
gradient descent iteration = 7
gd loss = 6355.402009586808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6348.015117720844
gradient descent iteration = 8
gd loss = 6348.015117720844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6341.327090307722
gradient descent iteration = 9
gd loss = 6341.327090307722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6334.695337342664
gradient descent iteration = 10
gd loss = 6334.695337342664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6328.522510558814
gradient descent iteration = 11
gd loss = 6328.522510558814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6322.371275856724
gradient descent iteration = 12
gd loss = 6322.371275856724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6316.587186862575
gradient descent iteration = 13
gd loss = 6316.587186862575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6310.784432184583
gradient descent iteration = 14
gd loss = 6310.784432184583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6305.303278835071
gradient descent iteration = 15
gd loss = 6305.303278835071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6299.772350178136
gradient descent iteration = 16
gd loss = 6299.772350178136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6294.536267635991
gradient descent iteration = 17
gd loss = 6294.536267635991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6289.227551656918
gradient descent iteration = 18
gd loss = 6289.227551656918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6284.196115764528
gradient descent iteration = 19
gd loss = 6284.196115764528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6279.075113229452
gradient descent iteration = 20
gd loss = 6279.075113229452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6274.218978982081
gradient descent iteration = 21
gd loss = 6274.218978982081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6269.260458005348
gradient descent iteration = 22
gd loss = 6269.260458005348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6264.557572563118
gradient descent iteration = 23
gd loss = 6264.557572563118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6259.742352296714
gradient descent iteration = 24
gd loss = 6259.742352296714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6255.17564517134
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6255.17564517134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6241.527574983093
gradient descent iteration = 1
gd loss = 6241.527574983093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6234.312264158816
gradient descent iteration = 2
gd loss = 6234.312264158816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6227.93318479769
gradient descent iteration = 3
gd loss = 6227.93318479769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6222.068845707424
gradient descent iteration = 4
gd loss = 6222.068845707424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6216.590616775762
gradient descent iteration = 5
gd loss = 6216.590616775762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6211.415413675452
gradient descent iteration = 6
gd loss = 6211.415413675452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6206.484752050286
gradient descent iteration = 7
gd loss = 6206.484752050286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6201.755745423417
gradient descent iteration = 8
gd loss = 6201.755745423417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6197.196049090747
gradient descent iteration = 9
gd loss = 6197.196049090747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6192.780741055501
gradient descent iteration = 10
gd loss = 6192.780741055501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6188.490283898291
gradient descent iteration = 11
gd loss = 6188.490283898291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6184.309135143549
gradient descent iteration = 12
gd loss = 6184.309135143549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6180.224771304826
gradient descent iteration = 13
gd loss = 6180.224771304826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6176.226984945939
gradient descent iteration = 14
gd loss = 6176.226984945939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6172.30736777832
gradient descent iteration = 15
gd loss = 6172.30736777832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6168.458925007913
gradient descent iteration = 16
gd loss = 6168.458925007913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6164.675783615429
gradient descent iteration = 17
gd loss = 6164.675783615429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6160.952968908909
gradient descent iteration = 18
gd loss = 6160.952968908909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6157.286231695948
gradient descent iteration = 19
gd loss = 6157.286231695948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6153.671913400537
gradient descent iteration = 20
gd loss = 6153.671913400537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6150.106839810481
gradient descent iteration = 21
gd loss = 6150.106839810481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6146.588236777616
gradient descent iteration = 22
gd loss = 6146.588236777616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6143.113663017622
gradient descent iteration = 23
gd loss = 6143.113663017622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6139.680955881928
gradient descent iteration = 24
gd loss = 6139.680955881928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6136.288187346441
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6136.288187346441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6132.305247490093
gradient descent iteration = 1
gd loss = 6132.305247490093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6128.67955511511
gradient descent iteration = 2
gd loss = 6128.67955511511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6125.248557127472
gradient descent iteration = 3
gd loss = 6125.248557127472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6121.952945971147
gradient descent iteration = 4
gd loss = 6121.952945971147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6118.765707719116
gradient descent iteration = 5
gd loss = 6118.765707719116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6115.67123753646
gradient descent iteration = 6
gd loss = 6115.67123753646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6112.658766105653
gradient descent iteration = 7
gd loss = 6112.658766105653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6109.720054822596
gradient descent iteration = 8
gd loss = 6109.720054822596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6106.848447807678
gradient descent iteration = 9
gd loss = 6106.848447807678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6104.038400400082
gradient descent iteration = 10
gd loss = 6104.038400400082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6101.285201226752
gradient descent iteration = 11
gd loss = 6101.285201226752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6098.584787847893
gradient descent iteration = 12
gd loss = 6098.584787847893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6095.933615628958
gradient descent iteration = 13
gd loss = 6095.933615628958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6093.328560814568
gradient descent iteration = 14
gd loss = 6093.328560814568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6090.766846968478
gradient descent iteration = 15
gd loss = 6090.766846968478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6088.245988112426
gradient descent iteration = 16
gd loss = 6088.245988112426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6085.763744005727
gradient descent iteration = 17
gd loss = 6085.763744005727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6083.31808469322
gradient descent iteration = 18
gd loss = 6083.31808469322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6080.907161758196
gradient descent iteration = 19
gd loss = 6080.907161758196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6078.529284966784
gradient descent iteration = 20
gd loss = 6078.529284966784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6076.182903007206
gradient descent iteration = 21
gd loss = 6076.182903007206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6073.866587415178
gradient descent iteration = 22
gd loss = 6073.866587415178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6071.579018976965
gradient descent iteration = 23
gd loss = 6071.579018976965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6069.318976138573
gradient descent iteration = 24
gd loss = 6069.318976138573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6067.085325076418
Initial loss = 6507.557823059018
Final loss = 6067.085325076418
Deformation gradient control sequence optimization finished.
Animation interval 28 took 1358 seconds.
Full animation took 40085 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 29************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 6858.915546433028
initial norm = 888.116663578719
convergence norm = 0.888116663578719
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 6858.915546433028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6792.864781786958
gradient descent iteration = 1
gd loss = 6792.864781786958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6761.098450482691
gradient descent iteration = 2
gd loss = 6761.098450482691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6740.869564920709
gradient descent iteration = 3
gd loss = 6740.869564920709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6724.943541182193
gradient descent iteration = 4
gd loss = 6724.943541182193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6714.80381805368
gradient descent iteration = 5
gd loss = 6714.80381805368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6707.470471378992
gradient descent iteration = 6
gd loss = 6707.470471378992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6699.821771568243
gradient descent iteration = 7
gd loss = 6699.821771568243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6693.206836363316
gradient descent iteration = 8
gd loss = 6693.206836363316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6686.594409021312
gradient descent iteration = 9
gd loss = 6686.594409021312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6680.559401013091
gradient descent iteration = 10
gd loss = 6680.559401013091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6674.525542153876
gradient descent iteration = 11
gd loss = 6674.525542153876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6668.908532526351
gradient descent iteration = 12
gd loss = 6668.908532526351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6663.256341655704
gradient descent iteration = 13
gd loss = 6663.256341655704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6657.949366476864
gradient descent iteration = 14
gd loss = 6657.949366476864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6652.575013748219
gradient descent iteration = 15
gd loss = 6652.575013748219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6647.508336838808
gradient descent iteration = 16
gd loss = 6647.508336838808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6642.350049556425
gradient descent iteration = 17
gd loss = 6642.350049556425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6637.47721714726
gradient descent iteration = 18
gd loss = 6637.47721714726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6632.495004693046
gradient descent iteration = 19
gd loss = 6632.495004693046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6627.783820081446
gradient descent iteration = 20
gd loss = 6627.783820081446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6622.950117635311
gradient descent iteration = 21
gd loss = 6622.950117635311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6618.377352546459
gradient descent iteration = 22
gd loss = 6618.377352546459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6613.672188948065
gradient descent iteration = 23
gd loss = 6613.672188948065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6609.220551088694
gradient descent iteration = 24
gd loss = 6609.220551088694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6604.628945260504
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6604.628945260504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6591.286475603388
gradient descent iteration = 1
gd loss = 6591.286475603388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6584.375405876715
gradient descent iteration = 2
gd loss = 6584.375405876715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6578.317032900409
gradient descent iteration = 3
gd loss = 6578.317032900409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6572.747371933444
gradient descent iteration = 4
gd loss = 6572.747371933444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6567.54156782747
gradient descent iteration = 5
gd loss = 6567.54156782747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6562.620446603675
gradient descent iteration = 6
gd loss = 6562.620446603675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6557.928388809398
gradient descent iteration = 7
gd loss = 6557.928388809398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6553.424735956105
gradient descent iteration = 8
gd loss = 6553.424735956105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6549.078931633169
gradient descent iteration = 9
gd loss = 6549.078931633169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6544.867495869199
gradient descent iteration = 10
gd loss = 6544.867495869199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6540.772048783257
gradient descent iteration = 11
gd loss = 6540.772048783257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6536.77797460786
gradient descent iteration = 12
gd loss = 6536.77797460786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6532.873491570897
gradient descent iteration = 13
gd loss = 6532.873491570897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6529.04898748425
gradient descent iteration = 14
gd loss = 6529.04898748425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6525.29653530122
gradient descent iteration = 15
gd loss = 6525.29653530122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6521.609533116449
gradient descent iteration = 16
gd loss = 6521.609533116449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6517.982432527754
gradient descent iteration = 17
gd loss = 6517.982432527754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6514.410530893003
gradient descent iteration = 18
gd loss = 6514.410530893003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6510.889810441984
gradient descent iteration = 19
gd loss = 6510.889810441984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6507.416812459414
gradient descent iteration = 20
gd loss = 6507.416812459414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6503.988537950889
gradient descent iteration = 21
gd loss = 6503.988537950889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6500.602368423382
gradient descent iteration = 22
gd loss = 6500.602368423382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6497.256002349654
gradient descent iteration = 23
gd loss = 6497.256002349654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6493.947404135442
gradient descent iteration = 24
gd loss = 6493.947404135442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6490.674762277053
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6490.674762277053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6486.930915423844
gradient descent iteration = 1
gd loss = 6486.930915423844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6483.497088308794
gradient descent iteration = 2
gd loss = 6483.497088308794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6480.24073774679
gradient descent iteration = 3
gd loss = 6480.24073774679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6477.110064974086
gradient descent iteration = 4
gd loss = 6477.110064974086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6474.080437905528
gradient descent iteration = 5
gd loss = 6474.080437905528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6471.137409601208
gradient descent iteration = 6
gd loss = 6471.137409601208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6468.271006327644
gradient descent iteration = 7
gd loss = 6468.271006327644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6465.473618013735
gradient descent iteration = 8
gd loss = 6465.473618013735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6462.739105438234
gradient descent iteration = 9
gd loss = 6462.739105438234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6460.062354458872
gradient descent iteration = 10
gd loss = 6460.062354458872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6457.439015973098
gradient descent iteration = 11
gd loss = 6457.439015973098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6454.865335461442
gradient descent iteration = 12
gd loss = 6454.865335461442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6452.338032736966
gradient descent iteration = 13
gd loss = 6452.338032736966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6449.854213239943
gradient descent iteration = 14
gd loss = 6449.854213239943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6447.41130074755
gradient descent iteration = 15
gd loss = 6447.41130074755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6445.006985355367
gradient descent iteration = 16
gd loss = 6445.006985355367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6442.639182634961
gradient descent iteration = 17
gd loss = 6442.639182634961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6440.306001079384
gradient descent iteration = 18
gd loss = 6440.306001079384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6438.005715855781
gradient descent iteration = 19
gd loss = 6438.005715855781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6435.736747381734
gradient descent iteration = 20
gd loss = 6435.736747381734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6433.497643632652
gradient descent iteration = 21
gd loss = 6433.497643632652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6431.287065401065
gradient descent iteration = 22
gd loss = 6431.287065401065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6429.103773873534
gradient descent iteration = 23
gd loss = 6429.103773873534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6426.946620111975
gradient descent iteration = 24
gd loss = 6426.946620111975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6424.814536014104
Initial loss = 6858.915546433028
Final loss = 6424.814536014104
Deformation gradient control sequence optimization finished.
Animation interval 29 took 1399 seconds.
Full animation took 41485 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 30************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7233.763216056174
initial norm = 768.0147915340117
convergence norm = 0.7680147915340118
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7233.763216056174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7176.173153460664
gradient descent iteration = 1
gd loss = 7176.173153460664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7145.90025060188
gradient descent iteration = 2
gd loss = 7145.90025060188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7125.851316795729
gradient descent iteration = 3
gd loss = 7125.851316795729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7109.651963621283
gradient descent iteration = 4
gd loss = 7109.651963621283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7098.706609200422
gradient descent iteration = 5
gd loss = 7098.706609200422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7091.116104501891
gradient descent iteration = 6
gd loss = 7091.116104501891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7083.256623980788
gradient descent iteration = 7
gd loss = 7083.256623980788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7076.175395209502
gradient descent iteration = 8
gd loss = 7076.175395209502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7069.387199681048
gradient descent iteration = 9
gd loss = 7069.387199681048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7062.846239860941
gradient descent iteration = 10
gd loss = 7062.846239860941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7056.650417328239
gradient descent iteration = 11
gd loss = 7056.650417328239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7050.526782498752
gradient descent iteration = 12
gd loss = 7050.526782498752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7044.730517593806
gradient descent iteration = 13
gd loss = 7044.730517593806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7038.92880976233
gradient descent iteration = 14
gd loss = 7038.92880976233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7033.431315655039
gradient descent iteration = 15
gd loss = 7033.431315655039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7027.886555748019
gradient descent iteration = 16
gd loss = 7027.886555748019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7022.627000754867
gradient descent iteration = 17
gd loss = 7022.627000754867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7017.294420648635
gradient descent iteration = 18
gd loss = 7017.294420648635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7012.232480826628
gradient descent iteration = 19
gd loss = 7012.232480826628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7007.080090865255
gradient descent iteration = 20
gd loss = 7007.080090865255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7002.187179914743
gradient descent iteration = 21
gd loss = 7002.187179914743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6997.191220129022
gradient descent iteration = 22
gd loss = 6997.191220129022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6992.446029407255
gradient descent iteration = 23
gd loss = 6992.446029407255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6987.588221858761
gradient descent iteration = 24
gd loss = 6987.588221858761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6982.97423127121
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 6982.97423127121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6969.680851365777
gradient descent iteration = 1
gd loss = 6969.680851365777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6962.83158567509
gradient descent iteration = 2
gd loss = 6962.83158567509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6956.811329621454
gradient descent iteration = 3
gd loss = 6956.811329621454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6951.269983981569
gradient descent iteration = 4
gd loss = 6951.269983981569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6946.084946626589
gradient descent iteration = 5
gd loss = 6946.084946626589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6941.178685801885
gradient descent iteration = 6
gd loss = 6941.178685801885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6936.496885696537
gradient descent iteration = 7
gd loss = 6936.496885696537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6931.999868608949
gradient descent iteration = 8
gd loss = 6931.999868608949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6927.657809086626
gradient descent iteration = 9
gd loss = 6927.657809086626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6923.447784081397
gradient descent iteration = 10
gd loss = 6923.447784081397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6919.351852751965
gradient descent iteration = 11
gd loss = 6919.351852751965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6915.355756979935
gradient descent iteration = 12
gd loss = 6915.355756979935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6911.448013810669
gradient descent iteration = 13
gd loss = 6911.448013810669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6907.619265038207
gradient descent iteration = 14
gd loss = 6907.619265038207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6903.861801136014
gradient descent iteration = 15
gd loss = 6903.861801136014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6900.169207194317
gradient descent iteration = 16
gd loss = 6900.169207194317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6896.536096245673
gradient descent iteration = 17
gd loss = 6896.536096245673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6892.957904850679
gradient descent iteration = 18
gd loss = 6892.957904850679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6889.430734993552
gradient descent iteration = 19
gd loss = 6889.430734993552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6885.951230749944
gradient descent iteration = 20
gd loss = 6885.951230749944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6882.516481153816
gradient descent iteration = 21
gd loss = 6882.516481153816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6879.123943141634
gradient descent iteration = 22
gd loss = 6879.123943141634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6875.771380512102
gradient descent iteration = 23
gd loss = 6875.771380512102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6872.456814592104
gradient descent iteration = 24
gd loss = 6872.456814592104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6869.178483534126
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 6869.178483534126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6865.294379930376
gradient descent iteration = 1
gd loss = 6865.294379930376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6861.754481594137
gradient descent iteration = 2
gd loss = 6861.754481594137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6858.407892734119
gradient descent iteration = 3
gd loss = 6858.407892734119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6855.196389825152
gradient descent iteration = 4
gd loss = 6855.196389825152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6852.092431249753
gradient descent iteration = 5
gd loss = 6852.092431249753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6849.079905700824
gradient descent iteration = 6
gd loss = 6849.079905700824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6846.147741092558
gradient descent iteration = 7
gd loss = 6846.147741092558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6843.287551016931
gradient descent iteration = 8
gd loss = 6843.287551016931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6840.492629233032
gradient descent iteration = 9
gd loss = 6840.492629233032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6837.757439472729
gradient descent iteration = 10
gd loss = 6837.757439472729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6835.077313560962
gradient descent iteration = 11
gd loss = 6835.077313560962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6832.44825301096
gradient descent iteration = 12
gd loss = 6832.44825301096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6829.866790421168
gradient descent iteration = 13
gd loss = 6829.866790421168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6827.329884393692
gradient descent iteration = 14
gd loss = 6827.329884393692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6824.834841337361
gradient descent iteration = 15
gd loss = 6824.834841337361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6822.379256149577
gradient descent iteration = 16
gd loss = 6822.379256149577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6819.960966042577
gradient descent iteration = 17
gd loss = 6819.960966042577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6817.578014114587
gradient descent iteration = 18
gd loss = 6817.578014114587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6815.228620217126
gradient descent iteration = 19
gd loss = 6815.228620217126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6812.911157352631
gradient descent iteration = 20
gd loss = 6812.911157352631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6810.624132343759
gradient descent iteration = 21
gd loss = 6810.624132343759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6808.366170009326
gradient descent iteration = 22
gd loss = 6808.366170009326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6806.136001312543
gradient descent iteration = 23
gd loss = 6806.136001312543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6803.932452387285
gradient descent iteration = 24
gd loss = 6803.932452387285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 6801.754432646893
Initial loss = 7233.763216056174
Final loss = 6801.754432646893
Deformation gradient control sequence optimization finished.
Animation interval 30 took 1407 seconds.
Full animation took 42892 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 31************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7642.849541773029
initial norm = 1001.078682714578
convergence norm = 1.001078682714578
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7642.849541773029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7567.37487944828
gradient descent iteration = 1
gd loss = 7567.37487944828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7531.762025056238
gradient descent iteration = 2
gd loss = 7531.762025056238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7510.203598169478
gradient descent iteration = 3
gd loss = 7510.203598169478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7492.453903578444
gradient descent iteration = 4
gd loss = 7492.453903578444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7479.506655000959
gradient descent iteration = 5
gd loss = 7479.506655000959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7472.594755693698
gradient descent iteration = 6
gd loss = 7472.594755693698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7464.661011166901
gradient descent iteration = 7
gd loss = 7464.661011166901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7458.066351579801
gradient descent iteration = 8
gd loss = 7458.066351579801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7451.267518267053
gradient descent iteration = 9
gd loss = 7451.267518267053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7445.114936583509
gradient descent iteration = 10
gd loss = 7445.114936583509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7438.893877964514
gradient descent iteration = 11
gd loss = 7438.893877964514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7433.095825280966
gradient descent iteration = 12
gd loss = 7433.095825280966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7427.238855446303
gradient descent iteration = 13
gd loss = 7427.238855446303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7421.714896418185
gradient descent iteration = 14
gd loss = 7421.714896418185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7416.118060182314
gradient descent iteration = 15
gd loss = 7416.118060182314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7410.811686990671
gradient descent iteration = 16
gd loss = 7410.811686990671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7405.416841694379
gradient descent iteration = 17
gd loss = 7405.416841694379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7400.289550782268
gradient descent iteration = 18
gd loss = 7400.289550782268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7395.060787892205
gradient descent iteration = 19
gd loss = 7395.060787892205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7390.085749291733
gradient descent iteration = 20
gd loss = 7390.085749291733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7384.999106397519
gradient descent iteration = 21
gd loss = 7384.999106397519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7380.157028734268
gradient descent iteration = 22
gd loss = 7380.157028734268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7375.195528272895
gradient descent iteration = 23
gd loss = 7375.195528272895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7370.472066750074
gradient descent iteration = 24
gd loss = 7370.472066750074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7365.623106897991
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 7365.623106897991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7352.569864810393
gradient descent iteration = 1
gd loss = 7352.569864810393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7345.843351894673
gradient descent iteration = 2
gd loss = 7345.843351894673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7339.965054227818
gradient descent iteration = 3
gd loss = 7339.965054227818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7334.535973188444
gradient descent iteration = 4
gd loss = 7334.535973188444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7329.436515491411
gradient descent iteration = 5
gd loss = 7329.436515491411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7324.594364134986
gradient descent iteration = 6
gd loss = 7324.594364134986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7319.959482286257
gradient descent iteration = 7
gd loss = 7319.959482286257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7315.495621300223
gradient descent iteration = 8
gd loss = 7315.495621300223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7311.175705374087
gradient descent iteration = 9
gd loss = 7311.175705374087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7306.979007445414
gradient descent iteration = 10
gd loss = 7306.979007445414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7302.88933141323
gradient descent iteration = 11
gd loss = 7302.88933141323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7298.893799495122
gradient descent iteration = 12
gd loss = 7298.893799495122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7294.982018687042
gradient descent iteration = 13
gd loss = 7294.982018687042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7291.145494795841
gradient descent iteration = 14
gd loss = 7291.145494795841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7287.377205083016
gradient descent iteration = 15
gd loss = 7287.377205083016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7283.671281080051
gradient descent iteration = 16
gd loss = 7283.671281080051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7280.022772132709
gradient descent iteration = 17
gd loss = 7280.022772132709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7276.427464017713
gradient descent iteration = 18
gd loss = 7276.427464017713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7272.881739239095
gradient descent iteration = 19
gd loss = 7272.881739239095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7269.382467857065
gradient descent iteration = 20
gd loss = 7269.382467857065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7265.926921302835
gradient descent iteration = 21
gd loss = 7265.926921302835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7262.512703951405
gradient descent iteration = 22
gd loss = 7262.512703951405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7259.137697893616
gradient descent iteration = 23
gd loss = 7259.137697893616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7255.800018326489
gradient descent iteration = 24
gd loss = 7255.800018326489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7252.497977412097
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 7252.497977412097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7248.60702885693
gradient descent iteration = 1
gd loss = 7248.60702885693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7245.027022930138
gradient descent iteration = 2
gd loss = 7245.027022930138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7241.632689073396
gradient descent iteration = 3
gd loss = 7241.632689073396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7238.371545951282
gradient descent iteration = 4
gd loss = 7238.371545951282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7235.217109287949
gradient descent iteration = 5
gd loss = 7235.217109287949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7232.153296069715
gradient descent iteration = 6
gd loss = 7232.153296069715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7229.168881888218
gradient descent iteration = 7
gd loss = 7229.168881888218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7226.255327047325
gradient descent iteration = 8
gd loss = 7226.255327047325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7223.405799932832
gradient descent iteration = 9
gd loss = 7223.405799932832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7220.614665267649
gradient descent iteration = 10
gd loss = 7220.614665267649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7217.877176420131
gradient descent iteration = 11
gd loss = 7217.877176420131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7215.189271036893
gradient descent iteration = 12
gd loss = 7215.189271036893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7212.547426428455
gradient descent iteration = 13
gd loss = 7212.547426428455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7209.948553219387
gradient descent iteration = 14
gd loss = 7209.948553219387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7207.389915189863
gradient descent iteration = 15
gd loss = 7207.389915189863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7204.86906779339
gradient descent iteration = 16
gd loss = 7204.86906779339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7202.383810276265
gradient descent iteration = 17
gd loss = 7202.383810276265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7199.932147857057
gradient descent iteration = 18
gd loss = 7199.932147857057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7197.51226423433
gradient descent iteration = 19
gd loss = 7197.51226423433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7195.122501574607
gradient descent iteration = 20
gd loss = 7195.122501574607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7192.761335137757
gradient descent iteration = 21
gd loss = 7192.761335137757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7190.427355861887
gradient descent iteration = 22
gd loss = 7190.427355861887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7188.119256623487
gradient descent iteration = 23
gd loss = 7188.119256623487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7185.83582084354
gradient descent iteration = 24
gd loss = 7185.83582084354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7183.575912782
Initial loss = 7642.849541773029
Final loss = 7183.575912782
Deformation gradient control sequence optimization finished.
Animation interval 31 took 1399 seconds.
Full animation took 44292 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 32************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 7997.034147802773
initial norm = 818.0455869687836
convergence norm = 0.8180455869687836
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 7997.034147802773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7936.743400742108
gradient descent iteration = 1
gd loss = 7936.743400742108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7907.776534307312
gradient descent iteration = 2
gd loss = 7907.776534307312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7888.858230618094
gradient descent iteration = 3
gd loss = 7888.858230618094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7874.684209042709
gradient descent iteration = 4
gd loss = 7874.684209042709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7865.895080651332
gradient descent iteration = 5
gd loss = 7865.895080651332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7857.604076394334
gradient descent iteration = 6
gd loss = 7857.604076394334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7850.114382299452
gradient descent iteration = 7
gd loss = 7850.114382299452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7842.89332964086
gradient descent iteration = 8
gd loss = 7842.89332964086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7836.188476702427
gradient descent iteration = 9
gd loss = 7836.188476702427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7829.595372170566
gradient descent iteration = 10
gd loss = 7829.595372170566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7823.394364520682
gradient descent iteration = 11
gd loss = 7823.394364520682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7817.216187185801
gradient descent iteration = 12
gd loss = 7817.216187185801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7811.365436056386
gradient descent iteration = 13
gd loss = 7811.365436056386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7805.48469250337
gradient descent iteration = 14
gd loss = 7805.48469250337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7799.893631834504
gradient descent iteration = 15
gd loss = 7799.893631834504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7794.239362965863
gradient descent iteration = 16
gd loss = 7794.239362965863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7788.85072371356
gradient descent iteration = 17
gd loss = 7788.85072371356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7783.376840997023
gradient descent iteration = 18
gd loss = 7783.376840997023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7778.152131043015
gradient descent iteration = 19
gd loss = 7778.152131043015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7772.826862610476
gradient descent iteration = 20
gd loss = 7772.826862610476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7767.738861831769
gradient descent iteration = 21
gd loss = 7767.738861831769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7762.539222920929
gradient descent iteration = 22
gd loss = 7762.539222920929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7757.567832473612
gradient descent iteration = 23
gd loss = 7757.567832473612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7752.476528856409
gradient descent iteration = 24
gd loss = 7752.476528856409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7747.606417310962
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 7747.606417310962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7734.649432472784
gradient descent iteration = 1
gd loss = 7734.649432472784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7728.076791449726
gradient descent iteration = 2
gd loss = 7728.076791449726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7722.300928164028
gradient descent iteration = 3
gd loss = 7722.300928164028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7716.955690227121
gradient descent iteration = 4
gd loss = 7716.955690227121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7711.927163300787
gradient descent iteration = 5
gd loss = 7711.927163300787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7707.145766162265
gradient descent iteration = 6
gd loss = 7707.145766162265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7702.563315299875
gradient descent iteration = 7
gd loss = 7702.563315299875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7698.14484792783
gradient descent iteration = 8
gd loss = 7698.14484792783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7693.8641878668
gradient descent iteration = 9
gd loss = 7693.8641878668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7689.701255590136
gradient descent iteration = 10
gd loss = 7689.701255590136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7685.640341687395
gradient descent iteration = 11
gd loss = 7685.640341687395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7681.668951688006
gradient descent iteration = 12
gd loss = 7681.668951688006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7677.777006600797
gradient descent iteration = 13
gd loss = 7677.777006600797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7673.956274068325
gradient descent iteration = 14
gd loss = 7673.956274068325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7670.199953610735
gradient descent iteration = 15
gd loss = 7670.199953610735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7666.502368993983
gradient descent iteration = 16
gd loss = 7666.502368993983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7662.858736309738
gradient descent iteration = 17
gd loss = 7662.858736309738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7659.264988490538
gradient descent iteration = 18
gd loss = 7659.264988490538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7655.717642261355
gradient descent iteration = 19
gd loss = 7655.717642261355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7652.213692922182
gradient descent iteration = 20
gd loss = 7652.213692922182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7648.750537570849
gradient descent iteration = 21
gd loss = 7648.750537570849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7645.325897778765
gradient descent iteration = 22
gd loss = 7645.325897778765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7641.937763748413
gradient descent iteration = 23
gd loss = 7641.937763748413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7638.584351849026
gradient descent iteration = 24
gd loss = 7638.584351849026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7635.264070266187
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 7635.264070266187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7630.831595493771
gradient descent iteration = 1
gd loss = 7630.831595493771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7626.770126273253
gradient descent iteration = 2
gd loss = 7626.770126273253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7622.924958218109
gradient descent iteration = 3
gd loss = 7622.924958218109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7619.232196019502
gradient descent iteration = 4
gd loss = 7619.232196019502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7615.659600907084
gradient descent iteration = 5
gd loss = 7615.659600907084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7612.187502908265
gradient descent iteration = 6
gd loss = 7612.187502908265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7608.80215299594
gradient descent iteration = 7
gd loss = 7608.80215299594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7605.493124019297
gradient descent iteration = 8
gd loss = 7605.493124019297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7602.252125417201
gradient descent iteration = 9
gd loss = 7602.252125417201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7599.072368620282
gradient descent iteration = 10
gd loss = 7599.072368620282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7595.948200101147
gradient descent iteration = 11
gd loss = 7595.948200101147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7592.874846556413
gradient descent iteration = 12
gd loss = 7592.874846556413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7589.848196792273
gradient descent iteration = 13
gd loss = 7589.848196792273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7586.864662663279
gradient descent iteration = 14
gd loss = 7586.864662663279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7583.92107918054
gradient descent iteration = 15
gd loss = 7583.92107918054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7581.014626782482
gradient descent iteration = 16
gd loss = 7581.014626782482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7578.142771300589
gradient descent iteration = 17
gd loss = 7578.142771300589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7575.303215732802
gradient descent iteration = 18
gd loss = 7575.303215732802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7572.493864001724
gradient descent iteration = 19
gd loss = 7572.493864001724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7569.712792240264
gradient descent iteration = 20
gd loss = 7569.712792240264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7566.958224725186
gradient descent iteration = 21
gd loss = 7566.958224725186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7564.228513383566
gradient descent iteration = 22
gd loss = 7564.228513383566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7561.52211697327
gradient descent iteration = 23
gd loss = 7561.52211697327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7558.83758949747
gradient descent iteration = 24
gd loss = 7558.83758949747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7556.173571793097
Initial loss = 7997.034147802773
Final loss = 7556.173571793097
Deformation gradient control sequence optimization finished.
Animation interval 32 took 1400 seconds.
Full animation took 45692 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 33************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8396.79368003361
initial norm = 1041.023813038692
convergence norm = 1.041023813038692
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8396.79368003361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8318.637991685249
gradient descent iteration = 1
gd loss = 8318.637991685249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8283.916562980306
gradient descent iteration = 2
gd loss = 8283.916562980306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8263.432702666285
gradient descent iteration = 3
gd loss = 8263.432702666285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8246.671146276176
gradient descent iteration = 4
gd loss = 8246.671146276176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8235.631338346799
gradient descent iteration = 5
gd loss = 8235.631338346799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8228.656982770963
gradient descent iteration = 6
gd loss = 8228.656982770963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8220.568669860291
gradient descent iteration = 7
gd loss = 8220.568669860291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8213.787881582291
gradient descent iteration = 8
gd loss = 8213.787881582291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8206.776641847648
gradient descent iteration = 9
gd loss = 8206.776641847648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8200.37057137388
gradient descent iteration = 10
gd loss = 8200.37057137388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8193.895654648599
gradient descent iteration = 11
gd loss = 8193.895654648599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8187.802958743012
gradient descent iteration = 12
gd loss = 8187.802958743012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8181.660182864283
gradient descent iteration = 13
gd loss = 8181.660182864283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8175.811376958265
gradient descent iteration = 14
gd loss = 8175.811376958265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8169.902163277435
gradient descent iteration = 15
gd loss = 8169.902163277435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8164.245474428868
gradient descent iteration = 16
gd loss = 8164.245474428868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8158.51433615745
gradient descent iteration = 17
gd loss = 8158.51433615745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8153.013099464994
gradient descent iteration = 18
gd loss = 8153.013099464994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8147.425121848175
gradient descent iteration = 19
gd loss = 8147.425121848175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8142.052915559417
gradient descent iteration = 20
gd loss = 8142.052915559417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8136.584109283973
gradient descent iteration = 21
gd loss = 8136.584109283973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8131.321253258101
gradient descent iteration = 22
gd loss = 8131.321253258101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8125.954071629908
gradient descent iteration = 23
gd loss = 8125.954071629908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8120.785463926153
gradient descent iteration = 24
gd loss = 8120.785463926153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8115.506392598643
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8115.506392598643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8102.980444666538
gradient descent iteration = 1
gd loss = 8102.980444666538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8096.665274687579
gradient descent iteration = 2
gd loss = 8096.665274687579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8091.183128374747
gradient descent iteration = 3
gd loss = 8091.183128374747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8086.116656142945
gradient descent iteration = 4
gd loss = 8086.116656142945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8081.350396088226
gradient descent iteration = 5
gd loss = 8081.350396088226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8076.816699160437
gradient descent iteration = 6
gd loss = 8076.816699160437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8072.469020190239
gradient descent iteration = 7
gd loss = 8072.469020190239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8068.273706801591
gradient descent iteration = 8
gd loss = 8068.273706801591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8064.205668562877
gradient descent iteration = 9
gd loss = 8064.205668562877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8060.245738155812
gradient descent iteration = 10
gd loss = 8060.245738155812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8056.378971648292
gradient descent iteration = 11
gd loss = 8056.378971648292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8052.593512724284
gradient descent iteration = 12
gd loss = 8052.593512724284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8048.879811372495
gradient descent iteration = 13
gd loss = 8048.879811372495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8045.230071496795
gradient descent iteration = 14
gd loss = 8045.230071496795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8041.637851925304
gradient descent iteration = 15
gd loss = 8041.637851925304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8038.097775671093
gradient descent iteration = 16
gd loss = 8038.097775671093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8034.605310348414
gradient descent iteration = 17
gd loss = 8034.605310348414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8031.156595048153
gradient descent iteration = 18
gd loss = 8031.156595048153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8027.748310409409
gradient descent iteration = 19
gd loss = 8027.748310409409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8024.377578222504
gradient descent iteration = 20
gd loss = 8024.377578222504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8021.041882290781
gradient descent iteration = 21
gd loss = 8021.041882290781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8017.739005591923
gradient descent iteration = 22
gd loss = 8017.739005591923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8014.466979569469
gradient descent iteration = 23
gd loss = 8014.466979569469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8011.22404354413
gradient descent iteration = 24
gd loss = 8011.22404354413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8008.00861218389
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8008.00861218389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8003.024068172402
gradient descent iteration = 1
gd loss = 8003.024068172402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7998.415287804495
gradient descent iteration = 2
gd loss = 7998.415287804495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7994.027351913617
gradient descent iteration = 3
gd loss = 7994.027351913617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7989.794609392045
gradient descent iteration = 4
gd loss = 7989.794609392045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7985.683206063394
gradient descent iteration = 5
gd loss = 7985.683206063394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7981.672103824902
gradient descent iteration = 6
gd loss = 7981.672103824902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7977.746374776121
gradient descent iteration = 7
gd loss = 7977.746374776121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7973.894560526623
gradient descent iteration = 8
gd loss = 7973.894560526623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7970.107456084723
gradient descent iteration = 9
gd loss = 7970.107456084723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7966.377439819816
gradient descent iteration = 10
gd loss = 7966.377439819816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7962.69807854062
gradient descent iteration = 11
gd loss = 7962.69807854062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7959.063904232552
gradient descent iteration = 12
gd loss = 7959.063904232552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7955.470232432429
gradient descent iteration = 13
gd loss = 7955.470232432429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7951.912925879655
gradient descent iteration = 14
gd loss = 7951.912925879655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7948.388288928666
gradient descent iteration = 15
gd loss = 7948.388288928666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7944.893105711
gradient descent iteration = 16
gd loss = 7944.893105711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7941.424580908942
gradient descent iteration = 17
gd loss = 7941.424580908942
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7937.980291924892
gradient descent iteration = 18
gd loss = 7937.980291924892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7934.558119627555
gradient descent iteration = 19
gd loss = 7934.558119627555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7931.156169772767
gradient descent iteration = 20
gd loss = 7931.156169772767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7927.772741677814
gradient descent iteration = 21
gd loss = 7927.772741677814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7924.406305196888
gradient descent iteration = 22
gd loss = 7924.406305196888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7921.055495994028
gradient descent iteration = 23
gd loss = 7921.055495994028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7917.719169589166
gradient descent iteration = 24
gd loss = 7917.719169589166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 7914.396341236961
Initial loss = 8396.79368003361
Final loss = 7914.396341236961
Deformation gradient control sequence optimization finished.
Animation interval 33 took 1406 seconds.
Full animation took 47098 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 34************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8726.439080245171
initial norm = 862.8628807495111
convergence norm = 0.8628628807495111
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8726.439080245171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8663.587701940734
gradient descent iteration = 1
gd loss = 8663.587701940734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8636.142298108898
gradient descent iteration = 2
gd loss = 8636.142298108898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8618.02222946011
gradient descent iteration = 3
gd loss = 8618.02222946011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8604.817450215056
gradient descent iteration = 4
gd loss = 8604.817450215056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8595.346432327888
gradient descent iteration = 5
gd loss = 8595.346432327888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8586.030014343532
gradient descent iteration = 6
gd loss = 8586.030014343532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8577.5472542148
gradient descent iteration = 7
gd loss = 8577.5472542148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8569.272088253974
gradient descent iteration = 8
gd loss = 8569.272088253974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8561.482435184467
gradient descent iteration = 9
gd loss = 8561.482435184467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8553.802314047471
gradient descent iteration = 10
gd loss = 8553.802314047471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8546.4868542041
gradient descent iteration = 11
gd loss = 8546.4868542041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8539.211854536716
gradient descent iteration = 12
gd loss = 8539.211854536716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8532.243329328921
gradient descent iteration = 13
gd loss = 8532.243329328921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8525.271461141008
gradient descent iteration = 14
gd loss = 8525.271461141008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8518.57249137377
gradient descent iteration = 15
gd loss = 8518.57249137377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8511.841589610554
gradient descent iteration = 16
gd loss = 8511.841589610554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8505.361919280307
gradient descent iteration = 17
gd loss = 8505.361919280307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8498.83085395011
gradient descent iteration = 18
gd loss = 8498.83085395011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8492.536170621133
gradient descent iteration = 19
gd loss = 8492.536170621133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8486.176495011747
gradient descent iteration = 20
gd loss = 8486.176495011747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8480.04249139787
gradient descent iteration = 21
gd loss = 8480.04249139787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8473.833522244506
gradient descent iteration = 22
gd loss = 8473.833522244506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8467.842143869582
gradient descent iteration = 23
gd loss = 8467.842143869582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8461.768278476582
gradient descent iteration = 24
gd loss = 8461.768278476582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8455.90581287603
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8455.90581287603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8443.271375258153
gradient descent iteration = 1
gd loss = 8443.271375258153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8436.798236069058
gradient descent iteration = 2
gd loss = 8436.798236069058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8431.085236308732
gradient descent iteration = 3
gd loss = 8431.085236308732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8425.757551978433
gradient descent iteration = 4
gd loss = 8425.757551978433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8420.703950657145
gradient descent iteration = 5
gd loss = 8420.703950657145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8415.858010321515
gradient descent iteration = 6
gd loss = 8415.858010321515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8411.17411014832
gradient descent iteration = 7
gd loss = 8411.17411014832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8406.61926808216
gradient descent iteration = 8
gd loss = 8406.61926808216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8402.168814487375
gradient descent iteration = 9
gd loss = 8402.168814487375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8397.803803602575
gradient descent iteration = 10
gd loss = 8397.803803602575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8393.509365478925
gradient descent iteration = 11
gd loss = 8393.509365478925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8389.273614118605
gradient descent iteration = 12
gd loss = 8389.273614118605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8385.086892103411
gradient descent iteration = 13
gd loss = 8385.086892103411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8380.941229658478
gradient descent iteration = 14
gd loss = 8380.941229658478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8376.829955177998
gradient descent iteration = 15
gd loss = 8376.829955177998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8372.747408276333
gradient descent iteration = 16
gd loss = 8372.747408276333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8368.688725949747
gradient descent iteration = 17
gd loss = 8368.688725949747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8364.649679563854
gradient descent iteration = 18
gd loss = 8364.649679563854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8360.626548094613
gradient descent iteration = 19
gd loss = 8360.626548094613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8356.616020447958
gradient descent iteration = 20
gd loss = 8356.616020447958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8352.615119466482
gradient descent iteration = 21
gd loss = 8352.615119466482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8348.621136360796
gradient descent iteration = 22
gd loss = 8348.621136360796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8344.63157923534
gradient descent iteration = 23
gd loss = 8344.63157923534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8340.644130716184
gradient descent iteration = 24
gd loss = 8340.644130716184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8336.656611725897
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8336.656611725897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8330.533923412853
gradient descent iteration = 1
gd loss = 8330.533923412853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8324.911743695176
gradient descent iteration = 2
gd loss = 8324.911743695176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8319.565503253321
gradient descent iteration = 3
gd loss = 8319.565503253321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8314.40983183248
gradient descent iteration = 4
gd loss = 8314.40983183248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8309.404239553985
gradient descent iteration = 5
gd loss = 8309.404239553985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8304.524634100882
gradient descent iteration = 6
gd loss = 8304.524634100882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8299.754109586966
gradient descent iteration = 7
gd loss = 8299.754109586966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8295.079618677313
gradient descent iteration = 8
gd loss = 8295.079618677313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8290.490588761206
gradient descent iteration = 9
gd loss = 8290.490588761206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8285.978215506946
gradient descent iteration = 10
gd loss = 8285.978215506946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8281.535086709002
gradient descent iteration = 11
gd loss = 8281.535086709002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8277.154916000271
gradient descent iteration = 12
gd loss = 8277.154916000271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8272.832312297711
gradient descent iteration = 13
gd loss = 8272.832312297711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8268.562858200097
gradient descent iteration = 14
gd loss = 8268.562858200097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8264.342996400823
gradient descent iteration = 15
gd loss = 8264.342996400823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8260.170051217428
gradient descent iteration = 16
gd loss = 8260.170051217428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8256.042202805604
gradient descent iteration = 17
gd loss = 8256.042202805604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8251.958032286477
gradient descent iteration = 18
gd loss = 8251.958032286477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8247.916399199386
gradient descent iteration = 19
gd loss = 8247.916399199386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8243.916365966046
gradient descent iteration = 20
gd loss = 8243.916365966046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8239.957140697148
gradient descent iteration = 21
gd loss = 8239.957140697148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8236.038031824202
gradient descent iteration = 22
gd loss = 8236.038031824202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8232.158424144154
gradient descent iteration = 23
gd loss = 8232.158424144154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8228.317699028767
gradient descent iteration = 24
gd loss = 8228.317699028767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8224.515156558346
Initial loss = 8726.439080245171
Final loss = 8224.515156558346
Deformation gradient control sequence optimization finished.
Animation interval 34 took 1400 seconds.
Full animation took 48498 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 35************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9042.289294933349
initial norm = 1069.899292874259
convergence norm = 1.069899292874259
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9042.289294933349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8961.416403123299
gradient descent iteration = 1
gd loss = 8961.416403123299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8924.792562408673
gradient descent iteration = 2
gd loss = 8924.792562408673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8903.962206035529
gradient descent iteration = 3
gd loss = 8903.962206035529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8886.480819090022
gradient descent iteration = 4
gd loss = 8886.480819090022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8873.754597737077
gradient descent iteration = 5
gd loss = 8873.754597737077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8867.102002463569
gradient descent iteration = 6
gd loss = 8867.102002463569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8858.809943311689
gradient descent iteration = 7
gd loss = 8858.809943311689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8851.987771685686
gradient descent iteration = 8
gd loss = 8851.987771685686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8844.763445062106
gradient descent iteration = 9
gd loss = 8844.763445062106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8838.144709301348
gradient descent iteration = 10
gd loss = 8838.144709301348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8831.390450100156
gradient descent iteration = 11
gd loss = 8831.390450100156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8824.976038663161
gradient descent iteration = 12
gd loss = 8824.976038663161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8818.475796245879
gradient descent iteration = 13
gd loss = 8818.475796245879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8812.212587549695
gradient descent iteration = 14
gd loss = 8812.212587549695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8805.859585378135
gradient descent iteration = 15
gd loss = 8805.859585378135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8799.693025897281
gradient descent iteration = 16
gd loss = 8799.693025897281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8793.419094431061
gradient descent iteration = 17
gd loss = 8793.419094431061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8787.298804536958
gradient descent iteration = 18
gd loss = 8787.298804536958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8781.049675406921
gradient descent iteration = 19
gd loss = 8781.049675406921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8774.926460733481
gradient descent iteration = 20
gd loss = 8774.926460733481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8768.651174400087
gradient descent iteration = 21
gd loss = 8768.651174400087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8762.476900560445
gradient descent iteration = 22
gd loss = 8762.476900560445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8756.128724220118
gradient descent iteration = 23
gd loss = 8756.128724220118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8749.854648698778
gradient descent iteration = 24
gd loss = 8749.854648698778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8743.377966537761
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8743.377966537761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8729.790389560852
gradient descent iteration = 1
gd loss = 8729.790389560852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8721.972634441578
gradient descent iteration = 2
gd loss = 8721.972634441578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8714.845051501296
gradient descent iteration = 3
gd loss = 8714.845051501296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8708.008340088494
gradient descent iteration = 4
gd loss = 8708.008340088494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8701.363982347082
gradient descent iteration = 5
gd loss = 8701.363982347082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8694.857462553671
gradient descent iteration = 6
gd loss = 8694.857462553671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8688.452913752848
gradient descent iteration = 7
gd loss = 8688.452913752848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8682.127487407457
gradient descent iteration = 8
gd loss = 8682.127487407457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8675.865432053457
gradient descent iteration = 9
gd loss = 8675.865432053457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8669.654765480291
gradient descent iteration = 10
gd loss = 8669.654765480291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8663.485809092996
gradient descent iteration = 11
gd loss = 8663.485809092996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8657.35049938908
gradient descent iteration = 12
gd loss = 8657.35049938908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8651.241277925172
gradient descent iteration = 13
gd loss = 8651.241277925172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8645.151194900558
gradient descent iteration = 14
gd loss = 8645.151194900558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8639.076303202077
gradient descent iteration = 15
gd loss = 8639.076303202077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8633.017204697799
gradient descent iteration = 16
gd loss = 8633.017204697799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8626.975938729105
gradient descent iteration = 17
gd loss = 8626.975938729105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8620.955228427125
gradient descent iteration = 18
gd loss = 8620.955228427125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8614.958169181018
gradient descent iteration = 19
gd loss = 8614.958169181018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8608.990127389998
gradient descent iteration = 20
gd loss = 8608.990127389998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8603.059345922202
gradient descent iteration = 21
gd loss = 8603.059345922202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8597.172346369085
gradient descent iteration = 22
gd loss = 8597.172346369085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8591.332921942454
gradient descent iteration = 23
gd loss = 8591.332921942454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8585.540849502526
gradient descent iteration = 24
gd loss = 8585.540849502526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8579.791445049437
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8579.791445049437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8574.696162301185
gradient descent iteration = 1
gd loss = 8574.696162301185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8570.019419718519
gradient descent iteration = 2
gd loss = 8570.019419718519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8565.568278899493
gradient descent iteration = 3
gd loss = 8565.568278899493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8561.268289133908
gradient descent iteration = 4
gd loss = 8561.268289133908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8557.084709188694
gradient descent iteration = 5
gd loss = 8557.084709188694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8552.997506990541
gradient descent iteration = 6
gd loss = 8552.997506990541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8548.993020489675
gradient descent iteration = 7
gd loss = 8548.993020489675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8545.060919899692
gradient descent iteration = 8
gd loss = 8545.060919899692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8541.192942419697
gradient descent iteration = 9
gd loss = 8541.192942419697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8537.38227090597
gradient descent iteration = 10
gd loss = 8537.38227090597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8533.623186502769
gradient descent iteration = 11
gd loss = 8533.623186502769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8529.910869290106
gradient descent iteration = 12
gd loss = 8529.910869290106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8526.241184439841
gradient descent iteration = 13
gd loss = 8526.241184439841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8522.610542977793
gradient descent iteration = 14
gd loss = 8522.610542977793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8519.015821186737
gradient descent iteration = 15
gd loss = 8519.015821186737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8515.454302421022
gradient descent iteration = 16
gd loss = 8515.454302421022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8511.923595141321
gradient descent iteration = 17
gd loss = 8511.923595141321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8508.421603088244
gradient descent iteration = 18
gd loss = 8508.421603088244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8504.946484498752
gradient descent iteration = 19
gd loss = 8504.946484498752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8501.496599019863
gradient descent iteration = 20
gd loss = 8501.496599019863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8498.070488054385
gradient descent iteration = 21
gd loss = 8498.070488054385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8494.666895806782
gradient descent iteration = 22
gd loss = 8494.666895806782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8491.284749112723
gradient descent iteration = 23
gd loss = 8491.284749112723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8487.923114683121
gradient descent iteration = 24
gd loss = 8487.923114683121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8484.581165478905
Initial loss = 9042.289294933349
Final loss = 8484.581165478905
Deformation gradient control sequence optimization finished.
Animation interval 35 took 1414 seconds.
Full animation took 49913 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 36************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9241.520375986169
initial norm = 978.7953410722793
convergence norm = 0.9787953410722793
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9241.520375986169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9166.922654156424
gradient descent iteration = 1
gd loss = 9166.922654156424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9130.125658294199
gradient descent iteration = 2
gd loss = 9130.125658294199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9106.487374398697
gradient descent iteration = 3
gd loss = 9106.487374398697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9085.212289614456
gradient descent iteration = 4
gd loss = 9085.212289614456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9066.154931453209
gradient descent iteration = 5
gd loss = 9066.154931453209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9050.357769993945
gradient descent iteration = 6
gd loss = 9050.357769993945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9037.877198822602
gradient descent iteration = 7
gd loss = 9037.877198822602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9025.872995909429
gradient descent iteration = 8
gd loss = 9025.872995909429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9014.225558447595
gradient descent iteration = 9
gd loss = 9014.225558447595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9002.776340802522
gradient descent iteration = 10
gd loss = 9002.776340802522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8991.709033238219
gradient descent iteration = 11
gd loss = 8991.709033238219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8980.792197470904
gradient descent iteration = 12
gd loss = 8980.792197470904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8970.206127042078
gradient descent iteration = 13
gd loss = 8970.206127042078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8959.701540666807
gradient descent iteration = 14
gd loss = 8959.701540666807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8949.469049468606
gradient descent iteration = 15
gd loss = 8949.469049468606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8939.263498908007
gradient descent iteration = 16
gd loss = 8939.263498908007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8929.294605405437
gradient descent iteration = 17
gd loss = 8929.294605405437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8919.342257899147
gradient descent iteration = 18
gd loss = 8919.342257899147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8909.642503181994
gradient descent iteration = 19
gd loss = 8909.642503181994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8899.977249473515
gradient descent iteration = 20
gd loss = 8899.977249473515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8890.580038401264
gradient descent iteration = 21
gd loss = 8890.580038401264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8881.228244563335
gradient descent iteration = 22
gd loss = 8881.228244563335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8872.154005439053
gradient descent iteration = 23
gd loss = 8872.154005439053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8863.124294462885
gradient descent iteration = 24
gd loss = 8863.124294462885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8854.366261310324
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8854.366261310324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8843.332480701221
gradient descent iteration = 1
gd loss = 8843.332480701221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8837.714116223289
gradient descent iteration = 2
gd loss = 8837.714116223289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8832.659061873588
gradient descent iteration = 3
gd loss = 8832.659061873588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8827.860350689809
gradient descent iteration = 4
gd loss = 8827.860350689809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8823.245130109653
gradient descent iteration = 5
gd loss = 8823.245130109653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8818.772404721603
gradient descent iteration = 6
gd loss = 8818.772404721603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8814.414203086893
gradient descent iteration = 7
gd loss = 8814.414203086893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8810.150231993328
gradient descent iteration = 8
gd loss = 8810.150231993328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8805.965197246374
gradient descent iteration = 9
gd loss = 8805.965197246374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8801.847232863058
gradient descent iteration = 10
gd loss = 8801.847232863058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8797.786914020227
gradient descent iteration = 11
gd loss = 8797.786914020227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8793.776605629644
gradient descent iteration = 12
gd loss = 8793.776605629644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8789.810014613009
gradient descent iteration = 13
gd loss = 8789.810014613009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8785.881872805023
gradient descent iteration = 14
gd loss = 8785.881872805023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8781.987705601199
gradient descent iteration = 15
gd loss = 8781.987705601199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8778.123660151234
gradient descent iteration = 16
gd loss = 8778.123660151234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8774.28637810785
gradient descent iteration = 17
gd loss = 8774.28637810785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8770.47290589964
gradient descent iteration = 18
gd loss = 8770.47290589964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8766.680610462034
gradient descent iteration = 19
gd loss = 8766.680610462034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8762.907114650607
gradient descent iteration = 20
gd loss = 8762.907114650607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8759.150251613823
gradient descent iteration = 21
gd loss = 8759.150251613823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8755.408027500647
gradient descent iteration = 22
gd loss = 8755.408027500647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8751.678588319321
gradient descent iteration = 23
gd loss = 8751.678588319321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8747.960194747175
gradient descent iteration = 24
gd loss = 8747.960194747175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8744.251201877472
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8744.251201877472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8739.217860453857
gradient descent iteration = 1
gd loss = 8739.217860453857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8734.547720194687
gradient descent iteration = 2
gd loss = 8734.547720194687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8730.099419177623
gradient descent iteration = 3
gd loss = 8730.099419177623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8725.809388605407
gradient descent iteration = 4
gd loss = 8725.809388605407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8721.642655312146
gradient descent iteration = 5
gd loss = 8721.642655312146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8717.576493564309
gradient descent iteration = 6
gd loss = 8717.576493564309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8713.594491368834
gradient descent iteration = 7
gd loss = 8713.594491368834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8709.684295617872
gradient descent iteration = 8
gd loss = 8709.684295617872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8705.836293733759
gradient descent iteration = 9
gd loss = 8705.836293733759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8702.042858222952
gradient descent iteration = 10
gd loss = 8702.042858222952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8698.297771894944
gradient descent iteration = 11
gd loss = 8698.297771894944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8694.595869387722
gradient descent iteration = 12
gd loss = 8694.595869387722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8690.932808461428
gradient descent iteration = 13
gd loss = 8690.932808461428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8687.304900203588
gradient descent iteration = 14
gd loss = 8687.304900203588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8683.708981742808
gradient descent iteration = 15
gd loss = 8683.708981742808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8680.142319611266
gradient descent iteration = 16
gd loss = 8680.142319611266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8676.602535299065
gradient descent iteration = 17
gd loss = 8676.602535299065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8673.087548088626
gradient descent iteration = 18
gd loss = 8673.087548088626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8669.595531285664
gradient descent iteration = 19
gd loss = 8669.595531285664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8666.124881595753
gradient descent iteration = 20
gd loss = 8666.124881595753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8662.674224728551
gradient descent iteration = 21
gd loss = 8662.674224728551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8659.242393704248
gradient descent iteration = 22
gd loss = 8659.242393704248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8655.828383491975
gradient descent iteration = 23
gd loss = 8655.828383491975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8652.431337298516
gradient descent iteration = 24
gd loss = 8652.431337298516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8649.050536549308
Initial loss = 9241.520375986169
Final loss = 8649.050536549308
Deformation gradient control sequence optimization finished.
Animation interval 36 took 1402 seconds.
Full animation took 51315 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 37************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9256.531800524412
initial norm = 1051.96066844705
convergence norm = 1.05196066844705
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9256.531800524412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9177.883871337071
gradient descent iteration = 1
gd loss = 9177.883871337071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9144.475402281816
gradient descent iteration = 2
gd loss = 9144.475402281816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9126.664878882702
gradient descent iteration = 3
gd loss = 9126.664878882702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9112.302455914138
gradient descent iteration = 4
gd loss = 9112.302455914138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9103.320657154738
gradient descent iteration = 5
gd loss = 9103.320657154738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9094.256407358947
gradient descent iteration = 6
gd loss = 9094.256407358947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9085.555176493919
gradient descent iteration = 7
gd loss = 9085.555176493919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9077.053945613494
gradient descent iteration = 8
gd loss = 9077.053945613494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9068.633309877807
gradient descent iteration = 9
gd loss = 9068.633309877807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9060.407887594996
gradient descent iteration = 10
gd loss = 9060.407887594996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9052.176041681356
gradient descent iteration = 11
gd loss = 9052.176041681356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9044.120927353148
gradient descent iteration = 12
gd loss = 9044.120927353148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9036.025916017163
gradient descent iteration = 13
gd loss = 9036.025916017163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9028.095700703394
gradient descent iteration = 14
gd loss = 9028.095700703394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9020.110538398721
gradient descent iteration = 15
gd loss = 9020.110538398721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9012.283579936358
gradient descent iteration = 16
gd loss = 9012.283579936358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9004.39461900957
gradient descent iteration = 17
gd loss = 9004.39461900957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8996.661041948339
gradient descent iteration = 18
gd loss = 8996.661041948339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8988.863225212006
gradient descent iteration = 19
gd loss = 8988.863225212006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8981.220710191374
gradient descent iteration = 20
gd loss = 8981.220710191374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8973.512606783412
gradient descent iteration = 21
gd loss = 8973.512606783412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8965.958216139647
gradient descent iteration = 22
gd loss = 8965.958216139647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8958.334920134137
gradient descent iteration = 23
gd loss = 8958.334920134137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8950.861052583039
gradient descent iteration = 24
gd loss = 8950.861052583039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8943.311988914194
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8943.311988914194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8932.140353210034
gradient descent iteration = 1
gd loss = 8932.140353210034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8926.351960436732
gradient descent iteration = 2
gd loss = 8926.351960436732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8921.176854492267
gradient descent iteration = 3
gd loss = 8921.176854492267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8916.238296073958
gradient descent iteration = 4
gd loss = 8916.238296073958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8911.457784403883
gradient descent iteration = 5
gd loss = 8911.457784403883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8906.796461182761
gradient descent iteration = 6
gd loss = 8906.796461182761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8902.2291459482
gradient descent iteration = 7
gd loss = 8902.2291459482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8897.738124665562
gradient descent iteration = 8
gd loss = 8897.738124665562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8893.310391311792
gradient descent iteration = 9
gd loss = 8893.310391311792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8888.93605293942
gradient descent iteration = 10
gd loss = 8888.93605293942
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8884.607268559332
gradient descent iteration = 11
gd loss = 8884.607268559332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8880.317612918452
gradient descent iteration = 12
gd loss = 8880.317612918452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8876.061657537213
gradient descent iteration = 13
gd loss = 8876.061657537213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8871.834692435157
gradient descent iteration = 14
gd loss = 8871.834692435157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8867.632614618804
gradient descent iteration = 15
gd loss = 8867.632614618804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8863.451888026837
gradient descent iteration = 16
gd loss = 8863.451888026837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8859.289359536673
gradient descent iteration = 17
gd loss = 8859.289359536673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8855.142175347832
gradient descent iteration = 18
gd loss = 8855.142175347832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8851.007750462419
gradient descent iteration = 19
gd loss = 8851.007750462419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8846.883732721091
gradient descent iteration = 20
gd loss = 8846.883732721091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8842.76800736073
gradient descent iteration = 21
gd loss = 8842.76800736073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8838.65871327684
gradient descent iteration = 22
gd loss = 8838.65871327684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8834.554273655902
gradient descent iteration = 23
gd loss = 8834.554273655902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8830.453473185955
gradient descent iteration = 24
gd loss = 8830.453473185955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8826.355488839885
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8826.355488839885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8821.868396373844
gradient descent iteration = 1
gd loss = 8821.868396373844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8817.693003318758
gradient descent iteration = 2
gd loss = 8817.693003318758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8813.714795619504
gradient descent iteration = 3
gd loss = 8813.714795619504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8809.880506191244
gradient descent iteration = 4
gd loss = 8809.880506191244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8806.160258956605
gradient descent iteration = 5
gd loss = 8806.160258956605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8802.534568687242
gradient descent iteration = 6
gd loss = 8802.534568687242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8798.989432022006
gradient descent iteration = 7
gd loss = 8798.989432022006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8795.514201382834
gradient descent iteration = 8
gd loss = 8795.514201382834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8792.100503339743
gradient descent iteration = 9
gd loss = 8792.100503339743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8788.741602321372
gradient descent iteration = 10
gd loss = 8788.741602321372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8785.431984487128
gradient descent iteration = 11
gd loss = 8785.431984487128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8782.167066919319
gradient descent iteration = 12
gd loss = 8782.167066919319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8778.942986568778
gradient descent iteration = 13
gd loss = 8778.942986568778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8775.756443838594
gradient descent iteration = 14
gd loss = 8775.756443838594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8772.604584834111
gradient descent iteration = 15
gd loss = 8772.604584834111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8769.4849101074
gradient descent iteration = 16
gd loss = 8769.4849101074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8766.395206041892
gradient descent iteration = 17
gd loss = 8766.395206041892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8763.333492169268
gradient descent iteration = 18
gd loss = 8763.333492169268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8760.297979704674
gradient descent iteration = 19
gd loss = 8760.297979704674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8757.287036561125
gradient descent iteration = 20
gd loss = 8757.287036561125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8754.299160293735
gradient descent iteration = 21
gd loss = 8754.299160293735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8751.332962008157
gradient descent iteration = 22
gd loss = 8751.332962008157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8748.387150455239
gradient descent iteration = 23
gd loss = 8748.387150455239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8745.460518922013
gradient descent iteration = 24
gd loss = 8745.460518922013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8742.551934612025
Initial loss = 9256.531800524412
Final loss = 8742.551934612025
Deformation gradient control sequence optimization finished.
Animation interval 37 took 1372 seconds.
Full animation took 52688 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 38************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9184.161049388791
initial norm = 939.9438695708609
convergence norm = 0.939943869570861
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9184.161049388791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9115.860557720065
gradient descent iteration = 1
gd loss = 9115.860557720065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9090.774969601662
gradient descent iteration = 2
gd loss = 9090.774969601662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9077.917073804787
gradient descent iteration = 3
gd loss = 9077.917073804787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9070.65382819863
gradient descent iteration = 4
gd loss = 9070.65382819863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9062.853193890447
gradient descent iteration = 5
gd loss = 9062.853193890447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9055.902889080277
gradient descent iteration = 6
gd loss = 9055.902889080277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9049.034006005702
gradient descent iteration = 7
gd loss = 9049.034006005702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9042.398751997285
gradient descent iteration = 8
gd loss = 9042.398751997285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9035.954366782611
gradient descent iteration = 9
gd loss = 9035.954366782611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9029.545605708687
gradient descent iteration = 10
gd loss = 9029.545605708687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9023.33997018905
gradient descent iteration = 11
gd loss = 9023.33997018905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9017.089759336493
gradient descent iteration = 12
gd loss = 9017.089759336493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9011.032274308976
gradient descent iteration = 13
gd loss = 9011.032274308976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9004.891518968428
gradient descent iteration = 14
gd loss = 9004.891518968428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8998.931741506689
gradient descent iteration = 15
gd loss = 8998.931741506689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8992.868680366495
gradient descent iteration = 16
gd loss = 8992.868680366495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8986.976894552534
gradient descent iteration = 17
gd loss = 8986.976894552534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8980.971521557445
gradient descent iteration = 18
gd loss = 8980.971521557445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8975.131924412646
gradient descent iteration = 19
gd loss = 8975.131924412646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8969.17433876663
gradient descent iteration = 20
gd loss = 8969.17433876663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8963.379641448524
gradient descent iteration = 21
gd loss = 8963.379641448524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8957.465182142882
gradient descent iteration = 22
gd loss = 8957.465182142882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8951.711703202216
gradient descent iteration = 23
gd loss = 8951.711703202216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8945.837422197365
gradient descent iteration = 24
gd loss = 8945.837422197365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8940.122328366118
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8940.122328366118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8929.543015985706
gradient descent iteration = 1
gd loss = 8929.543015985706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8924.948083561636
gradient descent iteration = 2
gd loss = 8924.948083561636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8920.858369553926
gradient descent iteration = 3
gd loss = 8920.858369553926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8916.943300771578
gradient descent iteration = 4
gd loss = 8916.943300771578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8913.14352862677
gradient descent iteration = 5
gd loss = 8913.14352862677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8909.430291390201
gradient descent iteration = 6
gd loss = 8909.430291390201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8905.785061561846
gradient descent iteration = 7
gd loss = 8905.785061561846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8902.194851476734
gradient descent iteration = 8
gd loss = 8902.194851476734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8898.650094023336
gradient descent iteration = 9
gd loss = 8898.650094023336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8895.143470202858
gradient descent iteration = 10
gd loss = 8895.143470202858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8891.669208208006
gradient descent iteration = 11
gd loss = 8891.669208208006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8888.222641108245
gradient descent iteration = 12
gd loss = 8888.222641108245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8884.799917188082
gradient descent iteration = 13
gd loss = 8884.799917188082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8881.397798852076
gradient descent iteration = 14
gd loss = 8881.397798852076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8878.013518708905
gradient descent iteration = 15
gd loss = 8878.013518708905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8874.644676913193
gradient descent iteration = 16
gd loss = 8874.644676913193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8871.289164407581
gradient descent iteration = 17
gd loss = 8871.289164407581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8867.945105096445
gradient descent iteration = 18
gd loss = 8867.945105096445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8864.610810990669
gradient descent iteration = 19
gd loss = 8864.610810990669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8861.284747634687
gradient descent iteration = 20
gd loss = 8861.284747634687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8857.965507070201
gradient descent iteration = 21
gd loss = 8857.965507070201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8854.651785766904
gradient descent iteration = 22
gd loss = 8854.651785766904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8851.342366808616
gradient descent iteration = 23
gd loss = 8851.342366808616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8848.036105894975
gradient descent iteration = 24
gd loss = 8848.036105894975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8844.731920485714
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8844.731920485714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8840.483586983459
gradient descent iteration = 1
gd loss = 8840.483586983459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8836.526030600187
gradient descent iteration = 2
gd loss = 8836.526030600187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8832.751592206416
gradient descent iteration = 3
gd loss = 8832.751592206416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8829.109591628405
gradient descent iteration = 4
gd loss = 8829.109591628405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8825.570851631966
gradient descent iteration = 5
gd loss = 8825.570851631966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8822.115907149513
gradient descent iteration = 6
gd loss = 8822.115907149513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8818.730610585633
gradient descent iteration = 7
gd loss = 8818.730610585633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8815.404215923265
gradient descent iteration = 8
gd loss = 8815.404215923265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8812.128350094015
gradient descent iteration = 9
gd loss = 8812.128350094015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8808.896370986418
gradient descent iteration = 10
gd loss = 8808.896370986418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8805.702948065393
gradient descent iteration = 11
gd loss = 8805.702948065393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8802.543765180322
gradient descent iteration = 12
gd loss = 8802.543765180322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8799.415311168739
gradient descent iteration = 13
gd loss = 8799.415311168739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8796.31471096032
gradient descent iteration = 14
gd loss = 8796.31471096032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8793.239574719979
gradient descent iteration = 15
gd loss = 8793.239574719979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8790.187871855125
gradient descent iteration = 16
gd loss = 8790.187871855125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8787.157886732997
gradient descent iteration = 17
gd loss = 8787.157886732997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8784.148161501796
gradient descent iteration = 18
gd loss = 8784.148161501796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8781.157445762443
gradient descent iteration = 19
gd loss = 8781.157445762443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8778.18465883166
gradient descent iteration = 20
gd loss = 8778.18465883166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8775.228857257132
gradient descent iteration = 21
gd loss = 8775.228857257132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8772.289204363015
gradient descent iteration = 22
gd loss = 8772.289204363015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8769.364938350844
gradient descent iteration = 23
gd loss = 8769.364938350844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8766.455363649866
gradient descent iteration = 24
gd loss = 8766.455363649866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8763.55983954751
Initial loss = 9184.161049388791
Final loss = 8763.55983954751
Deformation gradient control sequence optimization finished.
Animation interval 38 took 1376 seconds.
Full animation took 54064 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 39************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9171.115054594971
initial norm = 1054.95255807018
convergence norm = 1.05495255807018
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9171.115054594971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9093.130304334692
gradient descent iteration = 1
gd loss = 9093.130304334692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9063.315556605396
gradient descent iteration = 2
gd loss = 9063.315556605396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9050.606287936107
gradient descent iteration = 3
gd loss = 9050.606287936107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9044.310553539915
gradient descent iteration = 4
gd loss = 9044.310553539915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9038.163791425401
gradient descent iteration = 5
gd loss = 9038.163791425401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9032.272131387115
gradient descent iteration = 6
gd loss = 9032.272131387115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9026.585438729977
gradient descent iteration = 7
gd loss = 9026.585438729977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9021.106723492969
gradient descent iteration = 8
gd loss = 9021.106723492969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9015.6701850559
gradient descent iteration = 9
gd loss = 9015.6701850559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9010.410679819634
gradient descent iteration = 10
gd loss = 9010.410679819634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9005.117129119346
gradient descent iteration = 11
gd loss = 9005.117129119346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8999.982706350056
gradient descent iteration = 12
gd loss = 8999.982706350056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8994.774668418937
gradient descent iteration = 13
gd loss = 8994.774668418937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8989.714175877079
gradient descent iteration = 14
gd loss = 8989.714175877079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8984.557539079209
gradient descent iteration = 15
gd loss = 8984.557539079209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8979.540136746582
gradient descent iteration = 16
gd loss = 8979.540136746582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8974.412716786292
gradient descent iteration = 17
gd loss = 8974.412716786292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8969.418191904597
gradient descent iteration = 18
gd loss = 8969.418191904597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8964.304571254521
gradient descent iteration = 19
gd loss = 8964.304571254521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8959.318730560579
gradient descent iteration = 20
gd loss = 8959.318730560579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8954.207394866144
gradient descent iteration = 21
gd loss = 8954.207394866144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8949.219452828376
gradient descent iteration = 22
gd loss = 8949.219452828376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8944.101241450369
gradient descent iteration = 23
gd loss = 8944.101241450369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8939.102613538611
gradient descent iteration = 24
gd loss = 8939.102613538611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8933.970110196768
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8933.970110196768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8923.676224069808
gradient descent iteration = 1
gd loss = 8923.676224069808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8919.165991768286
gradient descent iteration = 2
gd loss = 8919.165991768286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8915.235689701978
gradient descent iteration = 3
gd loss = 8915.235689701978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8911.477808025196
gradient descent iteration = 4
gd loss = 8911.477808025196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8907.819764255037
gradient descent iteration = 5
gd loss = 8907.819764255037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8904.229946083611
gradient descent iteration = 6
gd loss = 8904.229946083611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8900.688912376725
gradient descent iteration = 7
gd loss = 8900.688912376725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8897.183351980037
gradient descent iteration = 8
gd loss = 8897.183351980037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8893.703620017399
gradient descent iteration = 9
gd loss = 8893.703620017399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8890.242424406615
gradient descent iteration = 10
gd loss = 8890.242424406615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8886.794075788821
gradient descent iteration = 11
gd loss = 8886.794075788821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8883.353993525878
gradient descent iteration = 12
gd loss = 8883.353993525878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8879.918379861627
gradient descent iteration = 13
gd loss = 8879.918379861627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8876.484008728685
gradient descent iteration = 14
gd loss = 8876.484008728685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8873.048077847978
gradient descent iteration = 15
gd loss = 8873.048077847978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8869.608103364766
gradient descent iteration = 16
gd loss = 8869.608103364766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8866.161842408508
gradient descent iteration = 17
gd loss = 8866.161842408508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8862.707233875515
gradient descent iteration = 18
gd loss = 8862.707233875515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8859.24235218252
gradient descent iteration = 19
gd loss = 8859.24235218252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8855.76537068471
gradient descent iteration = 20
gd loss = 8855.76537068471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8852.274533230568
gradient descent iteration = 21
gd loss = 8852.274533230568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8848.768142060137
gradient descent iteration = 22
gd loss = 8848.768142060137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8845.244527474799
gradient descent iteration = 23
gd loss = 8845.244527474799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8841.702018101629
gradient descent iteration = 24
gd loss = 8841.702018101629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8838.138923123639
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8838.138923123639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8833.944713000768
gradient descent iteration = 1
gd loss = 8833.944713000768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8830.044134348082
gradient descent iteration = 2
gd loss = 8830.044134348082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8826.318030262348
gradient descent iteration = 3
gd loss = 8826.318030262348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8822.716443943307
gradient descent iteration = 4
gd loss = 8822.716443943307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8819.213164662691
gradient descent iteration = 5
gd loss = 8819.213164662691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8815.791464890446
gradient descent iteration = 6
gd loss = 8815.791464890446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8812.439268039401
gradient descent iteration = 7
gd loss = 8812.439268039401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8809.147272925346
gradient descent iteration = 8
gd loss = 8809.147272925346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8805.908077301676
gradient descent iteration = 9
gd loss = 8805.908077301676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8802.71571016079
gradient descent iteration = 10
gd loss = 8802.71571016079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8799.565285740229
gradient descent iteration = 11
gd loss = 8799.565285740229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8796.452736881474
gradient descent iteration = 12
gd loss = 8796.452736881474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8793.374638392921
gradient descent iteration = 13
gd loss = 8793.374638392921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8790.3280721711
gradient descent iteration = 14
gd loss = 8790.3280721711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8787.310523032929
gradient descent iteration = 15
gd loss = 8787.310523032929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8784.319798341221
gradient descent iteration = 16
gd loss = 8784.319798341221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8781.353966263376
gradient descent iteration = 17
gd loss = 8781.353966263376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8778.411308224642
gradient descent iteration = 18
gd loss = 8778.411308224642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8775.490281792963
gradient descent iteration = 19
gd loss = 8775.490281792963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8772.589517845632
gradient descent iteration = 20
gd loss = 8772.589517845632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8769.707707280035
gradient descent iteration = 21
gd loss = 8769.707707280035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8766.843593623988
gradient descent iteration = 22
gd loss = 8766.843593623988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8763.995987047327
gradient descent iteration = 23
gd loss = 8763.995987047327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8761.163753080556
gradient descent iteration = 24
gd loss = 8761.163753080556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8758.345826149161
Initial loss = 9171.115054594971
Final loss = 8758.345826149161
Deformation gradient control sequence optimization finished.
Animation interval 39 took 1363 seconds.
Full animation took 55427 seconds so far.

X:\Projects\MPMAnimator3D\build\x64\Release\DiffMPMAnimator3D.exe (process 34756) exited with code 0.
To automatically close the console when debugging stops, enable Tools->Options->Debugging->Automatically close the console when debugging stops.
Press any key to close this window . . .