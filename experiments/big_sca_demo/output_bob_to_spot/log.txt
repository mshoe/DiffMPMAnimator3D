[polyscope] Backend: openGL3_glfw -- Loaded openGL version: 3.3.0 NVIDIA 522.25
reading experiments\big_sca_demo\input\bob.obj...
Warning: readOBJ() ignored non-comment line 3:
  o bob
experiments\big_sca_demo\input\bob.obj's max point is: 8.04758 10.3735 5.07375
experiments\big_sca_demo\input\bob.obj's min point is: -8.04758 -10.0423 -5.62409
generating point cloud...
generating mpm points...
generating mpm grid...
generated grid of size: 5120 KB
registering point cloud...
reading experiments\big_sca_demo\input\spot.obj...
Warning: readOBJ() ignored non-comment line 3:
  o spot
experiments\big_sca_demo\input\spot.obj's max point is: 5.18707  10.439 9.39011
experiments\big_sca_demo\input\spot.obj's min point is: -5.18707   -8.458 -9.20463
generating point cloud...
generating mpm points...
registering point cloud...
**********OPTIMIZING ANIMATION INTERVAL: 0************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 569913.3347532183
initial norm = 21639.5040694191
convergence norm = 21.6395040694191
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 569913.3347532183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 567750.073228112
gradient descent iteration = 1
gd loss = 567750.073228112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 565588.246245851
gradient descent iteration = 2
gd loss = 565588.246245851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 563427.9420114589
gradient descent iteration = 3
gd loss = 563427.9420114589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 561269.2448860569
gradient descent iteration = 4
gd loss = 561269.2448860569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 559112.2465012302
gradient descent iteration = 5
gd loss = 559112.2465012302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 556957.0625891975
gradient descent iteration = 6
gd loss = 556957.0625891975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 554803.8181755861
gradient descent iteration = 7
gd loss = 554803.8181755861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 552652.6382643782
gradient descent iteration = 8
gd loss = 552652.6382643782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 550503.6453220205
gradient descent iteration = 9
gd loss = 550503.6453220205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 548356.9588430331
gradient descent iteration = 10
gd loss = 548356.9588430331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 546212.6950784487
gradient descent iteration = 11
gd loss = 546212.6950784487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 544070.9668141595
gradient descent iteration = 12
gd loss = 544070.9668141595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 541931.8832858831
gradient descent iteration = 13
gd loss = 541931.8832858831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 539795.550262631
gradient descent iteration = 14
gd loss = 539795.550262631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 537662.0700687401
gradient descent iteration = 15
gd loss = 537662.0700687401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 535531.5414872286
gradient descent iteration = 16
gd loss = 535531.5414872286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 533404.0597000073
gradient descent iteration = 17
gd loss = 533404.0597000073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 531279.7161346535
gradient descent iteration = 18
gd loss = 531279.7161346535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 529158.5984665614
gradient descent iteration = 19
gd loss = 529158.5984665614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 527040.7904939264
gradient descent iteration = 20
gd loss = 527040.7904939264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 524926.372235809
gradient descent iteration = 21
gd loss = 524926.372235809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 522815.4199054288
gradient descent iteration = 22
gd loss = 522815.4199054288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 520708.0058669306
gradient descent iteration = 23
gd loss = 520708.0058669306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 518604.198799232
gradient descent iteration = 24
gd loss = 518604.198799232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 516504.0636719297
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 516504.0636719297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 515471.0204320733
gradient descent iteration = 1
gd loss = 515471.0204320733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 514438.9843984409
gradient descent iteration = 2
gd loss = 514438.9843984409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 513407.963111398
gradient descent iteration = 3
gd loss = 513407.963111398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 512377.9640924345
gradient descent iteration = 4
gd loss = 512377.9640924345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 511348.9948147143
gradient descent iteration = 5
gd loss = 511348.9948147143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 510321.0626979619
gradient descent iteration = 6
gd loss = 510321.0626979619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 509294.1751026978
gradient descent iteration = 7
gd loss = 509294.1751026978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 508268.3393229491
gradient descent iteration = 8
gd loss = 508268.3393229491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 507243.5625890656
gradient descent iteration = 9
gd loss = 507243.5625890656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 506219.8520856239
gradient descent iteration = 10
gd loss = 506219.8520856239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 505197.2149461924
gradient descent iteration = 11
gd loss = 505197.2149461924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 504175.6582392728
gradient descent iteration = 12
gd loss = 504175.6582392728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 503155.1889652784
gradient descent iteration = 13
gd loss = 503155.1889652784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 502135.8140557648
gradient descent iteration = 14
gd loss = 502135.8140557648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 501117.5403706502
gradient descent iteration = 15
gd loss = 501117.5403706502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 500100.3746973905
gradient descent iteration = 16
gd loss = 500100.3746973905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 499084.3237600746
gradient descent iteration = 17
gd loss = 499084.3237600746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 498069.3942369564
gradient descent iteration = 18
gd loss = 498069.3942369564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 497055.5927342176
gradient descent iteration = 19
gd loss = 497055.5927342176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 496042.9258215373
gradient descent iteration = 20
gd loss = 496042.9258215373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 495031.4002565565
gradient descent iteration = 21
gd loss = 495031.4002565565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 494021.0229514411
gradient descent iteration = 22
gd loss = 494021.0229514411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 493011.8008390808
gradient descent iteration = 23
gd loss = 493011.8008390808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 492003.7409539283
gradient descent iteration = 24
gd loss = 492003.7409539283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 490996.8505158502
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 490996.8505158502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 490140.2061081658
gradient descent iteration = 1
gd loss = 490140.2061081658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 489285.1190043107
gradient descent iteration = 2
gd loss = 489285.1190043107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 488431.5962748519
gradient descent iteration = 3
gd loss = 488431.5962748519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 487579.6449118106
gradient descent iteration = 4
gd loss = 487579.6449118106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 486729.2718255247
gradient descent iteration = 5
gd loss = 486729.2718255247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 485880.483843713
gradient descent iteration = 6
gd loss = 485880.483843713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 485033.2877093744
gradient descent iteration = 7
gd loss = 485033.2877093744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 484187.6900779883
gradient descent iteration = 8
gd loss = 484187.6900779883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 483343.6975185711
gradient descent iteration = 9
gd loss = 483343.6975185711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 482501.31651338
gradient descent iteration = 10
gd loss = 482501.31651338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 481660.5534574246
gradient descent iteration = 11
gd loss = 481660.5534574246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 480821.4146560273
gradient descent iteration = 12
gd loss = 480821.4146560273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 479983.9063254754
gradient descent iteration = 13
gd loss = 479983.9063254754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 479148.0345918817
gradient descent iteration = 14
gd loss = 479148.0345918817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 478313.805491226
gradient descent iteration = 15
gd loss = 478313.805491226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 477481.2249689864
gradient descent iteration = 16
gd loss = 477481.2249689864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 476650.2988807301
gradient descent iteration = 17
gd loss = 476650.2988807301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 475821.0329913148
gradient descent iteration = 18
gd loss = 475821.0329913148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 474993.4329761242
gradient descent iteration = 19
gd loss = 474993.4329761242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 474167.5044216451
gradient descent iteration = 20
gd loss = 474167.5044216451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 473343.2528268956
gradient descent iteration = 21
gd loss = 473343.2528268956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 472520.6836052635
gradient descent iteration = 22
gd loss = 472520.6836052635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 471699.8020823249
gradient descent iteration = 23
gd loss = 471699.8020823249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 470880.6134946284
gradient descent iteration = 24
gd loss = 470880.6134946284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 470063.1229973822
Initial loss = 569913.3347532183
Final loss = 470063.1229973822
Deformation gradient control sequence optimization finished.
Animation interval 0 took 1351 seconds.
Full animation took 1351 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 1************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 517208.2729571486
initial norm = 20942.20460412719
convergence norm = 20.94220460412719
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 517208.2729571486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 515114.9491593007
gradient descent iteration = 1
gd loss = 515114.9491593007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 513025.8223271103
gradient descent iteration = 2
gd loss = 513025.8223271103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 510940.9678918469
gradient descent iteration = 3
gd loss = 510940.9678918469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 508860.4579691804
gradient descent iteration = 4
gd loss = 508860.4579691804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 506784.362398551
gradient descent iteration = 5
gd loss = 506784.362398551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 504712.7481064746
gradient descent iteration = 6
gd loss = 504712.7481064746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 502645.6786599233
gradient descent iteration = 7
gd loss = 502645.6786599233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 500583.2151425754
gradient descent iteration = 8
gd loss = 500583.2151425754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 498525.4166135929
gradient descent iteration = 9
gd loss = 498525.4166135929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 496472.3388215033
gradient descent iteration = 10
gd loss = 496472.3388215033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 494424.0350440874
gradient descent iteration = 11
gd loss = 494424.0350440874
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 492380.5568014604
gradient descent iteration = 12
gd loss = 492380.5568014604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 490341.95271612
gradient descent iteration = 13
gd loss = 490341.95271612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 488308.2684462148
gradient descent iteration = 14
gd loss = 488308.2684462148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 486279.5468335213
gradient descent iteration = 15
gd loss = 486279.5468335213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 484255.8278433108
gradient descent iteration = 16
gd loss = 484255.8278433108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 482237.1508194536
gradient descent iteration = 17
gd loss = 482237.1508194536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 480223.5563717156
gradient descent iteration = 18
gd loss = 480223.5563717156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 478215.0859670276
gradient descent iteration = 19
gd loss = 478215.0859670276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 476211.7807567735
gradient descent iteration = 20
gd loss = 476211.7807567735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 474213.6799799795
gradient descent iteration = 21
gd loss = 474213.6799799795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 472220.8201906066
gradient descent iteration = 22
gd loss = 472220.8201906066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 470233.2360070309
gradient descent iteration = 23
gd loss = 470233.2360070309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 468250.9625367062
gradient descent iteration = 24
gd loss = 468250.9625367062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 466274.0389485993
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 466274.0389485993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 465197.3211578102
gradient descent iteration = 1
gd loss = 465197.3211578102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 464122.0386435945
gradient descent iteration = 2
gd loss = 464122.0386435945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 463048.2159248725
gradient descent iteration = 3
gd loss = 463048.2159248725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 461975.8775940138
gradient descent iteration = 4
gd loss = 461975.8775940138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 460905.0482454013
gradient descent iteration = 5
gd loss = 460905.0482454013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 459835.7523425472
gradient descent iteration = 6
gd loss = 459835.7523425472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 458768.0142055551
gradient descent iteration = 7
gd loss = 458768.0142055551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 457701.8581904236
gradient descent iteration = 8
gd loss = 457701.8581904236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 456637.3086175018
gradient descent iteration = 9
gd loss = 456637.3086175018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 455574.3897521174
gradient descent iteration = 10
gd loss = 455574.3897521174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 454513.1258806215
gradient descent iteration = 11
gd loss = 454513.1258806215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 453453.5413167764
gradient descent iteration = 12
gd loss = 453453.5413167764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 452395.6604139639
gradient descent iteration = 13
gd loss = 452395.6604139639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 451339.5076341723
gradient descent iteration = 14
gd loss = 451339.5076341723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 450285.1075685238
gradient descent iteration = 15
gd loss = 450285.1075685238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 449232.4848262982
gradient descent iteration = 16
gd loss = 449232.4848262982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 448181.6639279017
gradient descent iteration = 17
gd loss = 448181.6639279017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 447132.6692989831
gradient descent iteration = 18
gd loss = 447132.6692989831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 446085.5252907848
gradient descent iteration = 19
gd loss = 446085.5252907848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 445040.2561943238
gradient descent iteration = 20
gd loss = 445040.2561943238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 443996.8861374459
gradient descent iteration = 21
gd loss = 443996.8861374459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 442955.4390205195
gradient descent iteration = 22
gd loss = 442955.4390205195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 441915.9384160563
gradient descent iteration = 23
gd loss = 441915.9384160563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 440878.4076275431
gradient descent iteration = 24
gd loss = 440878.4076275431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 439842.8696444047
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 439842.8696444047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 439040.7715042456
gradient descent iteration = 1
gd loss = 439040.7715042456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 438240.7035918171
gradient descent iteration = 2
gd loss = 438240.7035918171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 437442.6661731663
gradient descent iteration = 3
gd loss = 437442.6661731663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 436646.6594134226
gradient descent iteration = 4
gd loss = 436646.6594134226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 435852.6833752233
gradient descent iteration = 5
gd loss = 435852.6833752233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 435060.7380184617
gradient descent iteration = 6
gd loss = 435060.7380184617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 434270.8232054883
gradient descent iteration = 7
gd loss = 434270.8232054883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 433482.9387085023
gradient descent iteration = 8
gd loss = 433482.9387085023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 432697.0842116436
gradient descent iteration = 9
gd loss = 432697.0842116436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 431913.2593059861
gradient descent iteration = 10
gd loss = 431913.2593059861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 431131.4634870799
gradient descent iteration = 11
gd loss = 431131.4634870799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 430351.6961567097
gradient descent iteration = 12
gd loss = 430351.6961567097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 429573.956628418
gradient descent iteration = 13
gd loss = 429573.956628418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 428798.2441265194
gradient descent iteration = 14
gd loss = 428798.2441265194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 428024.5577837647
gradient descent iteration = 15
gd loss = 428024.5577837647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 427252.8966415775
gradient descent iteration = 16
gd loss = 427252.8966415775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 426483.2596500416
gradient descent iteration = 17
gd loss = 426483.2596500416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 425715.6456701132
gradient descent iteration = 18
gd loss = 425715.6456701132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 424950.053478157
gradient descent iteration = 19
gd loss = 424950.053478157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 424186.4817661241
gradient descent iteration = 20
gd loss = 424186.4817661241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 423424.9291416974
gradient descent iteration = 21
gd loss = 423424.9291416974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 422665.3941286254
gradient descent iteration = 22
gd loss = 422665.3941286254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 421907.8751702001
gradient descent iteration = 23
gd loss = 421907.8751702001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 421152.3706307036
gradient descent iteration = 24
gd loss = 421152.3706307036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 420398.8788000745
Initial loss = 517208.2729571486
Final loss = 420398.8788000745
Deformation gradient control sequence optimization finished.
Animation interval 1 took 1347 seconds.
Full animation took 2698 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 2************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 445012.406257681
initial norm = 20085.57547728498
convergence norm = 20.08557547728498
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 445012.406257681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 443007.2379878518
gradient descent iteration = 1
gd loss = 443007.2379878518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 441009.0845274089
gradient descent iteration = 2
gd loss = 441009.0845274089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 439017.9867281058
gradient descent iteration = 3
gd loss = 439017.9867281058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 437033.985907318
gradient descent iteration = 4
gd loss = 437033.985907318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 435057.1233792216
gradient descent iteration = 5
gd loss = 435057.1233792216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 433087.4400027603
gradient descent iteration = 6
gd loss = 433087.4400027603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 431124.9748252638
gradient descent iteration = 7
gd loss = 431124.9748252638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 429169.7636158409
gradient descent iteration = 8
gd loss = 429169.7636158409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 427221.8386774692
gradient descent iteration = 9
gd loss = 427221.8386774692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 425281.2282981179
gradient descent iteration = 10
gd loss = 425281.2282981179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 423347.9566808489
gradient descent iteration = 11
gd loss = 423347.9566808489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 421422.0443883787
gradient descent iteration = 12
gd loss = 421422.0443883787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 419503.5086574795
gradient descent iteration = 13
gd loss = 419503.5086574795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 417592.3632115519
gradient descent iteration = 14
gd loss = 417592.3632115519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 415688.6172282983
gradient descent iteration = 15
gd loss = 415688.6172282983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 413792.2741616662
gradient descent iteration = 16
gd loss = 413792.2741616662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 411903.3313049453
gradient descent iteration = 17
gd loss = 411903.3313049453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 410021.7795727302
gradient descent iteration = 18
gd loss = 410021.7795727302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 408147.6030574603
gradient descent iteration = 19
gd loss = 408147.6030574603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 406280.779956087
gradient descent iteration = 20
gd loss = 406280.779956087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 404421.2841660873
gradient descent iteration = 21
gd loss = 404421.2841660873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 402569.0865001352
gradient descent iteration = 22
gd loss = 402569.0865001352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 400724.154441438
gradient descent iteration = 23
gd loss = 400724.154441438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 398886.4506222135
gradient descent iteration = 24
gd loss = 398886.4506222135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 397055.9321590618
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 397055.9321590618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 396018.6717991582
gradient descent iteration = 1
gd loss = 396018.6717991582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 394984.3595100922
gradient descent iteration = 2
gd loss = 394984.3595100922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 393953.0018834534
gradient descent iteration = 3
gd loss = 393953.0018834534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 392924.6049496658
gradient descent iteration = 4
gd loss = 392924.6049496658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 391899.1744923529
gradient descent iteration = 5
gd loss = 391899.1744923529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 390876.7161960399
gradient descent iteration = 6
gd loss = 390876.7161960399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 389857.2351862221
gradient descent iteration = 7
gd loss = 389857.2351862221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 388840.7359915664
gradient descent iteration = 8
gd loss = 388840.7359915664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 387827.2229297806
gradient descent iteration = 9
gd loss = 387827.2229297806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 386816.699687238
gradient descent iteration = 10
gd loss = 386816.699687238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 385809.1693759174
gradient descent iteration = 11
gd loss = 385809.1693759174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 384804.6349544578
gradient descent iteration = 12
gd loss = 384804.6349544578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 383803.0993847516
gradient descent iteration = 13
gd loss = 383803.0993847516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 382804.5657746789
gradient descent iteration = 14
gd loss = 382804.5657746789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 381809.0372168227
gradient descent iteration = 15
gd loss = 381809.0372168227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 380816.5169097706
gradient descent iteration = 16
gd loss = 380816.5169097706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 379827.0084556625
gradient descent iteration = 17
gd loss = 379827.0084556625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 378840.5159328462
gradient descent iteration = 18
gd loss = 378840.5159328462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 377857.0437045183
gradient descent iteration = 19
gd loss = 377857.0437045183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 376876.5961073961
gradient descent iteration = 20
gd loss = 376876.5961073961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 375899.1775995711
gradient descent iteration = 21
gd loss = 375899.1775995711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 374924.7929435496
gradient descent iteration = 22
gd loss = 374924.7929435496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 373953.4474008973
gradient descent iteration = 23
gd loss = 373953.4474008973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 372985.1466599168
gradient descent iteration = 24
gd loss = 372985.1466599168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 372019.8965249066
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 372019.8965249066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 371298.7316356223
gradient descent iteration = 1
gd loss = 371298.7316356223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 370579.9568074445
gradient descent iteration = 2
gd loss = 370579.9568074445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 369863.5666583261
gradient descent iteration = 3
gd loss = 369863.5666583261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 369149.5557754246
gradient descent iteration = 4
gd loss = 369149.5557754246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 368437.9187217404
gradient descent iteration = 5
gd loss = 368437.9187217404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 367728.6500259042
gradient descent iteration = 6
gd loss = 367728.6500259042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 367021.7441801825
gradient descent iteration = 7
gd loss = 367021.7441801825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 366317.1956451657
gradient descent iteration = 8
gd loss = 366317.1956451657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 365614.9988680845
gradient descent iteration = 9
gd loss = 365614.9988680845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 364915.1482640806
gradient descent iteration = 10
gd loss = 364915.1482640806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 364217.6382066973
gradient descent iteration = 11
gd loss = 364217.6382066973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 363522.4630232195
gradient descent iteration = 12
gd loss = 363522.4630232195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 362829.6170011627
gradient descent iteration = 13
gd loss = 362829.6170011627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 362139.0943882997
gradient descent iteration = 14
gd loss = 362139.0943882997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 361450.8893991143
gradient descent iteration = 15
gd loss = 361450.8893991143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360764.9962176767
gradient descent iteration = 16
gd loss = 360764.9962176767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360081.408984636
gradient descent iteration = 17
gd loss = 360081.408984636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 359400.1217861647
gradient descent iteration = 18
gd loss = 359400.1217861647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358721.1286646621
gradient descent iteration = 19
gd loss = 358721.1286646621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358044.4236264055
gradient descent iteration = 20
gd loss = 358044.4236264055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357370.0006379836
gradient descent iteration = 21
gd loss = 357370.0006379836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356697.8536129984
gradient descent iteration = 22
gd loss = 356697.8536129984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356027.976417146
gradient descent iteration = 23
gd loss = 356027.976417146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355360.3628738112
gradient descent iteration = 24
gd loss = 355360.3628738112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 354695.0067647026
Initial loss = 445012.406257681
Final loss = 354695.0067647026
Deformation gradient control sequence optimization finished.
Animation interval 2 took 1352 seconds.
Full animation took 4050 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 3************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 390257.0236604467
initial norm = 18208.47867680036
convergence norm = 18.20847867680036
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 390257.0236604467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 388439.2662239012
gradient descent iteration = 1
gd loss = 388439.2662239012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 386628.6749483099
gradient descent iteration = 2
gd loss = 386628.6749483099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 384825.2127797975
gradient descent iteration = 3
gd loss = 384825.2127797975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 383028.8393090931
gradient descent iteration = 4
gd loss = 383028.8393090931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 381239.5117330857
gradient descent iteration = 5
gd loss = 381239.5117330857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 379457.1870418426
gradient descent iteration = 6
gd loss = 379457.1870418426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 377681.8237655566
gradient descent iteration = 7
gd loss = 377681.8237655566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 375913.3828125029
gradient descent iteration = 8
gd loss = 375913.3828125029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 374151.8264287841
gradient descent iteration = 9
gd loss = 374151.8264287841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 372397.1179107784
gradient descent iteration = 10
gd loss = 372397.1179107784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 370649.2218852105
gradient descent iteration = 11
gd loss = 370649.2218852105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 368908.1055977021
gradient descent iteration = 12
gd loss = 368908.1055977021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 367173.7397472037
gradient descent iteration = 13
gd loss = 367173.7397472037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 365446.1002768068
gradient descent iteration = 14
gd loss = 365446.1002768068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 363725.1694096909
gradient descent iteration = 15
gd loss = 363725.1694096909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 362010.9351370019
gradient descent iteration = 16
gd loss = 362010.9351370019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360303.3899583412
gradient descent iteration = 17
gd loss = 360303.3899583412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358602.530673428
gradient descent iteration = 18
gd loss = 358602.530673428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356908.3594798585
gradient descent iteration = 19
gd loss = 356908.3594798585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355220.8851598731
gradient descent iteration = 20
gd loss = 355220.8851598731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353540.123685764
gradient descent iteration = 21
gd loss = 353540.123685764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 351866.0995273785
gradient descent iteration = 22
gd loss = 351866.0995273785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 350198.8452977936
gradient descent iteration = 23
gd loss = 350198.8452977936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 348538.4018576411
gradient descent iteration = 24
gd loss = 348538.4018576411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 346884.8179137263
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 346884.8179137263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 345801.4177524456
gradient descent iteration = 1
gd loss = 345801.4177524456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 344722.4328275706
gradient descent iteration = 2
gd loss = 344722.4328275706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 343647.8920574164
gradient descent iteration = 3
gd loss = 343647.8920574164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 342577.8243491839
gradient descent iteration = 4
gd loss = 342577.8243491839
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 341512.2582863884
gradient descent iteration = 5
gd loss = 341512.2582863884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 340451.2230121547
gradient descent iteration = 6
gd loss = 340451.2230121547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 339394.7481555421
gradient descent iteration = 7
gd loss = 339394.7481555421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 338342.8629120123
gradient descent iteration = 8
gd loss = 338342.8629120123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 337295.5964448015
gradient descent iteration = 9
gd loss = 337295.5964448015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 336252.9782709475
gradient descent iteration = 10
gd loss = 336252.9782709475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 335215.0382779582
gradient descent iteration = 11
gd loss = 335215.0382779582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 334181.8063239903
gradient descent iteration = 12
gd loss = 334181.8063239903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 333153.312470736
gradient descent iteration = 13
gd loss = 333153.312470736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 332129.5871666438
gradient descent iteration = 14
gd loss = 332129.5871666438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 331110.6602907936
gradient descent iteration = 15
gd loss = 331110.6602907936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 330096.5599118826
gradient descent iteration = 16
gd loss = 330096.5599118826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 329087.3118900661
gradient descent iteration = 17
gd loss = 329087.3118900661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 328082.9403749614
gradient descent iteration = 18
gd loss = 328082.9403749614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 327083.4683847118
gradient descent iteration = 19
gd loss = 327083.4683847118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 326088.9175060368
gradient descent iteration = 20
gd loss = 326088.9175060368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 325099.3078575736
gradient descent iteration = 21
gd loss = 325099.3078575736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324114.6585162635
gradient descent iteration = 22
gd loss = 324114.6585162635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 323134.9873939279
gradient descent iteration = 23
gd loss = 323134.9873939279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322160.3111257566
gradient descent iteration = 24
gd loss = 322160.3111257566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 321190.6450546544
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 321190.6450546544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320505.9968024208
gradient descent iteration = 1
gd loss = 320505.9968024208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319824.2259215746
gradient descent iteration = 2
gd loss = 319824.2259215746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319145.3209422379
gradient descent iteration = 3
gd loss = 319145.3209422379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 318469.2703799808
gradient descent iteration = 4
gd loss = 318469.2703799808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317796.0627269009
gradient descent iteration = 5
gd loss = 317796.0627269009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317125.6864509668
gradient descent iteration = 6
gd loss = 317125.6864509668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 316458.1299957596
gradient descent iteration = 7
gd loss = 316458.1299957596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315793.3817812362
gradient descent iteration = 8
gd loss = 315793.3817812362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315131.4302058723
gradient descent iteration = 9
gd loss = 315131.4302058723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 314472.2636481113
gradient descent iteration = 10
gd loss = 314472.2636481113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313815.8704670456
gradient descent iteration = 11
gd loss = 313815.8704670456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313162.2390094683
gradient descent iteration = 12
gd loss = 313162.2390094683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 312511.3576102612
gradient descent iteration = 13
gd loss = 312511.3576102612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311863.2145906024
gradient descent iteration = 14
gd loss = 311863.2145906024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311217.7982582519
gradient descent iteration = 15
gd loss = 311217.7982582519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 310575.0969092743
gradient descent iteration = 16
gd loss = 310575.0969092743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309935.0988337447
gradient descent iteration = 17
gd loss = 309935.0988337447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309297.7923176453
gradient descent iteration = 18
gd loss = 309297.7923176453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308663.1656460575
gradient descent iteration = 19
gd loss = 308663.1656460575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308031.207101483
gradient descent iteration = 20
gd loss = 308031.207101483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 307401.9049694688
gradient descent iteration = 21
gd loss = 307401.9049694688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306775.2475308015
gradient descent iteration = 22
gd loss = 306775.2475308015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306151.2230641993
gradient descent iteration = 23
gd loss = 306151.2230641993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305529.819847923
gradient descent iteration = 24
gd loss = 305529.819847923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304911.0261643885
Initial loss = 390257.0236604467
Final loss = 304911.0261643885
Deformation gradient control sequence optimization finished.
Animation interval 3 took 1357 seconds.
Full animation took 5408 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 4************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 325861.1710491805
initial norm = 16495.59817057045
convergence norm = 16.49559817057045
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 325861.1710491805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324215.6854385838
gradient descent iteration = 1
gd loss = 324215.6854385838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322578.5077159309
gradient descent iteration = 2
gd loss = 322578.5077159309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320949.792803479
gradient descent iteration = 3
gd loss = 320949.792803479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319329.6991857587
gradient descent iteration = 4
gd loss = 319329.6991857587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317718.3890857013
gradient descent iteration = 5
gd loss = 317718.3890857013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 316116.0267746181
gradient descent iteration = 6
gd loss = 316116.0267746181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 314522.7769411319
gradient descent iteration = 7
gd loss = 314522.7769411319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 312938.8039705948
gradient descent iteration = 8
gd loss = 312938.8039705948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311364.2705581099
gradient descent iteration = 9
gd loss = 311364.2705581099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309799.3367469395
gradient descent iteration = 10
gd loss = 309799.3367469395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308244.1583066948
gradient descent iteration = 11
gd loss = 308244.1583066948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306698.8848765633
gradient descent iteration = 12
gd loss = 306698.8848765633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305163.6585202466
gradient descent iteration = 13
gd loss = 305163.6585202466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303638.6139464506
gradient descent iteration = 14
gd loss = 303638.6139464506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 302123.8782434995
gradient descent iteration = 15
gd loss = 302123.8782434995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300619.570383279
gradient descent iteration = 16
gd loss = 300619.570383279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 299125.8005896107
gradient descent iteration = 17
gd loss = 299125.8005896107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297642.6715238638
gradient descent iteration = 18
gd loss = 297642.6715238638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 296170.2765554372
gradient descent iteration = 19
gd loss = 296170.2765554372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 294708.6984348625
gradient descent iteration = 20
gd loss = 294708.6984348625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 293258.008746909
gradient descent iteration = 21
gd loss = 293258.008746909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 291818.2679826904
gradient descent iteration = 22
gd loss = 291818.2679826904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 290389.5244549671
gradient descent iteration = 23
gd loss = 290389.5244549671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 288971.8139141373
gradient descent iteration = 24
gd loss = 288971.8139141373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 287565.1611274602
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 287565.1611274602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 286506.3584412578
gradient descent iteration = 1
gd loss = 286506.3584412578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 285456.0422445462
gradient descent iteration = 2
gd loss = 285456.0422445462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 284414.249337866
gradient descent iteration = 3
gd loss = 284414.249337866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 283381.0145079897
gradient descent iteration = 4
gd loss = 283381.0145079897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 282356.3689841036
gradient descent iteration = 5
gd loss = 282356.3689841036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281340.3413374996
gradient descent iteration = 6
gd loss = 281340.3413374996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 280332.9569707851
gradient descent iteration = 7
gd loss = 280332.9569707851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279334.2378224488
gradient descent iteration = 8
gd loss = 279334.2378224488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 278344.2021339049
gradient descent iteration = 9
gd loss = 278344.2021339049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277362.8634258352
gradient descent iteration = 10
gd loss = 277362.8634258352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276390.2300928333
gradient descent iteration = 11
gd loss = 276390.2300928333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 275426.3048416494
gradient descent iteration = 12
gd loss = 275426.3048416494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274471.0843246967
gradient descent iteration = 13
gd loss = 274471.0843246967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 273524.5603342311
gradient descent iteration = 14
gd loss = 273524.5603342311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 272586.7198177837
gradient descent iteration = 15
gd loss = 272586.7198177837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 271657.5448715638
gradient descent iteration = 16
gd loss = 271657.5448715638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270737.0129348203
gradient descent iteration = 17
gd loss = 270737.0129348203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269825.095899625
gradient descent iteration = 18
gd loss = 269825.095899625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268921.7593387601
gradient descent iteration = 19
gd loss = 268921.7593387601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268026.9632337729
gradient descent iteration = 20
gd loss = 268026.9632337729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267140.6627537585
gradient descent iteration = 21
gd loss = 267140.6627537585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266262.808434525
gradient descent iteration = 22
gd loss = 266262.808434525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265393.3468439019
gradient descent iteration = 23
gd loss = 265393.3468439019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264532.2200271827
gradient descent iteration = 24
gd loss = 264532.2200271827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263679.3652950753
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 263679.3652950753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263053.9647312348
gradient descent iteration = 1
gd loss = 263053.9647312348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 262432.246558333
gradient descent iteration = 2
gd loss = 262432.246558333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261814.1823616314
gradient descent iteration = 3
gd loss = 261814.1823616314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261199.743874403
gradient descent iteration = 4
gd loss = 261199.743874403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260588.9029730686
gradient descent iteration = 5
gd loss = 260588.9029730686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259981.631678936
gradient descent iteration = 6
gd loss = 259981.631678936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259377.9021519324
gradient descent iteration = 7
gd loss = 259377.9021519324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258777.6866954134
gradient descent iteration = 8
gd loss = 258777.6866954134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258180.9577597675
gradient descent iteration = 9
gd loss = 258180.9577597675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257587.6879564846
gradient descent iteration = 10
gd loss = 257587.6879564846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256997.8500621956
gradient descent iteration = 11
gd loss = 256997.8500621956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256411.4170144545
gradient descent iteration = 12
gd loss = 256411.4170144545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255828.3619062729
gradient descent iteration = 13
gd loss = 255828.3619062729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255248.6579852398
gradient descent iteration = 14
gd loss = 255248.6579852398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 254672.2786518042
gradient descent iteration = 15
gd loss = 254672.2786518042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 254099.1974627158
gradient descent iteration = 16
gd loss = 254099.1974627158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253529.3881265143
gradient descent iteration = 17
gd loss = 253529.3881265143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252962.8245067507
gradient descent iteration = 18
gd loss = 252962.8245067507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252399.480627741
gradient descent iteration = 19
gd loss = 252399.480627741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251839.3306723476
gradient descent iteration = 20
gd loss = 251839.3306723476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251282.3489797915
gradient descent iteration = 21
gd loss = 251282.3489797915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250728.5100510497
gradient descent iteration = 22
gd loss = 250728.5100510497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250177.7885546084
gradient descent iteration = 23
gd loss = 250177.7885546084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249630.1593252809
gradient descent iteration = 24
gd loss = 249630.1593252809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249085.5973641418
Initial loss = 325861.1710491805
Final loss = 249085.5973641418
Deformation gradient control sequence optimization finished.
Animation interval 4 took 1353 seconds.
Full animation took 6761 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 5************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 277378.2185001897
initial norm = 13770.47714285194
convergence norm = 13.77047714285194
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 277378.2185001897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276008.3842611968
gradient descent iteration = 1
gd loss = 276008.3842611968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274652.2975458834
gradient descent iteration = 2
gd loss = 274652.2975458834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 273309.7304384577
gradient descent iteration = 3
gd loss = 273309.7304384577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 271980.4533951046
gradient descent iteration = 4
gd loss = 271980.4533951046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270664.2368820253
gradient descent iteration = 5
gd loss = 270664.2368820253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269360.8514077566
gradient descent iteration = 6
gd loss = 269360.8514077566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268070.0693719272
gradient descent iteration = 7
gd loss = 268070.0693719272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266791.6663303199
gradient descent iteration = 8
gd loss = 266791.6663303199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265525.4214758012
gradient descent iteration = 9
gd loss = 265525.4214758012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264271.1169199912
gradient descent iteration = 10
gd loss = 264271.1169199912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263028.5375299884
gradient descent iteration = 11
gd loss = 263028.5375299884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261797.4729783057
gradient descent iteration = 12
gd loss = 261797.4729783057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260577.7179928188
gradient descent iteration = 13
gd loss = 260577.7179928188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259369.0716169686
gradient descent iteration = 14
gd loss = 259369.0716169686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258171.3375819554
gradient descent iteration = 15
gd loss = 258171.3375819554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256984.3238249746
gradient descent iteration = 16
gd loss = 256984.3238249746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255807.8418530734
gradient descent iteration = 17
gd loss = 255807.8418530734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 254641.7064058757
gradient descent iteration = 18
gd loss = 254641.7064058757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253485.7352908123
gradient descent iteration = 19
gd loss = 253485.7352908123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252339.7502794538
gradient descent iteration = 20
gd loss = 252339.7502794538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251203.577451905
gradient descent iteration = 21
gd loss = 251203.577451905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250077.0469956837
gradient descent iteration = 22
gd loss = 250077.0469956837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248959.9929344703
gradient descent iteration = 23
gd loss = 248959.9929344703
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247852.2532055835
gradient descent iteration = 24
gd loss = 247852.2532055835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246753.6695069259
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 246753.6695069259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 245656.9223352867
gradient descent iteration = 1
gd loss = 245656.9223352867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 244576.4598200393
gradient descent iteration = 2
gd loss = 244576.4598200393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 243511.9440522422
gradient descent iteration = 3
gd loss = 243511.9440522422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242463.0383641765
gradient descent iteration = 4
gd loss = 242463.0383641765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241429.407691877
gradient descent iteration = 5
gd loss = 241429.407691877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240410.7200532005
gradient descent iteration = 6
gd loss = 240410.7200532005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239406.6482465914
gradient descent iteration = 7
gd loss = 239406.6482465914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 238416.8671234215
gradient descent iteration = 8
gd loss = 238416.8671234215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 237441.0540574855
gradient descent iteration = 9
gd loss = 237441.0540574855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 236478.892935386
gradient descent iteration = 10
gd loss = 236478.892935386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 235530.0752640033
gradient descent iteration = 11
gd loss = 235530.0752640033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234594.2986375108
gradient descent iteration = 12
gd loss = 234594.2986375108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233671.2677619665
gradient descent iteration = 13
gd loss = 233671.2677619665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232760.6950143853
gradient descent iteration = 14
gd loss = 232760.6950143853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231862.2994139612
gradient descent iteration = 15
gd loss = 231862.2994139612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230975.8084316788
gradient descent iteration = 16
gd loss = 230975.8084316788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230100.9591861832
gradient descent iteration = 17
gd loss = 230100.9591861832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 229237.4978314427
gradient descent iteration = 18
gd loss = 229237.4978314427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228385.1796942463
gradient descent iteration = 19
gd loss = 228385.1796942463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227543.7659235509
gradient descent iteration = 20
gd loss = 227543.7659235509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226713.0247782464
gradient descent iteration = 21
gd loss = 226713.0247782464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225892.7315232629
gradient descent iteration = 22
gd loss = 225892.7315232629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225082.6688934619
gradient descent iteration = 23
gd loss = 225082.6688934619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224282.6271754408
gradient descent iteration = 24
gd loss = 224282.6271754408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223492.4040935346
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 223492.4040935346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222875.3451196486
gradient descent iteration = 1
gd loss = 222875.3451196486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222263.0503406358
gradient descent iteration = 2
gd loss = 222263.0503406358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221655.4600967496
gradient descent iteration = 3
gd loss = 221655.4600967496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221052.5156393394
gradient descent iteration = 4
gd loss = 221052.5156393394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220454.1591009135
gradient descent iteration = 5
gd loss = 220454.1591009135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219860.3334826396
gradient descent iteration = 6
gd loss = 219860.3334826396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219270.9826300723
gradient descent iteration = 7
gd loss = 219270.9826300723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218686.0512273165
gradient descent iteration = 8
gd loss = 218686.0512273165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218105.4848279729
gradient descent iteration = 9
gd loss = 218105.4848279729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217529.2298400774
gradient descent iteration = 10
gd loss = 217529.2298400774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216957.2335076042
gradient descent iteration = 11
gd loss = 216957.2335076042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216389.4439063956
gradient descent iteration = 12
gd loss = 216389.4439063956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215825.8099095142
gradient descent iteration = 13
gd loss = 215825.8099095142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215266.2811654946
gradient descent iteration = 14
gd loss = 215266.2811654946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214710.8080854047
gradient descent iteration = 15
gd loss = 214710.8080854047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214159.3418724047
gradient descent iteration = 16
gd loss = 214159.3418724047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213611.8344887716
gradient descent iteration = 17
gd loss = 213611.8344887716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213068.2386339114
gradient descent iteration = 18
gd loss = 213068.2386339114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212528.507738149
gradient descent iteration = 19
gd loss = 212528.507738149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211992.5959976504
gradient descent iteration = 20
gd loss = 211992.5959976504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211460.4583273345
gradient descent iteration = 21
gd loss = 211460.4583273345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210932.0503518159
gradient descent iteration = 22
gd loss = 210932.0503518159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210407.3283945069
gradient descent iteration = 23
gd loss = 210407.3283945069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209886.2494480433
gradient descent iteration = 24
gd loss = 209886.2494480433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209368.7711453607
Initial loss = 277378.2185001897
Final loss = 209368.7711453607
Deformation gradient control sequence optimization finished.
Animation interval 5 took 1355 seconds.
Full animation took 8117 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 6************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 229251.079913954
initial norm = 10129.27788475393
convergence norm = 10.12927788475393
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 229251.079913954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228242.7033354715
gradient descent iteration = 1
gd loss = 228242.7033354715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227242.8916244181
gradient descent iteration = 2
gd loss = 227242.8916244181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226251.4933152739
gradient descent iteration = 3
gd loss = 226251.4933152739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225268.3629199829
gradient descent iteration = 4
gd loss = 225268.3629199829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224293.3602599273
gradient descent iteration = 5
gd loss = 224293.3602599273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223326.3502441512
gradient descent iteration = 6
gd loss = 223326.3502441512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222367.2035106467
gradient descent iteration = 7
gd loss = 222367.2035106467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221415.7963000428
gradient descent iteration = 8
gd loss = 221415.7963000428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220472.0094195044
gradient descent iteration = 9
gd loss = 220472.0094195044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219535.7276259329
gradient descent iteration = 10
gd loss = 219535.7276259329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218606.8395837557
gradient descent iteration = 11
gd loss = 218606.8395837557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217685.237562476
gradient descent iteration = 12
gd loss = 217685.237562476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216770.8172290193
gradient descent iteration = 13
gd loss = 216770.8172290193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215863.4780365474
gradient descent iteration = 14
gd loss = 215863.4780365474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214963.1228331997
gradient descent iteration = 15
gd loss = 214963.1228331997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214069.6575725263
gradient descent iteration = 16
gd loss = 214069.6575725263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213182.9910322826
gradient descent iteration = 17
gd loss = 213182.9910322826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212303.0340467483
gradient descent iteration = 18
gd loss = 212303.0340467483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211429.6998247218
gradient descent iteration = 19
gd loss = 211429.6998247218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210562.9039586115
gradient descent iteration = 20
gd loss = 210562.9039586115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209702.5640458054
gradient descent iteration = 21
gd loss = 209702.5640458054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208848.5992639805
gradient descent iteration = 22
gd loss = 208848.5992639805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208000.9306820959
gradient descent iteration = 23
gd loss = 208000.9306820959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207159.4813091612
gradient descent iteration = 24
gd loss = 207159.4813091612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206324.1752939329
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 206324.1752939329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205393.7292486227
gradient descent iteration = 1
gd loss = 205393.7292486227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204478.8111629513
gradient descent iteration = 2
gd loss = 204478.8111629513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203578.9728483189
gradient descent iteration = 3
gd loss = 203578.9728483189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202693.7821908844
gradient descent iteration = 4
gd loss = 202693.7821908844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201822.824339599
gradient descent iteration = 5
gd loss = 201822.824339599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200965.7000413916
gradient descent iteration = 6
gd loss = 200965.7000413916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200122.0215551333
gradient descent iteration = 7
gd loss = 200122.0215551333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199291.4135149913
gradient descent iteration = 8
gd loss = 199291.4135149913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198473.5138807921
gradient descent iteration = 9
gd loss = 198473.5138807921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197667.9731192164
gradient descent iteration = 10
gd loss = 197667.9731192164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196874.4536854568
gradient descent iteration = 11
gd loss = 196874.4536854568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196092.6278096368
gradient descent iteration = 12
gd loss = 196092.6278096368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195322.1765425991
gradient descent iteration = 13
gd loss = 195322.1765425991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194562.7903854479
gradient descent iteration = 14
gd loss = 194562.7903854479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193814.1673848168
gradient descent iteration = 15
gd loss = 193814.1673848168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193076.0140658306
gradient descent iteration = 16
gd loss = 193076.0140658306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192348.0454060648
gradient descent iteration = 17
gd loss = 192348.0454060648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191629.9850852321
gradient descent iteration = 18
gd loss = 191629.9850852321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190921.5641052451
gradient descent iteration = 19
gd loss = 190921.5641052451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190222.5204376643
gradient descent iteration = 20
gd loss = 190222.5204376643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189532.5994791006
gradient descent iteration = 21
gd loss = 189532.5994791006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188851.5532799329
gradient descent iteration = 22
gd loss = 188851.5532799329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188179.1405971268
gradient descent iteration = 23
gd loss = 188179.1405971268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187515.1266396484
gradient descent iteration = 24
gd loss = 187515.1266396484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186859.2827441668
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 186859.2827441668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186239.9529954665
gradient descent iteration = 1
gd loss = 186239.9529954665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185627.6213551858
gradient descent iteration = 2
gd loss = 185627.6213551858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185022.1363745912
gradient descent iteration = 3
gd loss = 185022.1363745912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184423.3510467987
gradient descent iteration = 4
gd loss = 184423.3510467987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183831.122620349
gradient descent iteration = 5
gd loss = 183831.122620349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183245.3124441609
gradient descent iteration = 6
gd loss = 183245.3124441609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182665.7858316456
gradient descent iteration = 7
gd loss = 182665.7858316456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182092.4119028051
gradient descent iteration = 8
gd loss = 182092.4119028051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181525.0634237775
gradient descent iteration = 9
gd loss = 181525.0634237775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180963.6166966116
gradient descent iteration = 10
gd loss = 180963.6166966116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180407.9515027339
gradient descent iteration = 11
gd loss = 180407.9515027339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179857.9509018676
gradient descent iteration = 12
gd loss = 179857.9509018676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179313.5011155884
gradient descent iteration = 13
gd loss = 179313.5011155884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178774.4914378238
gradient descent iteration = 14
gd loss = 178774.4914378238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178240.8141359452
gradient descent iteration = 15
gd loss = 178240.8141359452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177712.3643629232
gradient descent iteration = 16
gd loss = 177712.3643629232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177189.0400965403
gradient descent iteration = 17
gd loss = 177189.0400965403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176670.7420446498
gradient descent iteration = 18
gd loss = 176670.7420446498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176157.373570166
gradient descent iteration = 19
gd loss = 176157.373570166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175648.8406072857
gradient descent iteration = 20
gd loss = 175648.8406072857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175145.0515896693
gradient descent iteration = 21
gd loss = 175145.0515896693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174645.9173822963
gradient descent iteration = 22
gd loss = 174645.9173822963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174151.351184762
gradient descent iteration = 23
gd loss = 174151.351184762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173661.2684658083
gradient descent iteration = 24
gd loss = 173661.2684658083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173175.5868961021
Initial loss = 229251.079913954
Final loss = 173175.5868961021
Deformation gradient control sequence optimization finished.
Animation interval 6 took 1351 seconds.
Full animation took 9468 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 7************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 189880.2077973174
initial norm = 7855.536205981187
convergence norm = 7.855536205981187
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 189880.2077973174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189098.3066926778
gradient descent iteration = 1
gd loss = 189098.3066926778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188323.215319043
gradient descent iteration = 2
gd loss = 188323.215319043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187554.8282201901
gradient descent iteration = 3
gd loss = 187554.8282201901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186793.0414586783
gradient descent iteration = 4
gd loss = 186793.0414586783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186037.7525418632
gradient descent iteration = 5
gd loss = 186037.7525418632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185288.8602582266
gradient descent iteration = 6
gd loss = 185288.8602582266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184546.2646702624
gradient descent iteration = 7
gd loss = 184546.2646702624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183809.8671387668
gradient descent iteration = 8
gd loss = 183809.8671387668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183079.5701332674
gradient descent iteration = 9
gd loss = 183079.5701332674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182355.2772925667
gradient descent iteration = 10
gd loss = 182355.2772925667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181636.8933607871
gradient descent iteration = 11
gd loss = 181636.8933607871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180924.3240522687
gradient descent iteration = 12
gd loss = 180924.3240522687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180217.476105099
gradient descent iteration = 13
gd loss = 180217.476105099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179516.2573886616
gradient descent iteration = 14
gd loss = 179516.2573886616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178820.5768772041
gradient descent iteration = 15
gd loss = 178820.5768772041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178130.3446334744
gradient descent iteration = 16
gd loss = 178130.3446334744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177445.4719636539
gradient descent iteration = 17
gd loss = 177445.4719636539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176765.8713962222
gradient descent iteration = 18
gd loss = 176765.8713962222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176091.456558774
gradient descent iteration = 19
gd loss = 176091.456558774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175422.142268931
gradient descent iteration = 20
gd loss = 175422.142268931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174757.844605673
gradient descent iteration = 21
gd loss = 174757.844605673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174098.4809270835
gradient descent iteration = 22
gd loss = 174098.4809270835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173443.969947384
gradient descent iteration = 23
gd loss = 173443.969947384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172794.231722051
gradient descent iteration = 24
gd loss = 172794.231722051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172149.187609458
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 172149.187609458
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171340.0220739884
gradient descent iteration = 1
gd loss = 171340.0220739884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170544.9843881844
gradient descent iteration = 2
gd loss = 170544.9843881844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169763.5105479308
gradient descent iteration = 3
gd loss = 169763.5105479308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168995.0624276797
gradient descent iteration = 4
gd loss = 168995.0624276797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168239.1273087146
gradient descent iteration = 5
gd loss = 168239.1273087146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167495.2178423339
gradient descent iteration = 6
gd loss = 167495.2178423339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166762.8699367804
gradient descent iteration = 7
gd loss = 166762.8699367804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166041.6425764423
gradient descent iteration = 8
gd loss = 166041.6425764423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165331.1190776974
gradient descent iteration = 9
gd loss = 165331.1190776974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164630.9052798176
gradient descent iteration = 10
gd loss = 164630.9052798176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163940.6285455626
gradient descent iteration = 11
gd loss = 163940.6285455626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163259.936076211
gradient descent iteration = 12
gd loss = 163259.936076211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162588.4976036141
gradient descent iteration = 13
gd loss = 162588.4976036141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161926.0043672943
gradient descent iteration = 14
gd loss = 161926.0043672943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161272.1650972413
gradient descent iteration = 15
gd loss = 161272.1650972413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160626.7081269226
gradient descent iteration = 16
gd loss = 160626.7081269226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159989.3800507951
gradient descent iteration = 17
gd loss = 159989.3800507951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159359.9409797488
gradient descent iteration = 18
gd loss = 159359.9409797488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158738.1609027553
gradient descent iteration = 19
gd loss = 158738.1609027553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158123.8203561853
gradient descent iteration = 20
gd loss = 158123.8203561853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157516.7106165687
gradient descent iteration = 21
gd loss = 157516.7106165687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156916.6326213226
gradient descent iteration = 22
gd loss = 156916.6326213226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156323.3959368361
gradient descent iteration = 23
gd loss = 156323.3959368361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155736.8170852451
gradient descent iteration = 24
gd loss = 155736.8170852451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155156.7186012987
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 155156.7186012987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154557.7466510145
gradient descent iteration = 1
gd loss = 154557.7466510145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153968.0174982508
gradient descent iteration = 2
gd loss = 153968.0174982508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153387.2176578601
gradient descent iteration = 3
gd loss = 153387.2176578601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152815.0480496105
gradient descent iteration = 4
gd loss = 152815.0480496105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152251.2232095923
gradient descent iteration = 5
gd loss = 152251.2232095923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151695.4706232475
gradient descent iteration = 6
gd loss = 151695.4706232475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151147.5300764729
gradient descent iteration = 7
gd loss = 151147.5300764729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150607.1529653136
gradient descent iteration = 8
gd loss = 150607.1529653136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150074.1016815183
gradient descent iteration = 9
gd loss = 150074.1016815183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149548.1489867453
gradient descent iteration = 10
gd loss = 149548.1489867453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149029.0774677692
gradient descent iteration = 11
gd loss = 149029.0774677692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148516.6791162631
gradient descent iteration = 12
gd loss = 148516.6791162631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148010.7548317145
gradient descent iteration = 13
gd loss = 148010.7548317145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147511.1139519042
gradient descent iteration = 14
gd loss = 147511.1139519042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147017.5738020506
gradient descent iteration = 15
gd loss = 147017.5738020506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146529.9593408925
gradient descent iteration = 16
gd loss = 146529.9593408925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146048.1028028668
gradient descent iteration = 17
gd loss = 146048.1028028668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145571.8433004728
gradient descent iteration = 18
gd loss = 145571.8433004728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145101.0264830983
gradient descent iteration = 19
gd loss = 145101.0264830983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144635.5042806726
gradient descent iteration = 20
gd loss = 144635.5042806726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144175.1345823242
gradient descent iteration = 21
gd loss = 144175.1345823242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143719.7809288104
gradient descent iteration = 22
gd loss = 143719.7809288104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143269.3122867949
gradient descent iteration = 23
gd loss = 143269.3122867949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142823.602830271
gradient descent iteration = 24
gd loss = 142823.602830271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142382.5316365483
Initial loss = 189880.2077973174
Final loss = 142382.5316365483
Deformation gradient control sequence optimization finished.
Animation interval 7 took 1352 seconds.
Full animation took 10820 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 8************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 156681.73808837
initial norm = 6182.710520301289
convergence norm = 6.182710520301289
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 156681.73808837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156066.7092521615
gradient descent iteration = 1
gd loss = 156066.7092521615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155457.6434135264
gradient descent iteration = 2
gd loss = 155457.6434135264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154854.4033108041
gradient descent iteration = 3
gd loss = 154854.4033108041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154256.8543574866
gradient descent iteration = 4
gd loss = 154256.8543574866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153664.8643724293
gradient descent iteration = 5
gd loss = 153664.8643724293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153078.3035406913
gradient descent iteration = 6
gd loss = 153078.3035406913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152497.044417185
gradient descent iteration = 7
gd loss = 152497.044417185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151920.9622397958
gradient descent iteration = 8
gd loss = 151920.9622397958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151349.9347934609
gradient descent iteration = 9
gd loss = 151349.9347934609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150783.8430274826
gradient descent iteration = 10
gd loss = 150783.8430274826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150222.5708358888
gradient descent iteration = 11
gd loss = 150222.5708358888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149666.0046472776
gradient descent iteration = 12
gd loss = 149666.0046472776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149114.0333102934
gradient descent iteration = 13
gd loss = 149114.0333102934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148566.5479530936
gradient descent iteration = 14
gd loss = 148566.5479530936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148023.4424676763
gradient descent iteration = 15
gd loss = 148023.4424676763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147484.6134592064
gradient descent iteration = 16
gd loss = 147484.6134592064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146949.9600017577
gradient descent iteration = 17
gd loss = 146949.9600017577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146419.3836059432
gradient descent iteration = 18
gd loss = 146419.3836059432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145892.7883579988
gradient descent iteration = 19
gd loss = 145892.7883579988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145370.0807952374
gradient descent iteration = 20
gd loss = 145370.0807952374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144851.1697136898
gradient descent iteration = 21
gd loss = 144851.1697136898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144335.9660870152
gradient descent iteration = 22
gd loss = 144335.9660870152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143824.3830206413
gradient descent iteration = 23
gd loss = 143824.3830206413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143316.3358173759
gradient descent iteration = 24
gd loss = 143316.3358173759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142811.7418956504
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 142811.7418956504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142086.057309794
gradient descent iteration = 1
gd loss = 142086.057309794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141371.9377550664
gradient descent iteration = 2
gd loss = 141371.9377550664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140668.921693306
gradient descent iteration = 3
gd loss = 140668.921693306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139976.576649356
gradient descent iteration = 4
gd loss = 139976.576649356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139294.4930102075
gradient descent iteration = 5
gd loss = 139294.4930102075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138622.2807854465
gradient descent iteration = 6
gd loss = 138622.2807854465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137959.5665885296
gradient descent iteration = 7
gd loss = 137959.5665885296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137305.996314755
gradient descent iteration = 8
gd loss = 137305.996314755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136661.2340578304
gradient descent iteration = 9
gd loss = 136661.2340578304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136024.9600729323
gradient descent iteration = 10
gd loss = 136024.9600729323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135396.8697810075
gradient descent iteration = 11
gd loss = 135396.8697810075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134776.6714617932
gradient descent iteration = 12
gd loss = 134776.6714617932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134164.0853841697
gradient descent iteration = 13
gd loss = 134164.0853841697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133558.8431031541
gradient descent iteration = 14
gd loss = 133558.8431031541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132960.6881407886
gradient descent iteration = 15
gd loss = 132960.6881407886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132369.3758756096
gradient descent iteration = 16
gd loss = 132369.3758756096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131784.672768977
gradient descent iteration = 17
gd loss = 131784.672768977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131206.3555178716
gradient descent iteration = 18
gd loss = 131206.3555178716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130634.210057454
gradient descent iteration = 19
gd loss = 130634.210057454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130068.031275563
gradient descent iteration = 20
gd loss = 130068.031275563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129507.6216916615
gradient descent iteration = 21
gd loss = 129507.6216916615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128952.7918629396
gradient descent iteration = 22
gd loss = 128952.7918629396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128403.3606028134
gradient descent iteration = 23
gd loss = 128403.3606028134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 127859.1553673236
gradient descent iteration = 24
gd loss = 127859.1553673236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 127320.0116587289
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 127320.0116587289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 126778.4991922356
gradient descent iteration = 1
gd loss = 126778.4991922356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 126246.6151269581
gradient descent iteration = 2
gd loss = 126246.6151269581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125723.9455175167
gradient descent iteration = 3
gd loss = 125723.9455175167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125210.1017700035
gradient descent iteration = 4
gd loss = 125210.1017700035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124704.7188363921
gradient descent iteration = 5
gd loss = 124704.7188363921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124207.4535376931
gradient descent iteration = 6
gd loss = 124207.4535376931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123717.9829758447
gradient descent iteration = 7
gd loss = 123717.9829758447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123236.0030907256
gradient descent iteration = 8
gd loss = 123236.0030907256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122761.2274288212
gradient descent iteration = 9
gd loss = 122761.2274288212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122293.3859186715
gradient descent iteration = 10
gd loss = 122293.3859186715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121832.2236961147
gradient descent iteration = 11
gd loss = 121832.2236961147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121377.5001594889
gradient descent iteration = 12
gd loss = 121377.5001594889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120928.9879735429
gradient descent iteration = 13
gd loss = 120928.9879735429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120486.4721080754
gradient descent iteration = 14
gd loss = 120486.4721080754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120049.7490668724
gradient descent iteration = 15
gd loss = 120049.7490668724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119618.6261310804
gradient descent iteration = 16
gd loss = 119618.6261310804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119192.920663573
gradient descent iteration = 17
gd loss = 119192.920663573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118772.4594671063
gradient descent iteration = 18
gd loss = 118772.4594671063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118357.0781124903
gradient descent iteration = 19
gd loss = 118357.0781124903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117946.6203821137
gradient descent iteration = 20
gd loss = 117946.6203821137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117540.9378003966
gradient descent iteration = 21
gd loss = 117540.9378003966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117139.8891213269
gradient descent iteration = 22
gd loss = 117139.8891213269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116743.3398680911
gradient descent iteration = 23
gd loss = 116743.3398680911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116351.1619618781
gradient descent iteration = 24
gd loss = 116351.1619618781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115963.2333335007
Initial loss = 156681.73808837
Final loss = 115963.2333335007
Deformation gradient control sequence optimization finished.
Animation interval 8 took 1349 seconds.
Full animation took 12170 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 9************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 126455.6018966872
initial norm = 4725.459946998022
convergence norm = 4.725459946998022
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 126455.6018966872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125985.4250133061
gradient descent iteration = 1
gd loss = 125985.4250133061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125519.5789037228
gradient descent iteration = 2
gd loss = 125519.5789037228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125057.9286924977
gradient descent iteration = 3
gd loss = 125057.9286924977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124600.3439402674
gradient descent iteration = 4
gd loss = 124600.3439402674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124146.6979588674
gradient descent iteration = 5
gd loss = 124146.6979588674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123696.8679523943
gradient descent iteration = 6
gd loss = 123696.8679523943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123250.7351803731
gradient descent iteration = 7
gd loss = 123250.7351803731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122808.1846614643
gradient descent iteration = 8
gd loss = 122808.1846614643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122369.1052062367
gradient descent iteration = 9
gd loss = 122369.1052062367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121933.3895269294
gradient descent iteration = 10
gd loss = 121933.3895269294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121500.9341833072
gradient descent iteration = 11
gd loss = 121500.9341833072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121071.6394342841
gradient descent iteration = 12
gd loss = 121071.6394342841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120645.409166639
gradient descent iteration = 13
gd loss = 120645.409166639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120222.1509483932
gradient descent iteration = 14
gd loss = 120222.1509483932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119801.7759660196
gradient descent iteration = 15
gd loss = 119801.7759660196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119384.1989578551
gradient descent iteration = 16
gd loss = 119384.1989578551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118969.3381630686
gradient descent iteration = 17
gd loss = 118969.3381630686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118557.1152743238
gradient descent iteration = 18
gd loss = 118557.1152743238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118147.4551742762
gradient descent iteration = 19
gd loss = 118147.4551742762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117740.2858489757
gradient descent iteration = 20
gd loss = 117740.2858489757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117335.5384086655
gradient descent iteration = 21
gd loss = 117335.5384086655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116933.1470501805
gradient descent iteration = 22
gd loss = 116933.1470501805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116533.0488575368
gradient descent iteration = 23
gd loss = 116533.0488575368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116135.183747976
gradient descent iteration = 24
gd loss = 116135.183747976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115739.4943572451
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 115739.4943572451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115095.4910418304
gradient descent iteration = 1
gd loss = 115095.4910418304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114460.845325169
gradient descent iteration = 2
gd loss = 114460.845325169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113835.1883529435
gradient descent iteration = 3
gd loss = 113835.1883529435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113218.1748895679
gradient descent iteration = 4
gd loss = 113218.1748895679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112609.4807431491
gradient descent iteration = 5
gd loss = 112609.4807431491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112008.8018738902
gradient descent iteration = 6
gd loss = 112008.8018738902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111415.8526067995
gradient descent iteration = 7
gd loss = 111415.8526067995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110830.364369814
gradient descent iteration = 8
gd loss = 110830.364369814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110252.0850249067
gradient descent iteration = 9
gd loss = 110252.0850249067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109680.7770533739
gradient descent iteration = 10
gd loss = 109680.7770533739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109116.2168606659
gradient descent iteration = 11
gd loss = 109116.2168606659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108558.1933850612
gradient descent iteration = 12
gd loss = 108558.1933850612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108006.5073531428
gradient descent iteration = 13
gd loss = 108006.5073531428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 107460.9705240826
gradient descent iteration = 14
gd loss = 107460.9705240826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106921.4050870225
gradient descent iteration = 15
gd loss = 106921.4050870225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106387.6433325877
gradient descent iteration = 16
gd loss = 106387.6433325877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105859.5274138092
gradient descent iteration = 17
gd loss = 105859.5274138092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105336.9083403413
gradient descent iteration = 18
gd loss = 105336.9083403413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104819.6460198246
gradient descent iteration = 19
gd loss = 104819.6460198246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104307.6091058756
gradient descent iteration = 20
gd loss = 104307.6091058756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103800.6743864811
gradient descent iteration = 21
gd loss = 103800.6743864811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103298.7263633981
gradient descent iteration = 22
gd loss = 103298.7263633981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102801.6566614097
gradient descent iteration = 23
gd loss = 102801.6566614097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102309.3632478124
gradient descent iteration = 24
gd loss = 102309.3632478124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101821.7499407942
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 101821.7499407942
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101367.3831742756
gradient descent iteration = 1
gd loss = 101367.3831742756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100921.2839050947
gradient descent iteration = 2
gd loss = 100921.2839050947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100483.0795057623
gradient descent iteration = 3
gd loss = 100483.0795057623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100052.4233242405
gradient descent iteration = 4
gd loss = 100052.4233242405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99628.99252424593
gradient descent iteration = 5
gd loss = 99628.99252424593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99212.48586361681
gradient descent iteration = 6
gd loss = 99212.48586361681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98802.62191799568
gradient descent iteration = 7
gd loss = 98802.62191799568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98399.13762353777
gradient descent iteration = 8
gd loss = 98399.13762353777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98001.78663759827
gradient descent iteration = 9
gd loss = 98001.78663759827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97610.33791498859
gradient descent iteration = 10
gd loss = 97610.33791498859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97224.5745441825
gradient descent iteration = 11
gd loss = 97224.5745441825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96844.29263451755
gradient descent iteration = 12
gd loss = 96844.29263451755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96469.30033004853
gradient descent iteration = 13
gd loss = 96469.30033004853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96099.41692298654
gradient descent iteration = 14
gd loss = 96099.41692298654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95734.47190979918
gradient descent iteration = 15
gd loss = 95734.47190979918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95374.30422019922
gradient descent iteration = 16
gd loss = 95374.30422019922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95018.76158436589
gradient descent iteration = 17
gd loss = 95018.76158436589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94667.69996475994
gradient descent iteration = 18
gd loss = 94667.69996475994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94320.98290089025
gradient descent iteration = 19
gd loss = 94320.98290089025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93978.48090926152
gradient descent iteration = 20
gd loss = 93978.48090926152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93640.07102916446
gradient descent iteration = 21
gd loss = 93640.07102916446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93305.63643650318
gradient descent iteration = 22
gd loss = 93305.63643650318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92975.06601460032
gradient descent iteration = 23
gd loss = 92975.06601460032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92648.25391278123
gradient descent iteration = 24
gd loss = 92648.25391278123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92325.09914220928
Initial loss = 126455.6018966872
Final loss = 92325.09914220928
Deformation gradient control sequence optimization finished.
Animation interval 9 took 1356 seconds.
Full animation took 13527 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 10************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 100144.3727152336
initial norm = 3949.269261072937
convergence norm = 3.949269261072937
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 100144.3727152336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99752.31120613709
gradient descent iteration = 1
gd loss = 99752.31120613709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99365.64277222323
gradient descent iteration = 2
gd loss = 99365.64277222323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98984.10553788113
gradient descent iteration = 3
gd loss = 98984.10553788113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98607.44664909787
gradient descent iteration = 4
gd loss = 98607.44664909787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98235.4234374295
gradient descent iteration = 5
gd loss = 98235.4234374295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97867.80408875983
gradient descent iteration = 6
gd loss = 97867.80408875983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97504.36748274762
gradient descent iteration = 7
gd loss = 97504.36748274762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97144.90338225875
gradient descent iteration = 8
gd loss = 97144.90338225875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96789.21265659072
gradient descent iteration = 9
gd loss = 96789.21265659072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96437.10758659484
gradient descent iteration = 10
gd loss = 96437.10758659484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96088.41170687304
gradient descent iteration = 11
gd loss = 96088.41170687304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95742.95958284328
gradient descent iteration = 12
gd loss = 95742.95958284328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95400.59633303501
gradient descent iteration = 13
gd loss = 95400.59633303501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95061.17714874707
gradient descent iteration = 14
gd loss = 95061.17714874707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94724.56663006573
gradient descent iteration = 15
gd loss = 94724.56663006573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94390.63860700144
gradient descent iteration = 16
gd loss = 94390.63860700144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94059.27596890941
gradient descent iteration = 17
gd loss = 94059.27596890941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93730.37006111474
gradient descent iteration = 18
gd loss = 93730.37006111474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93403.81998171302
gradient descent iteration = 19
gd loss = 93403.81998171302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93079.53208865618
gradient descent iteration = 20
gd loss = 93079.53208865618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92757.41957333752
gradient descent iteration = 21
gd loss = 92757.41957333752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92437.40203845751
gradient descent iteration = 22
gd loss = 92437.40203845751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92119.40490853949
gradient descent iteration = 23
gd loss = 92119.40490853949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91803.35898987621
gradient descent iteration = 24
gd loss = 91803.35898987621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91489.20009140938
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 91489.20009140938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90945.93042934996
gradient descent iteration = 1
gd loss = 90945.93042934996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90410.98328327478
gradient descent iteration = 2
gd loss = 90410.98328327478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89884.13033827816
gradient descent iteration = 3
gd loss = 89884.13033827816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89365.15322284836
gradient descent iteration = 4
gd loss = 89365.15322284836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88853.84354224807
gradient descent iteration = 5
gd loss = 88853.84354224807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88350.00353595777
gradient descent iteration = 6
gd loss = 88350.00353595777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87853.44542084148
gradient descent iteration = 7
gd loss = 87853.44542084148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87363.9893635356
gradient descent iteration = 8
gd loss = 87363.9893635356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86881.46271561508
gradient descent iteration = 9
gd loss = 86881.46271561508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86405.69977727004
gradient descent iteration = 10
gd loss = 86405.69977727004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85936.54091959607
gradient descent iteration = 11
gd loss = 85936.54091959607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85473.83273744489
gradient descent iteration = 12
gd loss = 85473.83273744489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85017.42871924253
gradient descent iteration = 13
gd loss = 85017.42871924253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84567.1886395914
gradient descent iteration = 14
gd loss = 84567.1886395914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84122.97756272345
gradient descent iteration = 15
gd loss = 84122.97756272345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83684.66483100776
gradient descent iteration = 16
gd loss = 83684.66483100776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83252.12394034151
gradient descent iteration = 17
gd loss = 83252.12394034151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82825.23298699818
gradient descent iteration = 18
gd loss = 82825.23298699818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82403.87422520753
gradient descent iteration = 19
gd loss = 82403.87422520753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81987.93355018753
gradient descent iteration = 20
gd loss = 81987.93355018753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81577.30061285927
gradient descent iteration = 21
gd loss = 81577.30061285927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81171.86876380985
gradient descent iteration = 22
gd loss = 81171.86876380985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80771.53467216951
gradient descent iteration = 23
gd loss = 80771.53467216951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80376.19854981467
gradient descent iteration = 24
gd loss = 80376.19854981467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79985.76454025746
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 79985.76454025746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79636.41575438695
gradient descent iteration = 1
gd loss = 79636.41575438695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79293.10543293327
gradient descent iteration = 2
gd loss = 79293.10543293327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78955.60131956877
gradient descent iteration = 3
gd loss = 78955.60131956877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78623.68512749033
gradient descent iteration = 4
gd loss = 78623.68512749033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78297.15138058116
gradient descent iteration = 5
gd loss = 78297.15138058116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77975.80636867428
gradient descent iteration = 6
gd loss = 77975.80636867428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77659.4672500344
gradient descent iteration = 7
gd loss = 77659.4672500344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77347.96132202746
gradient descent iteration = 8
gd loss = 77347.96132202746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77041.12517794603
gradient descent iteration = 9
gd loss = 77041.12517794603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76738.80405356766
gradient descent iteration = 10
gd loss = 76738.80405356766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76440.85124695973
gradient descent iteration = 11
gd loss = 76440.85124695973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76147.12757967439
gradient descent iteration = 12
gd loss = 76147.12757967439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75857.50083499136
gradient descent iteration = 13
gd loss = 75857.50083499136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75571.84528601746
gradient descent iteration = 14
gd loss = 75571.84528601746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75290.04128669515
gradient descent iteration = 15
gd loss = 75290.04128669515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75011.97488748364
gradient descent iteration = 16
gd loss = 75011.97488748364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74737.5375314477
gradient descent iteration = 17
gd loss = 74737.5375314477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74466.62569401046
gradient descent iteration = 18
gd loss = 74466.62569401046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74199.14053963039
gradient descent iteration = 19
gd loss = 74199.14053963039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73934.98765594991
gradient descent iteration = 20
gd loss = 73934.98765594991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73674.07675329629
gradient descent iteration = 21
gd loss = 73674.07675329629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73416.32137676084
gradient descent iteration = 22
gd loss = 73416.32137676084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73161.63869908427
gradient descent iteration = 23
gd loss = 73161.63869908427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72909.94934637808
gradient descent iteration = 24
gd loss = 72909.94934637808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72661.17723653052
Initial loss = 100144.3727152336
Final loss = 72661.17723653052
Deformation gradient control sequence optimization finished.
Animation interval 10 took 1353 seconds.
Full animation took 14881 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 11************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 78561.56568334241
initial norm = 3104.127406807879
convergence norm = 3.104127406807879
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 78561.56568334241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78253.55617238388
gradient descent iteration = 1
gd loss = 78253.55617238388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77950.08229969286
gradient descent iteration = 2
gd loss = 77950.08229969286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77650.89399938546
gradient descent iteration = 3
gd loss = 77650.89399938546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77355.75628881135
gradient descent iteration = 4
gd loss = 77355.75628881135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77064.44886952326
gradient descent iteration = 5
gd loss = 77064.44886952326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76776.76624697165
gradient descent iteration = 6
gd loss = 76776.76624697165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76492.51676597618
gradient descent iteration = 7
gd loss = 76492.51676597618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76211.52195020963
gradient descent iteration = 8
gd loss = 76211.52195020963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75933.61617307246
gradient descent iteration = 9
gd loss = 75933.61617307246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75658.64592157731
gradient descent iteration = 10
gd loss = 75658.64592157731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75386.46919328447
gradient descent iteration = 11
gd loss = 75386.46919328447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75116.95490830245
gradient descent iteration = 12
gd loss = 75116.95490830245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74849.98212225243
gradient descent iteration = 13
gd loss = 74849.98212225243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74585.43912293215
gradient descent iteration = 14
gd loss = 74585.43912293215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74323.22273573205
gradient descent iteration = 15
gd loss = 74323.22273573205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74063.2376676642
gradient descent iteration = 16
gd loss = 74063.2376676642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73805.39579546778
gradient descent iteration = 17
gd loss = 73805.39579546778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73549.61540513816
gradient descent iteration = 18
gd loss = 73549.61540513816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73295.82065758413
gradient descent iteration = 19
gd loss = 73295.82065758413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73043.94106532641
gradient descent iteration = 20
gd loss = 73043.94106532641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72793.91106700904
gradient descent iteration = 21
gd loss = 72793.91106700904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72545.66955411412
gradient descent iteration = 22
gd loss = 72545.66955411412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72299.15935386304
gradient descent iteration = 23
gd loss = 72299.15935386304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72054.32698044844
gradient descent iteration = 24
gd loss = 72054.32698044844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71811.1223613684
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 71811.1223613684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71362.09742905754
gradient descent iteration = 1
gd loss = 71362.09742905754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70921.82533836189
gradient descent iteration = 2
gd loss = 70921.82533836189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70490.04371806911
gradient descent iteration = 3
gd loss = 70490.04371806911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70066.50269084705
gradient descent iteration = 4
gd loss = 70066.50269084705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69650.96400117435
gradient descent iteration = 5
gd loss = 69650.96400117435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69243.2010761603
gradient descent iteration = 6
gd loss = 69243.2010761603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68842.99771813123
gradient descent iteration = 7
gd loss = 68842.99771813123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68450.14696910918
gradient descent iteration = 8
gd loss = 68450.14696910918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68064.45074851929
gradient descent iteration = 9
gd loss = 68064.45074851929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67685.71901010236
gradient descent iteration = 10
gd loss = 67685.71901010236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67313.76883390774
gradient descent iteration = 11
gd loss = 67313.76883390774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66948.42430161194
gradient descent iteration = 12
gd loss = 66948.42430161194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66589.51630437456
gradient descent iteration = 13
gd loss = 66589.51630437456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66236.88151730329
gradient descent iteration = 14
gd loss = 66236.88151730329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65890.36201816931
gradient descent iteration = 15
gd loss = 65890.36201816931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65549.80432155124
gradient descent iteration = 16
gd loss = 65549.80432155124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65215.05898635698
gradient descent iteration = 17
gd loss = 65215.05898635698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64885.98081293165
gradient descent iteration = 18
gd loss = 64885.98081293165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64562.4285149381
gradient descent iteration = 19
gd loss = 64562.4285149381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64244.26484993752
gradient descent iteration = 20
gd loss = 64244.26484993752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63931.35642283283
gradient descent iteration = 21
gd loss = 63931.35642283283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63623.57294466702
gradient descent iteration = 22
gd loss = 63623.57294466702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63320.7867373156
gradient descent iteration = 23
gd loss = 63320.7867373156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63022.87293003099
gradient descent iteration = 24
gd loss = 63022.87293003099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62729.70945395545
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 62729.70945395545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62464.38211660812
gradient descent iteration = 1
gd loss = 62464.38211660812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62204.0177014162
gradient descent iteration = 2
gd loss = 62204.0177014162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61948.4173720067
gradient descent iteration = 3
gd loss = 61948.4173720067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61697.39352080182
gradient descent iteration = 4
gd loss = 61697.39352080182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61450.76902591038
gradient descent iteration = 5
gd loss = 61450.76902591038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61208.37654193335
gradient descent iteration = 6
gd loss = 61208.37654193335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60970.05788456848
gradient descent iteration = 7
gd loss = 60970.05788456848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60735.66344567429
gradient descent iteration = 8
gd loss = 60735.66344567429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60505.05165869717
gradient descent iteration = 9
gd loss = 60505.05165869717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60278.08844799849
gradient descent iteration = 10
gd loss = 60278.08844799849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60054.64678863139
gradient descent iteration = 11
gd loss = 60054.64678863139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59834.60624999371
gradient descent iteration = 12
gd loss = 59834.60624999371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59617.85260316965
gradient descent iteration = 13
gd loss = 59617.85260316965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59404.27753796481
gradient descent iteration = 14
gd loss = 59404.27753796481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59193.77829021758
gradient descent iteration = 15
gd loss = 59193.77829021758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58986.25724971045
gradient descent iteration = 16
gd loss = 58986.25724971045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58781.62161339918
gradient descent iteration = 17
gd loss = 58781.62161339918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58579.78307067197
gradient descent iteration = 18
gd loss = 58579.78307067197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58380.6575388148
gradient descent iteration = 19
gd loss = 58380.6575388148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58184.16493879221
gradient descent iteration = 20
gd loss = 58184.16493879221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57990.22900684302
gradient descent iteration = 21
gd loss = 57990.22900684302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57798.77705131035
gradient descent iteration = 22
gd loss = 57798.77705131035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57609.73971215326
gradient descent iteration = 23
gd loss = 57609.73971215326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57423.05075700447
gradient descent iteration = 24
gd loss = 57423.05075700447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57238.64689342039
Initial loss = 78561.56568334241
Final loss = 57238.64689342039
Deformation gradient control sequence optimization finished.
Animation interval 11 took 1352 seconds.
Full animation took 16233 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 12************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 61632.40995859131
initial norm = 2466.455528290017
convergence norm = 2.466455528290017
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 61632.40995859131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61388.42625015521
gradient descent iteration = 1
gd loss = 61388.42625015521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61149.42833650397
gradient descent iteration = 2
gd loss = 61149.42833650397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60915.03187650556
gradient descent iteration = 3
gd loss = 60915.03187650556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60684.88265120384
gradient descent iteration = 4
gd loss = 60684.88265120384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60458.65600335361
gradient descent iteration = 5
gd loss = 60458.65600335361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60236.05574400326
gradient descent iteration = 6
gd loss = 60236.05574400326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60016.81296402459
gradient descent iteration = 7
gd loss = 60016.81296402459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59800.68476605789
gradient descent iteration = 8
gd loss = 59800.68476605789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59587.45228387658
gradient descent iteration = 9
gd loss = 59587.45228387658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59376.91859708823
gradient descent iteration = 10
gd loss = 59376.91859708823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59168.90649600338
gradient descent iteration = 11
gd loss = 59168.90649600338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58963.25631794069
gradient descent iteration = 12
gd loss = 58963.25631794069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58759.82393931488
gradient descent iteration = 13
gd loss = 58759.82393931488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58558.47895848846
gradient descent iteration = 14
gd loss = 58558.47895848846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58359.10314326907
gradient descent iteration = 15
gd loss = 58359.10314326907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58161.58892933102
gradient descent iteration = 16
gd loss = 58161.58892933102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57965.83805035101
gradient descent iteration = 17
gd loss = 57965.83805035101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57771.76011798441
gradient descent iteration = 18
gd loss = 57771.76011798441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57579.27152724728
gradient descent iteration = 19
gd loss = 57579.27152724728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57388.29450286385
gradient descent iteration = 20
gd loss = 57388.29450286385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57198.75637114865
gradient descent iteration = 21
gd loss = 57198.75637114865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57010.58906997995
gradient descent iteration = 22
gd loss = 57010.58906997995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56823.72861342939
gradient descent iteration = 23
gd loss = 56823.72861342939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56638.11481203586
gradient descent iteration = 24
gd loss = 56638.11481203586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56453.69063590233
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 56453.69063590233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56097.2368269514
gradient descent iteration = 1
gd loss = 56097.2368269514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55750.57392049892
gradient descent iteration = 2
gd loss = 55750.57392049892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55413.2405877489
gradient descent iteration = 3
gd loss = 55413.2405877489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55084.80125390871
gradient descent iteration = 4
gd loss = 55084.80125390871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54764.84454638042
gradient descent iteration = 5
gd loss = 54764.84454638042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54452.98167957547
gradient descent iteration = 6
gd loss = 54452.98167957547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54148.84496203458
gradient descent iteration = 7
gd loss = 54148.84496203458
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53852.08643246633
gradient descent iteration = 8
gd loss = 53852.08643246633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53562.37670887285
gradient descent iteration = 9
gd loss = 53562.37670887285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53279.40353302436
gradient descent iteration = 10
gd loss = 53279.40353302436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53002.87069297316
gradient descent iteration = 11
gd loss = 53002.87069297316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52732.49694581125
gradient descent iteration = 12
gd loss = 52732.49694581125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52468.015035778
gradient descent iteration = 13
gd loss = 52468.015035778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52209.1710981773
gradient descent iteration = 14
gd loss = 52209.1710981773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51955.72407635659
gradient descent iteration = 15
gd loss = 51955.72407635659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51707.44535383488
gradient descent iteration = 16
gd loss = 51707.44535383488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51464.11779145503
gradient descent iteration = 17
gd loss = 51464.11779145503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51225.53482055858
gradient descent iteration = 18
gd loss = 51225.53482055858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50991.49990143197
gradient descent iteration = 19
gd loss = 50991.49990143197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50761.82603977909
gradient descent iteration = 20
gd loss = 50761.82603977909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50536.33533559776
gradient descent iteration = 21
gd loss = 50536.33533559776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50314.85855519258
gradient descent iteration = 22
gd loss = 50314.85855519258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50097.23488173823
gradient descent iteration = 23
gd loss = 50097.23488173823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49883.311434371
gradient descent iteration = 24
gd loss = 49883.311434371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49672.94284842659
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 49672.94284842659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49466.75566981622
gradient descent iteration = 1
gd loss = 49466.75566981622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49265.90063060766
gradient descent iteration = 2
gd loss = 49265.90063060766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49069.98872257895
gradient descent iteration = 3
gd loss = 49069.98872257895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48878.67618786693
gradient descent iteration = 4
gd loss = 48878.67618786693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48691.65844069143
gradient descent iteration = 5
gd loss = 48691.65844069143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48508.66482743649
gradient descent iteration = 6
gd loss = 48508.66482743649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48329.45409641674
gradient descent iteration = 7
gd loss = 48329.45409641674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48153.81050647446
gradient descent iteration = 8
gd loss = 48153.81050647446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47981.5404913801
gradient descent iteration = 9
gd loss = 47981.5404913801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47812.4698492894
gradient descent iteration = 10
gd loss = 47812.4698492894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47646.44124835842
gradient descent iteration = 11
gd loss = 47646.44124835842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47483.31211561724
gradient descent iteration = 12
gd loss = 47483.31211561724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47322.95283149616
gradient descent iteration = 13
gd loss = 47322.95283149616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47165.24512955167
gradient descent iteration = 14
gd loss = 47165.24512955167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47010.08072970584
gradient descent iteration = 15
gd loss = 47010.08072970584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46857.36013341215
gradient descent iteration = 16
gd loss = 46857.36013341215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46706.99161920787
gradient descent iteration = 17
gd loss = 46706.99161920787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46558.89038119962
gradient descent iteration = 18
gd loss = 46558.89038119962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46412.97779460488
gradient descent iteration = 19
gd loss = 46412.97779460488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46269.18075614617
gradient descent iteration = 20
gd loss = 46269.18075614617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46127.43108195427
gradient descent iteration = 21
gd loss = 46127.43108195427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45987.66503822982
gradient descent iteration = 22
gd loss = 45987.66503822982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45849.82291962778
gradient descent iteration = 23
gd loss = 45849.82291962778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45713.84865837084
gradient descent iteration = 24
gd loss = 45713.84865837084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45579.68946263596
Initial loss = 61632.40995859131
Final loss = 45579.68946263596
Deformation gradient control sequence optimization finished.
Animation interval 12 took 1353 seconds.
Full animation took 17587 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 13************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 48740.89565055782
initial norm = 2074.510374242045
convergence norm = 2.074510374242045
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 48740.89565055782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48537.37533452357
gradient descent iteration = 1
gd loss = 48537.37533452357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48340.9940233679
gradient descent iteration = 2
gd loss = 48340.9940233679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48150.84798407662
gradient descent iteration = 3
gd loss = 48150.84798407662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47966.12162314276
gradient descent iteration = 4
gd loss = 47966.12162314276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47786.09603869385
gradient descent iteration = 5
gd loss = 47786.09603869385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47610.15041350165
gradient descent iteration = 6
gd loss = 47610.15041350165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47437.75751472448
gradient descent iteration = 7
gd loss = 47437.75751472448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47268.47552288581
gradient descent iteration = 8
gd loss = 47268.47552288581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47101.93816621012
gradient descent iteration = 9
gd loss = 47101.93816621012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46937.84350766865
gradient descent iteration = 10
gd loss = 46937.84350766865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46775.94295965618
gradient descent iteration = 11
gd loss = 46775.94295965618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46616.03167052929
gradient descent iteration = 12
gd loss = 46616.03167052929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46457.94029731718
gradient descent iteration = 13
gd loss = 46457.94029731718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46301.5279192861
gradient descent iteration = 14
gd loss = 46301.5279192861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46146.67651863707
gradient descent iteration = 15
gd loss = 46146.67651863707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45993.28586608597
gradient descent iteration = 16
gd loss = 45993.28586608597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45841.26945747001
gradient descent iteration = 17
gd loss = 45841.26945747001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45690.55145322455
gradient descent iteration = 18
gd loss = 45690.55145322455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45541.06413559523
gradient descent iteration = 19
gd loss = 45541.06413559523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45392.74572870808
gradient descent iteration = 20
gd loss = 45392.74572870808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45245.53864968576
gradient descent iteration = 21
gd loss = 45245.53864968576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45099.38815589893
gradient descent iteration = 22
gd loss = 45099.38815589893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44954.2416349202
gradient descent iteration = 23
gd loss = 44954.2416349202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44810.04893853505
gradient descent iteration = 24
gd loss = 44810.04893853505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44666.76255451905
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 44666.76255451905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44406.44558178947
gradient descent iteration = 1
gd loss = 44406.44558178947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44155.51638632814
gradient descent iteration = 2
gd loss = 44155.51638632814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43913.22390244052
gradient descent iteration = 3
gd loss = 43913.22390244052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43678.89478033078
gradient descent iteration = 4
gd loss = 43678.89478033078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43451.92383349499
gradient descent iteration = 5
gd loss = 43451.92383349499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43231.76603166004
gradient descent iteration = 6
gd loss = 43231.76603166004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43017.92969894925
gradient descent iteration = 7
gd loss = 43017.92969894925
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42809.97036344548
gradient descent iteration = 8
gd loss = 42809.97036344548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42607.48571305635
gradient descent iteration = 9
gd loss = 42607.48571305635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42410.11119578934
gradient descent iteration = 10
gd loss = 42410.11119578934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42217.51563319326
gradient descent iteration = 11
gd loss = 42217.51563319326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42029.39764213803
gradient descent iteration = 12
gd loss = 42029.39764213803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41845.482887164
gradient descent iteration = 13
gd loss = 41845.482887164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41665.52094760544
gradient descent iteration = 14
gd loss = 41665.52094760544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41489.28271228581
gradient descent iteration = 15
gd loss = 41489.28271228581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41316.55811430843
gradient descent iteration = 16
gd loss = 41316.55811430843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41147.15399914292
gradient descent iteration = 17
gd loss = 41147.15399914292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40980.8925752825
gradient descent iteration = 18
gd loss = 40980.8925752825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40817.61009746994
gradient descent iteration = 19
gd loss = 40817.61009746994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40657.15566873591
gradient descent iteration = 20
gd loss = 40657.15566873591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40499.39007160298
gradient descent iteration = 21
gd loss = 40499.39007160298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40344.18460915019
gradient descent iteration = 22
gd loss = 40344.18460915019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40191.42002154035
gradient descent iteration = 23
gd loss = 40191.42002154035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40040.98568887492
gradient descent iteration = 24
gd loss = 40040.98568887492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39892.77890283192
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 39892.77890283192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39736.54607310841
gradient descent iteration = 1
gd loss = 39736.54607310841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39586.83014488625
gradient descent iteration = 2
gd loss = 39586.83014488625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39442.80895364578
gradient descent iteration = 3
gd loss = 39442.80895364578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39303.80430361426
gradient descent iteration = 4
gd loss = 39303.80430361426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39169.25541641493
gradient descent iteration = 5
gd loss = 39169.25541641493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 39038.69704894547
gradient descent iteration = 6
gd loss = 39038.69704894547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38911.74161519417
gradient descent iteration = 7
gd loss = 38911.74161519417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38788.0646244569
gradient descent iteration = 8
gd loss = 38788.0646244569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38667.39288622338
gradient descent iteration = 9
gd loss = 38667.39288622338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38549.49493338524
gradient descent iteration = 10
gd loss = 38549.49493338524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38434.17332580566
gradient descent iteration = 11
gd loss = 38434.17332580566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38321.25843506672
gradient descent iteration = 12
gd loss = 38321.25843506672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38210.60337034491
gradient descent iteration = 13
gd loss = 38210.60337034491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38102.07983239474
gradient descent iteration = 14
gd loss = 38102.07983239474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37995.57476373726
gradient descent iteration = 15
gd loss = 37995.57476373726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37890.98772544091
gradient descent iteration = 16
gd loss = 37890.98772544091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37788.22884658014
gradient descent iteration = 17
gd loss = 37788.22884658014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37687.21717934782
gradient descent iteration = 18
gd loss = 37687.21717934782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37587.87935299224
gradient descent iteration = 19
gd loss = 37587.87935299224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37490.14844364802
gradient descent iteration = 20
gd loss = 37490.14844364802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37393.96306060793
gradient descent iteration = 21
gd loss = 37393.96306060793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37299.26661801387
gradient descent iteration = 22
gd loss = 37299.26661801387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37206.00664580616
gradient descent iteration = 23
gd loss = 37206.00664580616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37114.13422761406
gradient descent iteration = 24
gd loss = 37114.13422761406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37023.6035462065
Initial loss = 48740.89565055782
Final loss = 37023.6035462065
Deformation gradient control sequence optimization finished.
Animation interval 13 took 1352 seconds.
Full animation took 18939 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 14************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 38599.7597740371
initial norm = 1462.513452744894
convergence norm = 1.462513452744894
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 38599.7597740371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38455.92552459388
gradient descent iteration = 1
gd loss = 38455.92552459388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38316.36452694562
gradient descent iteration = 2
gd loss = 38316.36452694562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38180.44760595487
gradient descent iteration = 3
gd loss = 38180.44760595487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 38047.64823259449
gradient descent iteration = 4
gd loss = 38047.64823259449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37917.53107024988
gradient descent iteration = 5
gd loss = 37917.53107024988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37789.73899960898
gradient descent iteration = 6
gd loss = 37789.73899960898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37663.97925380957
gradient descent iteration = 7
gd loss = 37663.97925380957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37540.01031590898
gradient descent iteration = 8
gd loss = 37540.01031590898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37417.63157502122
gradient descent iteration = 9
gd loss = 37417.63157502122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37296.67583810638
gradient descent iteration = 10
gd loss = 37296.67583810638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37177.00273814048
gradient descent iteration = 11
gd loss = 37177.00273814048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 37058.49353845697
gradient descent iteration = 12
gd loss = 37058.49353845697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36941.04585950194
gradient descent iteration = 13
gd loss = 36941.04585950194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36824.57059436141
gradient descent iteration = 14
gd loss = 36824.57059436141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36708.99122261131
gradient descent iteration = 15
gd loss = 36708.99122261131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36594.25115713842
gradient descent iteration = 16
gd loss = 36594.25115713842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36480.31099765528
gradient descent iteration = 17
gd loss = 36480.31099765528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36367.1391377841
gradient descent iteration = 18
gd loss = 36367.1391377841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36254.70784689664
gradient descent iteration = 19
gd loss = 36254.70784689664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36142.99309300307
gradient descent iteration = 20
gd loss = 36142.99309300307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 36031.97542236947
gradient descent iteration = 21
gd loss = 36031.97542236947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35921.64168801589
gradient descent iteration = 22
gd loss = 35921.64168801589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35811.9847654734
gradient descent iteration = 23
gd loss = 35811.9847654734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35703.00147744136
gradient descent iteration = 24
gd loss = 35703.00147744136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35594.69072334598
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 35594.69072334598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35404.72738125134
gradient descent iteration = 1
gd loss = 35404.72738125134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35223.57619269999
gradient descent iteration = 2
gd loss = 35223.57619269999
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 35050.12662325861
gradient descent iteration = 3
gd loss = 35050.12662325861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34883.45885974226
gradient descent iteration = 4
gd loss = 34883.45885974226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34722.80655356096
gradient descent iteration = 5
gd loss = 34722.80655356096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34567.52775026619
gradient descent iteration = 6
gd loss = 34567.52775026619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34417.08144880182
gradient descent iteration = 7
gd loss = 34417.08144880182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34271.00813574193
gradient descent iteration = 8
gd loss = 34271.00813574193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 34128.91536167321
gradient descent iteration = 9
gd loss = 34128.91536167321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33990.46549929868
gradient descent iteration = 10
gd loss = 33990.46549929868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33855.36587421717
gradient descent iteration = 11
gd loss = 33855.36587421717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33723.36090332278
gradient descent iteration = 12
gd loss = 33723.36090332278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33594.22617049423
gradient descent iteration = 13
gd loss = 33594.22617049423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33467.763496575
gradient descent iteration = 14
gd loss = 33467.763496575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33343.79680914823
gradient descent iteration = 15
gd loss = 33343.79680914823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33222.16883400756
gradient descent iteration = 16
gd loss = 33222.16883400756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 33102.73856375983
gradient descent iteration = 17
gd loss = 33102.73856375983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32985.37903653883
gradient descent iteration = 18
gd loss = 32985.37903653883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32869.97542540658
gradient descent iteration = 19
gd loss = 32869.97542540658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32756.42383879366
gradient descent iteration = 20
gd loss = 32756.42383879366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32644.6297123613
gradient descent iteration = 21
gd loss = 32644.6297123613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32534.50640694167
gradient descent iteration = 22
gd loss = 32534.50640694167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32425.974281077
gradient descent iteration = 23
gd loss = 32425.974281077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32318.96005350766
gradient descent iteration = 24
gd loss = 32318.96005350766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32213.39621112727
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 32213.39621112727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32103.87019954632
gradient descent iteration = 1
gd loss = 32103.87019954632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 32000.97571286717
gradient descent iteration = 2
gd loss = 32000.97571286717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31903.43304365404
gradient descent iteration = 3
gd loss = 31903.43304365404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31810.27432803473
gradient descent iteration = 4
gd loss = 31810.27432803473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31720.76531391289
gradient descent iteration = 5
gd loss = 31720.76531391289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31634.34615697117
gradient descent iteration = 6
gd loss = 31634.34615697117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31550.58697002242
gradient descent iteration = 7
gd loss = 31550.58697002242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31469.15469359337
gradient descent iteration = 8
gd loss = 31469.15469359337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31389.78847067228
gradient descent iteration = 9
gd loss = 31389.78847067228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31312.2814331991
gradient descent iteration = 10
gd loss = 31312.2814331991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31236.46721736186
gradient descent iteration = 11
gd loss = 31236.46721736186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31162.21000051278
gradient descent iteration = 12
gd loss = 31162.21000051278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31089.39714560525
gradient descent iteration = 13
gd loss = 31089.39714560525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31017.93376083367
gradient descent iteration = 14
gd loss = 31017.93376083367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30947.73867977662
gradient descent iteration = 15
gd loss = 30947.73867977662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30878.74146240109
gradient descent iteration = 16
gd loss = 30878.74146240109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30810.88015816908
gradient descent iteration = 17
gd loss = 30810.88015816908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30744.09964606653
gradient descent iteration = 18
gd loss = 30744.09964606653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30678.35035878871
gradient descent iteration = 19
gd loss = 30678.35035878871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30613.5873317991
gradient descent iteration = 20
gd loss = 30613.5873317991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30549.76945063862
gradient descent iteration = 21
gd loss = 30549.76945063862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30486.85884603357
gradient descent iteration = 22
gd loss = 30486.85884603357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30424.82045052735
gradient descent iteration = 23
gd loss = 30424.82045052735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30363.62165665158
gradient descent iteration = 24
gd loss = 30363.62165665158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30303.23204413772
Initial loss = 38599.7597740371
Final loss = 30303.23204413772
Deformation gradient control sequence optimization finished.
Animation interval 14 took 1353 seconds.
Full animation took 20293 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 15************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 31229.31111194195
initial norm = 1272.40553049682
convergence norm = 1.27240553049682
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 31229.31111194195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 31106.11206814446
gradient descent iteration = 1
gd loss = 31106.11206814446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30990.04306570471
gradient descent iteration = 2
gd loss = 30990.04306570471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30879.94024007576
gradient descent iteration = 3
gd loss = 30879.94024007576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30774.72075920533
gradient descent iteration = 4
gd loss = 30774.72075920533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30673.43199983776
gradient descent iteration = 5
gd loss = 30673.43199983776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30575.27851895527
gradient descent iteration = 6
gd loss = 30575.27851895527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30479.62563940885
gradient descent iteration = 7
gd loss = 30479.62563940885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30385.98503972651
gradient descent iteration = 8
gd loss = 30385.98503972651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30293.99094306379
gradient descent iteration = 9
gd loss = 30293.99094306379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30203.37394531921
gradient descent iteration = 10
gd loss = 30203.37394531921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30113.93612144858
gradient descent iteration = 11
gd loss = 30113.93612144858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 30025.5303724983
gradient descent iteration = 12
gd loss = 30025.5303724983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29938.04526628872
gradient descent iteration = 13
gd loss = 29938.04526628872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29851.39399779473
gradient descent iteration = 14
gd loss = 29851.39399779473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29765.50681600091
gradient descent iteration = 15
gd loss = 29765.50681600091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29680.32566377488
gradient descent iteration = 16
gd loss = 29680.32566377488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29595.80059146912
gradient descent iteration = 17
gd loss = 29595.80059146912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29511.88733751108
gradient descent iteration = 18
gd loss = 29511.88733751108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29428.54568853992
gradient descent iteration = 19
gd loss = 29428.54568853992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29345.73836253935
gradient descent iteration = 20
gd loss = 29345.73836253935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29263.43035217176
gradient descent iteration = 21
gd loss = 29263.43035217176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29181.58854009504
gradient descent iteration = 22
gd loss = 29181.58854009504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29100.18158849249
gradient descent iteration = 23
gd loss = 29100.18158849249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 29019.17964525668
gradient descent iteration = 24
gd loss = 29019.17964525668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28938.55409005141
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 28938.55409005141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28803.18504515441
gradient descent iteration = 1
gd loss = 28803.18504515441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28674.82738910157
gradient descent iteration = 2
gd loss = 28674.82738910157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28552.19317557766
gradient descent iteration = 3
gd loss = 28552.19317557766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28434.32000759252
gradient descent iteration = 4
gd loss = 28434.32000759252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28320.47848830915
gradient descent iteration = 5
gd loss = 28320.47848830915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28210.10731287241
gradient descent iteration = 6
gd loss = 28210.10731287241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 28102.76832535716
gradient descent iteration = 7
gd loss = 28102.76832535716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27998.11454658157
gradient descent iteration = 8
gd loss = 27998.11454658157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27895.86693943849
gradient descent iteration = 9
gd loss = 27895.86693943849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27795.79735266562
gradient descent iteration = 10
gd loss = 27795.79735266562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27697.71637930851
gradient descent iteration = 11
gd loss = 27697.71637930851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27601.4649158015
gradient descent iteration = 12
gd loss = 27601.4649158015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27506.90821954496
gradient descent iteration = 13
gd loss = 27506.90821954496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27413.93140913859
gradient descent iteration = 14
gd loss = 27413.93140913859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27322.43582229085
gradient descent iteration = 15
gd loss = 27322.43582229085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27232.33587042425
gradient descent iteration = 16
gd loss = 27232.33587042425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27143.55621770351
gradient descent iteration = 17
gd loss = 27143.55621770351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 27056.03046567954
gradient descent iteration = 18
gd loss = 27056.03046567954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26969.69957792572
gradient descent iteration = 19
gd loss = 26969.69957792572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26884.5108467707
gradient descent iteration = 20
gd loss = 26884.5108467707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26800.41711190241
gradient descent iteration = 21
gd loss = 26800.41711190241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26717.37566252282
gradient descent iteration = 22
gd loss = 26717.37566252282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26635.34794574793
gradient descent iteration = 23
gd loss = 26635.34794574793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26554.30032680342
gradient descent iteration = 24
gd loss = 26554.30032680342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26474.20397293601
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 26474.20397293601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26395.66328140814
gradient descent iteration = 1
gd loss = 26395.66328140814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26322.97833395317
gradient descent iteration = 2
gd loss = 26322.97833395317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26254.56685997096
gradient descent iteration = 3
gd loss = 26254.56685997096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26189.36977212772
gradient descent iteration = 4
gd loss = 26189.36977212772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26126.67374921422
gradient descent iteration = 5
gd loss = 26126.67374921422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26065.99319148679
gradient descent iteration = 6
gd loss = 26065.99319148679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 26006.99239075881
gradient descent iteration = 7
gd loss = 26006.99239075881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25949.43453601369
gradient descent iteration = 8
gd loss = 25949.43453601369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25893.14843382551
gradient descent iteration = 9
gd loss = 25893.14843382551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25838.00679228987
gradient descent iteration = 10
gd loss = 25838.00679228987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25783.91207486408
gradient descent iteration = 11
gd loss = 25783.91207486408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25730.78719372844
gradient descent iteration = 12
gd loss = 25730.78719372844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25678.56935049619
gradient descent iteration = 13
gd loss = 25678.56935049619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25627.20596572705
gradient descent iteration = 14
gd loss = 25627.20596572705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25576.65196397047
gradient descent iteration = 15
gd loss = 25576.65196397047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25526.86793743319
gradient descent iteration = 16
gd loss = 25526.86793743319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25477.81888525392
gradient descent iteration = 17
gd loss = 25477.81888525392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25429.47329995056
gradient descent iteration = 18
gd loss = 25429.47329995056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25381.80255359181
gradient descent iteration = 19
gd loss = 25381.80255359181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25334.78042044656
gradient descent iteration = 20
gd loss = 25334.78042044656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25288.38270173657
gradient descent iteration = 21
gd loss = 25288.38270173657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25242.5869344098
gradient descent iteration = 22
gd loss = 25242.5869344098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25197.37220197248
gradient descent iteration = 23
gd loss = 25197.37220197248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25152.71895475404
gradient descent iteration = 24
gd loss = 25152.71895475404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25108.60885132915
Initial loss = 31229.31111194195
Final loss = 25108.60885132915
Deformation gradient control sequence optimization finished.
Animation interval 15 took 1355 seconds.
Full animation took 21648 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 16************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 25323.80495473373
initial norm = 782.878138344728
convergence norm = 0.782878138344728
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 25323.80495473373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25246.64276171001
gradient descent iteration = 1
gd loss = 25246.64276171001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25171.345733682
gradient descent iteration = 2
gd loss = 25171.345733682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25097.54292425437
gradient descent iteration = 3
gd loss = 25097.54292425437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 25024.96440427061
gradient descent iteration = 4
gd loss = 25024.96440427061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24953.40471856609
gradient descent iteration = 5
gd loss = 24953.40471856609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24882.70201927874
gradient descent iteration = 6
gd loss = 24882.70201927874
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24812.72692508709
gradient descent iteration = 7
gd loss = 24812.72692508709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24743.37693348009
gradient descent iteration = 8
gd loss = 24743.37693348009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24674.57231463996
gradient descent iteration = 9
gd loss = 24674.57231463996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24606.25295638075
gradient descent iteration = 10
gd loss = 24606.25295638075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24538.37371673752
gradient descent iteration = 11
gd loss = 24538.37371673752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24470.89903854639
gradient descent iteration = 12
gd loss = 24470.89903854639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24403.8001112949
gradient descent iteration = 13
gd loss = 24403.8001112949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24337.05184740443
gradient descent iteration = 14
gd loss = 24337.05184740443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24270.63037187438
gradient descent iteration = 15
gd loss = 24270.63037187438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24204.51249691962
gradient descent iteration = 16
gd loss = 24204.51249691962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24138.67612427852
gradient descent iteration = 17
gd loss = 24138.67612427852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24073.10010872647
gradient descent iteration = 18
gd loss = 24073.10010872647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 24007.76433033001
gradient descent iteration = 19
gd loss = 24007.76433033001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23942.65033776926
gradient descent iteration = 20
gd loss = 23942.65033776926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23877.74146014206
gradient descent iteration = 21
gd loss = 23877.74146014206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23813.0228009089
gradient descent iteration = 22
gd loss = 23813.0228009089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23748.48085338831
gradient descent iteration = 23
gd loss = 23748.48085338831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23684.10320785651
gradient descent iteration = 24
gd loss = 23684.10320785651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23619.87946391519
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 23619.87946391519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23528.69138025905
gradient descent iteration = 1
gd loss = 23528.69138025905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23442.06208282539
gradient descent iteration = 2
gd loss = 23442.06208282539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23359.08260242805
gradient descent iteration = 3
gd loss = 23359.08260242805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23279.11831909881
gradient descent iteration = 4
gd loss = 23279.11831909881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23201.7122722199
gradient descent iteration = 5
gd loss = 23201.7122722199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23126.52477094812
gradient descent iteration = 6
gd loss = 23126.52477094812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 23053.29531404881
gradient descent iteration = 7
gd loss = 23053.29531404881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22981.81832434397
gradient descent iteration = 8
gd loss = 22981.81832434397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22911.92755494333
gradient descent iteration = 9
gd loss = 22911.92755494333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22843.48592827179
gradient descent iteration = 10
gd loss = 22843.48592827179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22776.37875909085
gradient descent iteration = 11
gd loss = 22776.37875909085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22710.5087345783
gradient descent iteration = 12
gd loss = 22710.5087345783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22645.79212269084
gradient descent iteration = 13
gd loss = 22645.79212269084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22582.15607852674
gradient descent iteration = 14
gd loss = 22582.15607852674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22519.53662384721
gradient descent iteration = 15
gd loss = 22519.53662384721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22457.8773938474
gradient descent iteration = 16
gd loss = 22457.8773938474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22397.1284612
gradient descent iteration = 17
gd loss = 22397.1284612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22337.24522360727
gradient descent iteration = 18
gd loss = 22337.24522360727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22278.18761916436
gradient descent iteration = 19
gd loss = 22278.18761916436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22219.91934630611
gradient descent iteration = 20
gd loss = 22219.91934630611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22162.40737407664
gradient descent iteration = 21
gd loss = 22162.40737407664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22105.62139324165
gradient descent iteration = 22
gd loss = 22105.62139324165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 22049.53355417527
gradient descent iteration = 23
gd loss = 22049.53355417527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21994.11820495905
gradient descent iteration = 24
gd loss = 21994.11820495905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21939.35129055846
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 21939.35129055846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21886.10994591409
gradient descent iteration = 1
gd loss = 21886.10994591409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21837.05021732083
gradient descent iteration = 2
gd loss = 21837.05021732083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21790.84609606261
gradient descent iteration = 3
gd loss = 21790.84609606261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21746.69833461263
gradient descent iteration = 4
gd loss = 21746.69833461263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21704.11609440411
gradient descent iteration = 5
gd loss = 21704.11609440411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21662.78979633401
gradient descent iteration = 6
gd loss = 21662.78979633401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21622.51736183207
gradient descent iteration = 7
gd loss = 21622.51736183207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21583.16137997537
gradient descent iteration = 8
gd loss = 21583.16137997537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21544.62410068342
gradient descent iteration = 9
gd loss = 21544.62410068342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21506.83271662633
gradient descent iteration = 10
gd loss = 21506.83271662633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21469.7305687445
gradient descent iteration = 11
gd loss = 21469.7305687445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21433.27182701791
gradient descent iteration = 12
gd loss = 21433.27182701791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21397.41820676008
gradient descent iteration = 13
gd loss = 21397.41820676008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21362.13686053248
gradient descent iteration = 14
gd loss = 21362.13686053248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21327.39902897914
gradient descent iteration = 15
gd loss = 21327.39902897914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21293.17915631549
gradient descent iteration = 16
gd loss = 21293.17915631549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21259.45423991973
gradient descent iteration = 17
gd loss = 21259.45423991973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21226.20338400495
gradient descent iteration = 18
gd loss = 21226.20338400495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21193.40746437673
gradient descent iteration = 19
gd loss = 21193.40746437673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21161.04886226009
gradient descent iteration = 20
gd loss = 21161.04886226009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21129.11128535477
gradient descent iteration = 21
gd loss = 21129.11128535477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21097.57959161756
gradient descent iteration = 22
gd loss = 21097.57959161756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21066.43965828335
gradient descent iteration = 23
gd loss = 21066.43965828335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21035.67827492498
gradient descent iteration = 24
gd loss = 21035.67827492498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 21005.28305431563
Initial loss = 25323.80495473373
Final loss = 21005.28305431563
Deformation gradient control sequence optimization finished.
Animation interval 16 took 1359 seconds.
Full animation took 23007 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 17************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 20895.96925412088
initial norm = 813.1691820071341
convergence norm = 0.8131691820071341
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 20895.96925412088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20819.49168512746
gradient descent iteration = 1
gd loss = 20819.49168512746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20750.72906561114
gradient descent iteration = 2
gd loss = 20750.72906561114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20687.33734810899
gradient descent iteration = 3
gd loss = 20687.33734810899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20627.47657519169
gradient descent iteration = 4
gd loss = 20627.47657519169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20569.88486676616
gradient descent iteration = 5
gd loss = 20569.88486676616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20513.77164772318
gradient descent iteration = 6
gd loss = 20513.77164772318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20458.66271591365
gradient descent iteration = 7
gd loss = 20458.66271591365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20404.2750374358
gradient descent iteration = 8
gd loss = 20404.2750374358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20350.43674174717
gradient descent iteration = 9
gd loss = 20350.43674174717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20297.04251375849
gradient descent iteration = 10
gd loss = 20297.04251375849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20244.02728101309
gradient descent iteration = 11
gd loss = 20244.02728101309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20191.34923676946
gradient descent iteration = 12
gd loss = 20191.34923676946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20138.98013722639
gradient descent iteration = 13
gd loss = 20138.98013722639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20086.89950221163
gradient descent iteration = 14
gd loss = 20086.89950221163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 20035.09105329354
gradient descent iteration = 15
gd loss = 20035.09105329354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19983.54150360701
gradient descent iteration = 16
gd loss = 19983.54150360701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19932.23994681986
gradient descent iteration = 17
gd loss = 19932.23994681986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19881.1771077734
gradient descent iteration = 18
gd loss = 19881.1771077734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19830.34484177157
gradient descent iteration = 19
gd loss = 19830.34484177157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19779.73656344972
gradient descent iteration = 20
gd loss = 19779.73656344972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19729.34684128428
gradient descent iteration = 21
gd loss = 19729.34684128428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19679.17166828782
gradient descent iteration = 22
gd loss = 19679.17166828782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19629.20875414829
gradient descent iteration = 23
gd loss = 19629.20875414829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19579.4573583536
gradient descent iteration = 24
gd loss = 19579.4573583536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19529.9176223264
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 19529.9176223264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19464.68344598127
gradient descent iteration = 1
gd loss = 19464.68344598127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19402.93388215556
gradient descent iteration = 2
gd loss = 19402.93388215556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19344.09287083351
gradient descent iteration = 3
gd loss = 19344.09287083351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19287.72543995527
gradient descent iteration = 4
gd loss = 19287.72543995527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19233.49491634645
gradient descent iteration = 5
gd loss = 19233.49491634645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19181.13470401332
gradient descent iteration = 6
gd loss = 19181.13470401332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19130.42939537861
gradient descent iteration = 7
gd loss = 19130.42939537861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19081.20184781163
gradient descent iteration = 8
gd loss = 19081.20184781163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 19033.30435854605
gradient descent iteration = 9
gd loss = 19033.30435854605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18986.61263146461
gradient descent iteration = 10
gd loss = 18986.61263146461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18941.02087572536
gradient descent iteration = 11
gd loss = 18941.02087572536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18896.43803297695
gradient descent iteration = 12
gd loss = 18896.43803297695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18852.78520252728
gradient descent iteration = 13
gd loss = 18852.78520252728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18809.9936828725
gradient descent iteration = 14
gd loss = 18809.9936828725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18768.00319865879
gradient descent iteration = 15
gd loss = 18768.00319865879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18726.76047805751
gradient descent iteration = 16
gd loss = 18726.76047805751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18686.21818925377
gradient descent iteration = 17
gd loss = 18686.21818925377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18646.33390884505
gradient descent iteration = 18
gd loss = 18646.33390884505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18607.06928831883
gradient descent iteration = 19
gd loss = 18607.06928831883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18568.38937571917
gradient descent iteration = 20
gd loss = 18568.38937571917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18530.26208459777
gradient descent iteration = 21
gd loss = 18530.26208459777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18492.65791599482
gradient descent iteration = 22
gd loss = 18492.65791599482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18455.54951152598
gradient descent iteration = 23
gd loss = 18455.54951152598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18418.91114481467
gradient descent iteration = 24
gd loss = 18418.91114481467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18382.71844483897
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 18382.71844483897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18343.69096086487
gradient descent iteration = 1
gd loss = 18343.69096086487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18308.2107181701
gradient descent iteration = 2
gd loss = 18308.2107181701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18274.9871534354
gradient descent iteration = 3
gd loss = 18274.9871534354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18243.32202751412
gradient descent iteration = 4
gd loss = 18243.32202751412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18212.82103019538
gradient descent iteration = 5
gd loss = 18212.82103019538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18183.24962952787
gradient descent iteration = 6
gd loss = 18183.24962952787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18154.45993631012
gradient descent iteration = 7
gd loss = 18154.45993631012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18126.35276749542
gradient descent iteration = 8
gd loss = 18126.35276749542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18098.85744042746
gradient descent iteration = 9
gd loss = 18098.85744042746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18071.920696933
gradient descent iteration = 10
gd loss = 18071.920696933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18045.50042391933
gradient descent iteration = 11
gd loss = 18045.50042391933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 18019.56197020219
gradient descent iteration = 12
gd loss = 18019.56197020219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17994.07591202117
gradient descent iteration = 13
gd loss = 17994.07591202117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17969.0166577657
gradient descent iteration = 14
gd loss = 17969.0166577657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17944.36154437198
gradient descent iteration = 15
gd loss = 17944.36154437198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17920.09022595776
gradient descent iteration = 16
gd loss = 17920.09022595776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17896.18425875177
gradient descent iteration = 17
gd loss = 17896.18425875177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17872.62682610988
gradient descent iteration = 18
gd loss = 17872.62682610988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17849.40249338291
gradient descent iteration = 19
gd loss = 17849.40249338291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17826.49701807523
gradient descent iteration = 20
gd loss = 17826.49701807523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17803.89725990799
gradient descent iteration = 21
gd loss = 17803.89725990799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17781.59111388499
gradient descent iteration = 22
gd loss = 17781.59111388499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17759.56736436085
gradient descent iteration = 23
gd loss = 17759.56736436085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17737.81556206093
gradient descent iteration = 24
gd loss = 17737.81556206093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17716.32599403723
Initial loss = 20895.96925412088
Final loss = 17716.32599403723
Deformation gradient control sequence optimization finished.
Animation interval 17 took 1359 seconds.
Full animation took 24366 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 18************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 17531.16274616409
initial norm = 848.4912509394215
convergence norm = 0.8484912509394216
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 17531.16274616409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17454.35661237057
gradient descent iteration = 1
gd loss = 17454.35661237057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17390.88770920438
gradient descent iteration = 2
gd loss = 17390.88770920438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17336.88952069968
gradient descent iteration = 3
gd loss = 17336.88952069968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17288.94649613493
gradient descent iteration = 4
gd loss = 17288.94649613493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17244.71508094253
gradient descent iteration = 5
gd loss = 17244.71508094253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17202.79698123328
gradient descent iteration = 6
gd loss = 17202.79698123328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17162.3602008258
gradient descent iteration = 7
gd loss = 17162.3602008258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17122.8940637048
gradient descent iteration = 8
gd loss = 17122.8940637048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17084.08139667764
gradient descent iteration = 9
gd loss = 17084.08139667764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17045.72461514935
gradient descent iteration = 10
gd loss = 17045.72461514935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 17007.69964078009
gradient descent iteration = 11
gd loss = 17007.69964078009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16969.9273381236
gradient descent iteration = 12
gd loss = 16969.9273381236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16932.35626892444
gradient descent iteration = 13
gd loss = 16932.35626892444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16894.95353992113
gradient descent iteration = 14
gd loss = 16894.95353992113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16857.70073901673
gradient descent iteration = 15
gd loss = 16857.70073901673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16820.59281628661
gradient descent iteration = 16
gd loss = 16820.59281628661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16783.637951767
gradient descent iteration = 17
gd loss = 16783.637951767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16746.85695151994
gradient descent iteration = 18
gd loss = 16746.85695151994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16710.27822179982
gradient descent iteration = 19
gd loss = 16710.27822179982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16673.92874953257
gradient descent iteration = 20
gd loss = 16673.92874953257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16637.82585824205
gradient descent iteration = 21
gd loss = 16637.82585824205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16601.97395487143
gradient descent iteration = 22
gd loss = 16601.97395487143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16566.36621514786
gradient descent iteration = 23
gd loss = 16566.36621514786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16530.98976845311
gradient descent iteration = 24
gd loss = 16530.98976845311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16495.83064287919
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 16495.83064287919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16442.49179282513
gradient descent iteration = 1
gd loss = 16442.49179282513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16393.43837935236
gradient descent iteration = 2
gd loss = 16393.43837935236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16347.65998493393
gradient descent iteration = 3
gd loss = 16347.65998493393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16304.48753663216
gradient descent iteration = 4
gd loss = 16304.48753663216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16263.44985094994
gradient descent iteration = 5
gd loss = 16263.44985094994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16224.19913418142
gradient descent iteration = 6
gd loss = 16224.19913418142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16186.46929993313
gradient descent iteration = 7
gd loss = 16186.46929993313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16150.05120461228
gradient descent iteration = 8
gd loss = 16150.05120461228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16114.77704287679
gradient descent iteration = 9
gd loss = 16114.77704287679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16080.5100715008
gradient descent iteration = 10
gd loss = 16080.5100715008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16047.13745160863
gradient descent iteration = 11
gd loss = 16047.13745160863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 16014.56505980465
gradient descent iteration = 12
gd loss = 16014.56505980465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15982.7136470992
gradient descent iteration = 13
gd loss = 15982.7136470992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15951.51593792592
gradient descent iteration = 14
gd loss = 15951.51593792592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15920.9144432864
gradient descent iteration = 15
gd loss = 15920.9144432864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15890.85991742096
gradient descent iteration = 16
gd loss = 15890.85991742096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15861.31012356811
gradient descent iteration = 17
gd loss = 15861.31012356811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15832.22857290395
gradient descent iteration = 18
gd loss = 15832.22857290395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15803.58331207844
gradient descent iteration = 19
gd loss = 15803.58331207844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15775.34618218734
gradient descent iteration = 20
gd loss = 15775.34618218734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15747.49236055223
gradient descent iteration = 21
gd loss = 15747.49236055223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15719.99985242108
gradient descent iteration = 22
gd loss = 15719.99985242108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15692.8489872331
gradient descent iteration = 23
gd loss = 15692.8489872331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15666.02211749738
gradient descent iteration = 24
gd loss = 15666.02211749738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15639.50341456238
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 15639.50341456238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15606.94898063013
gradient descent iteration = 1
gd loss = 15606.94898063013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15578.23129339828
gradient descent iteration = 2
gd loss = 15578.23129339828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15551.56146723009
gradient descent iteration = 3
gd loss = 15551.56146723009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15526.20026676053
gradient descent iteration = 4
gd loss = 15526.20026676053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15501.80481068013
gradient descent iteration = 5
gd loss = 15501.80481068013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15478.19403148086
gradient descent iteration = 6
gd loss = 15478.19403148086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15455.25895866296
gradient descent iteration = 7
gd loss = 15455.25895866296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15432.92584464384
gradient descent iteration = 8
gd loss = 15432.92584464384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15411.13987252958
gradient descent iteration = 9
gd loss = 15411.13987252958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15389.85742917883
gradient descent iteration = 10
gd loss = 15389.85742917883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15369.04217244424
gradient descent iteration = 11
gd loss = 15369.04217244424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15348.6628792485
gradient descent iteration = 12
gd loss = 15348.6628792485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15328.69217474115
gradient descent iteration = 13
gd loss = 15328.69217474115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15309.10572173617
gradient descent iteration = 14
gd loss = 15309.10572173617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15289.88166841502
gradient descent iteration = 15
gd loss = 15289.88166841502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15271.00025167918
gradient descent iteration = 16
gd loss = 15271.00025167918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15252.44349738546
gradient descent iteration = 17
gd loss = 15252.44349738546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15234.19497951761
gradient descent iteration = 18
gd loss = 15234.19497951761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15216.23962572769
gradient descent iteration = 19
gd loss = 15216.23962572769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15198.5635554907
gradient descent iteration = 20
gd loss = 15198.5635554907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15181.15394756369
gradient descent iteration = 21
gd loss = 15181.15394756369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15163.99892910246
gradient descent iteration = 22
gd loss = 15163.99892910246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15147.0874770361
gradient descent iteration = 23
gd loss = 15147.0874770361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15130.40933551616
gradient descent iteration = 24
gd loss = 15130.40933551616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 15113.9549400456
Initial loss = 17531.16274616409
Final loss = 15113.9549400456
Deformation gradient control sequence optimization finished.
Animation interval 18 took 1356 seconds.
Full animation took 25723 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 19************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 15025.60197761599
initial norm = 873.1739143486302
convergence norm = 0.8731739143486302
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 15025.60197761599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14948.84823617343
gradient descent iteration = 1
gd loss = 14948.84823617343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14890.82388300723
gradient descent iteration = 2
gd loss = 14890.82388300723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14846.85883707313
gradient descent iteration = 3
gd loss = 14846.85883707313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14810.95914936112
gradient descent iteration = 4
gd loss = 14810.95914936112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14778.64539012308
gradient descent iteration = 5
gd loss = 14778.64539012308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14748.00219082358
gradient descent iteration = 6
gd loss = 14748.00219082358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14718.26277560891
gradient descent iteration = 7
gd loss = 14718.26277560891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14689.08212663285
gradient descent iteration = 8
gd loss = 14689.08212663285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14660.29448117415
gradient descent iteration = 9
gd loss = 14660.29448117415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14631.81268008664
gradient descent iteration = 10
gd loss = 14631.81268008664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14603.58531444438
gradient descent iteration = 11
gd loss = 14603.58531444438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14575.57840907943
gradient descent iteration = 12
gd loss = 14575.57840907943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14547.76770128881
gradient descent iteration = 13
gd loss = 14547.76770128881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14520.13565573063
gradient descent iteration = 14
gd loss = 14520.13565573063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14492.67082681801
gradient descent iteration = 15
gd loss = 14492.67082681801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14465.36785874214
gradient descent iteration = 16
gd loss = 14465.36785874214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14438.2257435045
gradient descent iteration = 17
gd loss = 14438.2257435045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14411.24486598784
gradient descent iteration = 18
gd loss = 14411.24486598784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14384.42506016572
gradient descent iteration = 19
gd loss = 14384.42506016572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14357.76478187014
gradient descent iteration = 20
gd loss = 14357.76478187014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14331.26116686043
gradient descent iteration = 21
gd loss = 14331.26116686043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14304.91090246415
gradient descent iteration = 22
gd loss = 14304.91090246415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14278.71080899806
gradient descent iteration = 23
gd loss = 14278.71080899806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14252.65783983088
gradient descent iteration = 24
gd loss = 14252.65783983088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14226.74914582804
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 14226.74914582804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14184.81582758779
gradient descent iteration = 1
gd loss = 14184.81582758779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14147.13675250004
gradient descent iteration = 2
gd loss = 14147.13675250004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14112.51431137477
gradient descent iteration = 3
gd loss = 14112.51431137477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14080.21309038958
gradient descent iteration = 4
gd loss = 14080.21309038958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14049.74020752899
gradient descent iteration = 5
gd loss = 14049.74020752899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 14020.74435068698
gradient descent iteration = 6
gd loss = 14020.74435068698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13992.96484965458
gradient descent iteration = 7
gd loss = 13992.96484965458
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13966.20312849161
gradient descent iteration = 8
gd loss = 13966.20312849161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13940.30497820645
gradient descent iteration = 9
gd loss = 13940.30497820645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13915.1490590993
gradient descent iteration = 10
gd loss = 13915.1490590993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13890.63880350252
gradient descent iteration = 11
gd loss = 13890.63880350252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13866.69660890578
gradient descent iteration = 12
gd loss = 13866.69660890578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13843.25952279608
gradient descent iteration = 13
gd loss = 13843.25952279608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13820.27609038281
gradient descent iteration = 14
gd loss = 13820.27609038281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13797.7039522534
gradient descent iteration = 15
gd loss = 13797.7039522534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13775.50792318757
gradient descent iteration = 16
gd loss = 13775.50792318757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13753.6585532636
gradient descent iteration = 17
gd loss = 13753.6585532636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13732.13103263053
gradient descent iteration = 18
gd loss = 13732.13103263053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13710.90439788259
gradient descent iteration = 19
gd loss = 13710.90439788259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13689.96080239085
gradient descent iteration = 20
gd loss = 13689.96080239085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13669.28497251628
gradient descent iteration = 21
gd loss = 13669.28497251628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13648.8638007107
gradient descent iteration = 22
gd loss = 13648.8638007107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13628.68600277831
gradient descent iteration = 23
gd loss = 13628.68600277831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13608.74184849617
gradient descent iteration = 24
gd loss = 13608.74184849617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13589.02294065651
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 13589.02294065651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13562.94862167729
gradient descent iteration = 1
gd loss = 13562.94862167729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13540.58937018499
gradient descent iteration = 2
gd loss = 13540.58937018499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13519.74768857487
gradient descent iteration = 3
gd loss = 13519.74768857487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13499.84911755863
gradient descent iteration = 4
gd loss = 13499.84911755863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13480.6780087725
gradient descent iteration = 5
gd loss = 13480.6780087725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13462.12250096723
gradient descent iteration = 6
gd loss = 13462.12250096723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13444.10992609426
gradient descent iteration = 7
gd loss = 13444.10992609426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13426.58631546485
gradient descent iteration = 8
gd loss = 13426.58631546485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13409.50855645913
gradient descent iteration = 9
gd loss = 13409.50855645913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13392.84079051618
gradient descent iteration = 10
gd loss = 13392.84079051618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13376.55246617221
gradient descent iteration = 11
gd loss = 13376.55246617221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13360.61713677608
gradient descent iteration = 12
gd loss = 13360.61713677608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13345.01164598136
gradient descent iteration = 13
gd loss = 13345.01164598136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13329.71553632627
gradient descent iteration = 14
gd loss = 13329.71553632627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13314.71060247041
gradient descent iteration = 15
gd loss = 13314.71060247041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13299.98054348928
gradient descent iteration = 16
gd loss = 13299.98054348928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13285.51068568072
gradient descent iteration = 17
gd loss = 13285.51068568072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13271.28775868633
gradient descent iteration = 18
gd loss = 13271.28775868633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13257.29971655915
gradient descent iteration = 19
gd loss = 13257.29971655915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13243.53558387009
gradient descent iteration = 20
gd loss = 13243.53558387009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13229.98531907357
gradient descent iteration = 21
gd loss = 13229.98531907357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13216.6397049991
gradient descent iteration = 22
gd loss = 13216.6397049991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13203.49025504791
gradient descent iteration = 23
gd loss = 13203.49025504791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13190.52913287078
gradient descent iteration = 24
gd loss = 13190.52913287078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13177.74908274863
Initial loss = 15025.60197761599
Final loss = 13177.74908274863
Deformation gradient control sequence optimization finished.
Animation interval 19 took 1355 seconds.
Full animation took 27079 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 20************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 13117.55375805488
initial norm = 738.6446099970372
convergence norm = 0.7386446099970372
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 13117.55375805488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13054.64329828987
gradient descent iteration = 1
gd loss = 13054.64329828987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 13010.57748178792
gradient descent iteration = 2
gd loss = 13010.57748178792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12978.93263992344
gradient descent iteration = 3
gd loss = 12978.93263992344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12952.65320588
gradient descent iteration = 4
gd loss = 12952.65320588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12928.42131064794
gradient descent iteration = 5
gd loss = 12928.42131064794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12905.04055845214
gradient descent iteration = 6
gd loss = 12905.04055845214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12882.12281145625
gradient descent iteration = 7
gd loss = 12882.12281145625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12859.54476915777
gradient descent iteration = 8
gd loss = 12859.54476915777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12837.25549401543
gradient descent iteration = 9
gd loss = 12837.25549401543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12815.22604949577
gradient descent iteration = 10
gd loss = 12815.22604949577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12793.43607339523
gradient descent iteration = 11
gd loss = 12793.43607339523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12771.86953457048
gradient descent iteration = 12
gd loss = 12771.86953457048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12750.51313175409
gradient descent iteration = 13
gd loss = 12750.51313175409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12729.35551729525
gradient descent iteration = 14
gd loss = 12729.35551729525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12708.38661261293
gradient descent iteration = 15
gd loss = 12708.38661261293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12687.59724230647
gradient descent iteration = 16
gd loss = 12687.59724230647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12666.97890015545
gradient descent iteration = 17
gd loss = 12666.97890015545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12646.52369987919
gradient descent iteration = 18
gd loss = 12646.52369987919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12626.22447979647
gradient descent iteration = 19
gd loss = 12626.22447979647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12606.07464357376
gradient descent iteration = 20
gd loss = 12606.07464357376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12586.06799630833
gradient descent iteration = 21
gd loss = 12586.06799630833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12566.1986642623
gradient descent iteration = 22
gd loss = 12566.1986642623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12546.46105872254
gradient descent iteration = 23
gd loss = 12546.46105872254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12526.84982991399
gradient descent iteration = 24
gd loss = 12526.84982991399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12507.35983994809
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 12507.35983994809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12473.50451948449
gradient descent iteration = 1
gd loss = 12473.50451948449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12443.96560020624
gradient descent iteration = 2
gd loss = 12443.96560020624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12417.26792965105
gradient descent iteration = 3
gd loss = 12417.26792965105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12392.61480307278
gradient descent iteration = 4
gd loss = 12392.61480307278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12369.50230797516
gradient descent iteration = 5
gd loss = 12369.50230797516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12347.58811361875
gradient descent iteration = 6
gd loss = 12347.58811361875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12326.630328258
gradient descent iteration = 7
gd loss = 12326.630328258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12306.45347466906
gradient descent iteration = 8
gd loss = 12306.45347466906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12286.92749900086
gradient descent iteration = 9
gd loss = 12286.92749900086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12267.95405272836
gradient descent iteration = 10
gd loss = 12267.95405272836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12249.45723508017
gradient descent iteration = 11
gd loss = 12249.45723508017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12231.37727757623
gradient descent iteration = 12
gd loss = 12231.37727757623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12213.66659210525
gradient descent iteration = 13
gd loss = 12213.66659210525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12196.28740696505
gradient descent iteration = 14
gd loss = 12196.28740696505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12179.20875931106
gradient descent iteration = 15
gd loss = 12179.20875931106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12162.40499350746
gradient descent iteration = 16
gd loss = 12162.40499350746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12145.8555642732
gradient descent iteration = 17
gd loss = 12145.8555642732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12129.54360212808
gradient descent iteration = 18
gd loss = 12129.54360212808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12113.45515872144
gradient descent iteration = 19
gd loss = 12113.45515872144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12097.57953173239
gradient descent iteration = 20
gd loss = 12097.57953173239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12081.90962482501
gradient descent iteration = 21
gd loss = 12081.90962482501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12066.44071832498
gradient descent iteration = 22
gd loss = 12066.44071832498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12051.16996629123
gradient descent iteration = 23
gd loss = 12051.16996629123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12036.09599225595
gradient descent iteration = 24
gd loss = 12036.09599225595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12021.21832227813
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 12021.21832227813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 12001.6146658064
gradient descent iteration = 1
gd loss = 12001.6146658064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11985.42417227296
gradient descent iteration = 2
gd loss = 11985.42417227296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11970.27487977733
gradient descent iteration = 3
gd loss = 11970.27487977733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11955.78831803905
gradient descent iteration = 4
gd loss = 11955.78831803905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11941.83277551513
gradient descent iteration = 5
gd loss = 11941.83277551513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11928.33450695257
gradient descent iteration = 6
gd loss = 11928.33450695257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11915.24129677133
gradient descent iteration = 7
gd loss = 11915.24129677133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11902.51245293159
gradient descent iteration = 8
gd loss = 11902.51245293159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11890.11483866797
gradient descent iteration = 9
gd loss = 11890.11483866797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11878.02077678313
gradient descent iteration = 10
gd loss = 11878.02077678313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11866.20674052521
gradient descent iteration = 11
gd loss = 11866.20674052521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11854.65246417695
gradient descent iteration = 12
gd loss = 11854.65246417695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11843.34030504604
gradient descent iteration = 13
gd loss = 11843.34030504604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11832.25477813965
gradient descent iteration = 14
gd loss = 11832.25477813965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11821.38219978103
gradient descent iteration = 15
gd loss = 11821.38219978103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11810.710377568
gradient descent iteration = 16
gd loss = 11810.710377568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11800.22837965829
gradient descent iteration = 17
gd loss = 11800.22837965829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11789.92635125932
gradient descent iteration = 18
gd loss = 11789.92635125932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11779.7953665792
gradient descent iteration = 19
gd loss = 11779.7953665792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11769.8273037196
gradient descent iteration = 20
gd loss = 11769.8273037196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11760.01474087902
gradient descent iteration = 21
gd loss = 11760.01474087902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11750.35087026308
gradient descent iteration = 22
gd loss = 11750.35087026308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11740.82943280939
gradient descent iteration = 23
gd loss = 11740.82943280939
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11731.44467321777
gradient descent iteration = 24
gd loss = 11731.44467321777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11722.19126639625
Initial loss = 13117.55375805488
Final loss = 11722.19126639625
Deformation gradient control sequence optimization finished.
Animation interval 20 took 1353 seconds.
Full animation took 28433 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 21************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 11677.70319194587
initial norm = 741.9466962283892
convergence norm = 0.7419466962283893
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 11677.70319194587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11616.03867740995
gradient descent iteration = 1
gd loss = 11616.03867740995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11576.76943754409
gradient descent iteration = 2
gd loss = 11576.76943754409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11552.36723004095
gradient descent iteration = 3
gd loss = 11552.36723004095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11532.24903571367
gradient descent iteration = 4
gd loss = 11532.24903571367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11513.3345075843
gradient descent iteration = 5
gd loss = 11513.3345075843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11495.01621244892
gradient descent iteration = 6
gd loss = 11495.01621244892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11477.13798601545
gradient descent iteration = 7
gd loss = 11477.13798601545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11459.61714355552
gradient descent iteration = 8
gd loss = 11459.61714355552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11442.39751945454
gradient descent iteration = 9
gd loss = 11442.39751945454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11425.43792096008
gradient descent iteration = 10
gd loss = 11425.43792096008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11408.70728509068
gradient descent iteration = 11
gd loss = 11408.70728509068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11392.18186054639
gradient descent iteration = 12
gd loss = 11392.18186054639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11375.84331680643
gradient descent iteration = 13
gd loss = 11375.84331680643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11359.67715926424
gradient descent iteration = 14
gd loss = 11359.67715926424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11343.6711297157
gradient descent iteration = 15
gd loss = 11343.6711297157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11327.81397693947
gradient descent iteration = 16
gd loss = 11327.81397693947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11312.0943559635
gradient descent iteration = 17
gd loss = 11312.0943559635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11296.49984716122
gradient descent iteration = 18
gd loss = 11296.49984716122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11281.01651536715
gradient descent iteration = 19
gd loss = 11281.01651536715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11265.63144975118
gradient descent iteration = 20
gd loss = 11265.63144975118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11250.33292731793
gradient descent iteration = 21
gd loss = 11250.33292731793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11235.11485793888
gradient descent iteration = 22
gd loss = 11235.11485793888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11219.9801409192
gradient descent iteration = 23
gd loss = 11219.9801409192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11204.93952618337
gradient descent iteration = 24
gd loss = 11204.93952618337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11190.01395212469
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 11190.01395212469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11163.87775031741
gradient descent iteration = 1
gd loss = 11163.87775031741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11142.09532371667
gradient descent iteration = 2
gd loss = 11142.09532371667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11122.90902042405
gradient descent iteration = 3
gd loss = 11122.90902042405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11105.47147668159
gradient descent iteration = 4
gd loss = 11105.47147668159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11089.28089417821
gradient descent iteration = 5
gd loss = 11089.28089417821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11074.01784400319
gradient descent iteration = 6
gd loss = 11074.01784400319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11059.47124825765
gradient descent iteration = 7
gd loss = 11059.47124825765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11045.49718406037
gradient descent iteration = 8
gd loss = 11045.49718406037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11031.99478272442
gradient descent iteration = 9
gd loss = 11031.99478272442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11018.89141552686
gradient descent iteration = 10
gd loss = 11018.89141552686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 11006.13336009008
gradient descent iteration = 11
gd loss = 11006.13336009008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10993.67980462536
gradient descent iteration = 12
gd loss = 10993.67980462536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10981.4989308237
gradient descent iteration = 13
gd loss = 10981.4989308237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10969.5653180125
gradient descent iteration = 14
gd loss = 10969.5653180125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10957.85819229013
gradient descent iteration = 15
gd loss = 10957.85819229013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10946.36022471387
gradient descent iteration = 16
gd loss = 10946.36022471387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10935.05670123567
gradient descent iteration = 17
gd loss = 10935.05670123567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10923.93493032657
gradient descent iteration = 18
gd loss = 10923.93493032657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10912.98379678794
gradient descent iteration = 19
gd loss = 10912.98379678794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10902.1934361517
gradient descent iteration = 20
gd loss = 10902.1934361517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10891.55499025134
gradient descent iteration = 21
gd loss = 10891.55499025134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10881.06041982191
gradient descent iteration = 22
gd loss = 10881.06041982191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10870.70236045323
gradient descent iteration = 23
gd loss = 10870.70236045323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10860.47403416185
gradient descent iteration = 24
gd loss = 10860.47403416185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10850.36914839164
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 10850.36914839164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10836.96155109714
gradient descent iteration = 1
gd loss = 10836.96155109714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10826.13200798244
gradient descent iteration = 2
gd loss = 10826.13200798244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10815.93228535888
gradient descent iteration = 3
gd loss = 10815.93228535888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10806.17382806531
gradient descent iteration = 4
gd loss = 10806.17382806531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10796.77893536498
gradient descent iteration = 5
gd loss = 10796.77893536498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10787.69593552673
gradient descent iteration = 6
gd loss = 10787.69593552673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10778.88637523642
gradient descent iteration = 7
gd loss = 10778.88637523642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10770.32017005215
gradient descent iteration = 8
gd loss = 10770.32017005215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10761.97305197852
gradient descent iteration = 9
gd loss = 10761.97305197852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10753.82501777093
gradient descent iteration = 10
gd loss = 10753.82501777093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10745.85930200216
gradient descent iteration = 11
gd loss = 10745.85930200216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10738.06165905022
gradient descent iteration = 12
gd loss = 10738.06165905022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10730.41984410051
gradient descent iteration = 13
gd loss = 10730.41984410051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10722.92322768861
gradient descent iteration = 14
gd loss = 10722.92322768861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10715.56249633358
gradient descent iteration = 15
gd loss = 10715.56249633358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10708.32942482889
gradient descent iteration = 16
gd loss = 10708.32942482889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10701.21670208466
gradient descent iteration = 17
gd loss = 10701.21670208466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10694.21778747133
gradient descent iteration = 18
gd loss = 10694.21778747133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10687.3267935626
gradient descent iteration = 19
gd loss = 10687.3267935626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10680.53839345965
gradient descent iteration = 20
gd loss = 10680.53839345965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10673.84774504105
gradient descent iteration = 21
gd loss = 10673.84774504105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10667.25042846814
gradient descent iteration = 22
gd loss = 10667.25042846814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10660.74239319006
gradient descent iteration = 23
gd loss = 10660.74239319006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10654.31991440048
gradient descent iteration = 24
gd loss = 10654.31991440048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10647.97955875723
Initial loss = 11677.70319194587
Final loss = 10647.97955875723
Deformation gradient control sequence optimization finished.
Animation interval 21 took 1355 seconds.
Full animation took 29788 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 22************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 10635.22592295157
initial norm = 738.5377748799037
convergence norm = 0.7385377748799038
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 10635.22592295157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10573.78981915202
gradient descent iteration = 1
gd loss = 10573.78981915202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10534.85211428185
gradient descent iteration = 2
gd loss = 10534.85211428185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10512.09321750624
gradient descent iteration = 3
gd loss = 10512.09321750624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10495.4487272283
gradient descent iteration = 4
gd loss = 10495.4487272283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10480.26639141767
gradient descent iteration = 5
gd loss = 10480.26639141767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10465.752092538
gradient descent iteration = 6
gd loss = 10465.752092538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10451.70372151207
gradient descent iteration = 7
gd loss = 10451.70372151207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10438.00991486921
gradient descent iteration = 8
gd loss = 10438.00991486921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10424.60195985512
gradient descent iteration = 9
gd loss = 10424.60195985512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10411.43657016359
gradient descent iteration = 10
gd loss = 10411.43657016359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10398.48678835597
gradient descent iteration = 11
gd loss = 10398.48678835597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10385.74112969504
gradient descent iteration = 12
gd loss = 10385.74112969504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10373.20618871642
gradient descent iteration = 13
gd loss = 10373.20618871642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10360.92347439566
gradient descent iteration = 14
gd loss = 10360.92347439566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10348.99436455882
gradient descent iteration = 15
gd loss = 10348.99436455882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10337.61490856566
gradient descent iteration = 16
gd loss = 10337.61490856566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10327.01317153822
gradient descent iteration = 17
gd loss = 10327.01317153822
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10317.22027231844
gradient descent iteration = 18
gd loss = 10317.22027231844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10307.95000232583
gradient descent iteration = 19
gd loss = 10307.95000232583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10298.93415243519
gradient descent iteration = 20
gd loss = 10298.93415243519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10290.06253608095
gradient descent iteration = 21
gd loss = 10290.06253608095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10281.3119792987
gradient descent iteration = 22
gd loss = 10281.3119792987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10272.66791187248
gradient descent iteration = 23
gd loss = 10272.66791187248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10264.12937612383
gradient descent iteration = 24
gd loss = 10264.12937612383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10255.68625271534
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 10255.68625271534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10238.8380324541
gradient descent iteration = 1
gd loss = 10238.8380324541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10225.27469894798
gradient descent iteration = 2
gd loss = 10225.27469894798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10213.39311355485
gradient descent iteration = 3
gd loss = 10213.39311355485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10202.62100432894
gradient descent iteration = 4
gd loss = 10202.62100432894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10192.63794585706
gradient descent iteration = 5
gd loss = 10192.63794585706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10183.23930908313
gradient descent iteration = 6
gd loss = 10183.23930908313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10174.28813674911
gradient descent iteration = 7
gd loss = 10174.28813674911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10165.69018012426
gradient descent iteration = 8
gd loss = 10165.69018012426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10157.37904454018
gradient descent iteration = 9
gd loss = 10157.37904454018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10149.30689887582
gradient descent iteration = 10
gd loss = 10149.30689887582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10141.43851398124
gradient descent iteration = 11
gd loss = 10141.43851398124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10133.74736900596
gradient descent iteration = 12
gd loss = 10133.74736900596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10126.21307048663
gradient descent iteration = 13
gd loss = 10126.21307048663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10118.81961155333
gradient descent iteration = 14
gd loss = 10118.81961155333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10111.55418406155
gradient descent iteration = 15
gd loss = 10111.55418406155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10104.40639225616
gradient descent iteration = 16
gd loss = 10104.40639225616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10097.3676602782
gradient descent iteration = 17
gd loss = 10097.3676602782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10090.43083711357
gradient descent iteration = 18
gd loss = 10090.43083711357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10083.58988795606
gradient descent iteration = 19
gd loss = 10083.58988795606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10076.83962616259
gradient descent iteration = 20
gd loss = 10076.83962616259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10070.17554557755
gradient descent iteration = 21
gd loss = 10070.17554557755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10063.59369828718
gradient descent iteration = 22
gd loss = 10063.59369828718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10057.09060143017
gradient descent iteration = 23
gd loss = 10057.09060143017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10050.66315234479
gradient descent iteration = 24
gd loss = 10050.66315234479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10044.30856459259
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 10044.30856459259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10036.53708437471
gradient descent iteration = 1
gd loss = 10036.53708437471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10029.99323176325
gradient descent iteration = 2
gd loss = 10029.99323176325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10023.79040806529
gradient descent iteration = 3
gd loss = 10023.79040806529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10017.8315246678
gradient descent iteration = 4
gd loss = 10017.8315246678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10012.07285434895
gradient descent iteration = 5
gd loss = 10012.07285434895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10006.48484062316
gradient descent iteration = 6
gd loss = 10006.48484062316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 10001.04543875933
gradient descent iteration = 7
gd loss = 10001.04543875933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9995.737464539616
gradient descent iteration = 8
gd loss = 9995.737464539616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9990.547146180894
gradient descent iteration = 9
gd loss = 9990.547146180894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9985.463221510343
gradient descent iteration = 10
gd loss = 9985.463221510343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9980.476331885115
gradient descent iteration = 11
gd loss = 9980.476331885115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9975.578595706416
gradient descent iteration = 12
gd loss = 9975.578595706416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9970.763298360755
gradient descent iteration = 13
gd loss = 9970.763298360755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9966.024660511488
gradient descent iteration = 14
gd loss = 9966.024660511488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9961.357661990853
gradient descent iteration = 15
gd loss = 9961.357661990853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9956.757906046974
gradient descent iteration = 16
gd loss = 9956.757906046974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9952.221513960249
gradient descent iteration = 17
gd loss = 9952.221513960249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9947.745045282025
gradient descent iteration = 18
gd loss = 9947.745045282025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9943.325428061236
gradient descent iteration = 19
gd loss = 9943.325428061236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9938.959901503706
gradient descent iteration = 20
gd loss = 9938.959901503706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9934.64597178937
gradient descent iteration = 21
gd loss = 9934.64597178937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9930.38137554533
gradient descent iteration = 22
gd loss = 9930.38137554533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9926.164049028326
gradient descent iteration = 23
gd loss = 9926.164049028326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9921.992103084118
gradient descent iteration = 24
gd loss = 9921.992103084118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9917.863801912732
Initial loss = 10635.22592295157
Final loss = 9917.863801912732
Deformation gradient control sequence optimization finished.
Animation interval 22 took 1353 seconds.
Full animation took 31142 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 23************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9935.215059609367
initial norm = 676.2295799114087
convergence norm = 0.6762295799114086
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9935.215059609367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9879.726124906576
gradient descent iteration = 1
gd loss = 9879.726124906576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9845.406250805152
gradient descent iteration = 2
gd loss = 9845.406250805152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9824.766132535728
gradient descent iteration = 3
gd loss = 9824.766132535728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9809.284188835618
gradient descent iteration = 4
gd loss = 9809.284188835618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9795.389190448393
gradient descent iteration = 5
gd loss = 9795.389190448393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9782.442504897273
gradient descent iteration = 6
gd loss = 9782.442504897273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9770.185806896612
gradient descent iteration = 7
gd loss = 9770.185806896612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9758.581048290785
gradient descent iteration = 8
gd loss = 9758.581048290785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9747.826504533132
gradient descent iteration = 9
gd loss = 9747.826504533132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9738.263564051405
gradient descent iteration = 10
gd loss = 9738.263564051405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9729.797333065131
gradient descent iteration = 11
gd loss = 9729.797333065131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9721.834458242884
gradient descent iteration = 12
gd loss = 9721.834458242884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9714.073937541903
gradient descent iteration = 13
gd loss = 9714.073937541903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9706.483132676851
gradient descent iteration = 14
gd loss = 9706.483132676851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9699.034978925787
gradient descent iteration = 15
gd loss = 9699.034978925787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9691.728577648186
gradient descent iteration = 16
gd loss = 9691.728577648186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9684.541807612011
gradient descent iteration = 17
gd loss = 9684.541807612011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9677.477589028291
gradient descent iteration = 18
gd loss = 9677.477589028291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9670.516518130758
gradient descent iteration = 19
gd loss = 9670.516518130758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9663.664013818203
gradient descent iteration = 20
gd loss = 9663.664013818203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9656.902450112872
gradient descent iteration = 21
gd loss = 9656.902450112872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9650.23884993176
gradient descent iteration = 22
gd loss = 9650.23884993176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9643.656758757837
gradient descent iteration = 23
gd loss = 9643.656758757837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9637.164387059373
gradient descent iteration = 24
gd loss = 9637.164387059373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9630.746088143707
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 9630.746088143707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9617.198878960868
gradient descent iteration = 1
gd loss = 9617.198878960868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9606.765673245465
gradient descent iteration = 2
gd loss = 9606.765673245465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9597.65974928725
gradient descent iteration = 3
gd loss = 9597.65974928725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9589.405120379979
gradient descent iteration = 4
gd loss = 9589.405120379979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9581.754711541298
gradient descent iteration = 5
gd loss = 9581.754711541298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9574.55255550425
gradient descent iteration = 6
gd loss = 9574.55255550425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9567.694327623552
gradient descent iteration = 7
gd loss = 9567.694327623552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9561.108135398399
gradient descent iteration = 8
gd loss = 9561.108135398399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9554.743240317783
gradient descent iteration = 9
gd loss = 9554.743240317783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9548.563027069491
gradient descent iteration = 10
gd loss = 9548.563027069491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9542.540490302372
gradient descent iteration = 11
gd loss = 9542.540490302372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9536.65528484093
gradient descent iteration = 12
gd loss = 9536.65528484093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9530.891766704699
gradient descent iteration = 13
gd loss = 9530.891766704699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9525.237669299197
gradient descent iteration = 14
gd loss = 9525.237669299197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9519.683192946295
gradient descent iteration = 15
gd loss = 9519.683192946295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9514.220372959773
gradient descent iteration = 16
gd loss = 9514.220372959773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9508.842638973691
gradient descent iteration = 17
gd loss = 9508.842638973691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9503.544492419487
gradient descent iteration = 18
gd loss = 9503.544492419487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9498.321271076526
gradient descent iteration = 19
gd loss = 9498.321271076526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9493.168964280496
gradient descent iteration = 20
gd loss = 9493.168964280496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9488.084077973193
gradient descent iteration = 21
gd loss = 9488.084077973193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9483.063534442976
gradient descent iteration = 22
gd loss = 9483.063534442976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9478.104596771598
gradient descent iteration = 23
gd loss = 9478.104596771598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9473.204817577172
gradient descent iteration = 24
gd loss = 9473.204817577172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9468.36200448206
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 9468.36200448206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9462.233971592763
gradient descent iteration = 1
gd loss = 9462.233971592763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9456.923791492227
gradient descent iteration = 2
gd loss = 9456.923791492227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9451.876893301333
gradient descent iteration = 3
gd loss = 9451.876893301333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9447.02285833221
gradient descent iteration = 4
gd loss = 9447.02285833221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9442.326779213012
gradient descent iteration = 5
gd loss = 9442.326779213012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9437.764563265477
gradient descent iteration = 6
gd loss = 9437.764563265477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9433.318214450022
gradient descent iteration = 7
gd loss = 9433.318214450022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9428.973784223841
gradient descent iteration = 8
gd loss = 9428.973784223841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9424.720182655074
gradient descent iteration = 9
gd loss = 9424.720182655074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9420.548422408427
gradient descent iteration = 10
gd loss = 9420.548422408427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9416.451104865475
gradient descent iteration = 11
gd loss = 9416.451104865475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9412.422056231002
gradient descent iteration = 12
gd loss = 9412.422056231002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9408.456062456142
gradient descent iteration = 13
gd loss = 9408.456062456142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9404.548672595274
gradient descent iteration = 14
gd loss = 9404.548672595274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9400.696050505927
gradient descent iteration = 15
gd loss = 9400.696050505927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9396.894861140216
gradient descent iteration = 16
gd loss = 9396.894861140216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9393.142181146208
gradient descent iteration = 17
gd loss = 9393.142181146208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9389.435429010764
gradient descent iteration = 18
gd loss = 9389.435429010764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9385.772309778726
gradient descent iteration = 19
gd loss = 9385.772309778726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9382.150770685052
gradient descent iteration = 20
gd loss = 9382.150770685052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9378.568965363784
gradient descent iteration = 21
gd loss = 9378.568965363784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9375.025224800647
gradient descent iteration = 22
gd loss = 9375.025224800647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9371.518032915412
gradient descent iteration = 23
gd loss = 9371.518032915412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9368.046006627108
gradient descent iteration = 24
gd loss = 9368.046006627108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9364.607879404313
Initial loss = 9935.215059609367
Final loss = 9364.607879404313
Deformation gradient control sequence optimization finished.
Animation interval 23 took 1351 seconds.
Full animation took 32493 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 24************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 9419.88158384489
initial norm = 664.9950144624884
convergence norm = 0.6649950144624884
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 9419.88158384489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9365.55348567617
gradient descent iteration = 1
gd loss = 9365.55348567617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9332.528861974579
gradient descent iteration = 2
gd loss = 9332.528861974579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9313.121426568536
gradient descent iteration = 3
gd loss = 9313.121426568536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9298.556714615639
gradient descent iteration = 4
gd loss = 9298.556714615639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9285.569965554263
gradient descent iteration = 5
gd loss = 9285.569965554263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9273.628994450781
gradient descent iteration = 6
gd loss = 9273.628994450781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9262.615882668455
gradient descent iteration = 7
gd loss = 9262.615882668455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9252.841549780574
gradient descent iteration = 8
gd loss = 9252.841549780574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9244.649911366696
gradient descent iteration = 9
gd loss = 9244.649911366696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9237.405576858169
gradient descent iteration = 10
gd loss = 9237.405576858169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9230.407836396273
gradient descent iteration = 11
gd loss = 9230.407836396273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9223.618082395818
gradient descent iteration = 12
gd loss = 9223.618082395818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9216.995168945001
gradient descent iteration = 13
gd loss = 9216.995168945001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9210.540568063838
gradient descent iteration = 14
gd loss = 9210.540568063838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9204.217149969099
gradient descent iteration = 15
gd loss = 9204.217149969099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9198.035404695134
gradient descent iteration = 16
gd loss = 9198.035404695134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9191.960620025968
gradient descent iteration = 17
gd loss = 9191.960620025968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9186.009075232536
gradient descent iteration = 18
gd loss = 9186.009075232536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9180.146860702054
gradient descent iteration = 19
gd loss = 9180.146860702054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9174.394389601652
gradient descent iteration = 20
gd loss = 9174.394389601652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9168.717805630184
gradient descent iteration = 21
gd loss = 9168.717805630184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9163.140668323082
gradient descent iteration = 22
gd loss = 9163.140668323082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9157.628840201833
gradient descent iteration = 23
gd loss = 9157.628840201833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9152.20835284603
gradient descent iteration = 24
gd loss = 9152.20835284603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9146.844628420862
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 9146.844628420862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9134.85962218253
gradient descent iteration = 1
gd loss = 9134.85962218253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9126.04969925735
gradient descent iteration = 2
gd loss = 9126.04969925735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9118.358088855106
gradient descent iteration = 3
gd loss = 9118.358088855106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9111.373404940638
gradient descent iteration = 4
gd loss = 9111.373404940638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9104.890254436941
gradient descent iteration = 5
gd loss = 9104.890254436941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9098.779839916273
gradient descent iteration = 6
gd loss = 9098.779839916273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9092.956046337946
gradient descent iteration = 7
gd loss = 9092.956046337946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9087.359379670152
gradient descent iteration = 8
gd loss = 9087.359379670152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9081.947669085655
gradient descent iteration = 9
gd loss = 9081.947669085655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9076.690296964269
gradient descent iteration = 10
gd loss = 9076.690296964269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9071.564538248072
gradient descent iteration = 11
gd loss = 9071.564538248072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9066.553185399202
gradient descent iteration = 12
gd loss = 9066.553185399202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9061.64294926577
gradient descent iteration = 13
gd loss = 9061.64294926577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9056.823366175995
gradient descent iteration = 14
gd loss = 9056.823366175995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9052.086050256632
gradient descent iteration = 15
gd loss = 9052.086050256632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9047.424185798833
gradient descent iteration = 16
gd loss = 9047.424185798833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9042.832163514275
gradient descent iteration = 17
gd loss = 9042.832163514275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9038.305292009451
gradient descent iteration = 18
gd loss = 9038.305292009451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9033.839609714005
gradient descent iteration = 19
gd loss = 9033.839609714005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9029.431735783493
gradient descent iteration = 20
gd loss = 9029.431735783493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9025.078743971768
gradient descent iteration = 21
gd loss = 9025.078743971768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9020.778077459299
gradient descent iteration = 22
gd loss = 9020.778077459299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9016.527485078788
gradient descent iteration = 23
gd loss = 9016.527485078788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9012.324970147667
gradient descent iteration = 24
gd loss = 9012.324970147667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9008.168746509213
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 9008.168746509213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 9002.824840326259
gradient descent iteration = 1
gd loss = 9002.824840326259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8998.128339417044
gradient descent iteration = 2
gd loss = 8998.128339417044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8993.66777673355
gradient descent iteration = 3
gd loss = 8993.66777673355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8989.382894369572
gradient descent iteration = 4
gd loss = 8989.382894369572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8985.242292342367
gradient descent iteration = 5
gd loss = 8985.242292342367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8981.224012379396
gradient descent iteration = 6
gd loss = 8981.224012379396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8977.311591238413
gradient descent iteration = 7
gd loss = 8977.311591238413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8973.492259853647
gradient descent iteration = 8
gd loss = 8973.492259853647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8969.755878936812
gradient descent iteration = 9
gd loss = 8969.755878936812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8966.094246448887
gradient descent iteration = 10
gd loss = 8966.094246448887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8962.50062259213
gradient descent iteration = 11
gd loss = 8962.50062259213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8958.969392678928
gradient descent iteration = 12
gd loss = 8958.969392678928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8955.495820983106
gradient descent iteration = 13
gd loss = 8955.495820983106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8952.07586811988
gradient descent iteration = 14
gd loss = 8952.07586811988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8948.706053504886
gradient descent iteration = 15
gd loss = 8948.706053504886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8945.383350909222
gradient descent iteration = 16
gd loss = 8945.383350909222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8942.105107746003
gradient descent iteration = 17
gd loss = 8942.105107746003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8938.868991145393
gradient descent iteration = 18
gd loss = 8938.868991145393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8935.672930283046
gradient descent iteration = 19
gd loss = 8935.672930283046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8932.515068332832
gradient descent iteration = 20
gd loss = 8932.515068332832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8929.393729808537
gradient descent iteration = 21
gd loss = 8929.393729808537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8926.307394929303
gradient descent iteration = 22
gd loss = 8926.307394929303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8923.254677707046
gradient descent iteration = 23
gd loss = 8923.254677707046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8920.234308125981
gradient descent iteration = 24
gd loss = 8920.234308125981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8917.245117205061
Initial loss = 9419.88158384489
Final loss = 8917.245117205061
Deformation gradient control sequence optimization finished.
Animation interval 24 took 1353 seconds.
Full animation took 33847 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 25************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8990.342245353218
initial norm = 619.3136319039775
convergence norm = 0.6193136319039775
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8990.342245353218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8939.839120517887
gradient descent iteration = 1
gd loss = 8939.839120517887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8908.726366359157
gradient descent iteration = 2
gd loss = 8908.726366359157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8889.781392633977
gradient descent iteration = 3
gd loss = 8889.781392633977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8875.778995906769
gradient descent iteration = 4
gd loss = 8875.778995906769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8863.526900324199
gradient descent iteration = 5
gd loss = 8863.526900324199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8852.41655634694
gradient descent iteration = 6
gd loss = 8852.41655634694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8842.414909960875
gradient descent iteration = 7
gd loss = 8842.414909960875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8834.167995658887
gradient descent iteration = 8
gd loss = 8834.167995658887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8827.654122670225
gradient descent iteration = 9
gd loss = 8827.654122670225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8821.440333107372
gradient descent iteration = 10
gd loss = 8821.440333107372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8815.407492126647
gradient descent iteration = 11
gd loss = 8815.407492126647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8809.565205791181
gradient descent iteration = 12
gd loss = 8809.565205791181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8803.87372074534
gradient descent iteration = 13
gd loss = 8803.87372074534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8798.338412230109
gradient descent iteration = 14
gd loss = 8798.338412230109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8792.924152375836
gradient descent iteration = 15
gd loss = 8792.924152375836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8787.645199929688
gradient descent iteration = 16
gd loss = 8787.645199929688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8782.462717798637
gradient descent iteration = 17
gd loss = 8782.462717798637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8777.401490465698
gradient descent iteration = 18
gd loss = 8777.401490465698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8772.415487267921
gradient descent iteration = 19
gd loss = 8772.415487267921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8767.541328329273
gradient descent iteration = 20
gd loss = 8767.541328329273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8762.723859700427
gradient descent iteration = 21
gd loss = 8762.723859700427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8758.012467281371
gradient descent iteration = 22
gd loss = 8758.012467281371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8753.34206571524
gradient descent iteration = 23
gd loss = 8753.34206571524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8748.77441526692
gradient descent iteration = 24
gd loss = 8748.77441526692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8744.234435306711
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8744.234435306711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8733.609979238285
gradient descent iteration = 1
gd loss = 8733.609979238285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8726.345854354804
gradient descent iteration = 2
gd loss = 8726.345854354804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8719.932681309665
gradient descent iteration = 3
gd loss = 8719.932681309665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8714.063931404515
gradient descent iteration = 4
gd loss = 8714.063931404515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8708.585518366704
gradient descent iteration = 5
gd loss = 8708.585518366704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8703.400143824963
gradient descent iteration = 6
gd loss = 8703.400143824963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8698.442616993963
gradient descent iteration = 7
gd loss = 8698.442616993963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8693.66772617017
gradient descent iteration = 8
gd loss = 8693.66772617017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8689.043214017116
gradient descent iteration = 9
gd loss = 8689.043214017116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8684.545480437302
gradient descent iteration = 10
gd loss = 8684.545480437302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8680.156852737297
gradient descent iteration = 11
gd loss = 8680.156852737297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8675.863798822525
gradient descent iteration = 12
gd loss = 8675.863798822525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8671.655738724881
gradient descent iteration = 13
gd loss = 8671.655738724881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8667.524240169207
gradient descent iteration = 14
gd loss = 8667.524240169207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8663.462459278062
gradient descent iteration = 15
gd loss = 8663.462459278062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8659.464751176005
gradient descent iteration = 16
gd loss = 8659.464751176005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8655.526393274853
gradient descent iteration = 17
gd loss = 8655.526393274853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8651.643387885382
gradient descent iteration = 18
gd loss = 8651.643387885382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8647.812308274302
gradient descent iteration = 19
gd loss = 8647.812308274302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8644.030181062646
gradient descent iteration = 20
gd loss = 8644.030181062646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8640.294401783147
gradient descent iteration = 21
gd loss = 8640.294401783147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8636.602676498747
gradient descent iteration = 22
gd loss = 8636.602676498747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8632.952975533211
gradient descent iteration = 23
gd loss = 8632.952975533211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8629.343481686299
gradient descent iteration = 24
gd loss = 8629.343481686299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8625.772557332126
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8625.772557332126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8621.249815653598
gradient descent iteration = 1
gd loss = 8621.249815653598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8617.179740584201
gradient descent iteration = 2
gd loss = 8617.179740584201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8613.309008373095
gradient descent iteration = 3
gd loss = 8613.309008373095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8609.588809193463
gradient descent iteration = 4
gd loss = 8609.588809193463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8605.99155678548
gradient descent iteration = 5
gd loss = 8605.99155678548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8602.497603829032
gradient descent iteration = 6
gd loss = 8602.497603829032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8599.092100607133
gradient descent iteration = 7
gd loss = 8599.092100607133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8595.763489315063
gradient descent iteration = 8
gd loss = 8595.763489315063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8592.502587113848
gradient descent iteration = 9
gd loss = 8592.502587113848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8589.301976531789
gradient descent iteration = 10
gd loss = 8589.301976531789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8586.155586659228
gradient descent iteration = 11
gd loss = 8586.155586659228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8583.058388346428
gradient descent iteration = 12
gd loss = 8583.058388346428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8580.006166924191
gradient descent iteration = 13
gd loss = 8580.006166924191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8576.995355141562
gradient descent iteration = 14
gd loss = 8576.995355141562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8574.022906532427
gradient descent iteration = 15
gd loss = 8574.022906532427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8571.086199322695
gradient descent iteration = 16
gd loss = 8571.086199322695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8568.182961402126
gradient descent iteration = 17
gd loss = 8568.182961402126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8565.311209082269
gradient descent iteration = 18
gd loss = 8565.311209082269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8562.469200588132
gradient descent iteration = 19
gd loss = 8562.469200588132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8559.655406794722
gradient descent iteration = 20
gd loss = 8559.655406794722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8556.868497149469
gradient descent iteration = 21
gd loss = 8556.868497149469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8554.10729402612
gradient descent iteration = 22
gd loss = 8554.10729402612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8551.370745366001
gradient descent iteration = 23
gd loss = 8551.370745366001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8548.657908677549
gradient descent iteration = 24
gd loss = 8548.657908677549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8545.96794098295
Initial loss = 8990.342245353218
Final loss = 8545.96794098295
Deformation gradient control sequence optimization finished.
Animation interval 25 took 1352 seconds.
Full animation took 35199 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 26************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8607.101134252694
initial norm = 519.9292273312624
convergence norm = 0.5199292273312623
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8607.101134252694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8566.081288971001
gradient descent iteration = 1
gd loss = 8566.081288971001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8542.66096234896
gradient descent iteration = 2
gd loss = 8542.66096234896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8528.458113819868
gradient descent iteration = 3
gd loss = 8528.458113819868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8516.549335054015
gradient descent iteration = 4
gd loss = 8516.549335054015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8505.731843961023
gradient descent iteration = 5
gd loss = 8505.731843961023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8495.6821340394
gradient descent iteration = 6
gd loss = 8495.6821340394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8486.869538985469
gradient descent iteration = 7
gd loss = 8486.869538985469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8481.038068255328
gradient descent iteration = 8
gd loss = 8481.038068255328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8476.241541850053
gradient descent iteration = 9
gd loss = 8476.241541850053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8471.12424044523
gradient descent iteration = 10
gd loss = 8471.12424044523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8466.359720437365
gradient descent iteration = 11
gd loss = 8466.359720437365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8461.567055685196
gradient descent iteration = 12
gd loss = 8461.567055685196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8456.968485108053
gradient descent iteration = 13
gd loss = 8456.968485108053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8452.380727788704
gradient descent iteration = 14
gd loss = 8452.380727788704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8447.948297311397
gradient descent iteration = 15
gd loss = 8447.948297311397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8443.524189595497
gradient descent iteration = 16
gd loss = 8443.524189595497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8439.241048968806
gradient descent iteration = 17
gd loss = 8439.241048968806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8434.957894115072
gradient descent iteration = 18
gd loss = 8434.957894115072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8430.807755200793
gradient descent iteration = 19
gd loss = 8430.807755200793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8426.649570585489
gradient descent iteration = 20
gd loss = 8426.649570585489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8422.618789197279
gradient descent iteration = 21
gd loss = 8422.618789197279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8418.57309062825
gradient descent iteration = 22
gd loss = 8418.57309062825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8414.650386954467
gradient descent iteration = 23
gd loss = 8414.650386954467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8410.706972977257
gradient descent iteration = 24
gd loss = 8410.706972977257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8406.882918590338
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8406.882918590338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8396.490909419246
gradient descent iteration = 1
gd loss = 8396.490909419246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8390.330017611521
gradient descent iteration = 2
gd loss = 8390.330017611521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8384.81701801302
gradient descent iteration = 3
gd loss = 8384.81701801302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8379.725858663562
gradient descent iteration = 4
gd loss = 8379.725858663562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8374.941538060863
gradient descent iteration = 5
gd loss = 8374.941538060863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8370.39080776757
gradient descent iteration = 6
gd loss = 8370.39080776757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8366.024084173019
gradient descent iteration = 7
gd loss = 8366.024084173019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8361.806510720298
gradient descent iteration = 8
gd loss = 8361.806510720298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8357.712853740954
gradient descent iteration = 9
gd loss = 8357.712853740954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8353.72438706621
gradient descent iteration = 10
gd loss = 8353.72438706621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8349.826904033756
gradient descent iteration = 11
gd loss = 8349.826904033756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8346.009411004545
gradient descent iteration = 12
gd loss = 8346.009411004545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8342.263245859334
gradient descent iteration = 13
gd loss = 8342.263245859334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8338.581465912641
gradient descent iteration = 14
gd loss = 8338.581465912641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8334.958422188165
gradient descent iteration = 15
gd loss = 8334.958422188165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8331.38945411104
gradient descent iteration = 16
gd loss = 8331.38945411104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8327.870672555844
gradient descent iteration = 17
gd loss = 8327.870672555844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8324.3987994494
gradient descent iteration = 18
gd loss = 8324.3987994494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8320.971046446535
gradient descent iteration = 19
gd loss = 8320.971046446535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8317.585022687936
gradient descent iteration = 20
gd loss = 8317.585022687936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8314.238664648708
gradient descent iteration = 21
gd loss = 8314.238664648708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8310.930181638214
gradient descent iteration = 22
gd loss = 8310.930181638214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8307.658014448725
gradient descent iteration = 23
gd loss = 8307.658014448725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8304.420811612208
gradient descent iteration = 24
gd loss = 8304.420811612208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8301.217397650566
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 8301.217397650566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8297.140704595146
gradient descent iteration = 1
gd loss = 8297.140704595146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8293.415753242067
gradient descent iteration = 2
gd loss = 8293.415753242067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8289.865572755452
gradient descent iteration = 3
gd loss = 8289.865572755452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8286.449957247882
gradient descent iteration = 4
gd loss = 8286.449957247882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8283.145816144772
gradient descent iteration = 5
gd loss = 8283.145816144772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8279.936691531337
gradient descent iteration = 6
gd loss = 8279.936691531337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8276.810115317448
gradient descent iteration = 7
gd loss = 8276.810115317448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8273.756354500061
gradient descent iteration = 8
gd loss = 8273.756354500061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8270.767651977456
gradient descent iteration = 9
gd loss = 8270.767651977456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8267.837722718512
gradient descent iteration = 10
gd loss = 8267.837722718512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8264.961402305496
gradient descent iteration = 11
gd loss = 8264.961402305496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8262.134404498682
gradient descent iteration = 12
gd loss = 8262.134404498682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8259.353204508205
gradient descent iteration = 13
gd loss = 8259.353204508205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8256.614875016538
gradient descent iteration = 14
gd loss = 8256.614875016538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8253.916903908606
gradient descent iteration = 15
gd loss = 8253.916903908606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8251.257109974487
gradient descent iteration = 16
gd loss = 8251.257109974487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8248.633577872904
gradient descent iteration = 17
gd loss = 8248.633577872904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8246.044608217004
gradient descent iteration = 18
gd loss = 8246.044608217004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8243.488678788111
gradient descent iteration = 19
gd loss = 8243.488678788111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8240.964412947917
gradient descent iteration = 20
gd loss = 8240.964412947917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8238.470557799244
gradient descent iteration = 21
gd loss = 8238.470557799244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8236.005965204655
gradient descent iteration = 22
gd loss = 8236.005965204655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8233.569575424266
gradient descent iteration = 23
gd loss = 8233.569575424266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8231.160402508483
gradient descent iteration = 24
gd loss = 8231.160402508483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8228.777526542128
Initial loss = 8607.101134252694
Final loss = 8228.777526542128
Deformation gradient control sequence optimization finished.
Animation interval 26 took 1351 seconds.
Full animation took 36551 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 27************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 8288.229250424822
initial norm = 480.8893883729996
convergence norm = 0.4808893883729997
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 8288.229250424822
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8251.144292671011
gradient descent iteration = 1
gd loss = 8251.144292671011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8230.36173952496
gradient descent iteration = 2
gd loss = 8230.36173952496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8217.533149530645
gradient descent iteration = 3
gd loss = 8217.533149530645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8206.801104723145
gradient descent iteration = 4
gd loss = 8206.801104723145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8198.257355962183
gradient descent iteration = 5
gd loss = 8198.257355962183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8193.471198513209
gradient descent iteration = 6
gd loss = 8193.471198513209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8188.658506185246
gradient descent iteration = 7
gd loss = 8188.658506185246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8184.154958888478
gradient descent iteration = 8
gd loss = 8184.154958888478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8179.708103007254
gradient descent iteration = 9
gd loss = 8179.708103007254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8175.467391301278
gradient descent iteration = 10
gd loss = 8175.467391301278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8171.26173202055
gradient descent iteration = 11
gd loss = 8171.26173202055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8167.225598259602
gradient descent iteration = 12
gd loss = 8167.225598259602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8163.205425520893
gradient descent iteration = 13
gd loss = 8163.205425520893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8159.33678546704
gradient descent iteration = 14
gd loss = 8159.33678546704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8155.469668416756
gradient descent iteration = 15
gd loss = 8155.469668416756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8151.743038129401
gradient descent iteration = 16
gd loss = 8151.743038129401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8148.006996274503
gradient descent iteration = 17
gd loss = 8148.006996274503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8144.403714569357
gradient descent iteration = 18
gd loss = 8144.403714569357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8140.782481726067
gradient descent iteration = 19
gd loss = 8140.782481726067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8137.288201966727
gradient descent iteration = 20
gd loss = 8137.288201966727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8133.769149220156
gradient descent iteration = 21
gd loss = 8133.769149220156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8130.372609116033
gradient descent iteration = 22
gd loss = 8130.372609116033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8126.945747566681
gradient descent iteration = 23
gd loss = 8126.945747566681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8123.637822054297
gradient descent iteration = 24
gd loss = 8123.637822054297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8120.294928035153
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 8120.294928035153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8111.319780473729
gradient descent iteration = 1
gd loss = 8111.319780473729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8106.207587861879
gradient descent iteration = 2
gd loss = 8106.207587861879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8101.603833979364
gradient descent iteration = 3
gd loss = 8101.603833979364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8097.348051125317
gradient descent iteration = 4
gd loss = 8097.348051125317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8093.349675557919
gradient descent iteration = 5
gd loss = 8093.349675557919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8089.548967077683
gradient descent iteration = 6
gd loss = 8089.548967077683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8085.90482112668
gradient descent iteration = 7
gd loss = 8085.90482112668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8082.388069476096
gradient descent iteration = 8
gd loss = 8082.388069476096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 8078.977454931419
gradient descent iteration = 9
gd loss = 8078.977454931419
