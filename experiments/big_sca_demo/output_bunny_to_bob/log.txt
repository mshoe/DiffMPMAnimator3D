gradient descent iteration = 9
gd loss = 765833.5355809758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 764067.0916674235
gradient descent iteration = 10
gd loss = 764067.0916674235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 762304.0634021771
gradient descent iteration = 11
gd loss = 762304.0634021771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 760544.1509888159
gradient descent iteration = 12
gd loss = 760544.1509888159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 758787.0582867181
gradient descent iteration = 13
gd loss = 758787.0582867181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 757032.4918890446
gradient descent iteration = 14
gd loss = 757032.4918890446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 755280.158596059
gradient descent iteration = 15
gd loss = 755280.158596059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 753529.7636176621
gradient descent iteration = 16
gd loss = 753529.7636176621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 751781.0075675527
gradient descent iteration = 17
gd loss = 751781.0075675527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 750033.5863011191
gradient descent iteration = 18
gd loss = 750033.5863011191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 748287.1911323641
gradient descent iteration = 19
gd loss = 748287.1911323641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 746541.5055523848
gradient descent iteration = 20
gd loss = 746541.5055523848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 744796.2056223328
gradient descent iteration = 21
gd loss = 744796.2056223328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 743050.9601031438
gradient descent iteration = 22
gd loss = 743050.9601031438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 741305.4308258004
gradient descent iteration = 23
gd loss = 741305.4308258004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 739559.2690220352
gradient descent iteration = 24
gd loss = 739559.2690220352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 737812.1130418502
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 737812.1130418502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 734614.811566463
gradient descent iteration = 1
gd loss = 734614.811566463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 731427.0597607287
gradient descent iteration = 2
gd loss = 731427.0597607287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 728248.7239524592
gradient descent iteration = 3
gd loss = 728248.7239524592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 725079.6598914471
gradient descent iteration = 4
gd loss = 725079.6598914471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 721919.7157729405
gradient descent iteration = 5
gd loss = 721919.7157729405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 718768.7405081368
gradient descent iteration = 6
gd loss = 718768.7405081368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 715626.5863430229
gradient descent iteration = 7
gd loss = 715626.5863430229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 712493.1176589325
gradient descent iteration = 8
gd loss = 712493.1176589325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 709368.2253226298
gradient descent iteration = 9
gd loss = 709368.2253226298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 706251.8402444036
gradient descent iteration = 10
gd loss = 706251.8402444036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 703143.933515726
gradient descent iteration = 11
gd loss = 703143.933515726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 700044.5201155067
gradient descent iteration = 12
gd loss = 700044.5201155067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 696953.6612783786
gradient descent iteration = 13
gd loss = 696953.6612783786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 693871.4654963001
gradient descent iteration = 14
gd loss = 693871.4654963001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 690798.0954356029
gradient descent iteration = 15
gd loss = 690798.0954356029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 687733.7593078258
gradient descent iteration = 16
gd loss = 687733.7593078258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 684678.7246441027
gradient descent iteration = 17
gd loss = 684678.7246441027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 681633.3268468408
gradient descent iteration = 18
gd loss = 681633.3268468408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 678597.9662629259
gradient descent iteration = 19
gd loss = 678597.9662629259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 675573.1089835698
gradient descent iteration = 20
gd loss = 675573.1089835698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 672559.2782903251
gradient descent iteration = 21
gd loss = 672559.2782903251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 669557.04099941
gradient descent iteration = 22
gd loss = 669557.04099941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 666566.9899415323
gradient descent iteration = 23
gd loss = 666566.9899415323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 663589.7262244244
gradient descent iteration = 24
gd loss = 663589.7262244244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 660625.8631283428
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 660625.8631283428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 659270.3278083943
gradient descent iteration = 1
gd loss = 659270.3278083943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 657925.7622336581
gradient descent iteration = 2
gd loss = 657925.7622336581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 656591.9933336682
gradient descent iteration = 3
gd loss = 656591.9933336682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 655268.8526878919
gradient descent iteration = 4
gd loss = 655268.8526878919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 653956.1765424776
gradient descent iteration = 5
gd loss = 653956.1765424776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 652653.8056988729
gradient descent iteration = 6
gd loss = 652653.8056988729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 651361.5852861
gradient descent iteration = 7
gd loss = 651361.5852861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 650079.3644534106
gradient descent iteration = 8
gd loss = 650079.3644534106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 648806.996216682
gradient descent iteration = 9
gd loss = 648806.996216682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 647544.337322486
gradient descent iteration = 10
gd loss = 647544.337322486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 646291.248130815
gradient descent iteration = 11
gd loss = 646291.248130815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 645047.5924366525
gradient descent iteration = 12
gd loss = 645047.5924366525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 643813.237358497
gradient descent iteration = 13
gd loss = 643813.237358497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 642588.0532455087
gradient descent iteration = 14
gd loss = 642588.0532455087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 641371.9137040052
gradient descent iteration = 15
gd loss = 641371.9137040052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 640164.6953714808
gradient descent iteration = 16
gd loss = 640164.6953714808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 638966.2777891267
gradient descent iteration = 17
gd loss = 638966.2777891267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 637776.5434180505
gradient descent iteration = 18
gd loss = 637776.5434180505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 636595.3774884804
gradient descent iteration = 19
gd loss = 636595.3774884804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 635422.6679655353
gradient descent iteration = 20
gd loss = 635422.6679655353
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 634258.3052989722
gradient descent iteration = 21
gd loss = 634258.3052989722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 633102.1821896436
gradient descent iteration = 22
gd loss = 633102.1821896436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 631954.1935607983
gradient descent iteration = 23
gd loss = 631954.1935607983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 630814.2364399576
gradient descent iteration = 24
gd loss = 630814.2364399576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 629682.2099513373
Initial loss = 781950.4239219484
Final loss = 629682.2099513373
Deformation gradient control sequence optimization finished.
Animation interval 0 took 1336 seconds.
Full animation took 1336 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 1************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 662505.3726898117
initial norm = 16809.49131311602
convergence norm = 16.80949131311602
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 662505.3726898117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 660824.8318546065
gradient descent iteration = 1
gd loss = 660824.8318546065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 659144.5717631767
gradient descent iteration = 2
gd loss = 659144.5717631767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 657464.0835112624
gradient descent iteration = 3
gd loss = 657464.0835112624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 655782.978573564
gradient descent iteration = 4
gd loss = 655782.978573564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 654100.9807544751
gradient descent iteration = 5
gd loss = 654100.9807544751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 652417.9111735723
gradient descent iteration = 6
gd loss = 652417.9111735723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 650733.671838833
gradient descent iteration = 7
gd loss = 650733.671838833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 649048.2297191913
gradient descent iteration = 8
gd loss = 649048.2297191913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 647361.6028197329
gradient descent iteration = 9
gd loss = 647361.6028197329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 645673.8444663138
gradient descent iteration = 10
gd loss = 645673.8444663138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 643985.026024754
gradient descent iteration = 11
gd loss = 643985.026024754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 642295.2182091888
gradient descent iteration = 12
gd loss = 642295.2182091888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 640604.4708302111
gradient descent iteration = 13
gd loss = 640604.4708302111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 638912.7944653298
gradient descent iteration = 14
gd loss = 638912.7944653298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 637220.1418961624
gradient descent iteration = 15
gd loss = 637220.1418961624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 635526.3940708515
gradient descent iteration = 16
gd loss = 635526.3940708515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 633831.3451834779
gradient descent iteration = 17
gd loss = 633831.3451834779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 632134.6914831148
gradient descent iteration = 18
gd loss = 632134.6914831148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 630436.0254468321
gradient descent iteration = 19
gd loss = 630436.0254468321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 628734.8329639218
gradient descent iteration = 20
gd loss = 628734.8329639218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 627030.498525928
gradient descent iteration = 21
gd loss = 627030.498525928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 625322.3262320249
gradient descent iteration = 22
gd loss = 625322.3262320249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 623609.5614897031
gradient descent iteration = 23
gd loss = 623609.5614897031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 621891.4362131377
gradient descent iteration = 24
gd loss = 621891.4362131377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 620167.2637915493
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 620167.2637915493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 617830.3718790683
gradient descent iteration = 1
gd loss = 617830.3718790683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 615505.1726290948
gradient descent iteration = 2
gd loss = 615505.1726290948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 613191.8971311086
gradient descent iteration = 3
gd loss = 613191.8971311086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 610890.8400845663
gradient descent iteration = 4
gd loss = 610890.8400845663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 608602.3577677764
gradient descent iteration = 5
gd loss = 608602.3577677764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 606326.8639054423
gradient descent iteration = 6
gd loss = 606326.8639054423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 604064.8260837916
gradient descent iteration = 7
gd loss = 604064.8260837916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 601816.7533596712
gradient descent iteration = 8
gd loss = 601816.7533596712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 599583.1719256653
gradient descent iteration = 9
gd loss = 599583.1719256653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 597364.6011024493
gradient descent iteration = 10
gd loss = 597364.6011024493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 595161.5338896357
gradient descent iteration = 11
gd loss = 595161.5338896357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 592974.4216610257
gradient descent iteration = 12
gd loss = 592974.4216610257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 590803.657906726
gradient descent iteration = 13
gd loss = 590803.657906726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 588649.5725944269
gradient descent iteration = 14
gd loss = 588649.5725944269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 586512.4339110713
gradient descent iteration = 15
gd loss = 586512.4339110713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 584392.4541865479
gradient descent iteration = 16
gd loss = 584392.4541865479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 582289.7926180883
gradient descent iteration = 17
gd loss = 582289.7926180883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 580204.5667354376
gradient descent iteration = 18
gd loss = 580204.5667354376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 578136.8584896626
gradient descent iteration = 19
gd loss = 578136.8584896626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 576086.7189625821
gradient descent iteration = 20
gd loss = 576086.7189625821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 574054.1748624233
gradient descent iteration = 21
gd loss = 574054.1748624233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 572039.2331984423
gradient descent iteration = 22
gd loss = 572039.2331984423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 570041.8878407785
gradient descent iteration = 23
gd loss = 570041.8878407785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 568062.1202390781
gradient descent iteration = 24
gd loss = 568062.1202390781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 566099.9013634755
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 566099.9013634755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 565256.0953777725
gradient descent iteration = 1
gd loss = 565256.0953777725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 564417.5059405125
gradient descent iteration = 2
gd loss = 564417.5059405125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 563584.0752611911
gradient descent iteration = 3
gd loss = 563584.0752611911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 562755.7463736479
gradient descent iteration = 4
gd loss = 562755.7463736479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 561932.4631154414
gradient descent iteration = 5
gd loss = 561932.4631154414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 561114.1701635324
gradient descent iteration = 6
gd loss = 561114.1701635324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 560300.8130248974
gradient descent iteration = 7
gd loss = 560300.8130248974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 559492.3379936122
gradient descent iteration = 8
gd loss = 559492.3379936122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 558688.6921434846
gradient descent iteration = 9
gd loss = 558688.6921434846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 557889.8232961672
gradient descent iteration = 10
gd loss = 557889.8232961672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 557095.6800198447
gradient descent iteration = 11
gd loss = 557095.6800198447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 556306.2116856324
gradient descent iteration = 12
gd loss = 556306.2116856324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 555521.3684122933
gradient descent iteration = 13
gd loss = 555521.3684122933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 554741.1010122359
gradient descent iteration = 14
gd loss = 554741.1010122359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 553965.3610039321
gradient descent iteration = 15
gd loss = 553965.3610039321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 553194.1006114414
gradient descent iteration = 16
gd loss = 553194.1006114414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 552427.272793844
gradient descent iteration = 17
gd loss = 552427.272793844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 551664.8312213524
gradient descent iteration = 18
gd loss = 551664.8312213524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 550906.730228876
gradient descent iteration = 19
gd loss = 550906.730228876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 550152.9248208844
gradient descent iteration = 20
gd loss = 550152.9248208844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 549403.3706789515
gradient descent iteration = 21
gd loss = 549403.3706789515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 548658.0241224063
gradient descent iteration = 22
gd loss = 548658.0241224063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 547916.8420826223
gradient descent iteration = 23
gd loss = 547916.8420826223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 547179.7821091526
gradient descent iteration = 24
gd loss = 547179.7821091526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 546446.802374523
Initial loss = 662505.3726898117
Final loss = 546446.802374523
Deformation gradient control sequence optimization finished.
Animation interval 1 took 1334 seconds.
Full animation took 2671 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 2************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 576594.4636030373
initial norm = 15632.20667083716
convergence norm = 15.63220667083716
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 576594.4636030373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 575030.7889765626
gradient descent iteration = 1
gd loss = 575030.7889765626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 573465.8401424766
gradient descent iteration = 2
gd loss = 573465.8401424766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 571899.4501719235
gradient descent iteration = 3
gd loss = 571899.4501719235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 570331.544285654
gradient descent iteration = 4
gd loss = 570331.544285654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 568762.1314391646
gradient descent iteration = 5
gd loss = 568762.1314391646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 567191.295466515
gradient descent iteration = 6
gd loss = 567191.295466515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 565619.1764837279
gradient descent iteration = 7
gd loss = 565619.1764837279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 564045.9449338105
gradient descent iteration = 8
gd loss = 564045.9449338105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 562471.7758752264
gradient descent iteration = 9
gd loss = 562471.7758752264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 560896.832073194
gradient descent iteration = 10
gd loss = 560896.832073194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 559321.2514565606
gradient descent iteration = 11
gd loss = 559321.2514565606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 557745.1470845877
gradient descent iteration = 12
gd loss = 557745.1470845877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 556168.6128934191
gradient descent iteration = 13
gd loss = 556168.6128934191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 554591.7290560124
gradient descent iteration = 14
gd loss = 554591.7290560124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 553014.5717080864
gradient descent iteration = 15
gd loss = 553014.5717080864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 551437.223608137
gradient descent iteration = 16
gd loss = 551437.223608137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 549859.7844239125
gradient descent iteration = 17
gd loss = 549859.7844239125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 548282.3752806841
gradient descent iteration = 18
gd loss = 548282.3752806841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 546705.1362141208
gradient descent iteration = 19
gd loss = 546705.1362141208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 545128.2084780965
gradient descent iteration = 20
gd loss = 545128.2084780965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 543551.7376857464
gradient descent iteration = 21
gd loss = 543551.7376857464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 541975.8825976157
gradient descent iteration = 22
gd loss = 541975.8825976157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 540400.808355342
gradient descent iteration = 23
gd loss = 540400.808355342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 538826.6752866582
gradient descent iteration = 24
gd loss = 538826.6752866582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 537253.628755039
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 537253.628755039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 535409.9616664668
gradient descent iteration = 1
gd loss = 535409.9616664668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 533583.8867354625
gradient descent iteration = 2
gd loss = 533583.8867354625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 531775.2828689851
gradient descent iteration = 3
gd loss = 531775.2828689851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 529984.0208983984
gradient descent iteration = 4
gd loss = 529984.0208983984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 528209.9643908872
gradient descent iteration = 5
gd loss = 528209.9643908872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 526452.9747387067
gradient descent iteration = 6
gd loss = 526452.9747387067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 524712.9150526087
gradient descent iteration = 7
gd loss = 524712.9150526087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 522989.6479516602
gradient descent iteration = 8
gd loss = 522989.6479516602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 521283.0336076188
gradient descent iteration = 9
gd loss = 521283.0336076188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 519592.9328851059
gradient descent iteration = 10
gd loss = 519592.9328851059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 517919.2057183984
gradient descent iteration = 11
gd loss = 517919.2057183984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 516261.7135064563
gradient descent iteration = 12
gd loss = 516261.7135064563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 514620.3148944862
gradient descent iteration = 13
gd loss = 514620.3148944862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 512994.8650019215
gradient descent iteration = 14
gd loss = 512994.8650019215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 511385.2166135387
gradient descent iteration = 15
gd loss = 511385.2166135387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 509791.2204155866
gradient descent iteration = 16
gd loss = 509791.2204155866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 508212.7252182466
gradient descent iteration = 17
gd loss = 508212.7252182466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 506649.5786539955
gradient descent iteration = 18
gd loss = 506649.5786539955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 505101.6295262462
gradient descent iteration = 19
gd loss = 505101.6295262462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 503568.7287806375
gradient descent iteration = 20
gd loss = 503568.7287806375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 502050.7290393368
gradient descent iteration = 21
gd loss = 502050.7290393368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 500547.4820731857
gradient descent iteration = 22
gd loss = 500547.4820731857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 499058.8397703207
gradient descent iteration = 23
gd loss = 499058.8397703207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 497584.6539631943
gradient descent iteration = 24
gd loss = 497584.6539631943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 496124.7792469034
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 496124.7792469034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 495522.3276593655
gradient descent iteration = 1
gd loss = 495522.3276593655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 494923.0212674459
gradient descent iteration = 2
gd loss = 494923.0212674459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 494326.8280604908
gradient descent iteration = 3
gd loss = 494326.8280604908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 493733.7164801527
gradient descent iteration = 4
gd loss = 493733.7164801527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 493143.655415676
gradient descent iteration = 5
gd loss = 493143.655415676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 492556.6141676751
gradient descent iteration = 6
gd loss = 492556.6141676751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 491972.5624546365
gradient descent iteration = 7
gd loss = 491972.5624546365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 491391.4704247277
gradient descent iteration = 8
gd loss = 491391.4704247277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 490813.3086403069
gradient descent iteration = 9
gd loss = 490813.3086403069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 490238.0480344677
gradient descent iteration = 10
gd loss = 490238.0480344677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 489665.6599012921
gradient descent iteration = 11
gd loss = 489665.6599012921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 489096.1159326633
gradient descent iteration = 12
gd loss = 489096.1159326633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 488529.388227366
gradient descent iteration = 13
gd loss = 488529.388227366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 487965.4492889215
gradient descent iteration = 14
gd loss = 487965.4492889215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 487404.2720125898
gradient descent iteration = 15
gd loss = 487404.2720125898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 486845.8296730797
gradient descent iteration = 16
gd loss = 486845.8296730797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 486290.095928496
gradient descent iteration = 17
gd loss = 486290.095928496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 485737.0447866129
gradient descent iteration = 18
gd loss = 485737.0447866129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 485186.6506163594
gradient descent iteration = 19
gd loss = 485186.6506163594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 484638.8881804802
gradient descent iteration = 20
gd loss = 484638.8881804802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 484093.7326649814
gradient descent iteration = 21
gd loss = 484093.7326649814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 483551.1596159933
gradient descent iteration = 22
gd loss = 483551.1596159933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 483011.1449440346
gradient descent iteration = 23
gd loss = 483011.1449440346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 482473.6649222533
gradient descent iteration = 24
gd loss = 482473.6649222533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 481938.6961515856
Initial loss = 576594.4636030373
Final loss = 481938.6961515856
Deformation gradient control sequence optimization finished.
Animation interval 2 took 1337 seconds.
Full animation took 4008 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 3************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 504151.0804199122
initial norm = 14187.68229354652
convergence norm = 14.18768229354652
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 504151.0804199122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 502733.0452714931
gradient descent iteration = 1
gd loss = 502733.0452714931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 501316.5434846542
gradient descent iteration = 2
gd loss = 501316.5434846542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 499902.0713948683
gradient descent iteration = 3
gd loss = 499902.0713948683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 498490.0769965345
gradient descent iteration = 4
gd loss = 498490.0769965345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 497080.932898398
gradient descent iteration = 5
gd loss = 497080.932898398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 495674.9285045901
gradient descent iteration = 6
gd loss = 495674.9285045901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 494272.274346578
gradient descent iteration = 7
gd loss = 494272.274346578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 492873.1156741116
gradient descent iteration = 8
gd loss = 492873.1156741116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 491477.5479979261
gradient descent iteration = 9
gd loss = 491477.5479979261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 490085.6308483973
gradient descent iteration = 10
gd loss = 490085.6308483973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 488697.3988056667
gradient descent iteration = 11
gd loss = 488697.3988056667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 487312.8693354821
gradient descent iteration = 12
gd loss = 487312.8693354821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 485932.0503434456
gradient descent iteration = 13
gd loss = 485932.0503434456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 484554.9419933475
gradient descent iteration = 14
gd loss = 484554.9419933475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 483181.5384753438
gradient descent iteration = 15
gd loss = 483181.5384753438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 481811.829802632
gradient descent iteration = 16
gd loss = 481811.829802632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 480445.803013719
gradient descent iteration = 17
gd loss = 480445.803013719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 479083.4415998752
gradient descent iteration = 18
gd loss = 479083.4415998752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 477724.7245409586
gradient descent iteration = 19
gd loss = 477724.7245409586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 476369.6267253864
gradient descent iteration = 20
gd loss = 476369.6267253864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 475018.1202927338
gradient descent iteration = 21
gd loss = 475018.1202927338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 473670.1740835411
gradient descent iteration = 22
gd loss = 473670.1740835411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 472325.752572957
gradient descent iteration = 23
gd loss = 472325.752572957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 470984.8146944449
gradient descent iteration = 24
gd loss = 470984.8146944449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 469647.3144017286
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 469647.3144017286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 468288.908744205
gradient descent iteration = 1
gd loss = 468288.908744205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 466945.0944551545
gradient descent iteration = 2
gd loss = 466945.0944551545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 465615.6871652306
gradient descent iteration = 3
gd loss = 465615.6871652306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 464300.5077816062
gradient descent iteration = 4
gd loss = 464300.5077816062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 462999.3817647524
gradient descent iteration = 5
gd loss = 462999.3817647524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 461712.1387229601
gradient descent iteration = 6
gd loss = 461712.1387229601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 460438.6079561875
gradient descent iteration = 7
gd loss = 460438.6079561875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 459178.6182918841
gradient descent iteration = 8
gd loss = 459178.6182918841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 457932.0040079758
gradient descent iteration = 9
gd loss = 457932.0040079758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 456698.6041498854
gradient descent iteration = 10
gd loss = 456698.6041498854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 455478.2606347611
gradient descent iteration = 11
gd loss = 455478.2606347611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 454270.818274151
gradient descent iteration = 12
gd loss = 454270.818274151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 453076.1254300378
gradient descent iteration = 13
gd loss = 453076.1254300378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 451894.0350417871
gradient descent iteration = 14
gd loss = 451894.0350417871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 450724.4016862246
gradient descent iteration = 15
gd loss = 450724.4016862246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 449567.0829149697
gradient descent iteration = 16
gd loss = 449567.0829149697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 448421.9389648351
gradient descent iteration = 17
gd loss = 448421.9389648351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 447288.831783139
gradient descent iteration = 18
gd loss = 447288.831783139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 446167.6245195502
gradient descent iteration = 19
gd loss = 446167.6245195502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 445058.180356712
gradient descent iteration = 20
gd loss = 445058.180356712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 443960.3633382304
gradient descent iteration = 21
gd loss = 443960.3633382304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 442874.0396589965
gradient descent iteration = 22
gd loss = 442874.0396589965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 441799.0786607868
gradient descent iteration = 23
gd loss = 441799.0786607868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 440735.3505175587
gradient descent iteration = 24
gd loss = 440735.3505175587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 439682.7257098217
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 439682.7257098217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 439159.5944794167
gradient descent iteration = 1
gd loss = 439159.5944794167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 438639.2989650055
gradient descent iteration = 2
gd loss = 438639.2989650055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 438121.8107040047
gradient descent iteration = 3
gd loss = 438121.8107040047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 437607.1015475433
gradient descent iteration = 4
gd loss = 437607.1015475433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 437095.1436646362
gradient descent iteration = 5
gd loss = 437095.1436646362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 436585.9095386078
gradient descent iteration = 6
gd loss = 436585.9095386078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 436079.3719842943
gradient descent iteration = 7
gd loss = 436079.3719842943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 435575.5041546253
gradient descent iteration = 8
gd loss = 435575.5041546253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 435074.2795275398
gradient descent iteration = 9
gd loss = 435074.2795275398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 434575.6719389257
gradient descent iteration = 10
gd loss = 434575.6719389257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 434079.655544018
gradient descent iteration = 11
gd loss = 434079.655544018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 433586.2048120971
gradient descent iteration = 12
gd loss = 433586.2048120971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 433095.2945624253
gradient descent iteration = 13
gd loss = 433095.2945624253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 432606.8999659049
gradient descent iteration = 14
gd loss = 432606.8999659049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 432120.9965265665
gradient descent iteration = 15
gd loss = 432120.9965265665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 431637.5600618273
gradient descent iteration = 16
gd loss = 431637.5600618273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 431156.5667340459
gradient descent iteration = 17
gd loss = 431156.5667340459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 430677.9930338025
gradient descent iteration = 18
gd loss = 430677.9930338025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 430201.8157793322
gradient descent iteration = 19
gd loss = 430201.8157793322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 429728.0120816978
gradient descent iteration = 20
gd loss = 429728.0120816978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 429256.5593505605
gradient descent iteration = 21
gd loss = 429256.5593505605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 428787.4353368356
gradient descent iteration = 22
gd loss = 428787.4353368356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 428320.6180867107
gradient descent iteration = 23
gd loss = 428320.6180867107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 427856.0859418313
gradient descent iteration = 24
gd loss = 427856.0859418313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 427393.8175756051
Initial loss = 504151.0804199122
Final loss = 427393.8175756051
Deformation gradient control sequence optimization finished.
Animation interval 3 took 1335 seconds.
Full animation took 5343 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 4************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 444612.7772719388
initial norm = 12784.73526778774
convergence norm = 12.78473526778775
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 444612.7772719388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 443332.8445846763
gradient descent iteration = 1
gd loss = 443332.8445846763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 442048.5712642121
gradient descent iteration = 2
gd loss = 442048.5712642121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 440757.3892690955
gradient descent iteration = 3
gd loss = 440757.3892690955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 439455.7377805235
gradient descent iteration = 4
gd loss = 439455.7377805235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 438139.1288690044
gradient descent iteration = 5
gd loss = 438139.1288690044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 436803.7494447361
gradient descent iteration = 6
gd loss = 436803.7494447361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 435451.5405888441
gradient descent iteration = 7
gd loss = 435451.5405888441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 434094.4507862564
gradient descent iteration = 8
gd loss = 434094.4507862564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 432747.1425311501
gradient descent iteration = 9
gd loss = 432747.1425311501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 431417.0163966102
gradient descent iteration = 10
gd loss = 431417.0163966102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 430104.4779354155
gradient descent iteration = 11
gd loss = 430104.4779354155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 428807.3097349327
gradient descent iteration = 12
gd loss = 428807.3097349327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 427523.0380730745
gradient descent iteration = 13
gd loss = 427523.0380730745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 426249.6169000517
gradient descent iteration = 14
gd loss = 426249.6169000517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 424985.4880793575
gradient descent iteration = 15
gd loss = 424985.4880793575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 423729.491869157
gradient descent iteration = 16
gd loss = 423729.491869157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 422480.7806611027
gradient descent iteration = 17
gd loss = 422480.7806611027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 421238.7572833854
gradient descent iteration = 18
gd loss = 421238.7572833854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 420003.0321545137
gradient descent iteration = 19
gd loss = 420003.0321545137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 418773.3865691182
gradient descent iteration = 20
gd loss = 418773.3865691182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 417549.7515802176
gradient descent iteration = 21
gd loss = 417549.7515802176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 416332.1890106741
gradient descent iteration = 22
gd loss = 416332.1890106741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 415120.8656568878
gradient descent iteration = 23
gd loss = 415120.8656568878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 413916.0299723448
gradient descent iteration = 24
gd loss = 413916.0299723448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 412717.9863216102
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 412717.9863216102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 411801.4420723669
gradient descent iteration = 1
gd loss = 411801.4420723669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 410896.9218941163
gradient descent iteration = 2
gd loss = 410896.9218941163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 410004.243175659
gradient descent iteration = 3
gd loss = 410004.243175659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 409123.2234872663
gradient descent iteration = 4
gd loss = 409123.2234872663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 408253.6806591398
gradient descent iteration = 5
gd loss = 408253.6806591398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 407395.4330109782
gradient descent iteration = 6
gd loss = 407395.4330109782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 406548.299648761
gradient descent iteration = 7
gd loss = 406548.299648761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 405712.1008613202
gradient descent iteration = 8
gd loss = 405712.1008613202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 404886.6575481583
gradient descent iteration = 9
gd loss = 404886.6575481583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 404071.791790225
gradient descent iteration = 10
gd loss = 404071.791790225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 403267.3268948159
gradient descent iteration = 11
gd loss = 403267.3268948159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 402473.0870572363
gradient descent iteration = 12
gd loss = 402473.0870572363
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 401688.8974904747
gradient descent iteration = 13
gd loss = 401688.8974904747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 400914.5848530069
gradient descent iteration = 14
gd loss = 400914.5848530069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 400149.9775294064
gradient descent iteration = 15
gd loss = 400149.9775294064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 399394.9050873721
gradient descent iteration = 16
gd loss = 399394.9050873721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 398649.1989131091
gradient descent iteration = 17
gd loss = 398649.1989131091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 397912.6925446003
gradient descent iteration = 18
gd loss = 397912.6925446003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 397185.2219561833
gradient descent iteration = 19
gd loss = 397185.2219561833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 396466.6256563473
gradient descent iteration = 20
gd loss = 396466.6256563473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 395756.7448041565
gradient descent iteration = 21
gd loss = 395756.7448041565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 395055.4229344449
gradient descent iteration = 22
gd loss = 395055.4229344449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 394362.5060905495
gradient descent iteration = 23
gd loss = 394362.5060905495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 393677.843177087
gradient descent iteration = 24
gd loss = 393677.843177087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 393001.2864916702
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 393001.2864916702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 392548.6897708212
gradient descent iteration = 1
gd loss = 392548.6897708212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 392098.8581578169
gradient descent iteration = 2
gd loss = 392098.8581578169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 391651.7608475933
gradient descent iteration = 3
gd loss = 391651.7608475933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 391207.3674230274
gradient descent iteration = 4
gd loss = 391207.3674230274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 390765.6478635906
gradient descent iteration = 5
gd loss = 390765.6478635906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 390326.5725422124
gradient descent iteration = 6
gd loss = 390326.5725422124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 389890.1122181842
gradient descent iteration = 7
gd loss = 389890.1122181842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 389456.2380219995
gradient descent iteration = 8
gd loss = 389456.2380219995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 389024.9214480707
gradient descent iteration = 9
gd loss = 389024.9214480707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 388596.1343700566
gradient descent iteration = 10
gd loss = 388596.1343700566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 388169.849042676
gradient descent iteration = 11
gd loss = 388169.849042676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 387746.0380761883
gradient descent iteration = 12
gd loss = 387746.0380761883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 387324.674440722
gradient descent iteration = 13
gd loss = 387324.674440722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 386905.7314711025
gradient descent iteration = 14
gd loss = 386905.7314711025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 386489.1828516888
gradient descent iteration = 15
gd loss = 386489.1828516888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 386075.0026144978
gradient descent iteration = 16
gd loss = 386075.0026144978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 385663.1651275317
gradient descent iteration = 17
gd loss = 385663.1651275317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 385253.6450949043
gradient descent iteration = 18
gd loss = 385253.6450949043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 384846.4175783418
gradient descent iteration = 19
gd loss = 384846.4175783418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 384441.4579736146
gradient descent iteration = 20
gd loss = 384441.4579736146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 384038.741999957
gradient descent iteration = 21
gd loss = 384038.741999957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 383638.2456841778
gradient descent iteration = 22
gd loss = 383638.2456841778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 383239.9453496712
gradient descent iteration = 23
gd loss = 383239.9453496712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 382843.8176269597
gradient descent iteration = 24
gd loss = 382843.8176269597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 382449.8394582635
Initial loss = 444612.7772719388
Final loss = 382449.8394582635
Deformation gradient control sequence optimization finished.
Animation interval 4 took 1336 seconds.
Full animation took 6679 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 5************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 396706.4925479853
initial norm = 10648.25825871313
convergence norm = 10.64825825871313
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 396706.4925479853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 395645.1807564283
gradient descent iteration = 1
gd loss = 395645.1807564283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 394590.9588083957
gradient descent iteration = 2
gd loss = 394590.9588083957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 393543.9079099107
gradient descent iteration = 3
gd loss = 393543.9079099107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 392504.105926304
gradient descent iteration = 4
gd loss = 392504.105926304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 391471.627460783
gradient descent iteration = 5
gd loss = 391471.627460783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 390446.5418266666
gradient descent iteration = 6
gd loss = 390446.5418266666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 389428.9106962411
gradient descent iteration = 7
gd loss = 389428.9106962411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 388418.7886266693
gradient descent iteration = 8
gd loss = 388418.7886266693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 387416.2245805761
gradient descent iteration = 9
gd loss = 387416.2245805761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 386421.2600889588
gradient descent iteration = 10
gd loss = 386421.2600889588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 385433.9268107177
gradient descent iteration = 11
gd loss = 385433.9268107177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 384454.2470522287
gradient descent iteration = 12
gd loss = 384454.2470522287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 383482.2350837215
gradient descent iteration = 13
gd loss = 383482.2350837215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 382517.8978039728
gradient descent iteration = 14
gd loss = 382517.8978039728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 381561.2359162339
gradient descent iteration = 15
gd loss = 381561.2359162339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 380612.2445931156
gradient descent iteration = 16
gd loss = 380612.2445931156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 379670.9121249104
gradient descent iteration = 17
gd loss = 379670.9121249104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 378737.2189309964
gradient descent iteration = 18
gd loss = 378737.2189309964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 377811.1384235586
gradient descent iteration = 19
gd loss = 377811.1384235586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 376892.6389840844
gradient descent iteration = 20
gd loss = 376892.6389840844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 375981.6862492592
gradient descent iteration = 21
gd loss = 375981.6862492592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 375078.2433516643
gradient descent iteration = 22
gd loss = 375078.2433516643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 374182.2704690202
gradient descent iteration = 23
gd loss = 374182.2704690202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 373293.7250758407
gradient descent iteration = 24
gd loss = 373293.7250758407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 372412.5614991782
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 372412.5614991782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 371719.6250635918
gradient descent iteration = 1
gd loss = 371719.6250635918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 371036.1614723595
gradient descent iteration = 2
gd loss = 371036.1614723595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 370361.9626999313
gradient descent iteration = 3
gd loss = 370361.9626999313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 369696.825256522
gradient descent iteration = 4
gd loss = 369696.825256522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 369040.5497400966
gradient descent iteration = 5
gd loss = 369040.5497400966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 368392.94074132
gradient descent iteration = 6
gd loss = 368392.94074132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 367753.8072843339
gradient descent iteration = 7
gd loss = 367753.8072843339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 367122.9635293214
gradient descent iteration = 8
gd loss = 367122.9635293214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 366500.2282962714
gradient descent iteration = 9
gd loss = 366500.2282962714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 365885.4245058024
gradient descent iteration = 10
gd loss = 365885.4245058024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 365278.3790364013
gradient descent iteration = 11
gd loss = 365278.3790364013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 364678.9229272056
gradient descent iteration = 12
gd loss = 364678.9229272056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 364086.8915650844
gradient descent iteration = 13
gd loss = 364086.8915650844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 363502.1242997416
gradient descent iteration = 14
gd loss = 363502.1242997416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 362924.4645056718
gradient descent iteration = 15
gd loss = 362924.4645056718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 362353.7593570737
gradient descent iteration = 16
gd loss = 362353.7593570737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 361789.8596351655
gradient descent iteration = 17
gd loss = 361789.8596351655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 361232.619928495
gradient descent iteration = 18
gd loss = 361232.619928495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360681.8986792983
gradient descent iteration = 19
gd loss = 360681.8986792983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360137.5579797657
gradient descent iteration = 20
gd loss = 360137.5579797657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 359599.4632567477
gradient descent iteration = 21
gd loss = 359599.4632567477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 359067.4830886608
gradient descent iteration = 22
gd loss = 359067.4830886608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358541.4892094618
gradient descent iteration = 23
gd loss = 358541.4892094618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358021.35616168
gradient descent iteration = 24
gd loss = 358021.35616168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357506.9610754531
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 357506.9610754531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357004.3238148133
gradient descent iteration = 1
gd loss = 357004.3238148133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356506.0596596231
gradient descent iteration = 2
gd loss = 356506.0596596231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356012.1009230653
gradient descent iteration = 3
gd loss = 356012.1009230653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355522.3811280736
gradient descent iteration = 4
gd loss = 355522.3811280736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355036.8349725154
gradient descent iteration = 5
gd loss = 355036.8349725154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 354555.3983458651
gradient descent iteration = 6
gd loss = 354555.3983458651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 354078.0082943073
gradient descent iteration = 7
gd loss = 354078.0082943073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353604.60301497
gradient descent iteration = 8
gd loss = 353604.60301497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353135.1218536549
gradient descent iteration = 9
gd loss = 353135.1218536549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 352669.5053030828
gradient descent iteration = 10
gd loss = 352669.5053030828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 352207.6949672553
gradient descent iteration = 11
gd loss = 352207.6949672553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 351749.6335273881
gradient descent iteration = 12
gd loss = 351749.6335273881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 351295.2647144448
gradient descent iteration = 13
gd loss = 351295.2647144448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 350844.5332672781
gradient descent iteration = 14
gd loss = 350844.5332672781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 350397.3849183865
gradient descent iteration = 15
gd loss = 350397.3849183865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 349953.7664008912
gradient descent iteration = 16
gd loss = 349953.7664008912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 349513.6254183411
gradient descent iteration = 17
gd loss = 349513.6254183411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 349076.910633175
gradient descent iteration = 18
gd loss = 349076.910633175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 348643.5716694502
gradient descent iteration = 19
gd loss = 348643.5716694502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 348213.5590824622
gradient descent iteration = 20
gd loss = 348213.5590824622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 347786.8243588369
gradient descent iteration = 21
gd loss = 347786.8243588369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 347363.3198685386
gradient descent iteration = 22
gd loss = 347363.3198685386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 346942.9988425776
gradient descent iteration = 23
gd loss = 346942.9988425776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 346525.8153751574
gradient descent iteration = 24
gd loss = 346525.8153751574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 346111.7243958069
Initial loss = 396706.4925479853
Final loss = 346111.7243958069
Deformation gradient control sequence optimization finished.
Animation interval 5 took 1337 seconds.
Full animation took 8017 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 6************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 362147.9599272621
initial norm = 8611.319209516787
convergence norm = 8.611319209516788
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 362147.9599272621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 361290.449650684
gradient descent iteration = 1
gd loss = 361290.449650684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 360440.1051601759
gradient descent iteration = 2
gd loss = 360440.1051601759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 359596.8972161916
gradient descent iteration = 3
gd loss = 359596.8972161916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 358760.7940243633
gradient descent iteration = 4
gd loss = 358760.7940243633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357931.7608984653
gradient descent iteration = 5
gd loss = 357931.7608984653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 357109.7589652638
gradient descent iteration = 6
gd loss = 357109.7589652638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 356294.7457271552
gradient descent iteration = 7
gd loss = 356294.7457271552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 355486.6754949759
gradient descent iteration = 8
gd loss = 355486.6754949759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 354685.4979097348
gradient descent iteration = 9
gd loss = 354685.4979097348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353891.1580185848
gradient descent iteration = 10
gd loss = 353891.1580185848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 353103.5975291601
gradient descent iteration = 11
gd loss = 353103.5975291601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 352322.7544898272
gradient descent iteration = 12
gd loss = 352322.7544898272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 351548.5633106186
gradient descent iteration = 13
gd loss = 351548.5633106186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 350780.9549501687
gradient descent iteration = 14
gd loss = 350780.9549501687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 350019.8568555425
gradient descent iteration = 15
gd loss = 350019.8568555425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 349265.1923896893
gradient descent iteration = 16
gd loss = 349265.1923896893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 348516.8814028045
gradient descent iteration = 17
gd loss = 348516.8814028045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 347774.8408119082
gradient descent iteration = 18
gd loss = 347774.8408119082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 347038.9849475633
gradient descent iteration = 19
gd loss = 347038.9849475633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 346309.2248917063
gradient descent iteration = 20
gd loss = 346309.2248917063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 345585.4691841815
gradient descent iteration = 21
gd loss = 345585.4691841815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 344867.6243377106
gradient descent iteration = 22
gd loss = 344867.6243377106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 344155.5950041833
gradient descent iteration = 23
gd loss = 344155.5950041833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 343449.2839097862
gradient descent iteration = 24
gd loss = 343449.2839097862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 342748.5921356747
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 342748.5921356747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 342205.4765564867
gradient descent iteration = 1
gd loss = 342205.4765564867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 341669.1935317448
gradient descent iteration = 2
gd loss = 341669.1935317448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 341139.5884959237
gradient descent iteration = 3
gd loss = 341139.5884959237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 340616.5109146952
gradient descent iteration = 4
gd loss = 340616.5109146952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 340099.8142166986
gradient descent iteration = 5
gd loss = 340099.8142166986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 339589.3555594923
gradient descent iteration = 6
gd loss = 339589.3555594923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 339084.9955049567
gradient descent iteration = 7
gd loss = 339084.9955049567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 338586.59792639
gradient descent iteration = 8
gd loss = 338586.59792639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 338094.0302362388
gradient descent iteration = 9
gd loss = 338094.0302362388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 337607.1635969789
gradient descent iteration = 10
gd loss = 337607.1635969789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 337125.8728750434
gradient descent iteration = 11
gd loss = 337125.8728750434
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 336650.0366144364
gradient descent iteration = 12
gd loss = 336650.0366144364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 336179.5362986506
gradient descent iteration = 13
gd loss = 336179.5362986506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 335714.2563467131
gradient descent iteration = 14
gd loss = 335714.2563467131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 335254.0844316055
gradient descent iteration = 15
gd loss = 335254.0844316055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 334798.9110782761
gradient descent iteration = 16
gd loss = 334798.9110782761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 334348.6297297745
gradient descent iteration = 17
gd loss = 334348.6297297745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 333903.136616157
gradient descent iteration = 18
gd loss = 333903.136616157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 333462.3304736336
gradient descent iteration = 19
gd loss = 333462.3304736336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 333026.1124226449
gradient descent iteration = 20
gd loss = 333026.1124226449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 332594.3862529392
gradient descent iteration = 21
gd loss = 332594.3862529392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 332167.058157269
gradient descent iteration = 22
gd loss = 332167.058157269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 331744.0364207288
gradient descent iteration = 23
gd loss = 331744.0364207288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 331325.2313097416
gradient descent iteration = 24
gd loss = 331325.2313097416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 330910.5551318534
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 330910.5551318534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 330385.2995628054
gradient descent iteration = 1
gd loss = 330385.2995628054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 329865.9370632778
gradient descent iteration = 2
gd loss = 329865.9370632778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 329352.355663973
gradient descent iteration = 3
gd loss = 329352.355663973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 328844.4457665827
gradient descent iteration = 4
gd loss = 328844.4457665827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 328342.1001108857
gradient descent iteration = 5
gd loss = 328342.1001108857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 327845.2137537149
gradient descent iteration = 6
gd loss = 327845.2137537149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 327353.684040955
gradient descent iteration = 7
gd loss = 327353.684040955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 326867.4105158563
gradient descent iteration = 8
gd loss = 326867.4105158563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 326386.2948423221
gradient descent iteration = 9
gd loss = 326386.2948423221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 325910.2407740873
gradient descent iteration = 10
gd loss = 325910.2407740873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 325439.1541219729
gradient descent iteration = 11
gd loss = 325439.1541219729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324972.9427249312
gradient descent iteration = 12
gd loss = 324972.9427249312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324511.5163990105
gradient descent iteration = 13
gd loss = 324511.5163990105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324054.7868810932
gradient descent iteration = 14
gd loss = 324054.7868810932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 323602.6678617684
gradient descent iteration = 15
gd loss = 323602.6678617684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 323155.0749600969
gradient descent iteration = 16
gd loss = 323155.0749600969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322711.9256292183
gradient descent iteration = 17
gd loss = 322711.9256292183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322273.1391218122
gradient descent iteration = 18
gd loss = 322273.1391218122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 321838.6364457806
gradient descent iteration = 19
gd loss = 321838.6364457806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 321408.3403496654
gradient descent iteration = 20
gd loss = 321408.3403496654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320982.1752753163
gradient descent iteration = 21
gd loss = 320982.1752753163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320560.0673452529
gradient descent iteration = 22
gd loss = 320560.0673452529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320141.9442766884
gradient descent iteration = 23
gd loss = 320141.9442766884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319727.7353169677
gradient descent iteration = 24
gd loss = 319727.7353169677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319317.3712425259
Initial loss = 362147.9599272621
Final loss = 319317.3712425259
Deformation gradient control sequence optimization finished.
Animation interval 6 took 1340 seconds.
Full animation took 9357 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 7************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 332055.7061768687
initial norm = 7047.040048090337
convergence norm = 7.047040048090337
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 332055.7061768687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 331354.7907233764
gradient descent iteration = 1
gd loss = 331354.7907233764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 330661.1855113091
gradient descent iteration = 2
gd loss = 330661.1855113091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 329974.7625892985
gradient descent iteration = 3
gd loss = 329974.7625892985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 329295.3876708337
gradient descent iteration = 4
gd loss = 329295.3876708337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 328622.9213419026
gradient descent iteration = 5
gd loss = 328622.9213419026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 327957.2193506674
gradient descent iteration = 6
gd loss = 327957.2193506674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 327298.1336947275
gradient descent iteration = 7
gd loss = 327298.1336947275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 326645.5120452059
gradient descent iteration = 8
gd loss = 326645.5120452059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 325999.1978395822
gradient descent iteration = 9
gd loss = 325999.1978395822
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 325359.031380547
gradient descent iteration = 10
gd loss = 325359.031380547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324724.8508348929
gradient descent iteration = 11
gd loss = 324724.8508348929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 324096.4934059167
gradient descent iteration = 12
gd loss = 324096.4934059167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 323473.795704287
gradient descent iteration = 13
gd loss = 323473.795704287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322856.5937430143
gradient descent iteration = 14
gd loss = 322856.5937430143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 322244.7234772123
gradient descent iteration = 15
gd loss = 322244.7234772123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 321638.0211942573
gradient descent iteration = 16
gd loss = 321638.0211942573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 321036.3244148102
gradient descent iteration = 17
gd loss = 321036.3244148102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 320439.4718849614
gradient descent iteration = 18
gd loss = 320439.4718849614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319847.3037404746
gradient descent iteration = 19
gd loss = 319847.3037404746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 319259.6618904884
gradient descent iteration = 20
gd loss = 319259.6618904884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 318676.3908021572
gradient descent iteration = 21
gd loss = 318676.3908021572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 318097.3389438108
gradient descent iteration = 22
gd loss = 318097.3389438108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 317522.3592153344
gradient descent iteration = 23
gd loss = 317522.3592153344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 316951.3088005181
gradient descent iteration = 24
gd loss = 316951.3088005181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 316384.0491558909
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 316384.0491558909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315960.9807207945
gradient descent iteration = 1
gd loss = 315960.9807207945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315542.6692416196
gradient descent iteration = 2
gd loss = 315542.6692416196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 315128.9834380957
gradient descent iteration = 3
gd loss = 315128.9834380957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 314719.7969694601
gradient descent iteration = 4
gd loss = 314719.7969694601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 314314.9880671295
gradient descent iteration = 5
gd loss = 314314.9880671295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313914.4391186064
gradient descent iteration = 6
gd loss = 313914.4391186064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313518.0363282082
gradient descent iteration = 7
gd loss = 313518.0363282082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 313125.6692461137
gradient descent iteration = 8
gd loss = 313125.6692461137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 312737.2309591754
gradient descent iteration = 9
gd loss = 312737.2309591754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 312352.6181870806
gradient descent iteration = 10
gd loss = 312352.6181870806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311971.7309508479
gradient descent iteration = 11
gd loss = 311971.7309508479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311594.4724779589
gradient descent iteration = 12
gd loss = 311594.4724779589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 311220.7490699184
gradient descent iteration = 13
gd loss = 311220.7490699184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 310850.4700238341
gradient descent iteration = 14
gd loss = 310850.4700238341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 310483.5477050829
gradient descent iteration = 15
gd loss = 310483.5477050829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 310119.897165175
gradient descent iteration = 16
gd loss = 310119.897165175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309759.4361161729
gradient descent iteration = 17
gd loss = 309759.4361161729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309402.0850398902
gradient descent iteration = 18
gd loss = 309402.0850398902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 309047.7669573593
gradient descent iteration = 19
gd loss = 309047.7669573593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308696.4071959769
gradient descent iteration = 20
gd loss = 308696.4071959769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308347.9334922803
gradient descent iteration = 21
gd loss = 308347.9334922803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 308002.2760549336
gradient descent iteration = 22
gd loss = 308002.2760549336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 307659.3671971778
gradient descent iteration = 23
gd loss = 307659.3671971778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 307319.1411190062
gradient descent iteration = 24
gd loss = 307319.1411190062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306981.5342690058
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 306981.5342690058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 306439.4593396749
gradient descent iteration = 1
gd loss = 306439.4593396749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305905.1086656865
gradient descent iteration = 2
gd loss = 305905.1086656865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305378.2987914485
gradient descent iteration = 3
gd loss = 305378.2987914485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304858.8510724081
gradient descent iteration = 4
gd loss = 304858.8510724081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304346.5916305915
gradient descent iteration = 5
gd loss = 304346.5916305915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303841.3512986914
gradient descent iteration = 6
gd loss = 303841.3512986914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303342.9654677349
gradient descent iteration = 7
gd loss = 303342.9654677349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 302851.2739751622
gradient descent iteration = 8
gd loss = 302851.2739751622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 302366.1209396087
gradient descent iteration = 9
gd loss = 302366.1209396087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 301887.3546954484
gradient descent iteration = 10
gd loss = 301887.3546954484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 301414.8277780817
gradient descent iteration = 11
gd loss = 301414.8277780817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300948.3967688961
gradient descent iteration = 12
gd loss = 300948.3967688961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300487.9221728094
gradient descent iteration = 13
gd loss = 300487.9221728094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300033.2683729795
gradient descent iteration = 14
gd loss = 300033.2683729795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 299584.3034445149
gradient descent iteration = 15
gd loss = 299584.3034445149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 299140.899004061
gradient descent iteration = 16
gd loss = 299140.899004061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 298702.9301385161
gradient descent iteration = 17
gd loss = 298702.9301385161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 298270.2753289681
gradient descent iteration = 18
gd loss = 298270.2753289681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297842.8163746223
gradient descent iteration = 19
gd loss = 297842.8163746223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297420.4383101541
gradient descent iteration = 20
gd loss = 297420.4383101541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297003.029325853
gradient descent iteration = 21
gd loss = 297003.029325853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 296590.4807109548
gradient descent iteration = 22
gd loss = 296590.4807109548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 296182.6867356143
gradient descent iteration = 23
gd loss = 296182.6867356143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 295779.5445315729
gradient descent iteration = 24
gd loss = 295779.5445315729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 295380.9539911957
Initial loss = 332055.7061768687
Final loss = 295380.9539911957
Deformation gradient control sequence optimization finished.
Animation interval 7 took 1400 seconds.
Full animation took 10757 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 8************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 306051.1505382661
initial norm = 6066.778597474226
convergence norm = 6.066778597474226
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 306051.1505382661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 305448.2290275798
gradient descent iteration = 1
gd loss = 305448.2290275798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304852.5025037961
gradient descent iteration = 2
gd loss = 304852.5025037961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 304263.7384159117
gradient descent iteration = 3
gd loss = 304263.7384159117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303681.696036337
gradient descent iteration = 4
gd loss = 303681.696036337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 303106.1287481768
gradient descent iteration = 5
gd loss = 303106.1287481768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 302536.7868491114
gradient descent iteration = 6
gd loss = 302536.7868491114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 301973.4202763286
gradient descent iteration = 7
gd loss = 301973.4202763286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 301415.7802753251
gradient descent iteration = 8
gd loss = 301415.7802753251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300863.6210134192
gradient descent iteration = 9
gd loss = 300863.6210134192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 300316.7019546268
gradient descent iteration = 10
gd loss = 300316.7019546268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 299774.7899757107
gradient descent iteration = 11
gd loss = 299774.7899757107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 299237.6607401634
gradient descent iteration = 12
gd loss = 299237.6607401634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 298705.0991158088
gradient descent iteration = 13
gd loss = 298705.0991158088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 298176.8992761482
gradient descent iteration = 14
gd loss = 298176.8992761482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297652.8640925232
gradient descent iteration = 15
gd loss = 297652.8640925232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 297132.8058624329
gradient descent iteration = 16
gd loss = 297132.8058624329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 296616.5464683646
gradient descent iteration = 17
gd loss = 296616.5464683646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 296103.9169127529
gradient descent iteration = 18
gd loss = 296103.9169127529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 295594.7559650944
gradient descent iteration = 19
gd loss = 295594.7559650944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 295088.9105996802
gradient descent iteration = 20
gd loss = 295088.9105996802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 294586.2360295253
gradient descent iteration = 21
gd loss = 294586.2360295253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 294086.5949859589
gradient descent iteration = 22
gd loss = 294086.5949859589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 293589.8572765721
gradient descent iteration = 23
gd loss = 293589.8572765721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 293095.8997423592
gradient descent iteration = 24
gd loss = 293095.8997423592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 292604.6060528766
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 292604.6060528766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 292256.8223686922
gradient descent iteration = 1
gd loss = 292256.8223686922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 291912.4510452777
gradient descent iteration = 2
gd loss = 291912.4510452777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 291571.3908936519
gradient descent iteration = 3
gd loss = 291571.3908936519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 291233.5469307466
gradient descent iteration = 4
gd loss = 291233.5469307466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 290898.8298515462
gradient descent iteration = 5
gd loss = 290898.8298515462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 290567.155998258
gradient descent iteration = 6
gd loss = 290567.155998258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 290238.4466933162
gradient descent iteration = 7
gd loss = 290238.4466933162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 289912.6275852356
gradient descent iteration = 8
gd loss = 289912.6275852356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 289589.6281043637
gradient descent iteration = 9
gd loss = 289589.6281043637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 289269.3808681031
gradient descent iteration = 10
gd loss = 289269.3808681031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 288951.8214228465
gradient descent iteration = 11
gd loss = 288951.8214228465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 288636.8879696912
gradient descent iteration = 12
gd loss = 288636.8879696912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 288324.5213000351
gradient descent iteration = 13
gd loss = 288324.5213000351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 288014.6641860895
gradient descent iteration = 14
gd loss = 288014.6641860895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 287707.2611510336
gradient descent iteration = 15
gd loss = 287707.2611510336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 287402.2584703989
gradient descent iteration = 16
gd loss = 287402.2584703989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 287099.6037357236
gradient descent iteration = 17
gd loss = 287099.6037357236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 286799.2458217662
gradient descent iteration = 18
gd loss = 286799.2458217662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 286501.135056871
gradient descent iteration = 19
gd loss = 286501.135056871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 286205.2231083121
gradient descent iteration = 20
gd loss = 286205.2231083121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 285911.4630222456
gradient descent iteration = 21
gd loss = 285911.4630222456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 285619.8090563632
gradient descent iteration = 22
gd loss = 285619.8090563632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 285330.2165164334
gradient descent iteration = 23
gd loss = 285330.2165164334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 285042.6415917043
gradient descent iteration = 24
gd loss = 285042.6415917043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 284757.0412969386
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 284757.0412969386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 284274.0192353421
gradient descent iteration = 1
gd loss = 284274.0192353421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 283798.9924253226
gradient descent iteration = 2
gd loss = 283798.9924253226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 283331.7442732385
gradient descent iteration = 3
gd loss = 283331.7442732385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 282872.0650754305
gradient descent iteration = 4
gd loss = 282872.0650754305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 282419.7517047311
gradient descent iteration = 5
gd loss = 282419.7517047311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281974.6073561661
gradient descent iteration = 6
gd loss = 281974.6073561661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281536.4413893552
gradient descent iteration = 7
gd loss = 281536.4413893552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281105.0692176749
gradient descent iteration = 8
gd loss = 281105.0692176749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 280680.3120910169
gradient descent iteration = 9
gd loss = 280680.3120910169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 280261.9968191225
gradient descent iteration = 10
gd loss = 280261.9968191225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279849.9556141132
gradient descent iteration = 11
gd loss = 279849.9556141132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279444.0259127049
gradient descent iteration = 12
gd loss = 279444.0259127049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279044.0502127197
gradient descent iteration = 13
gd loss = 279044.0502127197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 278649.8759572867
gradient descent iteration = 14
gd loss = 278649.8759572867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 278261.3552829636
gradient descent iteration = 15
gd loss = 278261.3552829636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277878.3447921412
gradient descent iteration = 16
gd loss = 277878.3447921412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277500.705511309
gradient descent iteration = 17
gd loss = 277500.705511309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277128.302747391
gradient descent iteration = 18
gd loss = 277128.302747391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276761.0059757083
gradient descent iteration = 19
gd loss = 276761.0059757083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276398.6886535982
gradient descent iteration = 20
gd loss = 276398.6886535982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276041.2280607494
gradient descent iteration = 21
gd loss = 276041.2280607494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 275688.5051699748
gradient descent iteration = 22
gd loss = 275688.5051699748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 275340.4045148324
gradient descent iteration = 23
gd loss = 275340.4045148324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274996.81408665
gradient descent iteration = 24
gd loss = 274996.81408665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274657.6252183573
Initial loss = 306051.1505382661
Final loss = 274657.6252183573
Deformation gradient control sequence optimization finished.
Animation interval 8 took 1401 seconds.
Full animation took 12159 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 9************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 282492.548145936
initial norm = 5379.252826111543
convergence norm = 5.379252826111543
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 282492.548145936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281958.6496405246
gradient descent iteration = 1
gd loss = 281958.6496405246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 281432.420233918
gradient descent iteration = 2
gd loss = 281432.420233918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 280913.5170424269
gradient descent iteration = 3
gd loss = 280913.5170424269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 280401.6212704527
gradient descent iteration = 4
gd loss = 280401.6212704527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279896.4229243049
gradient descent iteration = 5
gd loss = 279896.4229243049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 279397.6164070833
gradient descent iteration = 6
gd loss = 279397.6164070833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 278904.8998656251
gradient descent iteration = 7
gd loss = 278904.8998656251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 278417.9750537549
gradient descent iteration = 8
gd loss = 278417.9750537549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277936.5481992018
gradient descent iteration = 9
gd loss = 277936.5481992018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 277460.3303496797
gradient descent iteration = 10
gd loss = 277460.3303496797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276989.0383453582
gradient descent iteration = 11
gd loss = 276989.0383453582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276522.3971526366
gradient descent iteration = 12
gd loss = 276522.3971526366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 276060.1408583152
gradient descent iteration = 13
gd loss = 276060.1408583152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 275602.0133921922
gradient descent iteration = 14
gd loss = 275602.0133921922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 275147.7710159904
gradient descent iteration = 15
gd loss = 275147.7710159904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274697.1809380801
gradient descent iteration = 16
gd loss = 274697.1809380801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 274250.0221207166
gradient descent iteration = 17
gd loss = 274250.0221207166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 273806.0856009079
gradient descent iteration = 18
gd loss = 273806.0856009079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 273365.1764589106
gradient descent iteration = 19
gd loss = 273365.1764589106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 272927.1121987121
gradient descent iteration = 20
gd loss = 272927.1121987121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 272491.7220258539
gradient descent iteration = 21
gd loss = 272491.7220258539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 272058.8473835957
gradient descent iteration = 22
gd loss = 272058.8473835957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 271628.3425077312
gradient descent iteration = 23
gd loss = 271628.3425077312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 271200.0723844049
gradient descent iteration = 24
gd loss = 271200.0723844049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270773.9109379177
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 270773.9109379177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270485.0978469043
gradient descent iteration = 1
gd loss = 270485.0978469043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 270198.9624227733
gradient descent iteration = 2
gd loss = 270198.9624227733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269915.3775886029
gradient descent iteration = 3
gd loss = 269915.3775886029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269634.2559535412
gradient descent iteration = 4
gd loss = 269634.2559535412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269355.5212381229
gradient descent iteration = 5
gd loss = 269355.5212381229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 269079.1023612156
gradient descent iteration = 6
gd loss = 269079.1023612156
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268804.9323721813
gradient descent iteration = 7
gd loss = 268804.9323721813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268532.9478853746
gradient descent iteration = 8
gd loss = 268532.9478853746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 268263.0887498174
gradient descent iteration = 9
gd loss = 268263.0887498174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267995.2977440681
gradient descent iteration = 10
gd loss = 267995.2977440681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267729.520562879
gradient descent iteration = 11
gd loss = 267729.520562879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267465.706141701
gradient descent iteration = 12
gd loss = 267465.706141701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 267203.8064824176
gradient descent iteration = 13
gd loss = 267203.8064824176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266943.7764061933
gradient descent iteration = 14
gd loss = 266943.7764061933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266685.573005896
gradient descent iteration = 15
gd loss = 266685.573005896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266429.1552085057
gradient descent iteration = 16
gd loss = 266429.1552085057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 266174.483805913
gradient descent iteration = 17
gd loss = 266174.483805913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265921.5214355131
gradient descent iteration = 18
gd loss = 265921.5214355131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265670.2326172257
gradient descent iteration = 19
gd loss = 265670.2326172257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265420.5831936935
gradient descent iteration = 20
gd loss = 265420.5831936935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 265172.5401810763
gradient descent iteration = 21
gd loss = 265172.5401810763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264926.0719608251
gradient descent iteration = 22
gd loss = 264926.0719608251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264681.1481771887
gradient descent iteration = 23
gd loss = 264681.1481771887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264437.7393787258
gradient descent iteration = 24
gd loss = 264437.7393787258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 264195.8167893572
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 264195.8167893572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263792.3948443854
gradient descent iteration = 1
gd loss = 263792.3948443854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263396.574029231
gradient descent iteration = 2
gd loss = 263396.574029231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 263008.1140573872
gradient descent iteration = 3
gd loss = 263008.1140573872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 262626.7834342052
gradient descent iteration = 4
gd loss = 262626.7834342052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 262252.3591224257
gradient descent iteration = 5
gd loss = 262252.3591224257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261884.6262537886
gradient descent iteration = 6
gd loss = 261884.6262537886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261523.3779420378
gradient descent iteration = 7
gd loss = 261523.3779420378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 261168.4149369811
gradient descent iteration = 8
gd loss = 261168.4149369811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260819.5453061995
gradient descent iteration = 9
gd loss = 260819.5453061995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260476.5841808116
gradient descent iteration = 10
gd loss = 260476.5841808116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260139.3534602006
gradient descent iteration = 11
gd loss = 260139.3534602006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259807.6815348117
gradient descent iteration = 12
gd loss = 259807.6815348117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259481.4030201263
gradient descent iteration = 13
gd loss = 259481.4030201263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259160.3585437736
gradient descent iteration = 14
gd loss = 259160.3585437736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258844.3945576864
gradient descent iteration = 15
gd loss = 258844.3945576864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258533.3631045028
gradient descent iteration = 16
gd loss = 258533.3631045028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258227.1215693102
gradient descent iteration = 17
gd loss = 258227.1215693102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257925.5324097021
gradient descent iteration = 18
gd loss = 257925.5324097021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257628.462979313
gradient descent iteration = 19
gd loss = 257628.462979313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257335.7853314275
gradient descent iteration = 20
gd loss = 257335.7853314275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257047.376001126
gradient descent iteration = 21
gd loss = 257047.376001126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256763.115831495
gradient descent iteration = 22
gd loss = 256763.115831495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256482.8898252538
gradient descent iteration = 23
gd loss = 256482.8898252538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256206.5869625777
gradient descent iteration = 24
gd loss = 256206.5869625777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255934.1000470538
Initial loss = 282492.548145936
Final loss = 255934.1000470538
Deformation gradient control sequence optimization finished.
Animation interval 9 took 1371 seconds.
Full animation took 13530 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 10************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 261365.1004758824
initial norm = 4778.051130971257
convergence norm = 4.778051130971257
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 261365.1004758824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260916.1488314234
gradient descent iteration = 1
gd loss = 260916.1488314234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260468.2344802283
gradient descent iteration = 2
gd loss = 260468.2344802283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 260020.972693289
gradient descent iteration = 3
gd loss = 260020.972693289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259576.7913710418
gradient descent iteration = 4
gd loss = 259576.7913710418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 259138.0818621758
gradient descent iteration = 5
gd loss = 259138.0818621758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258705.6089895512
gradient descent iteration = 6
gd loss = 258705.6089895512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 258279.5131645421
gradient descent iteration = 7
gd loss = 258279.5131645421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257859.6673962245
gradient descent iteration = 8
gd loss = 257859.6673962245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257445.8500567323
gradient descent iteration = 9
gd loss = 257445.8500567323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 257037.9046467883
gradient descent iteration = 10
gd loss = 257037.9046467883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256635.7958441187
gradient descent iteration = 11
gd loss = 256635.7958441187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 256239.569876257
gradient descent iteration = 12
gd loss = 256239.569876257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255848.4996029086
gradient descent iteration = 13
gd loss = 255848.4996029086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255461.2634397638
gradient descent iteration = 14
gd loss = 255461.2634397638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 255076.4469564443
gradient descent iteration = 15
gd loss = 255076.4469564443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 254694.0404718135
gradient descent iteration = 16
gd loss = 254694.0404718135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 254314.0905981105
gradient descent iteration = 17
gd loss = 254314.0905981105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253936.7534693008
gradient descent iteration = 18
gd loss = 253936.7534693008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253562.0082620578
gradient descent iteration = 19
gd loss = 253562.0082620578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 253189.8178349423
gradient descent iteration = 20
gd loss = 253189.8178349423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252820.1016257374
gradient descent iteration = 21
gd loss = 252820.1016257374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252452.799617303
gradient descent iteration = 22
gd loss = 252452.799617303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 252087.8539282561
gradient descent iteration = 23
gd loss = 252087.8539282561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251725.2470623189
gradient descent iteration = 24
gd loss = 251725.2470623189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251364.9684578978
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 251364.9684578978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 251117.8620575278
gradient descent iteration = 1
gd loss = 251117.8620575278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250873.1172997809
gradient descent iteration = 2
gd loss = 250873.1172997809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250630.3370371507
gradient descent iteration = 3
gd loss = 250630.3370371507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250389.4618147771
gradient descent iteration = 4
gd loss = 250389.4618147771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 250150.4365402434
gradient descent iteration = 5
gd loss = 250150.4365402434
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249913.2086558254
gradient descent iteration = 6
gd loss = 249913.2086558254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249677.7278027823
gradient descent iteration = 7
gd loss = 249677.7278027823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249443.9456366468
gradient descent iteration = 8
gd loss = 249443.9456366468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 249211.8158247235
gradient descent iteration = 9
gd loss = 249211.8158247235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248981.2939273026
gradient descent iteration = 10
gd loss = 248981.2939273026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248752.3373866251
gradient descent iteration = 11
gd loss = 248752.3373866251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248524.905462384
gradient descent iteration = 12
gd loss = 248524.905462384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248298.9590536898
gradient descent iteration = 13
gd loss = 248298.9590536898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 248074.4607530194
gradient descent iteration = 14
gd loss = 248074.4607530194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247851.3747416027
gradient descent iteration = 15
gd loss = 247851.3747416027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247629.6668780352
gradient descent iteration = 16
gd loss = 247629.6668780352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247409.3045456291
gradient descent iteration = 17
gd loss = 247409.3045456291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 247190.2562429472
gradient descent iteration = 18
gd loss = 247190.2562429472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246972.4916834411
gradient descent iteration = 19
gd loss = 246972.4916834411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246755.9819204393
gradient descent iteration = 20
gd loss = 246755.9819204393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246540.6991680836
gradient descent iteration = 21
gd loss = 246540.6991680836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246326.6167220974
gradient descent iteration = 22
gd loss = 246326.6167220974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 246113.7089215003
gradient descent iteration = 23
gd loss = 246113.7089215003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 245901.9510461977
gradient descent iteration = 24
gd loss = 245901.9510461977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 245691.3192229111
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 245691.3192229111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 245345.6480106873
gradient descent iteration = 1
gd loss = 245345.6480106873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 245007.4713903893
gradient descent iteration = 2
gd loss = 245007.4713903893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 244676.5117402423
gradient descent iteration = 3
gd loss = 244676.5117402423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 244352.5034486695
gradient descent iteration = 4
gd loss = 244352.5034486695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 244035.1923906204
gradient descent iteration = 5
gd loss = 244035.1923906204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 243724.3354611435
gradient descent iteration = 6
gd loss = 243724.3354611435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 243419.7001193327
gradient descent iteration = 7
gd loss = 243419.7001193327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 243121.0639499622
gradient descent iteration = 8
gd loss = 243121.0639499622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242828.2141219622
gradient descent iteration = 9
gd loss = 242828.2141219622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242540.94695136
gradient descent iteration = 10
gd loss = 242540.94695136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242259.0674700334
gradient descent iteration = 11
gd loss = 242259.0674700334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241982.3890400893
gradient descent iteration = 12
gd loss = 241982.3890400893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241710.7329436152
gradient descent iteration = 13
gd loss = 241710.7329436152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241443.9280268538
gradient descent iteration = 14
gd loss = 241443.9280268538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241181.8103130615
gradient descent iteration = 15
gd loss = 241181.8103130615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240924.222673629
gradient descent iteration = 16
gd loss = 240924.222673629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240671.0145571203
gradient descent iteration = 17
gd loss = 240671.0145571203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240422.0416337685
gradient descent iteration = 18
gd loss = 240422.0416337685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240177.1655407227
gradient descent iteration = 19
gd loss = 240177.1655407227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239936.2535877211
gradient descent iteration = 20
gd loss = 239936.2535877211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239699.1785131438
gradient descent iteration = 21
gd loss = 239699.1785131438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239465.8182009154
gradient descent iteration = 22
gd loss = 239465.8182009154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239236.0553994565
gradient descent iteration = 23
gd loss = 239236.0553994565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239009.7774857998
gradient descent iteration = 24
gd loss = 239009.7774857998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 238786.8762607566
Initial loss = 261365.1004758824
Final loss = 238786.8762607566
Deformation gradient control sequence optimization finished.
Animation interval 10 took 1345 seconds.
Full animation took 14875 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 11************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 243789.5810209281
initial norm = 4799.944850134459
convergence norm = 4.799944850134459
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 243789.5810209281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 243426.3759939073
gradient descent iteration = 1
gd loss = 243426.3759939073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242980.0186605522
gradient descent iteration = 2
gd loss = 242980.0186605522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242561.474831041
gradient descent iteration = 3
gd loss = 242561.474831041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 242151.5783553896
gradient descent iteration = 4
gd loss = 242151.5783553896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241750.3901017426
gradient descent iteration = 5
gd loss = 241750.3901017426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 241357.296088731
gradient descent iteration = 6
gd loss = 241357.296088731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240971.6923601151
gradient descent iteration = 7
gd loss = 240971.6923601151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240593.0088370351
gradient descent iteration = 8
gd loss = 240593.0088370351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 240220.7117348189
gradient descent iteration = 9
gd loss = 240220.7117348189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239854.3048329139
gradient descent iteration = 10
gd loss = 239854.3048329139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239493.3286247198
gradient descent iteration = 11
gd loss = 239493.3286247198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 239137.3596593597
gradient descent iteration = 12
gd loss = 239137.3596593597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 238786.0095084679
gradient descent iteration = 13
gd loss = 238786.0095084679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 238438.9231400246
gradient descent iteration = 14
gd loss = 238438.9231400246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 238095.7769032367
gradient descent iteration = 15
gd loss = 238095.7769032367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 237756.2774205567
gradient descent iteration = 16
gd loss = 237756.2774205567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 237420.160329431
gradient descent iteration = 17
gd loss = 237420.160329431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 237087.1889445763
gradient descent iteration = 18
gd loss = 237087.1889445763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 236757.1539960441
gradient descent iteration = 19
gd loss = 236757.1539960441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 236429.8710418772
gradient descent iteration = 20
gd loss = 236429.8710418772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 236105.1916553358
gradient descent iteration = 21
gd loss = 236105.1916553358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 235783.1008712531
gradient descent iteration = 22
gd loss = 235783.1008712531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 235464.4951458527
gradient descent iteration = 23
gd loss = 235464.4951458527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 235154.7013307956
gradient descent iteration = 24
gd loss = 235154.7013307956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234857.8298787927
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 234857.8298787927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234642.5284735021
gradient descent iteration = 1
gd loss = 234642.5284735021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234434.6886359908
gradient descent iteration = 2
gd loss = 234434.6886359908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234229.3157558628
gradient descent iteration = 3
gd loss = 234229.3157558628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 234025.5077099212
gradient descent iteration = 4
gd loss = 234025.5077099212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233823.157595385
gradient descent iteration = 5
gd loss = 233823.157595385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233622.2235710975
gradient descent iteration = 6
gd loss = 233622.2235710975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233422.669623135
gradient descent iteration = 7
gd loss = 233422.669623135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233224.4616728324
gradient descent iteration = 8
gd loss = 233224.4616728324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 233027.5672084616
gradient descent iteration = 9
gd loss = 233027.5672084616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232831.9551957306
gradient descent iteration = 10
gd loss = 232831.9551957306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232637.595929258
gradient descent iteration = 11
gd loss = 232637.595929258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232444.4610106824
gradient descent iteration = 12
gd loss = 232444.4610106824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232252.523328211
gradient descent iteration = 13
gd loss = 232252.523328211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 232061.7569353942
gradient descent iteration = 14
gd loss = 232061.7569353942
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231872.1369245962
gradient descent iteration = 15
gd loss = 231872.1369245962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231683.6393568359
gradient descent iteration = 16
gd loss = 231683.6393568359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231496.241104586
gradient descent iteration = 17
gd loss = 231496.241104586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231309.9198610747
gradient descent iteration = 18
gd loss = 231309.9198610747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 231124.6541625202
gradient descent iteration = 19
gd loss = 231124.6541625202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230940.4233739461
gradient descent iteration = 20
gd loss = 230940.4233739461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230757.2076409713
gradient descent iteration = 21
gd loss = 230757.2076409713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230574.9877644264
gradient descent iteration = 22
gd loss = 230574.9877644264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230393.7451477828
gradient descent iteration = 23
gd loss = 230393.7451477828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230213.4617670704
gradient descent iteration = 24
gd loss = 230213.4617670704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 230034.1201603486
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 230034.1201603486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 229759.4810870639
gradient descent iteration = 1
gd loss = 229759.4810870639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 229491.2337580999
gradient descent iteration = 2
gd loss = 229491.2337580999
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 229229.1115272062
gradient descent iteration = 3
gd loss = 229229.1115272062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228972.8610539043
gradient descent iteration = 4
gd loss = 228972.8610539043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228722.2416467888
gradient descent iteration = 5
gd loss = 228722.2416467888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228477.0246245886
gradient descent iteration = 6
gd loss = 228477.0246245886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228236.9926669551
gradient descent iteration = 7
gd loss = 228236.9926669551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 228001.9392071851
gradient descent iteration = 8
gd loss = 228001.9392071851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227771.6678584703
gradient descent iteration = 9
gd loss = 227771.6678584703
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227545.9918795978
gradient descent iteration = 10
gd loss = 227545.9918795978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227324.7336337615
gradient descent iteration = 11
gd loss = 227324.7336337615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227107.724065702
gradient descent iteration = 12
gd loss = 227107.724065702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226894.8022275073
gradient descent iteration = 13
gd loss = 226894.8022275073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226685.8147796714
gradient descent iteration = 14
gd loss = 226685.8147796714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226480.6155535028
gradient descent iteration = 15
gd loss = 226480.6155535028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226279.0651559011
gradient descent iteration = 16
gd loss = 226279.0651559011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226081.0305917154
gradient descent iteration = 17
gd loss = 226081.0305917154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225886.3849329477
gradient descent iteration = 18
gd loss = 225886.3849329477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225695.0070168623
gradient descent iteration = 19
gd loss = 225695.0070168623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225506.7811635654
gradient descent iteration = 20
gd loss = 225506.7811635654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225321.5969134495
gradient descent iteration = 21
gd loss = 225321.5969134495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225139.3487006364
gradient descent iteration = 22
gd loss = 225139.3487006364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224959.9356015909
gradient descent iteration = 23
gd loss = 224959.9356015909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224783.2611286265
gradient descent iteration = 24
gd loss = 224783.2611286265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224609.2330252512
Initial loss = 243789.5810209281
Final loss = 224609.2330252512
Deformation gradient control sequence optimization finished.
Animation interval 11 took 1336 seconds.
Full animation took 16212 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 12************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 227653.1126339996
initial norm = 3875.48473567289
convergence norm = 3.87548473567289
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 227653.1126339996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 227347.2434734805
gradient descent iteration = 1
gd loss = 227347.2434734805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226993.7960619222
gradient descent iteration = 2
gd loss = 226993.7960619222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226654.2722791594
gradient descent iteration = 3
gd loss = 226654.2722791594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 226322.217660476
gradient descent iteration = 4
gd loss = 226322.217660476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225996.9340586116
gradient descent iteration = 5
gd loss = 225996.9340586116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225677.7823308875
gradient descent iteration = 6
gd loss = 225677.7823308875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225364.1838831392
gradient descent iteration = 7
gd loss = 225364.1838831392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 225055.6196162595
gradient descent iteration = 8
gd loss = 225055.6196162595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224751.6273553378
gradient descent iteration = 9
gd loss = 224751.6273553378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224451.7980045873
gradient descent iteration = 10
gd loss = 224451.7980045873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 224155.7723315741
gradient descent iteration = 11
gd loss = 224155.7723315741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223863.2374612866
gradient descent iteration = 12
gd loss = 223863.2374612866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223573.9205859437
gradient descent iteration = 13
gd loss = 223573.9205859437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223287.5856927895
gradient descent iteration = 14
gd loss = 223287.5856927895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 223004.0283539002
gradient descent iteration = 15
gd loss = 223004.0283539002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222723.0722834926
gradient descent iteration = 16
gd loss = 222723.0722834926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222444.5665229617
gradient descent iteration = 17
gd loss = 222444.5665229617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 222168.3813797204
gradient descent iteration = 18
gd loss = 222168.3813797204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221894.4039251093
gradient descent iteration = 19
gd loss = 221894.4039251093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221622.5337991327
gradient descent iteration = 20
gd loss = 221622.5337991327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221352.680940253
gradient descent iteration = 21
gd loss = 221352.680940253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 221084.7686471618
gradient descent iteration = 22
gd loss = 221084.7686471618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220818.739732352
gradient descent iteration = 23
gd loss = 220818.739732352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220554.6140483068
gradient descent iteration = 24
gd loss = 220554.6140483068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220292.8760314944
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 220292.8760314944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 220094.384757715
gradient descent iteration = 1
gd loss = 220094.384757715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219898.0804207053
gradient descent iteration = 2
gd loss = 219898.0804207053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219703.6064183054
gradient descent iteration = 3
gd loss = 219703.6064183054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219510.7984336118
gradient descent iteration = 4
gd loss = 219510.7984336118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219319.5847236672
gradient descent iteration = 5
gd loss = 219319.5847236672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 219129.9097189085
gradient descent iteration = 6
gd loss = 219129.9097189085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218941.7259076454
gradient descent iteration = 7
gd loss = 218941.7259076454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218754.9899020213
gradient descent iteration = 8
gd loss = 218754.9899020213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218569.6617452283
gradient descent iteration = 9
gd loss = 218569.6617452283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218385.7039798364
gradient descent iteration = 10
gd loss = 218385.7039798364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218203.0813591541
gradient descent iteration = 11
gd loss = 218203.0813591541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 218021.7605384523
gradient descent iteration = 12
gd loss = 218021.7605384523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217841.7100498526
gradient descent iteration = 13
gd loss = 217841.7100498526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217662.9001097544
gradient descent iteration = 14
gd loss = 217662.9001097544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217485.3024670389
gradient descent iteration = 15
gd loss = 217485.3024670389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217308.8902836866
gradient descent iteration = 16
gd loss = 217308.8902836866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 217133.6380810217
gradient descent iteration = 17
gd loss = 217133.6380810217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216959.5215944451
gradient descent iteration = 18
gd loss = 216959.5215944451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216786.5177359524
gradient descent iteration = 19
gd loss = 216786.5177359524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216614.604395331
gradient descent iteration = 20
gd loss = 216614.604395331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216443.7604170166
gradient descent iteration = 21
gd loss = 216443.7604170166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216273.9656236888
gradient descent iteration = 22
gd loss = 216273.9656236888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 216105.2007219912
gradient descent iteration = 23
gd loss = 216105.2007219912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215937.4472402452
gradient descent iteration = 24
gd loss = 215937.4472402452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215770.6874809644
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 215770.6874809644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215545.1780227754
gradient descent iteration = 1
gd loss = 215545.1780227754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215325.6592428366
gradient descent iteration = 2
gd loss = 215325.6592428366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 215111.8033404131
gradient descent iteration = 3
gd loss = 215111.8033404131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214903.3069274033
gradient descent iteration = 4
gd loss = 214903.3069274033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214699.8887325561
gradient descent iteration = 5
gd loss = 214699.8887325561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214501.2875413861
gradient descent iteration = 6
gd loss = 214501.2875413861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214307.2602828274
gradient descent iteration = 7
gd loss = 214307.2602828274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 214117.5803571219
gradient descent iteration = 8
gd loss = 214117.5803571219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213932.0361130024
gradient descent iteration = 9
gd loss = 213932.0361130024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213750.4295642056
gradient descent iteration = 10
gd loss = 213750.4295642056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213572.5752352173
gradient descent iteration = 11
gd loss = 213572.5752352173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213398.2991126908
gradient descent iteration = 12
gd loss = 213398.2991126908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213227.437749031
gradient descent iteration = 13
gd loss = 213227.437749031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 213059.8374859314
gradient descent iteration = 14
gd loss = 213059.8374859314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212895.3537409296
gradient descent iteration = 15
gd loss = 212895.3537409296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212733.8503537854
gradient descent iteration = 16
gd loss = 212733.8503537854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212575.1990060786
gradient descent iteration = 17
gd loss = 212575.1990060786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212419.2786877227
gradient descent iteration = 18
gd loss = 212419.2786877227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212265.9752174398
gradient descent iteration = 19
gd loss = 212265.9752174398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212115.1808108457
gradient descent iteration = 20
gd loss = 212115.1808108457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211966.7936519157
gradient descent iteration = 21
gd loss = 211966.7936519157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211820.7175185596
gradient descent iteration = 22
gd loss = 211820.7175185596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211676.8614209234
gradient descent iteration = 23
gd loss = 211676.8614209234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211535.1392804464
gradient descent iteration = 24
gd loss = 211535.1392804464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211395.4696642079
Initial loss = 227653.1126339996
Final loss = 211395.4696642079
Deformation gradient control sequence optimization finished.
Animation interval 12 took 1341 seconds.
Full animation took 17554 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 13************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 212633.259850643
initial norm = 3652.804758442406
convergence norm = 3.652804758442406
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 212633.259850643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212328.509325801
gradient descent iteration = 1
gd loss = 212328.509325801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 212018.1037899097
gradient descent iteration = 2
gd loss = 212018.1037899097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211722.1865858685
gradient descent iteration = 3
gd loss = 211722.1865858685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211439.027878723
gradient descent iteration = 4
gd loss = 211439.027878723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 211166.9850566577
gradient descent iteration = 5
gd loss = 211166.9850566577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210904.5651376502
gradient descent iteration = 6
gd loss = 210904.5651376502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210650.4162427549
gradient descent iteration = 7
gd loss = 210650.4162427549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210403.3229103348
gradient descent iteration = 8
gd loss = 210403.3229103348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 210162.2140650013
gradient descent iteration = 9
gd loss = 210162.2140650013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209926.1670976936
gradient descent iteration = 10
gd loss = 209926.1670976936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209694.4036182141
gradient descent iteration = 11
gd loss = 209694.4036182141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209466.279127515
gradient descent iteration = 12
gd loss = 209466.279127515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209241.2677102093
gradient descent iteration = 13
gd loss = 209241.2677102093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 209018.9447629252
gradient descent iteration = 14
gd loss = 209018.9447629252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208798.969257291
gradient descent iteration = 15
gd loss = 208798.969257291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208581.0676840965
gradient descent iteration = 16
gd loss = 208581.0676840965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208365.0214422374
gradient descent iteration = 17
gd loss = 208365.0214422374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 208150.6562725648
gradient descent iteration = 18
gd loss = 208150.6562725648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207937.8325440287
gradient descent iteration = 19
gd loss = 207937.8325440287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207726.4376634357
gradient descent iteration = 20
gd loss = 207726.4376634357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207516.3796238003
gradient descent iteration = 21
gd loss = 207516.3796238003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207307.582551779
gradient descent iteration = 22
gd loss = 207307.582551779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 207099.9836317073
gradient descent iteration = 23
gd loss = 207099.9836317073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206893.5306817448
gradient descent iteration = 24
gd loss = 206893.5306817448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206688.1802317415
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 206688.1802317415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206510.4918967773
gradient descent iteration = 1
gd loss = 206510.4918967773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206334.89880687
gradient descent iteration = 2
gd loss = 206334.89880687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 206161.2192751864
gradient descent iteration = 3
gd loss = 206161.2192751864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205989.3547554454
gradient descent iteration = 4
gd loss = 205989.3547554454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205819.2245304755
gradient descent iteration = 5
gd loss = 205819.2245304755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205650.7564633964
gradient descent iteration = 6
gd loss = 205650.7564633964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205483.8847178294
gradient descent iteration = 7
gd loss = 205483.8847178294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205318.5487651579
gradient descent iteration = 8
gd loss = 205318.5487651579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 205154.6927146786
gradient descent iteration = 9
gd loss = 205154.6927146786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204992.2648811417
gradient descent iteration = 10
gd loss = 204992.2648811417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204831.2174581131
gradient descent iteration = 11
gd loss = 204831.2174581131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204671.5061559533
gradient descent iteration = 12
gd loss = 204671.5061559533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204513.0899865225
gradient descent iteration = 13
gd loss = 204513.0899865225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204355.9308935412
gradient descent iteration = 14
gd loss = 204355.9308935412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204199.9934909014
gradient descent iteration = 15
gd loss = 204199.9934909014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 204045.2446813769
gradient descent iteration = 16
gd loss = 204045.2446813769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203891.6533881089
gradient descent iteration = 17
gd loss = 203891.6533881089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203739.190375303
gradient descent iteration = 18
gd loss = 203739.190375303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203587.8280729523
gradient descent iteration = 19
gd loss = 203587.8280729523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203437.5405474955
gradient descent iteration = 20
gd loss = 203437.5405474955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203288.3033727286
gradient descent iteration = 21
gd loss = 203288.3033727286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 203140.0934917498
gradient descent iteration = 22
gd loss = 203140.0934917498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202992.8892324054
gradient descent iteration = 23
gd loss = 202992.8892324054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202846.6701660045
gradient descent iteration = 24
gd loss = 202846.6701660045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202701.4170631726
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 202701.4170631726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202523.2503401006
gradient descent iteration = 1
gd loss = 202523.2503401006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202350.0218445373
gradient descent iteration = 2
gd loss = 202350.0218445373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202181.3468245459
gradient descent iteration = 3
gd loss = 202181.3468245459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 202016.9075215071
gradient descent iteration = 4
gd loss = 202016.9075215071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201856.4302183975
gradient descent iteration = 5
gd loss = 201856.4302183975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201699.6722548508
gradient descent iteration = 6
gd loss = 201699.6722548508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201546.4146719598
gradient descent iteration = 7
gd loss = 201546.4146719598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201396.4577792708
gradient descent iteration = 8
gd loss = 201396.4577792708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201249.6182612254
gradient descent iteration = 9
gd loss = 201249.6182612254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 201105.7271661166
gradient descent iteration = 10
gd loss = 201105.7271661166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200964.6283057114
gradient descent iteration = 11
gd loss = 200964.6283057114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200826.1769380759
gradient descent iteration = 12
gd loss = 200826.1769380759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200690.2386247843
gradient descent iteration = 13
gd loss = 200690.2386247843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200556.6882190754
gradient descent iteration = 14
gd loss = 200556.6882190754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200425.4088920952
gradient descent iteration = 15
gd loss = 200425.4088920952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200296.29113396
gradient descent iteration = 16
gd loss = 200296.29113396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200169.2316731777
gradient descent iteration = 17
gd loss = 200169.2316731777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 200044.1321190234
gradient descent iteration = 18
gd loss = 200044.1321190234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199920.8969956724
gradient descent iteration = 19
gd loss = 199920.8969956724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199799.4304127637
gradient descent iteration = 20
gd loss = 199799.4304127637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199679.6315947429
gradient descent iteration = 21
gd loss = 199679.6315947429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199561.4215195095
gradient descent iteration = 22
gd loss = 199561.4215195095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199453.1203874341
gradient descent iteration = 23
gd loss = 199453.1203874341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199332.5238707622
gradient descent iteration = 24
gd loss = 199332.5238707622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199219.2276768564
Initial loss = 212633.259850643
Final loss = 199219.2276768564
Deformation gradient control sequence optimization finished.
Animation interval 13 took 1332 seconds.
Full animation took 18886 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 14************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 199403.212453664
initial norm = 2887.281332896296
convergence norm = 2.887281332896296
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 199403.212453664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 199192.6555351739
gradient descent iteration = 1
gd loss = 199192.6555351739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198962.0276881092
gradient descent iteration = 2
gd loss = 198962.0276881092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198745.3019656683
gradient descent iteration = 3
gd loss = 198745.3019656683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198538.0928559242
gradient descent iteration = 4
gd loss = 198538.0928559242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198337.9246100733
gradient descent iteration = 5
gd loss = 198337.9246100733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 198143.3341073009
gradient descent iteration = 6
gd loss = 198143.3341073009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197953.2348606015
gradient descent iteration = 7
gd loss = 197953.2348606015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197766.7801680705
gradient descent iteration = 8
gd loss = 197766.7801680705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197583.3113249856
gradient descent iteration = 9
gd loss = 197583.3113249856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197402.3227432511
gradient descent iteration = 10
gd loss = 197402.3227432511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197223.4298145757
gradient descent iteration = 11
gd loss = 197223.4298145757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 197046.3490613821
gradient descent iteration = 12
gd loss = 197046.3490613821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196870.8852638901
gradient descent iteration = 13
gd loss = 196870.8852638901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196696.955322312
gradient descent iteration = 14
gd loss = 196696.955322312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196524.6420517941
gradient descent iteration = 15
gd loss = 196524.6420517941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196354.3033391426
gradient descent iteration = 16
gd loss = 196354.3033391426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196186.1400506523
gradient descent iteration = 17
gd loss = 196186.1400506523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 196019.4796754385
gradient descent iteration = 18
gd loss = 196019.4796754385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195852.5458671745
gradient descent iteration = 19
gd loss = 195852.5458671745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195685.416249055
gradient descent iteration = 20
gd loss = 195685.416249055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195518.4127785413
gradient descent iteration = 21
gd loss = 195518.4127785413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195351.8873490559
gradient descent iteration = 22
gd loss = 195351.8873490559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195185.9506681032
gradient descent iteration = 23
gd loss = 195185.9506681032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 195020.6506853036
gradient descent iteration = 24
gd loss = 195020.6506853036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194855.9900760728
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 194855.9900760728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194702.4234131835
gradient descent iteration = 1
gd loss = 194702.4234131835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194551.1607375366
gradient descent iteration = 2
gd loss = 194551.1607375366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194401.9378419486
gradient descent iteration = 3
gd loss = 194401.9378419486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194254.6148346308
gradient descent iteration = 4
gd loss = 194254.6148346308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 194109.0839849354
gradient descent iteration = 5
gd loss = 194109.0839849354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193965.2542855221
gradient descent iteration = 6
gd loss = 193965.2542855221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193823.0465054577
gradient descent iteration = 7
gd loss = 193823.0465054577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193682.3904377391
gradient descent iteration = 8
gd loss = 193682.3904377391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193543.2231279657
gradient descent iteration = 9
gd loss = 193543.2231279657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193405.4877816506
gradient descent iteration = 10
gd loss = 193405.4877816506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193269.1327333189
gradient descent iteration = 11
gd loss = 193269.1327333189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193134.110672734
gradient descent iteration = 12
gd loss = 193134.110672734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 193000.3780202174
gradient descent iteration = 13
gd loss = 193000.3780202174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192867.894445788
gradient descent iteration = 14
gd loss = 192867.894445788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192736.6224020165
gradient descent iteration = 15
gd loss = 192736.6224020165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192606.5267344491
gradient descent iteration = 16
gd loss = 192606.5267344491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192477.5745301706
gradient descent iteration = 17
gd loss = 192477.5745301706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192349.7348961512
gradient descent iteration = 18
gd loss = 192349.7348961512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192222.9787169418
gradient descent iteration = 19
gd loss = 192222.9787169418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 192097.2784921038
gradient descent iteration = 20
gd loss = 192097.2784921038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191972.6083481176
gradient descent iteration = 21
gd loss = 191972.6083481176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191848.9438331038
gradient descent iteration = 22
gd loss = 191848.9438331038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191726.2616480154
gradient descent iteration = 23
gd loss = 191726.2616480154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191604.5396366208
gradient descent iteration = 24
gd loss = 191604.5396366208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191483.7566723868
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 191483.7566723868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191344.2670140627
gradient descent iteration = 1
gd loss = 191344.2670140627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191208.3996964119
gradient descent iteration = 2
gd loss = 191208.3996964119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 191075.8765313383
gradient descent iteration = 3
gd loss = 191075.8765313383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190946.458643332
gradient descent iteration = 4
gd loss = 190946.458643332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190819.9367086641
gradient descent iteration = 5
gd loss = 190819.9367086641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190696.1246228687
gradient descent iteration = 6
gd loss = 190696.1246228687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190574.8552969449
gradient descent iteration = 7
gd loss = 190574.8552969449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190455.9777052217
gradient descent iteration = 8
gd loss = 190455.9777052217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190339.3546731151
gradient descent iteration = 9
gd loss = 190339.3546731151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190224.8611537372
gradient descent iteration = 10
gd loss = 190224.8611537372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190112.3828202373
gradient descent iteration = 11
gd loss = 190112.3828202373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 190001.8149043559
gradient descent iteration = 12
gd loss = 190001.8149043559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189893.0611822742
gradient descent iteration = 13
gd loss = 189893.0611822742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189786.0330980117
gradient descent iteration = 14
gd loss = 189786.0330980117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189680.6490002836
gradient descent iteration = 15
gd loss = 189680.6490002836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189576.8334667737
gradient descent iteration = 16
gd loss = 189576.8334667737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189474.5167210776
gradient descent iteration = 17
gd loss = 189474.5167210776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189373.6340797487
gradient descent iteration = 18
gd loss = 189373.6340797487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189274.1254747816
gradient descent iteration = 19
gd loss = 189274.1254747816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189175.9350303735
gradient descent iteration = 20
gd loss = 189175.9350303735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 189079.0106803817
gradient descent iteration = 21
gd loss = 189079.0106803817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188983.3038402369
gradient descent iteration = 22
gd loss = 188983.3038402369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188888.7691241268
gradient descent iteration = 23
gd loss = 188888.7691241268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188795.3640368877
gradient descent iteration = 24
gd loss = 188795.3640368877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188703.0487176531
Initial loss = 199403.212453664
Final loss = 188703.0487176531
Deformation gradient control sequence optimization finished.
Animation interval 14 took 1343 seconds.
Full animation took 20230 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 15************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 188987.9166739806
initial norm = 2369.617222172216
convergence norm = 2.369617222172216
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 188987.9166739806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188763.2665370433
gradient descent iteration = 1
gd loss = 188763.2665370433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188559.4316903386
gradient descent iteration = 2
gd loss = 188559.4316903386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188368.5857797844
gradient descent iteration = 3
gd loss = 188368.5857797844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188188.3608204356
gradient descent iteration = 4
gd loss = 188188.3608204356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 188016.5900404298
gradient descent iteration = 5
gd loss = 188016.5900404298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187851.4452498397
gradient descent iteration = 6
gd loss = 187851.4452498397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187691.4616472208
gradient descent iteration = 7
gd loss = 187691.4616472208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187535.5121897518
gradient descent iteration = 8
gd loss = 187535.5121897518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187382.7533431165
gradient descent iteration = 9
gd loss = 187382.7533431165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187232.5627662755
gradient descent iteration = 10
gd loss = 187232.5627662755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 187084.4823089141
gradient descent iteration = 11
gd loss = 187084.4823089141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186938.1722975501
gradient descent iteration = 12
gd loss = 186938.1722975501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186793.3775241803
gradient descent iteration = 13
gd loss = 186793.3775241803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186649.902968278
gradient descent iteration = 14
gd loss = 186649.902968278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186507.5968075206
gradient descent iteration = 15
gd loss = 186507.5968075206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186366.3388325729
gradient descent iteration = 16
gd loss = 186366.3388325729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186226.0324017282
gradient descent iteration = 17
gd loss = 186226.0324017282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 186086.5987437225
gradient descent iteration = 18
gd loss = 186086.5987437225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185947.9730649389
gradient descent iteration = 19
gd loss = 185947.9730649389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185810.1023333483
gradient descent iteration = 20
gd loss = 185810.1023333483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185672.9492789682
gradient descent iteration = 21
gd loss = 185672.9492789682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185536.6115641173
gradient descent iteration = 22
gd loss = 185536.6115641173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185404.5765300975
gradient descent iteration = 23
gd loss = 185404.5765300975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185302.5121786094
gradient descent iteration = 24
gd loss = 185302.5121786094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185171.6122358621
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 185171.6122358621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 185044.4188178054
gradient descent iteration = 1
gd loss = 185044.4188178054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184921.3571875549
gradient descent iteration = 2
gd loss = 184921.3571875549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184800.2611400278
gradient descent iteration = 3
gd loss = 184800.2611400278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184680.8428784351
gradient descent iteration = 4
gd loss = 184680.8428784351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184562.9835708539
gradient descent iteration = 5
gd loss = 184562.9835708539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184446.5911665048
gradient descent iteration = 6
gd loss = 184446.5911665048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184331.5864357652
gradient descent iteration = 7
gd loss = 184331.5864357652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184217.8998967492
gradient descent iteration = 8
gd loss = 184217.8998967492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 184105.4700749985
gradient descent iteration = 9
gd loss = 184105.4700749985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183994.2421843192
gradient descent iteration = 10
gd loss = 183994.2421843192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183884.1669763055
gradient descent iteration = 11
gd loss = 183884.1669763055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183775.1999021974
gradient descent iteration = 12
gd loss = 183775.1999021974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183667.3004145803
gradient descent iteration = 13
gd loss = 183667.3004145803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183560.4313263542
gradient descent iteration = 14
gd loss = 183560.4313263542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183454.5583282579
gradient descent iteration = 15
gd loss = 183454.5583282579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183349.6496297578
gradient descent iteration = 16
gd loss = 183349.6496297578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183245.6757566625
gradient descent iteration = 17
gd loss = 183245.6757566625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183142.6092955073
gradient descent iteration = 18
gd loss = 183142.6092955073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 183040.4246327733
gradient descent iteration = 19
gd loss = 183040.4246327733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182939.0977241722
gradient descent iteration = 20
gd loss = 182939.0977241722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182838.60592919
gradient descent iteration = 21
gd loss = 182838.60592919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182738.9279028977
gradient descent iteration = 22
gd loss = 182738.9279028977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182640.043460317
gradient descent iteration = 23
gd loss = 182640.043460317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182541.9334214226
gradient descent iteration = 24
gd loss = 182541.9334214226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182444.57953312
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 182444.57953312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182337.0628307749
gradient descent iteration = 1
gd loss = 182337.0628307749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182232.1615948656
gradient descent iteration = 2
gd loss = 182232.1615948656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182129.6665400857
gradient descent iteration = 3
gd loss = 182129.6665400857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 182029.3965652189
gradient descent iteration = 4
gd loss = 182029.3965652189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181931.1929240021
gradient descent iteration = 5
gd loss = 181931.1929240021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181834.9152925947
gradient descent iteration = 6
gd loss = 181834.9152925947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181740.4387822041
gradient descent iteration = 7
gd loss = 181740.4387822041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181647.6516536188
gradient descent iteration = 8
gd loss = 181647.6516536188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181556.4535720118
gradient descent iteration = 9
gd loss = 181556.4535720118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181466.754190624
gradient descent iteration = 10
gd loss = 181466.754190624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181378.4718349449
gradient descent iteration = 11
gd loss = 181378.4718349449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181291.5324652286
gradient descent iteration = 12
gd loss = 181291.5324652286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181205.8687632364
gradient descent iteration = 13
gd loss = 181205.8687632364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181121.4193323016
gradient descent iteration = 14
gd loss = 181121.4193323016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 181038.1280369538
gradient descent iteration = 15
gd loss = 181038.1280369538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180955.9434150216
gradient descent iteration = 16
gd loss = 180955.9434150216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180874.8181623016
gradient descent iteration = 17
gd loss = 180874.8181623016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180794.7086922113
gradient descent iteration = 18
gd loss = 180794.7086922113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180715.5747471969
gradient descent iteration = 19
gd loss = 180715.5747471969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180637.3790577382
gradient descent iteration = 20
gd loss = 180637.3790577382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180560.0870394329
gradient descent iteration = 21
gd loss = 180560.0870394329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180483.6665423121
gradient descent iteration = 22
gd loss = 180483.6665423121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180408.087643019
gradient descent iteration = 23
gd loss = 180408.087643019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180333.3224275634
gradient descent iteration = 24
gd loss = 180333.3224275634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 180259.34482948
Initial loss = 188987.9166739806
Final loss = 180259.34482948
Deformation gradient control sequence optimization finished.
Animation interval 15 took 1335 seconds.
Full animation took 21566 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 16************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 180066.9402917531
initial norm = 2035.76664253899
convergence norm = 2.03576664253899
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 180066.9402917531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179909.6207164257
gradient descent iteration = 1
gd loss = 179909.6207164257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179748.6482734202
gradient descent iteration = 2
gd loss = 179748.6482734202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179598.4384133054
gradient descent iteration = 3
gd loss = 179598.4384133054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179455.7984852355
gradient descent iteration = 4
gd loss = 179455.7984852355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179319.0289024712
gradient descent iteration = 5
gd loss = 179319.0289024712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179186.8034442501
gradient descent iteration = 6
gd loss = 179186.8034442501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 179058.1134442006
gradient descent iteration = 7
gd loss = 179058.1134442006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178932.2092237943
gradient descent iteration = 8
gd loss = 178932.2092237943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178808.5387539089
gradient descent iteration = 9
gd loss = 178808.5387539089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178686.6951417419
gradient descent iteration = 10
gd loss = 178686.6951417419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178566.376164269
gradient descent iteration = 11
gd loss = 178566.376164269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178447.3547387253
gradient descent iteration = 12
gd loss = 178447.3547387253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178329.4581690953
gradient descent iteration = 13
gd loss = 178329.4581690953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178212.5534096778
gradient descent iteration = 14
gd loss = 178212.5534096778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 178096.5366447009
gradient descent iteration = 15
gd loss = 178096.5366447009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177981.3258144543
gradient descent iteration = 16
gd loss = 177981.3258144543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177866.8551445348
gradient descent iteration = 17
gd loss = 177866.8551445348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177753.0712278334
gradient descent iteration = 18
gd loss = 177753.0712278334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177639.9300878387
gradient descent iteration = 19
gd loss = 177639.9300878387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177527.3950945887
gradient descent iteration = 20
gd loss = 177527.3950945887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177415.4354231198
gradient descent iteration = 21
gd loss = 177415.4354231198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177304.0250400311
gradient descent iteration = 22
gd loss = 177304.0250400311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177193.1418166121
gradient descent iteration = 23
gd loss = 177193.1418166121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 177082.7669453599
gradient descent iteration = 24
gd loss = 177082.7669453599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176972.8843088461
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 176972.8843088461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176855.377312885
gradient descent iteration = 1
gd loss = 176855.377312885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176740.2565934818
gradient descent iteration = 2
gd loss = 176740.2565934818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176627.3022954783
gradient descent iteration = 3
gd loss = 176627.3022954783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176516.3477448105
gradient descent iteration = 4
gd loss = 176516.3477448105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176407.2532842484
gradient descent iteration = 5
gd loss = 176407.2532842484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176299.8991098659
gradient descent iteration = 6
gd loss = 176299.8991098659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176194.1811790974
gradient descent iteration = 7
gd loss = 176194.1811790974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 176090.0082946882
gradient descent iteration = 8
gd loss = 176090.0082946882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175987.2998243332
gradient descent iteration = 9
gd loss = 175987.2998243332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175885.983935174
gradient descent iteration = 10
gd loss = 175885.983935174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175785.9962010221
gradient descent iteration = 11
gd loss = 175785.9962010221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175687.2785357681
gradient descent iteration = 12
gd loss = 175687.2785357681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175589.7783251909
gradient descent iteration = 13
gd loss = 175589.7783251909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175493.4475983416
gradient descent iteration = 14
gd loss = 175493.4475983416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175398.2424736836
gradient descent iteration = 15
gd loss = 175398.2424736836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175304.1226799565
gradient descent iteration = 16
gd loss = 175304.1226799565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175211.0510570067
gradient descent iteration = 17
gd loss = 175211.0510570067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175118.9931545556
gradient descent iteration = 18
gd loss = 175118.9931545556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 175027.9169098549
gradient descent iteration = 19
gd loss = 175027.9169098549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174937.7923773213
gradient descent iteration = 20
gd loss = 174937.7923773213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174848.5915342178
gradient descent iteration = 21
gd loss = 174848.5915342178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174760.2881114218
gradient descent iteration = 22
gd loss = 174760.2881114218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174672.8574548367
gradient descent iteration = 23
gd loss = 174672.8574548367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174586.2763754604
gradient descent iteration = 24
gd loss = 174586.2763754604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174500.5229342375
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 174500.5229342375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174408.1015615523
gradient descent iteration = 1
gd loss = 174408.1015615523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174317.912981431
gradient descent iteration = 2
gd loss = 174317.912981431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174229.7604457699
gradient descent iteration = 3
gd loss = 174229.7604457699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174143.4779775007
gradient descent iteration = 4
gd loss = 174143.4779775007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 174058.9240287731
gradient descent iteration = 5
gd loss = 174058.9240287731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173975.9769055961
gradient descent iteration = 6
gd loss = 173975.9769055961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173894.5312524438
gradient descent iteration = 7
gd loss = 173894.5312524438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173814.4952693997
gradient descent iteration = 8
gd loss = 173814.4952693997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173735.7883538473
gradient descent iteration = 9
gd loss = 173735.7883538473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173658.3392453115
gradient descent iteration = 10
gd loss = 173658.3392453115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173582.0845263065
gradient descent iteration = 11
gd loss = 173582.0845263065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173506.9674005692
gradient descent iteration = 12
gd loss = 173506.9674005692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173432.9367069979
gradient descent iteration = 13
gd loss = 173432.9367069979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173359.9461339501
gradient descent iteration = 14
gd loss = 173359.9461339501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173287.9535498733
gradient descent iteration = 15
gd loss = 173287.9535498733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173216.9204186233
gradient descent iteration = 16
gd loss = 173216.9204186233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173146.8112954168
gradient descent iteration = 17
gd loss = 173146.8112954168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173077.5934348667
gradient descent iteration = 18
gd loss = 173077.5934348667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 173009.2364794738
gradient descent iteration = 19
gd loss = 173009.2364794738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172941.7121958455
gradient descent iteration = 20
gd loss = 172941.7121958455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172874.9942798472
gradient descent iteration = 21
gd loss = 172874.9942798472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172809.058074157
gradient descent iteration = 22
gd loss = 172809.058074157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172743.8803683569
gradient descent iteration = 23
gd loss = 172743.8803683569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172679.439261904
gradient descent iteration = 24
gd loss = 172679.439261904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172615.7140567136
Initial loss = 180066.9402917531
Final loss = 172615.7140567136
Deformation gradient control sequence optimization finished.
Animation interval 16 took 1334 seconds.
Full animation took 22900 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 17************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 172667.5348769652
initial norm = 1872.362035131034
convergence norm = 1.872362035131034
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 172667.5348769652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172519.4986226374
gradient descent iteration = 1
gd loss = 172519.4986226374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172373.3492098239
gradient descent iteration = 2
gd loss = 172373.3492098239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172229.1774425862
gradient descent iteration = 3
gd loss = 172229.1774425862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 172095.0603261304
gradient descent iteration = 4
gd loss = 172095.0603261304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171968.922465344
gradient descent iteration = 5
gd loss = 171968.922465344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171849.1912086318
gradient descent iteration = 6
gd loss = 171849.1912086318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171734.5590166733
gradient descent iteration = 7
gd loss = 171734.5590166733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171623.9735966655
gradient descent iteration = 8
gd loss = 171623.9735966655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171516.6077883146
gradient descent iteration = 9
gd loss = 171516.6077883146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171411.8210642879
gradient descent iteration = 10
gd loss = 171411.8210642879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171309.1216904737
gradient descent iteration = 11
gd loss = 171309.1216904737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171208.1338621152
gradient descent iteration = 12
gd loss = 171208.1338621152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171108.5708892953
gradient descent iteration = 13
gd loss = 171108.5708892953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 171010.2139652283
gradient descent iteration = 14
gd loss = 171010.2139652283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170912.8956281607
gradient descent iteration = 15
gd loss = 170912.8956281607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170816.487157527
gradient descent iteration = 16
gd loss = 170816.487157527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170720.8891305582
gradient descent iteration = 17
gd loss = 170720.8891305582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170626.0275960676
gradient descent iteration = 18
gd loss = 170626.0275960676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170532.0538445957
gradient descent iteration = 19
gd loss = 170532.0538445957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170440.9040433823
gradient descent iteration = 20
gd loss = 170440.9040433823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170348.1824208566
gradient descent iteration = 21
gd loss = 170348.1824208566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170257.1067462364
gradient descent iteration = 22
gd loss = 170257.1067462364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170171.559061661
gradient descent iteration = 23
gd loss = 170171.559061661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 170081.4152687448
gradient descent iteration = 24
gd loss = 170081.4152687448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169991.5367743525
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 169991.5367743525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169888.7957335085
gradient descent iteration = 1
gd loss = 169888.7957335085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169788.8776290524
gradient descent iteration = 2
gd loss = 169788.8776290524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169691.2416673017
gradient descent iteration = 3
gd loss = 169691.2416673017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169595.6615955087
gradient descent iteration = 4
gd loss = 169595.6615955087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169501.9737740917
gradient descent iteration = 5
gd loss = 169501.9737740917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169410.0412343517
gradient descent iteration = 6
gd loss = 169410.0412343517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169319.7459772763
gradient descent iteration = 7
gd loss = 169319.7459772763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169230.985075022
gradient descent iteration = 8
gd loss = 169230.985075022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169143.6679621333
gradient descent iteration = 9
gd loss = 169143.6679621333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 169057.7144644281
gradient descent iteration = 10
gd loss = 169057.7144644281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168973.0531130835
gradient descent iteration = 11
gd loss = 168973.0531130835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168889.6197170889
gradient descent iteration = 12
gd loss = 168889.6197170889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168807.356286084
gradient descent iteration = 13
gd loss = 168807.356286084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168726.2101765691
gradient descent iteration = 14
gd loss = 168726.2101765691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168646.1334249643
gradient descent iteration = 15
gd loss = 168646.1334249643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168567.0820392738
gradient descent iteration = 16
gd loss = 168567.0820392738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168489.0155082606
gradient descent iteration = 17
gd loss = 168489.0155082606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168411.8963907589
gradient descent iteration = 18
gd loss = 168411.8963907589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168335.6899146865
gradient descent iteration = 19
gd loss = 168335.6899146865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168260.3636791998
gradient descent iteration = 20
gd loss = 168260.3636791998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168185.8874119609
gradient descent iteration = 21
gd loss = 168185.8874119609
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168112.2327499869
gradient descent iteration = 22
gd loss = 168112.2327499869
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 168039.3730634869
gradient descent iteration = 23
gd loss = 168039.3730634869
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167967.2832691866
gradient descent iteration = 24
gd loss = 167967.2832691866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167895.9396168559
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 167895.9396168559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167819.474636009
gradient descent iteration = 1
gd loss = 167819.474636009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167745.0592990708
gradient descent iteration = 2
gd loss = 167745.0592990708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167672.4766719678
gradient descent iteration = 3
gd loss = 167672.4766719678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167601.5496430465
gradient descent iteration = 4
gd loss = 167601.5496430465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167532.1313767758
gradient descent iteration = 5
gd loss = 167532.1313767758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167464.1009633033
gradient descent iteration = 6
gd loss = 167464.1009633033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167397.3585148059
gradient descent iteration = 7
gd loss = 167397.3585148059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167331.8194655113
gradient descent iteration = 8
gd loss = 167331.8194655113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167267.4088618554
gradient descent iteration = 9
gd loss = 167267.4088618554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167204.0541306433
gradient descent iteration = 10
gd loss = 167204.0541306433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167141.6664280702
gradient descent iteration = 11
gd loss = 167141.6664280702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167080.2553665718
gradient descent iteration = 12
gd loss = 167080.2553665718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 167021.0758740057
gradient descent iteration = 13
gd loss = 167021.0758740057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166961.5707595729
gradient descent iteration = 14
gd loss = 166961.5707595729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166902.9266005938
gradient descent iteration = 15
gd loss = 166902.9266005938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166845.1083826667
gradient descent iteration = 16
gd loss = 166845.1083826667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166788.0841364418
gradient descent iteration = 17
gd loss = 166788.0841364418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166731.8243326986
gradient descent iteration = 18
gd loss = 166731.8243326986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166676.3014778359
gradient descent iteration = 19
gd loss = 166676.3014778359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166621.4898263867
gradient descent iteration = 20
gd loss = 166621.4898263867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166567.3651573737
gradient descent iteration = 21
gd loss = 166567.3651573737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166513.9046043956
gradient descent iteration = 22
gd loss = 166513.9046043956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166461.0865047324
gradient descent iteration = 23
gd loss = 166461.0865047324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166408.8902472033
gradient descent iteration = 24
gd loss = 166408.8902472033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166357.2961568167
Initial loss = 172667.5348769652
Final loss = 166357.2961568167
Deformation gradient control sequence optimization finished.
Animation interval 17 took 1331 seconds.
Full animation took 24231 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 18************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 166517.5196769867
initial norm = 1630.692478227362
convergence norm = 1.630692478227362
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 166517.5196769867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166361.649062794
gradient descent iteration = 1
gd loss = 166361.649062794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166226.3067754776
gradient descent iteration = 2
gd loss = 166226.3067754776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 166103.6444065824
gradient descent iteration = 3
gd loss = 166103.6444065824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165990.4281002887
gradient descent iteration = 4
gd loss = 165990.4281002887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165884.7255950682
gradient descent iteration = 5
gd loss = 165884.7255950682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165786.5319106232
gradient descent iteration = 6
gd loss = 165786.5319106232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165695.0265799331
gradient descent iteration = 7
gd loss = 165695.0265799331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165610.2932738586
gradient descent iteration = 8
gd loss = 165610.2932738586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165519.4891243071
gradient descent iteration = 9
gd loss = 165519.4891243071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165430.7832940729
gradient descent iteration = 10
gd loss = 165430.7832940729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165343.9768643947
gradient descent iteration = 11
gd loss = 165343.9768643947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165258.9598826534
gradient descent iteration = 12
gd loss = 165258.9598826534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165175.9809893806
gradient descent iteration = 13
gd loss = 165175.9809893806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165094.0692900673
gradient descent iteration = 14
gd loss = 165094.0692900673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 165013.5050970041
gradient descent iteration = 15
gd loss = 165013.5050970041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164932.6766958718
gradient descent iteration = 16
gd loss = 164932.6766958718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164852.4179672652
gradient descent iteration = 17
gd loss = 164852.4179672652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164772.5226696648
gradient descent iteration = 18
gd loss = 164772.5226696648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164693.2497293212
gradient descent iteration = 19
gd loss = 164693.2497293212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164614.6921946483
gradient descent iteration = 20
gd loss = 164614.6921946483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164536.8184579209
gradient descent iteration = 21
gd loss = 164536.8184579209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164459.8867150452
gradient descent iteration = 22
gd loss = 164459.8867150452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164383.3423766565
gradient descent iteration = 23
gd loss = 164383.3423766565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164307.4902375121
gradient descent iteration = 24
gd loss = 164307.4902375121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164231.6921693976
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 164231.6921693976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164145.7050316944
gradient descent iteration = 1
gd loss = 164145.7050316944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 164062.6553096894
gradient descent iteration = 2
gd loss = 164062.6553096894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163981.7154202533
gradient descent iteration = 3
gd loss = 163981.7154202533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163902.6501172492
gradient descent iteration = 4
gd loss = 163902.6501172492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163825.2879898004
gradient descent iteration = 5
gd loss = 163825.2879898004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163749.4893618782
gradient descent iteration = 6
gd loss = 163749.4893618782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163675.1372367265
gradient descent iteration = 7
gd loss = 163675.1372367265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163602.1313997979
gradient descent iteration = 8
gd loss = 163602.1313997979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163530.3848567392
gradient descent iteration = 9
gd loss = 163530.3848567392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163459.8212990447
gradient descent iteration = 10
gd loss = 163459.8212990447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163390.3732049186
gradient descent iteration = 11
gd loss = 163390.3732049186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163321.980323257
gradient descent iteration = 12
gd loss = 163321.980323257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163254.5885660918
gradient descent iteration = 13
gd loss = 163254.5885660918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163188.1492284948
gradient descent iteration = 14
gd loss = 163188.1492284948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163122.6181667697
gradient descent iteration = 15
gd loss = 163122.6181667697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 163057.9551532588
gradient descent iteration = 16
gd loss = 163057.9551532588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162994.1233123202
gradient descent iteration = 17
gd loss = 162994.1233123202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162931.0887402878
gradient descent iteration = 18
gd loss = 162931.0887402878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162868.8201349356
gradient descent iteration = 19
gd loss = 162868.8201349356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162807.2885096481
gradient descent iteration = 20
gd loss = 162807.2885096481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162746.4669712539
gradient descent iteration = 21
gd loss = 162746.4669712539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162686.3304988814
gradient descent iteration = 22
gd loss = 162686.3304988814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162626.8557459496
gradient descent iteration = 23
gd loss = 162626.8557459496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162568.020887764
gradient descent iteration = 24
gd loss = 162568.020887764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162509.8055064119
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 162509.8055064119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162448.9763597158
gradient descent iteration = 1
gd loss = 162448.9763597158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162389.8874608745
gradient descent iteration = 2
gd loss = 162389.8874608745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162332.2796725169
gradient descent iteration = 3
gd loss = 162332.2796725169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162275.9762152837
gradient descent iteration = 4
gd loss = 162275.9762152837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162220.8492735093
gradient descent iteration = 5
gd loss = 162220.8492735093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162166.7997529699
gradient descent iteration = 6
gd loss = 162166.7997529699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162113.7469330949
gradient descent iteration = 7
gd loss = 162113.7469330949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162061.6232679012
gradient descent iteration = 8
gd loss = 162061.6232679012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 162010.3712964755
gradient descent iteration = 9
gd loss = 162010.3712964755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161959.9413534793
gradient descent iteration = 10
gd loss = 161959.9413534793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161910.2898191768
gradient descent iteration = 11
gd loss = 161910.2898191768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161861.3778756413
gradient descent iteration = 12
gd loss = 161861.3778756413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161813.1705918143
gradient descent iteration = 13
gd loss = 161813.1705918143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161765.6362549951
gradient descent iteration = 14
gd loss = 161765.6362549951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161718.7458276223
gradient descent iteration = 15
gd loss = 161718.7458276223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161672.4725334085
gradient descent iteration = 16
gd loss = 161672.4725334085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161626.7915424686
gradient descent iteration = 17
gd loss = 161626.7915424686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161581.6797207907
gradient descent iteration = 18
gd loss = 161581.6797207907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161537.1154281798
gradient descent iteration = 19
gd loss = 161537.1154281798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161493.0783636017
gradient descent iteration = 20
gd loss = 161493.0783636017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161449.5494806459
gradient descent iteration = 21
gd loss = 161449.5494806459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161406.5108464324
gradient descent iteration = 22
gd loss = 161406.5108464324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161363.9455032305
gradient descent iteration = 23
gd loss = 161363.9455032305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161321.8373889223
gradient descent iteration = 24
gd loss = 161321.8373889223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161280.1712673114
Initial loss = 166517.5196769867
Final loss = 161280.1712673114
Deformation gradient control sequence optimization finished.
Animation interval 18 took 1330 seconds.
Full animation took 25561 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 19************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 161350.2289879229
initial norm = 1687.107632556056
convergence norm = 1.687107632556056
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 161350.2289879229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161278.6476430685
gradient descent iteration = 1
gd loss = 161278.6476430685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161162.6363479497
gradient descent iteration = 2
gd loss = 161162.6363479497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 161064.215376351
gradient descent iteration = 3
gd loss = 161064.215376351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160975.9869700522
gradient descent iteration = 4
gd loss = 160975.9869700522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160893.1213169692
gradient descent iteration = 5
gd loss = 160893.1213169692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160815.4983681638
gradient descent iteration = 6
gd loss = 160815.4983681638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160738.5918740152
gradient descent iteration = 7
gd loss = 160738.5918740152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160664.9596684301
gradient descent iteration = 8
gd loss = 160664.9596684301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160594.1374087386
gradient descent iteration = 9
gd loss = 160594.1374087386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160523.2107342329
gradient descent iteration = 10
gd loss = 160523.2107342329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160452.2794803561
gradient descent iteration = 11
gd loss = 160452.2794803561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160381.5393320429
gradient descent iteration = 12
gd loss = 160381.5393320429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160311.4191866983
gradient descent iteration = 13
gd loss = 160311.4191866983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160242.0685667622
gradient descent iteration = 14
gd loss = 160242.0685667622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160173.4025016435
gradient descent iteration = 15
gd loss = 160173.4025016435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160105.4996705027
gradient descent iteration = 16
gd loss = 160105.4996705027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 160038.2238876282
gradient descent iteration = 17
gd loss = 160038.2238876282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159971.6970259534
gradient descent iteration = 18
gd loss = 159971.6970259534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159905.7515408123
gradient descent iteration = 19
gd loss = 159905.7515408123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159840.6158394433
gradient descent iteration = 20
gd loss = 159840.6158394433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159776.0315264816
gradient descent iteration = 21
gd loss = 159776.0315264816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159712.3928968437
gradient descent iteration = 22
gd loss = 159712.3928968437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159649.1650362005
gradient descent iteration = 23
gd loss = 159649.1650362005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159586.8484867592
gradient descent iteration = 24
gd loss = 159586.8484867592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159524.5521045452
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 159524.5521045452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159454.7226956583
gradient descent iteration = 1
gd loss = 159454.7226956583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159387.2107932763
gradient descent iteration = 2
gd loss = 159387.2107932763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159321.3686353183
gradient descent iteration = 3
gd loss = 159321.3686353183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159257.0032265002
gradient descent iteration = 4
gd loss = 159257.0032265002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159193.9756281591
gradient descent iteration = 5
gd loss = 159193.9756281591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159132.1751199382
gradient descent iteration = 6
gd loss = 159132.1751199382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159071.5107522066
gradient descent iteration = 7
gd loss = 159071.5107522066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 159011.9062475323
gradient descent iteration = 8
gd loss = 159011.9062475323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158953.2965180264
gradient descent iteration = 9
gd loss = 158953.2965180264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158895.6252241097
gradient descent iteration = 10
gd loss = 158895.6252241097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158838.8429820883
gradient descent iteration = 11
gd loss = 158838.8429820883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158782.9059939017
gradient descent iteration = 12
gd loss = 158782.9059939017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158727.7750474098
gradient descent iteration = 13
gd loss = 158727.7750474098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158673.4147370145
gradient descent iteration = 14
gd loss = 158673.4147370145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158619.792856129
gradient descent iteration = 15
gd loss = 158619.792856129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158566.879856941
gradient descent iteration = 16
gd loss = 158566.879856941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158514.6484797166
gradient descent iteration = 17
gd loss = 158514.6484797166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158463.0735263128
gradient descent iteration = 18
gd loss = 158463.0735263128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158412.1315456952
gradient descent iteration = 19
gd loss = 158412.1315456952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158361.8005804181
gradient descent iteration = 20
gd loss = 158361.8005804181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158312.0600037926
gradient descent iteration = 21
gd loss = 158312.0600037926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158262.890410698
gradient descent iteration = 22
gd loss = 158262.890410698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158214.2735614045
gradient descent iteration = 23
gd loss = 158214.2735614045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158166.1922975344
gradient descent iteration = 24
gd loss = 158166.1922975344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158118.630436899
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 158118.630436899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158066.3762727777
gradient descent iteration = 1
gd loss = 158066.3762727777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 158015.6226543504
gradient descent iteration = 2
gd loss = 158015.6226543504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157966.0834652016
gradient descent iteration = 3
gd loss = 157966.0834652016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157917.5887816795
gradient descent iteration = 4
gd loss = 157917.5887816795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157870.0223525992
gradient descent iteration = 5
gd loss = 157870.0223525992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157823.2987343072
gradient descent iteration = 6
gd loss = 157823.2987343072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157777.3521244533
gradient descent iteration = 7
gd loss = 157777.3521244533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157732.1300791599
gradient descent iteration = 8
gd loss = 157732.1300791599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157687.589690444
gradient descent iteration = 9
gd loss = 157687.589690444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157643.6947133518
gradient descent iteration = 10
gd loss = 157643.6947133518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157600.4137965792
gradient descent iteration = 11
gd loss = 157600.4137965792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157557.7193351342
gradient descent iteration = 12
gd loss = 157557.7193351342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157515.5866511239
gradient descent iteration = 13
gd loss = 157515.5866511239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157473.9933631877
gradient descent iteration = 14
gd loss = 157473.9933631877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157432.9189758474
gradient descent iteration = 15
gd loss = 157432.9189758474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157392.3445751733
gradient descent iteration = 16
gd loss = 157392.3445751733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157352.2525697192
gradient descent iteration = 17
gd loss = 157352.2525697192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157312.6265024277
gradient descent iteration = 18
gd loss = 157312.6265024277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157273.4509078238
gradient descent iteration = 19
gd loss = 157273.4509078238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157234.7111876727
gradient descent iteration = 20
gd loss = 157234.7111876727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157196.393508216
gradient descent iteration = 21
gd loss = 157196.393508216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157158.4847634391
gradient descent iteration = 22
gd loss = 157158.4847634391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157120.9724915743
gradient descent iteration = 23
gd loss = 157120.9724915743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157083.8448142739
gradient descent iteration = 24
gd loss = 157083.8448142739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 157047.0903945373
Initial loss = 161350.2289879229
Final loss = 157047.0903945373
Deformation gradient control sequence optimization finished.
Animation interval 19 took 1327 seconds.
Full animation took 26889 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 20************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 157022.8415665565
initial norm = 1168.818564614398
convergence norm = 1.168818564614398
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 157022.8415665565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156968.1546816332
gradient descent iteration = 1
gd loss = 156968.1546816332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156891.8627435933
gradient descent iteration = 2
gd loss = 156891.8627435933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156816.8471799946
gradient descent iteration = 3
gd loss = 156816.8471799946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156745.6070425588
gradient descent iteration = 4
gd loss = 156745.6070425588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156676.697581311
gradient descent iteration = 5
gd loss = 156676.697581311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156610.3717626013
gradient descent iteration = 6
gd loss = 156610.3717626013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156545.8837802574
gradient descent iteration = 7
gd loss = 156545.8837802574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156483.1178355182
gradient descent iteration = 8
gd loss = 156483.1178355182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156421.5882702019
gradient descent iteration = 9
gd loss = 156421.5882702019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156361.2378821767
gradient descent iteration = 10
gd loss = 156361.2378821767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156301.8073959987
gradient descent iteration = 11
gd loss = 156301.8073959987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156243.5361218759
gradient descent iteration = 12
gd loss = 156243.5361218759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156186.3628703896
gradient descent iteration = 13
gd loss = 156186.3628703896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156129.7630682986
gradient descent iteration = 14
gd loss = 156129.7630682986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156073.025350163
gradient descent iteration = 15
gd loss = 156073.025350163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 156016.8558984864
gradient descent iteration = 16
gd loss = 156016.8558984864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155961.1216578635
gradient descent iteration = 17
gd loss = 155961.1216578635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155905.9385875002
gradient descent iteration = 18
gd loss = 155905.9385875002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155851.1397250505
gradient descent iteration = 19
gd loss = 155851.1397250505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155796.8549870286
gradient descent iteration = 20
gd loss = 155796.8549870286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155742.919146605
gradient descent iteration = 21
gd loss = 155742.919146605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155689.4878906083
gradient descent iteration = 22
gd loss = 155689.4878906083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155636.4490238018
gradient descent iteration = 23
gd loss = 155636.4490238018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155584.2047872275
gradient descent iteration = 24
gd loss = 155584.2047872275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155533.6033476506
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 155533.6033476506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155476.1070675275
gradient descent iteration = 1
gd loss = 155476.1070675275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155420.9777499966
gradient descent iteration = 2
gd loss = 155420.9777499966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155367.1579390193
gradient descent iteration = 3
gd loss = 155367.1579390193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155314.4687600318
gradient descent iteration = 4
gd loss = 155314.4687600318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155262.8010856579
gradient descent iteration = 5
gd loss = 155262.8010856579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155212.071561023
gradient descent iteration = 6
gd loss = 155212.071561023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155162.2133703193
gradient descent iteration = 7
gd loss = 155162.2133703193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155113.171277734
gradient descent iteration = 8
gd loss = 155113.171277734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155064.8985776627
gradient descent iteration = 9
gd loss = 155064.8985776627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 155017.3550469966
gradient descent iteration = 10
gd loss = 155017.3550469966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154970.5055293745
gradient descent iteration = 11
gd loss = 154970.5055293745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154924.318926912
gradient descent iteration = 12
gd loss = 154924.318926912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154878.7674198205
gradient descent iteration = 13
gd loss = 154878.7674198205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154833.8258829625
gradient descent iteration = 14
gd loss = 154833.8258829625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154789.4714361636
gradient descent iteration = 15
gd loss = 154789.4714361636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154745.6831107603
gradient descent iteration = 16
gd loss = 154745.6831107603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154702.4415696258
gradient descent iteration = 17
gd loss = 154702.4415696258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154659.7289020495
gradient descent iteration = 18
gd loss = 154659.7289020495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154617.5285844931
gradient descent iteration = 19
gd loss = 154617.5285844931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154575.8251936793
gradient descent iteration = 20
gd loss = 154575.8251936793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154534.6042274364
gradient descent iteration = 21
gd loss = 154534.6042274364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154493.8519945674
gradient descent iteration = 22
gd loss = 154493.8519945674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154453.5558493844
gradient descent iteration = 23
gd loss = 154453.5558493844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154413.7079325596
gradient descent iteration = 24
gd loss = 154413.7079325596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154374.4252686957
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 154374.4252686957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154327.7062998678
gradient descent iteration = 1
gd loss = 154327.7062998678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154282.471908046
gradient descent iteration = 2
gd loss = 154282.471908046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154238.336337248
gradient descent iteration = 3
gd loss = 154238.336337248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154195.1268200435
gradient descent iteration = 4
gd loss = 154195.1268200435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154152.7414381508
gradient descent iteration = 5
gd loss = 154152.7414381508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154111.1107917535
gradient descent iteration = 6
gd loss = 154111.1107917535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154070.1825483657
gradient descent iteration = 7
gd loss = 154070.1825483657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 154029.9144443249
gradient descent iteration = 8
gd loss = 154029.9144443249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153990.270784829
gradient descent iteration = 9
gd loss = 153990.270784829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153951.220485234
gradient descent iteration = 10
gd loss = 153951.220485234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153912.7358788525
gradient descent iteration = 11
gd loss = 153912.7358788525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153874.7919502814
gradient descent iteration = 12
gd loss = 153874.7919502814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153837.365814684
gradient descent iteration = 13
gd loss = 153837.365814684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153800.4363501494
gradient descent iteration = 14
gd loss = 153800.4363501494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153763.9839104209
gradient descent iteration = 15
gd loss = 153763.9839104209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153727.9902644454
gradient descent iteration = 16
gd loss = 153727.9902644454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153692.4389136987
gradient descent iteration = 17
gd loss = 153692.4389136987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153657.3147243922
gradient descent iteration = 18
gd loss = 153657.3147243922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153622.6034139023
gradient descent iteration = 19
gd loss = 153622.6034139023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153588.291510879
gradient descent iteration = 20
gd loss = 153588.291510879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153554.366183312
gradient descent iteration = 21
gd loss = 153554.366183312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153520.8151596258
gradient descent iteration = 22
gd loss = 153520.8151596258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153487.6266515811
gradient descent iteration = 23
gd loss = 153487.6266515811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153454.7893453854
gradient descent iteration = 24
gd loss = 153454.7893453854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153422.2923782638
Initial loss = 157022.8415665565
Final loss = 153422.2923782638
Deformation gradient control sequence optimization finished.
Animation interval 20 took 1327 seconds.
Full animation took 28217 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 21************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 153307.5923392945
initial norm = 1034.146413639856
convergence norm = 1.034146413639856
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 153307.5923392945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153237.0967784504
gradient descent iteration = 1
gd loss = 153237.0967784504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153185.2025556918
gradient descent iteration = 2
gd loss = 153185.2025556918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153120.5677400422
gradient descent iteration = 3
gd loss = 153120.5677400422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153061.1340630923
gradient descent iteration = 4
gd loss = 153061.1340630923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 153004.5697094891
gradient descent iteration = 5
gd loss = 153004.5697094891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152950.8066956184
gradient descent iteration = 6
gd loss = 152950.8066956184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152898.7809339016
gradient descent iteration = 7
gd loss = 152898.7809339016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152847.9019483569
gradient descent iteration = 8
gd loss = 152847.9019483569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152797.6557356835
gradient descent iteration = 9
gd loss = 152797.6557356835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152749.916494489
gradient descent iteration = 10
gd loss = 152749.916494489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152704.9727516687
gradient descent iteration = 11
gd loss = 152704.9727516687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152656.7987376798
gradient descent iteration = 12
gd loss = 152656.7987376798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152607.7899783225
gradient descent iteration = 13
gd loss = 152607.7899783225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152558.7267675197
gradient descent iteration = 14
gd loss = 152558.7267675197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152509.9517827949
gradient descent iteration = 15
gd loss = 152509.9517827949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152461.5345183844
gradient descent iteration = 16
gd loss = 152461.5345183844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152413.5605146387
gradient descent iteration = 17
gd loss = 152413.5605146387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152366.1060597564
gradient descent iteration = 18
gd loss = 152366.1060597564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152319.3611682887
gradient descent iteration = 19
gd loss = 152319.3611682887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152273.2100108145
gradient descent iteration = 20
gd loss = 152273.2100108145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152228.5402274604
gradient descent iteration = 21
gd loss = 152228.5402274604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152186.4472901077
gradient descent iteration = 22
gd loss = 152186.4472901077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152145.3134851641
gradient descent iteration = 23
gd loss = 152145.3134851641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152104.3394219118
gradient descent iteration = 24
gd loss = 152104.3394219118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152059.545259329
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 152059.545259329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 152014.3422146864
gradient descent iteration = 1
gd loss = 152014.3422146864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151971.3236477928
gradient descent iteration = 2
gd loss = 151971.3236477928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151929.5080017185
gradient descent iteration = 3
gd loss = 151929.5080017185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151887.9350671792
gradient descent iteration = 4
gd loss = 151887.9350671792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151666.4470239263
gradient descent iteration = 5
gd loss = 151666.4470239263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151627.0737562461
gradient descent iteration = 6
gd loss = 151627.0737562461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151588.3791619884
gradient descent iteration = 7
gd loss = 151588.3791619884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151550.3231613089
gradient descent iteration = 8
gd loss = 151550.3231613089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151512.8707050714
gradient descent iteration = 9
gd loss = 151512.8707050714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151475.9905880649
gradient descent iteration = 10
gd loss = 151475.9905880649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151439.6546581204
gradient descent iteration = 11
gd loss = 151439.6546581204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151403.8372922226
gradient descent iteration = 12
gd loss = 151403.8372922226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151368.5150415051
gradient descent iteration = 13
gd loss = 151368.5150415051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151333.6662870338
gradient descent iteration = 14
gd loss = 151333.6662870338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151299.270993664
gradient descent iteration = 15
gd loss = 151299.270993664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151265.3105706584
gradient descent iteration = 16
gd loss = 151265.3105706584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151231.7677374127
gradient descent iteration = 17
gd loss = 151231.7677374127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151198.6263449203
gradient descent iteration = 18
gd loss = 151198.6263449203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151165.8714132758
gradient descent iteration = 19
gd loss = 151165.8714132758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151133.4888741673
gradient descent iteration = 20
gd loss = 151133.4888741673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151101.4654251173
gradient descent iteration = 21
gd loss = 151101.4654251173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151069.7884921097
gradient descent iteration = 22
gd loss = 151069.7884921097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151038.4461453783
gradient descent iteration = 23
gd loss = 151038.4461453783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 151007.4270368795
gradient descent iteration = 24
gd loss = 151007.4270368795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150976.7203643813
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 150976.7203643813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150938.7619400548
gradient descent iteration = 1
gd loss = 150938.7619400548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150902.1792787078
gradient descent iteration = 2
gd loss = 150902.1792787078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150866.6531619334
gradient descent iteration = 3
gd loss = 150866.6531619334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150832.0080021825
gradient descent iteration = 4
gd loss = 150832.0080021825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150798.1366474243
gradient descent iteration = 5
gd loss = 150798.1366474243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150764.9664743416
gradient descent iteration = 6
gd loss = 150764.9664743416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150732.4434962259
gradient descent iteration = 7
gd loss = 150732.4434962259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150700.5245936257
gradient descent iteration = 8
gd loss = 150700.5245936257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150669.1735089135
gradient descent iteration = 9
gd loss = 150669.1735089135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150638.3587208686
gradient descent iteration = 10
gd loss = 150638.3587208686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150608.0522387103
gradient descent iteration = 11
gd loss = 150608.0522387103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150578.2288694065
gradient descent iteration = 12
gd loss = 150578.2288694065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150548.8657435281
gradient descent iteration = 13
gd loss = 150548.8657435281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150519.9419857197
gradient descent iteration = 14
gd loss = 150519.9419857197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150491.4384737716
gradient descent iteration = 15
gd loss = 150491.4384737716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150463.3376999837
gradient descent iteration = 16
gd loss = 150463.3376999837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150435.624103806
gradient descent iteration = 17
gd loss = 150435.624103806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150408.2839478455
gradient descent iteration = 18
gd loss = 150408.2839478455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150381.3045991676
gradient descent iteration = 19
gd loss = 150381.3045991676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150354.6743483234
gradient descent iteration = 20
gd loss = 150354.6743483234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150328.3823314162
gradient descent iteration = 21
gd loss = 150328.3823314162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150302.4184749147
gradient descent iteration = 22
gd loss = 150302.4184749147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150276.7734130502
gradient descent iteration = 23
gd loss = 150276.7734130502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150251.438379428
gradient descent iteration = 24
gd loss = 150251.438379428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 150226.4051500859
Initial loss = 153307.5923392945
Final loss = 150226.4051500859
Deformation gradient control sequence optimization finished.
Animation interval 21 took 1324 seconds.
Full animation took 29541 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 22************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 150055.4183138217
initial norm = 1087.540290318769
convergence norm = 1.087540290318769
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 150055.4183138217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149983.7315010329
gradient descent iteration = 1
gd loss = 149983.7315010329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149923.5059644078
gradient descent iteration = 2
gd loss = 149923.5059644078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149871.9311683967
gradient descent iteration = 3
gd loss = 149871.9311683967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149828.5863987402
gradient descent iteration = 4
gd loss = 149828.5863987402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149781.7673643512
gradient descent iteration = 5
gd loss = 149781.7673643512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149736.4126472005
gradient descent iteration = 6
gd loss = 149736.4126472005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149691.8138830967
gradient descent iteration = 7
gd loss = 149691.8138830967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149648.1667798996
gradient descent iteration = 8
gd loss = 149648.1667798996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149605.1677930322
gradient descent iteration = 9
gd loss = 149605.1677930322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149562.7922906637
gradient descent iteration = 10
gd loss = 149562.7922906637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149520.8869040969
gradient descent iteration = 11
gd loss = 149520.8869040969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149479.4308532501
gradient descent iteration = 12
gd loss = 149479.4308532501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149438.3670762762
gradient descent iteration = 13
gd loss = 149438.3670762762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149397.7333950839
gradient descent iteration = 14
gd loss = 149397.7333950839
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149357.5279733213
gradient descent iteration = 15
gd loss = 149357.5279733213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149317.7692888842
gradient descent iteration = 16
gd loss = 149317.7692888842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149278.3788008062
gradient descent iteration = 17
gd loss = 149278.3788008062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149239.3938023972
gradient descent iteration = 18
gd loss = 149239.3938023972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149200.7401168843
gradient descent iteration = 19
gd loss = 149200.7401168843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149162.4928420968
gradient descent iteration = 20
gd loss = 149162.4928420968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149124.5086519663
gradient descent iteration = 21
gd loss = 149124.5086519663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149086.8962153053
gradient descent iteration = 22
gd loss = 149086.8962153053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149049.46678343
gradient descent iteration = 23
gd loss = 149049.46678343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 149012.383917042
gradient descent iteration = 24
gd loss = 149012.383917042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148975.4387709027
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 148975.4387709027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148937.0262372395
gradient descent iteration = 1
gd loss = 148937.0262372395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148899.5509028719
gradient descent iteration = 2
gd loss = 148899.5509028719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148862.751371999
gradient descent iteration = 3
gd loss = 148862.751371999
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148826.5439709631
gradient descent iteration = 4
gd loss = 148826.5439709631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148790.8762899839
gradient descent iteration = 5
gd loss = 148790.8762899839
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148755.7098764472
gradient descent iteration = 6
gd loss = 148755.7098764472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148721.0147508532
gradient descent iteration = 7
gd loss = 148721.0147508532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148686.7666130913
gradient descent iteration = 8
gd loss = 148686.7666130913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148652.9450493097
gradient descent iteration = 9
gd loss = 148652.9450493097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148619.5327132249
gradient descent iteration = 10
gd loss = 148619.5327132249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148586.5149678579
gradient descent iteration = 11
gd loss = 148586.5149678579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148553.8790764022
gradient descent iteration = 12
gd loss = 148553.8790764022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148521.6136248948
gradient descent iteration = 13
gd loss = 148521.6136248948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148489.7082861968
gradient descent iteration = 14
gd loss = 148489.7082861968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148458.1536610233
gradient descent iteration = 15
gd loss = 148458.1536610233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148426.9412718111
gradient descent iteration = 16
gd loss = 148426.9412718111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148396.0634723782
gradient descent iteration = 17
gd loss = 148396.0634723782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148365.5130526358
gradient descent iteration = 18
gd loss = 148365.5130526358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148335.2831607998
gradient descent iteration = 19
gd loss = 148335.2831607998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148305.3671982757
gradient descent iteration = 20
gd loss = 148305.3671982757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148275.7587397314
gradient descent iteration = 21
gd loss = 148275.7587397314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148246.4515311357
gradient descent iteration = 22
gd loss = 148246.4515311357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148217.4395378908
gradient descent iteration = 23
gd loss = 148217.4395378908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148188.7167104447
gradient descent iteration = 24
gd loss = 148188.7167104447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148160.2768964324
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 148160.2768964324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148126.7890780206
gradient descent iteration = 1
gd loss = 148126.7890780206
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148094.7622527039
gradient descent iteration = 2
gd loss = 148094.7622527039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148063.7735938197
gradient descent iteration = 3
gd loss = 148063.7735938197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148033.6088372587
gradient descent iteration = 4
gd loss = 148033.6088372587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 148004.1455495236
gradient descent iteration = 5
gd loss = 148004.1455495236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147975.3045802459
gradient descent iteration = 6
gd loss = 147975.3045802459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147947.0288015538
gradient descent iteration = 7
gd loss = 147947.0288015538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147919.273381641
gradient descent iteration = 8
gd loss = 147919.273381641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147892.0011448155
gradient descent iteration = 9
gd loss = 147892.0011448155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147865.1801723021
gradient descent iteration = 10
gd loss = 147865.1801723021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147838.7823780452
gradient descent iteration = 11
gd loss = 147838.7823780452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147812.7827854395
gradient descent iteration = 12
gd loss = 147812.7827854395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147787.1590556404
gradient descent iteration = 13
gd loss = 147787.1590556404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147761.8909846484
gradient descent iteration = 14
gd loss = 147761.8909846484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147736.960164155
gradient descent iteration = 15
gd loss = 147736.960164155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147712.3496763461
gradient descent iteration = 16
gd loss = 147712.3496763461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147688.0439409153
gradient descent iteration = 17
gd loss = 147688.0439409153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147664.028636119
gradient descent iteration = 18
gd loss = 147664.028636119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147640.2905460013
gradient descent iteration = 19
gd loss = 147640.2905460013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147616.8175811534
gradient descent iteration = 20
gd loss = 147616.8175811534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147593.5990236947
gradient descent iteration = 21
gd loss = 147593.5990236947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147570.6250143058
gradient descent iteration = 22
gd loss = 147570.6250143058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147547.8863401905
gradient descent iteration = 23
gd loss = 147547.8863401905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147525.3743268997
gradient descent iteration = 24
gd loss = 147525.3743268997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147503.0808061488
Initial loss = 150055.4183138217
Final loss = 147503.0808061488
Deformation gradient control sequence optimization finished.
Animation interval 22 took 1320 seconds.
Full animation took 30862 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 23************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 147325.9053225375
initial norm = 1080.785531639706
convergence norm = 1.080785531639706
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 147325.9053225375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147241.0278078494
gradient descent iteration = 1
gd loss = 147241.0278078494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147178.9051213288
gradient descent iteration = 2
gd loss = 147178.9051213288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147127.6174874214
gradient descent iteration = 3
gd loss = 147127.6174874214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147081.942119977
gradient descent iteration = 4
gd loss = 147081.942119977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147041.4022373285
gradient descent iteration = 5
gd loss = 147041.4022373285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 147000.4110574621
gradient descent iteration = 6
gd loss = 147000.4110574621
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146960.7532600649
gradient descent iteration = 7
gd loss = 146960.7532600649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146921.5494816408
gradient descent iteration = 8
gd loss = 146921.5494816408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146883.0538189827
gradient descent iteration = 9
gd loss = 146883.0538189827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146845.0121827549
gradient descent iteration = 10
gd loss = 146845.0121827549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146807.5046985546
gradient descent iteration = 11
gd loss = 146807.5046985546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146770.4027794903
gradient descent iteration = 12
gd loss = 146770.4027794903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146733.7526527099
gradient descent iteration = 13
gd loss = 146733.7526527099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146697.4580909133
gradient descent iteration = 14
gd loss = 146697.4580909133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146661.5783008782
gradient descent iteration = 15
gd loss = 146661.5783008782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146626.0141099101
gradient descent iteration = 16
gd loss = 146626.0141099101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146590.8687122781
gradient descent iteration = 17
gd loss = 146590.8687122781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146555.9992180429
gradient descent iteration = 18
gd loss = 146555.9992180429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146521.601451358
gradient descent iteration = 19
gd loss = 146521.601451358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146487.4085708277
gradient descent iteration = 20
gd loss = 146487.4085708277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146453.7771513309
gradient descent iteration = 21
gd loss = 146453.7771513309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146420.1855635163
gradient descent iteration = 22
gd loss = 146420.1855635163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146387.1717540668
gradient descent iteration = 23
gd loss = 146387.1717540668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146354.0195118278
gradient descent iteration = 24
gd loss = 146354.0195118278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146321.3529338526
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 146321.3529338526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146284.8388037706
gradient descent iteration = 1
gd loss = 146284.8388037706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146249.9139681242
gradient descent iteration = 2
gd loss = 146249.9139681242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146215.8508357731
gradient descent iteration = 3
gd loss = 146215.8508357731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146182.4877501941
gradient descent iteration = 4
gd loss = 146182.4877501941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146149.7436741664
gradient descent iteration = 5
gd loss = 146149.7436741664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146117.5609035953
gradient descent iteration = 6
gd loss = 146117.5609035953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146085.894571558
gradient descent iteration = 7
gd loss = 146085.894571558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146054.70826107
gradient descent iteration = 8
gd loss = 146054.70826107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 146023.9713096257
gradient descent iteration = 9
gd loss = 146023.9713096257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145993.6573423837
gradient descent iteration = 10
gd loss = 145993.6573423837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145963.7433239226
gradient descent iteration = 11
gd loss = 145963.7433239226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145934.2087993538
gradient descent iteration = 12
gd loss = 145934.2087993538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145905.0359263042
gradient descent iteration = 13
gd loss = 145905.0359263042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145876.2091602815
gradient descent iteration = 14
gd loss = 145876.2091602815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145847.714650603
gradient descent iteration = 15
gd loss = 145847.714650603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145819.5398110755
gradient descent iteration = 16
gd loss = 145819.5398110755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145791.6730332211
gradient descent iteration = 17
gd loss = 145791.6730332211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145764.1034346782
gradient descent iteration = 18
gd loss = 145764.1034346782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145736.8207245743
gradient descent iteration = 19
gd loss = 145736.8207245743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145709.8148440722
gradient descent iteration = 20
gd loss = 145709.8148440722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145683.0759350249
gradient descent iteration = 21
gd loss = 145683.0759350249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145656.5946147754
gradient descent iteration = 22
gd loss = 145656.5946147754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145630.3621067606
gradient descent iteration = 23
gd loss = 145630.3621067606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145604.3700239501
gradient descent iteration = 24
gd loss = 145604.3700239501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145578.6103106769
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 145578.6103106769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145546.9062872535
gradient descent iteration = 1
gd loss = 145546.9062872535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145516.3901179568
gradient descent iteration = 2
gd loss = 145516.3901179568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145486.8025738723
gradient descent iteration = 3
gd loss = 145486.8025738723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145458.0086524036
gradient descent iteration = 4
gd loss = 145458.0086524036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145429.9291617262
gradient descent iteration = 5
gd loss = 145429.9291617262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145402.5108656275
gradient descent iteration = 6
gd loss = 145402.5108656275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145375.7128638622
gradient descent iteration = 7
gd loss = 145375.7128638622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145349.5004966145
gradient descent iteration = 8
gd loss = 145349.5004966145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145323.8423050768
gradient descent iteration = 9
gd loss = 145323.8423050768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145298.708574089
gradient descent iteration = 10
gd loss = 145298.708574089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145274.0708360049
gradient descent iteration = 11
gd loss = 145274.0708360049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145249.9017582437
gradient descent iteration = 12
gd loss = 145249.9017582437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145226.1752047338
gradient descent iteration = 13
gd loss = 145226.1752047338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145202.8663475278
gradient descent iteration = 14
gd loss = 145202.8663475278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145179.9517824837
gradient descent iteration = 15
gd loss = 145179.9517824837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145157.4095403411
gradient descent iteration = 16
gd loss = 145157.4095403411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145135.2191744809
gradient descent iteration = 17
gd loss = 145135.2191744809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145113.3617664112
gradient descent iteration = 18
gd loss = 145113.3617664112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145091.8198979524
gradient descent iteration = 19
gd loss = 145091.8198979524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145070.5776008033
gradient descent iteration = 20
gd loss = 145070.5776008033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145049.6202829498
gradient descent iteration = 21
gd loss = 145049.6202829498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145028.9347310076
gradient descent iteration = 22
gd loss = 145028.9347310076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 145008.5092230426
gradient descent iteration = 23
gd loss = 145008.5092230426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144988.3332351529
gradient descent iteration = 24
gd loss = 144988.3332351529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144968.3972051695
Initial loss = 147325.9053225375
Final loss = 144968.3972051695
Deformation gradient control sequence optimization finished.
Animation interval 23 took 1320 seconds.
Full animation took 32183 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 24************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 144854.6919439564
initial norm = 1444.033106132076
convergence norm = 1.444033106132076
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 144854.6919439564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144774.7230683818
gradient descent iteration = 1
gd loss = 144774.7230683818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144690.3739537888
gradient descent iteration = 2
gd loss = 144690.3739537888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144625.9391432282
gradient descent iteration = 3
gd loss = 144625.9391432282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144571.9545025912
gradient descent iteration = 4
gd loss = 144571.9545025912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144525.5280409139
gradient descent iteration = 5
gd loss = 144525.5280409139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144484.0501033368
gradient descent iteration = 6
gd loss = 144484.0501033368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144445.607361167
gradient descent iteration = 7
gd loss = 144445.607361167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144409.0580629272
gradient descent iteration = 8
gd loss = 144409.0580629272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144373.8274973762
gradient descent iteration = 9
gd loss = 144373.8274973762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144339.7918436913
gradient descent iteration = 10
gd loss = 144339.7918436913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144307.8363052971
gradient descent iteration = 11
gd loss = 144307.8363052971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144278.2223510624
gradient descent iteration = 12
gd loss = 144278.2223510624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144250.8105769058
gradient descent iteration = 13
gd loss = 144250.8105769058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144219.6814770669
gradient descent iteration = 14
gd loss = 144219.6814770669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144188.5850835668
gradient descent iteration = 15
gd loss = 144188.5850835668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144157.5359983779
gradient descent iteration = 16
gd loss = 144157.5359983779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144126.6873425177
gradient descent iteration = 17
gd loss = 144126.6873425177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144096.0579071485
gradient descent iteration = 18
gd loss = 144096.0579071485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144065.7359580163
gradient descent iteration = 19
gd loss = 144065.7359580163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144035.7322657081
gradient descent iteration = 20
gd loss = 144035.7322657081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 144006.2408088137
gradient descent iteration = 21
gd loss = 144006.2408088137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143976.8326286149
gradient descent iteration = 22
gd loss = 143976.8326286149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143947.9909174684
gradient descent iteration = 23
gd loss = 143947.9909174684
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143919.3460980426
gradient descent iteration = 24
gd loss = 143919.3460980426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143892.2854011048
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 143892.2854011048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143859.6942240601
gradient descent iteration = 1
gd loss = 143859.6942240601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143829.1909956916
gradient descent iteration = 2
gd loss = 143829.1909956916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143799.4981613426
gradient descent iteration = 3
gd loss = 143799.4981613426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143770.3841202889
gradient descent iteration = 4
gd loss = 143770.3841202889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143741.7719635026
gradient descent iteration = 5
gd loss = 143741.7719635026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143713.612518951
gradient descent iteration = 6
gd loss = 143713.612518951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143685.8686640619
gradient descent iteration = 7
gd loss = 143685.8686640619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143658.5112395023
gradient descent iteration = 8
gd loss = 143658.5112395023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143631.5168510346
gradient descent iteration = 9
gd loss = 143631.5168510346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143604.8662837327
gradient descent iteration = 10
gd loss = 143604.8662837327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143578.5436962912
gradient descent iteration = 11
gd loss = 143578.5436962912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143552.5359463739
gradient descent iteration = 12
gd loss = 143552.5359463739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143526.8319732613
gradient descent iteration = 13
gd loss = 143526.8319732613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143501.4222713057
gradient descent iteration = 14
gd loss = 143501.4222713057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143476.2984690988
gradient descent iteration = 15
gd loss = 143476.2984690988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143451.4531431244
gradient descent iteration = 16
gd loss = 143451.4531431244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143426.8796060515
gradient descent iteration = 17
gd loss = 143426.8796060515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143402.5716007447
gradient descent iteration = 18
gd loss = 143402.5716007447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143378.5230759002
gradient descent iteration = 19
gd loss = 143378.5230759002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143354.7280691346
gradient descent iteration = 20
gd loss = 143354.7280691346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143331.1806563433
gradient descent iteration = 21
gd loss = 143331.1806563433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143307.8748676749
gradient descent iteration = 22
gd loss = 143307.8748676749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143284.8046397179
gradient descent iteration = 23
gd loss = 143284.8046397179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143261.9639042279
gradient descent iteration = 24
gd loss = 143261.9639042279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143239.3467319205
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 143239.3467319205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143212.5526022974
gradient descent iteration = 1
gd loss = 143212.5526022974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143186.9250675192
gradient descent iteration = 2
gd loss = 143186.9250675192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143162.0973139924
gradient descent iteration = 3
gd loss = 143162.0973139924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143137.8863301238
gradient descent iteration = 4
gd loss = 143137.8863301238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143114.186021877
gradient descent iteration = 5
gd loss = 143114.186021877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143090.9258774432
gradient descent iteration = 6
gd loss = 143090.9258774432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143068.053920229
gradient descent iteration = 7
gd loss = 143068.053920229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143045.5289917657
gradient descent iteration = 8
gd loss = 143045.5289917657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143023.3165691944
gradient descent iteration = 9
gd loss = 143023.3165691944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 143001.3868480638
gradient descent iteration = 10
gd loss = 143001.3868480638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142979.7137096969
gradient descent iteration = 11
gd loss = 142979.7137096969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142958.2743256669
gradient descent iteration = 12
gd loss = 142958.2743256669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142937.0491138865
gradient descent iteration = 13
gd loss = 142937.0491138865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142916.0208256514
gradient descent iteration = 14
gd loss = 142916.0208256514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142895.1746201025
gradient descent iteration = 15
gd loss = 142895.1746201025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142874.4979414731
gradient descent iteration = 16
gd loss = 142874.4979414731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142853.9796675594
gradient descent iteration = 17
gd loss = 142853.9796675594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142833.6099749018
gradient descent iteration = 18
gd loss = 142833.6099749018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142813.3802396201
gradient descent iteration = 19
gd loss = 142813.3802396201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142793.2830549686
gradient descent iteration = 20
gd loss = 142793.2830549686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142773.3123212116
gradient descent iteration = 21
gd loss = 142773.3123212116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142753.4636403234
gradient descent iteration = 22
gd loss = 142753.4636403234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142733.7344048363
gradient descent iteration = 23
gd loss = 142733.7344048363
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142714.1237318355
gradient descent iteration = 24
gd loss = 142714.1237318355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142694.6325843481
Initial loss = 144854.6919439564
Final loss = 142694.6325843481
Deformation gradient control sequence optimization finished.
Animation interval 24 took 1320 seconds.
Full animation took 33503 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 25************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 142523.4863989075
initial norm = 1112.946528406728
convergence norm = 1.112946528406728
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 142523.4863989075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142433.7385753076
gradient descent iteration = 1
gd loss = 142433.7385753076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142368.166470047
gradient descent iteration = 2
gd loss = 142368.166470047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142320.4394540279
gradient descent iteration = 3
gd loss = 142320.4394540279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142290.0008522807
gradient descent iteration = 4
gd loss = 142290.0008522807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142247.9450415634
gradient descent iteration = 5
gd loss = 142247.9450415634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142210.6807440627
gradient descent iteration = 6
gd loss = 142210.6807440627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142175.5028855437
gradient descent iteration = 7
gd loss = 142175.5028855437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142141.3573996878
gradient descent iteration = 8
gd loss = 142141.3573996878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142107.7757745871
gradient descent iteration = 9
gd loss = 142107.7757745871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142074.5474509002
gradient descent iteration = 10
gd loss = 142074.5474509002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142041.7006709569
gradient descent iteration = 11
gd loss = 142041.7006709569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 142009.4136413795
gradient descent iteration = 12
gd loss = 142009.4136413795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141977.9207502126
gradient descent iteration = 13
gd loss = 141977.9207502126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141947.2508507498
gradient descent iteration = 14
gd loss = 141947.2508507498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141917.3692507791
gradient descent iteration = 15
gd loss = 141917.3692507791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141888.0315905213
gradient descent iteration = 16
gd loss = 141888.0315905213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141859.6992729898
gradient descent iteration = 17
gd loss = 141859.6992729898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141831.4750750464
gradient descent iteration = 18
gd loss = 141831.4750750464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141805.6092404987
gradient descent iteration = 19
gd loss = 141805.6092404987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141777.5695950057
gradient descent iteration = 20
gd loss = 141777.5695950057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141750.4658341935
gradient descent iteration = 21
gd loss = 141750.4658341935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141723.0263781311
gradient descent iteration = 22
gd loss = 141723.0263781311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141696.4466000294
gradient descent iteration = 23
gd loss = 141696.4466000294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141669.3282760785
gradient descent iteration = 24
gd loss = 141669.3282760785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141642.7583514081
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 141642.7583514081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141611.4425812059
gradient descent iteration = 1
gd loss = 141611.4425812059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141581.8904668834
gradient descent iteration = 2
gd loss = 141581.8904668834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141553.2168837991
gradient descent iteration = 3
gd loss = 141553.2168837991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141525.2429355057
gradient descent iteration = 4
gd loss = 141525.2429355057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141497.873945237
gradient descent iteration = 5
gd loss = 141497.873945237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141471.043780045
gradient descent iteration = 6
gd loss = 141471.043780045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141444.7024136737
gradient descent iteration = 7
gd loss = 141444.7024136737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141418.8103770412
gradient descent iteration = 8
gd loss = 141418.8103770412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141393.3354883616
gradient descent iteration = 9
gd loss = 141393.3354883616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141368.2505724194
gradient descent iteration = 10
gd loss = 141368.2505724194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141343.5323883753
gradient descent iteration = 11
gd loss = 141343.5323883753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141319.1604537207
gradient descent iteration = 12
gd loss = 141319.1604537207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141295.1163313411
gradient descent iteration = 13
gd loss = 141295.1163313411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141271.383193038
gradient descent iteration = 14
gd loss = 141271.383193038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141247.9458480024
gradient descent iteration = 15
gd loss = 141247.9458480024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141224.7903115599
gradient descent iteration = 16
gd loss = 141224.7903115599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141201.9036431075
gradient descent iteration = 17
gd loss = 141201.9036431075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141179.273953404
gradient descent iteration = 18
gd loss = 141179.273953404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141156.8901573636
gradient descent iteration = 19
gd loss = 141156.8901573636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141134.7418790115
gradient descent iteration = 20
gd loss = 141134.7418790115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141112.8193754387
gradient descent iteration = 21
gd loss = 141112.8193754387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141091.1133693055
gradient descent iteration = 22
gd loss = 141091.1133693055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141069.6148901063
gradient descent iteration = 23
gd loss = 141069.6148901063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141048.3154668527
gradient descent iteration = 24
gd loss = 141048.3154668527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141027.2071404656
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 141027.2071404656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 141001.9488297916
gradient descent iteration = 1
gd loss = 141001.9488297916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140977.6418380428
gradient descent iteration = 2
gd loss = 140977.6418380428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140954.00271751
gradient descent iteration = 3
gd loss = 140954.00271751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140930.9001506951
gradient descent iteration = 4
gd loss = 140930.9001506951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140908.2585883577
gradient descent iteration = 5
gd loss = 140908.2585883577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140886.0272141611
gradient descent iteration = 6
gd loss = 140886.0272141611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140864.1683688782
gradient descent iteration = 7
gd loss = 140864.1683688782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140842.652499601
gradient descent iteration = 8
gd loss = 140842.652499601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140821.4555251494
gradient descent iteration = 9
gd loss = 140821.4555251494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140800.5574205235
gradient descent iteration = 10
gd loss = 140800.5574205235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140779.9417897025
gradient descent iteration = 11
gd loss = 140779.9417897025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140759.5955209003
gradient descent iteration = 12
gd loss = 140759.5955209003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140739.5074455674
gradient descent iteration = 13
gd loss = 140739.5074455674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140719.6677416551
gradient descent iteration = 14
gd loss = 140719.6677416551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140700.0675655787
gradient descent iteration = 15
gd loss = 140700.0675655787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140680.6987516492
gradient descent iteration = 16
gd loss = 140680.6987516492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140661.5534919816
gradient descent iteration = 17
gd loss = 140661.5534919816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140642.6239905856
gradient descent iteration = 18
gd loss = 140642.6239905856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140623.9026414172
gradient descent iteration = 19
gd loss = 140623.9026414172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140605.3820797814
gradient descent iteration = 20
gd loss = 140605.3820797814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140587.0551322802
gradient descent iteration = 21
gd loss = 140587.0551322802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140568.9147954817
gradient descent iteration = 22
gd loss = 140568.9147954817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140550.9542528533
gradient descent iteration = 23
gd loss = 140550.9542528533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140533.1670269015
gradient descent iteration = 24
gd loss = 140533.1670269015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140515.5471167382
Initial loss = 142523.4863989075
Final loss = 140515.5471167382
Deformation gradient control sequence optimization finished.
Animation interval 25 took 1317 seconds.
Full animation took 34821 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 26************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 140389.5869519979
initial norm = 1426.505940329352
convergence norm = 1.426505940329352
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 140389.5869519979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140307.5219149087
gradient descent iteration = 1
gd loss = 140307.5219149087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140249.353875647
gradient descent iteration = 2
gd loss = 140249.353875647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140189.8767914429
gradient descent iteration = 3
gd loss = 140189.8767914429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140144.7518744195
gradient descent iteration = 4
gd loss = 140144.7518744195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140107.0183356481
gradient descent iteration = 5
gd loss = 140107.0183356481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140073.3737409211
gradient descent iteration = 6
gd loss = 140073.3737409211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140041.6876640427
gradient descent iteration = 7
gd loss = 140041.6876640427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 140011.0393471325
gradient descent iteration = 8
gd loss = 140011.0393471325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139981.2853185001
gradient descent iteration = 9
gd loss = 139981.2853185001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139952.4208076776
gradient descent iteration = 10
gd loss = 139952.4208076776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139925.5043003014
gradient descent iteration = 11
gd loss = 139925.5043003014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139898.1981190223
gradient descent iteration = 12
gd loss = 139898.1981190223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139872.154610978
gradient descent iteration = 13
gd loss = 139872.154610978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139844.8885247083
gradient descent iteration = 14
gd loss = 139844.8885247083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139818.3806895079
gradient descent iteration = 15
gd loss = 139818.3806895079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139791.7029685764
gradient descent iteration = 16
gd loss = 139791.7029685764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139765.627969361
gradient descent iteration = 17
gd loss = 139765.627969361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139739.2992756479
gradient descent iteration = 18
gd loss = 139739.2992756479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139713.8296601367
gradient descent iteration = 19
gd loss = 139713.8296601367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139688.0950871136
gradient descent iteration = 20
gd loss = 139688.0950871136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139663.1642749753
gradient descent iteration = 21
gd loss = 139663.1642749753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139638.1232074239
gradient descent iteration = 22
gd loss = 139638.1232074239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139613.6246288117
gradient descent iteration = 23
gd loss = 139613.6246288117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139588.6506658191
gradient descent iteration = 24
gd loss = 139588.6506658191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139564.2800256227
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 139564.2800256227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139534.6450144555
gradient descent iteration = 1
gd loss = 139534.6450144555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139506.8935905006
gradient descent iteration = 2
gd loss = 139506.8935905006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139480.0236007567
gradient descent iteration = 3
gd loss = 139480.0236007567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139453.8728090033
gradient descent iteration = 4
gd loss = 139453.8728090033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139428.9311457024
gradient descent iteration = 5
gd loss = 139428.9311457024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139403.7020255046
gradient descent iteration = 6
gd loss = 139403.7020255046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139379.0865803071
gradient descent iteration = 7
gd loss = 139379.0865803071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139355.0431480681
gradient descent iteration = 8
gd loss = 139355.0431480681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139331.4799082912
gradient descent iteration = 9
gd loss = 139331.4799082912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139308.346115497
gradient descent iteration = 10
gd loss = 139308.346115497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139285.6112535174
gradient descent iteration = 11
gd loss = 139285.6112535174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139263.251569836
gradient descent iteration = 12
gd loss = 139263.251569836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139241.2460420128
gradient descent iteration = 13
gd loss = 139241.2460420128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139219.5760497868
gradient descent iteration = 14
gd loss = 139219.5760497868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139198.2254267258
gradient descent iteration = 15
gd loss = 139198.2254267258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139177.1804463701
gradient descent iteration = 16
gd loss = 139177.1804463701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139156.4297695512
gradient descent iteration = 17
gd loss = 139156.4297695512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139135.9645922297
gradient descent iteration = 18
gd loss = 139135.9645922297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139115.8792652368
gradient descent iteration = 19
gd loss = 139115.8792652368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139096.9795274899
gradient descent iteration = 20
gd loss = 139096.9795274899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139076.949615322
gradient descent iteration = 21
gd loss = 139076.949615322
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139057.3041063693
gradient descent iteration = 22
gd loss = 139057.3041063693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139038.0058093791
gradient descent iteration = 23
gd loss = 139038.0058093791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139019.0135966436
gradient descent iteration = 24
gd loss = 139019.0135966436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 139000.2916317346
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 139000.2916317346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138974.7978772929
gradient descent iteration = 1
gd loss = 138974.7978772929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138950.529148267
gradient descent iteration = 2
gd loss = 138950.529148267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138926.9865994019
gradient descent iteration = 3
gd loss = 138926.9865994019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138903.9919732299
gradient descent iteration = 4
gd loss = 138903.9919732299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138881.4580907842
gradient descent iteration = 5
gd loss = 138881.4580907842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138859.3297916256
gradient descent iteration = 6
gd loss = 138859.3297916256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138837.5666398813
gradient descent iteration = 7
gd loss = 138837.5666398813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138816.13684157
gradient descent iteration = 8
gd loss = 138816.13684157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138795.0144128455
gradient descent iteration = 9
gd loss = 138795.0144128455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138774.177678192
gradient descent iteration = 10
gd loss = 138774.177678192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138753.6083850297
gradient descent iteration = 11
gd loss = 138753.6083850297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138733.2910730876
gradient descent iteration = 12
gd loss = 138733.2910730876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138713.2126753876
gradient descent iteration = 13
gd loss = 138713.2126753876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138693.3621836646
gradient descent iteration = 14
gd loss = 138693.3621836646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138673.7306411957
gradient descent iteration = 15
gd loss = 138673.7306411957
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138654.3113759608
gradient descent iteration = 16
gd loss = 138654.3113759608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138635.0991694516
gradient descent iteration = 17
gd loss = 138635.0991694516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138616.0898171524
gradient descent iteration = 18
gd loss = 138616.0898171524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138597.2797432563
gradient descent iteration = 19
gd loss = 138597.2797432563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138578.665298749
gradient descent iteration = 20
gd loss = 138578.665298749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138560.2605850243
gradient descent iteration = 21
gd loss = 138560.2605850243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138543.1881601501
gradient descent iteration = 22
gd loss = 138543.1881601501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138525.1172622142
gradient descent iteration = 23
gd loss = 138525.1172622142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138507.2436471274
gradient descent iteration = 24
gd loss = 138507.2436471274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138489.5668407957
Initial loss = 140389.5869519979
Final loss = 138489.5668407957
Deformation gradient control sequence optimization finished.
Animation interval 26 took 1319 seconds.
Full animation took 36140 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 27************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 138329.7903245275
initial norm = 1022.490546893632
convergence norm = 1.022490546893632
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 138329.7903245275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138247.4213634859
gradient descent iteration = 1
gd loss = 138247.4213634859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138189.1835130303
gradient descent iteration = 2
gd loss = 138189.1835130303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138137.5716867429
gradient descent iteration = 3
gd loss = 138137.5716867429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138095.6641553605
gradient descent iteration = 4
gd loss = 138095.6641553605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138059.8149035051
gradient descent iteration = 5
gd loss = 138059.8149035051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 138027.5906996681
gradient descent iteration = 6
gd loss = 138027.5906996681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137997.6993779153
gradient descent iteration = 7
gd loss = 137997.6993779153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137971.015542875
gradient descent iteration = 8
gd loss = 137971.015542875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137942.6088322767
gradient descent iteration = 9
gd loss = 137942.6088322767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137915.1415429284
gradient descent iteration = 10
gd loss = 137915.1415429284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137887.116756571
gradient descent iteration = 11
gd loss = 137887.116756571
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137859.8164624533
gradient descent iteration = 12
gd loss = 137859.8164624533
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137832.095939034
gradient descent iteration = 13
gd loss = 137832.095939034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137805.1211951526
gradient descent iteration = 14
gd loss = 137805.1211951526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137777.7707542545
gradient descent iteration = 15
gd loss = 137777.7707542545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137751.1392099259
gradient descent iteration = 16
gd loss = 137751.1392099259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137724.1303656723
gradient descent iteration = 17
gd loss = 137724.1303656723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137697.7448885318
gradient descent iteration = 18
gd loss = 137697.7448885318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137671.0616836863
gradient descent iteration = 19
gd loss = 137671.0616836863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137644.951853896
gradient descent iteration = 20
gd loss = 137644.951853896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137618.6527667802
gradient descent iteration = 21
gd loss = 137618.6527667802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137592.9152122855
gradient descent iteration = 22
gd loss = 137592.9152122855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137567.0668515396
gradient descent iteration = 23
gd loss = 137567.0668515396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137541.7727579846
gradient descent iteration = 24
gd loss = 137541.7727579846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137516.4068953752
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 137516.4068953752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137486.835584637
gradient descent iteration = 1
gd loss = 137486.835584637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137458.7551169459
gradient descent iteration = 2
gd loss = 137458.7551169459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137431.4955537743
gradient descent iteration = 3
gd loss = 137431.4955537743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137404.9522950622
gradient descent iteration = 4
gd loss = 137404.9522950622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137379.063839538
gradient descent iteration = 5
gd loss = 137379.063839538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137353.7828555042
gradient descent iteration = 6
gd loss = 137353.7828555042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137329.0700589215
gradient descent iteration = 7
gd loss = 137329.0700589215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137304.891519155
gradient descent iteration = 8
gd loss = 137304.891519155
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137281.2168887756
gradient descent iteration = 9
gd loss = 137281.2168887756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137258.0180774456
gradient descent iteration = 10
gd loss = 137258.0180774456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137235.268615298
gradient descent iteration = 11
gd loss = 137235.268615298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137212.9435462437
gradient descent iteration = 12
gd loss = 137212.9435462437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137191.0195410951
gradient descent iteration = 13
gd loss = 137191.0195410951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137169.4755761642
gradient descent iteration = 14
gd loss = 137169.4755761642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137148.2920936275
gradient descent iteration = 15
gd loss = 137148.2920936275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137127.4508181586
gradient descent iteration = 16
gd loss = 137127.4508181586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137106.9348889567
gradient descent iteration = 17
gd loss = 137106.9348889567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137086.7288827266
gradient descent iteration = 18
gd loss = 137086.7288827266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137066.8187015182
gradient descent iteration = 19
gd loss = 137066.8187015182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137047.1913631808
gradient descent iteration = 20
gd loss = 137047.1913631808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137027.8348073474
gradient descent iteration = 21
gd loss = 137027.8348073474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 137008.7377071917
gradient descent iteration = 22
gd loss = 137008.7377071917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136989.8892568841
gradient descent iteration = 23
gd loss = 136989.8892568841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136971.2791061959
gradient descent iteration = 24
gd loss = 136971.2791061959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136952.8974068564
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 136952.8974068564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136922.6338052377
gradient descent iteration = 1
gd loss = 136922.6338052377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136894.1392660752
gradient descent iteration = 2
gd loss = 136894.1392660752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136866.8995088761
gradient descent iteration = 3
gd loss = 136866.8995088761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136840.7079519334
gradient descent iteration = 4
gd loss = 136840.7079519334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136815.4500061396
gradient descent iteration = 5
gd loss = 136815.4500061396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136791.0457539314
gradient descent iteration = 6
gd loss = 136791.0457539314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136767.4321916997
gradient descent iteration = 7
gd loss = 136767.4321916997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136744.5563267137
gradient descent iteration = 8
gd loss = 136744.5563267137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136722.3718625871
gradient descent iteration = 9
gd loss = 136722.3718625871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136700.8374015563
gradient descent iteration = 10
gd loss = 136700.8374015563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136679.9153481891
gradient descent iteration = 11
gd loss = 136679.9153481891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136659.5712032111
gradient descent iteration = 12
gd loss = 136659.5712032111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136639.7730384407
gradient descent iteration = 13
gd loss = 136639.7730384407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136620.4911345588
gradient descent iteration = 14
gd loss = 136620.4911345588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136601.6977338534
gradient descent iteration = 15
gd loss = 136601.6977338534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136583.3668098153
gradient descent iteration = 16
gd loss = 136583.3668098153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136565.4739061142
gradient descent iteration = 17
gd loss = 136565.4739061142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136547.9960145472
gradient descent iteration = 18
gd loss = 136547.9960145472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136530.9114762918
gradient descent iteration = 19
gd loss = 136530.9114762918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136514.1999090307
gradient descent iteration = 20
gd loss = 136514.1999090307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136497.8421993232
gradient descent iteration = 21
gd loss = 136497.8421993232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136481.8205444874
gradient descent iteration = 22
gd loss = 136481.8205444874
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136466.1182462414
gradient descent iteration = 23
gd loss = 136466.1182462414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136450.719608385
gradient descent iteration = 24
gd loss = 136450.719608385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136435.609885238
Initial loss = 138329.7903245275
Final loss = 136435.609885238
Deformation gradient control sequence optimization finished.
Animation interval 27 took 1319 seconds.
Full animation took 37460 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 28************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 136293.2616740039
initial norm = 1021.640534101862
convergence norm = 1.021640534101862
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 136293.2616740039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136218.2469451016
gradient descent iteration = 1
gd loss = 136218.2469451016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136162.2834782845
gradient descent iteration = 2
gd loss = 136162.2834782845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136113.5149454727
gradient descent iteration = 3
gd loss = 136113.5149454727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136073.8209629351
gradient descent iteration = 4
gd loss = 136073.8209629351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136039.6465639414
gradient descent iteration = 5
gd loss = 136039.6465639414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 136008.2582818315
gradient descent iteration = 6
gd loss = 136008.2582818315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135978.2920650677
gradient descent iteration = 7
gd loss = 135978.2920650677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135949.1805238065
gradient descent iteration = 8
gd loss = 135949.1805238065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135920.6702931274
gradient descent iteration = 9
gd loss = 135920.6702931274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135892.6462615459
gradient descent iteration = 10
gd loss = 135892.6462615459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135865.0576169855
gradient descent iteration = 11
gd loss = 135865.0576169855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135837.9743597371
gradient descent iteration = 12
gd loss = 135837.9743597371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135811.4011942983
gradient descent iteration = 13
gd loss = 135811.4011942983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135785.8123253464
gradient descent iteration = 14
gd loss = 135785.8123253464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135760.3481436828
gradient descent iteration = 15
gd loss = 135760.3481436828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135735.8455915547
gradient descent iteration = 16
gd loss = 135735.8455915547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135710.7256890987
gradient descent iteration = 17
gd loss = 135710.7256890987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135686.1274393093
gradient descent iteration = 18
gd loss = 135686.1274393093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135661.365714765
gradient descent iteration = 19
gd loss = 135661.365714765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135637.0517276988
gradient descent iteration = 20
gd loss = 135637.0517276988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135612.7079544447
gradient descent iteration = 21
gd loss = 135612.7079544447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135588.7751929907
gradient descent iteration = 22
gd loss = 135588.7751929907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135564.8558210034
gradient descent iteration = 23
gd loss = 135564.8558210034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135541.3244075924
gradient descent iteration = 24
gd loss = 135541.3244075924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135517.8186283435
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 135517.8186283435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135491.8692979572
gradient descent iteration = 1
gd loss = 135491.8692979572
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135467.1315937855
gradient descent iteration = 2
gd loss = 135467.1315937855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135443.1234380292
gradient descent iteration = 3
gd loss = 135443.1234380292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135419.7556449848
gradient descent iteration = 4
gd loss = 135419.7556449848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135396.9689804317
gradient descent iteration = 5
gd loss = 135396.9689804317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135374.7182563115
gradient descent iteration = 6
gd loss = 135374.7182563115
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135352.9668128038
gradient descent iteration = 7
gd loss = 135352.9668128038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135331.6843813134
gradient descent iteration = 8
gd loss = 135331.6843813134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135310.8461540589
gradient descent iteration = 9
gd loss = 135310.8461540589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135290.4308489034
gradient descent iteration = 10
gd loss = 135290.4308489034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135270.4191912329
gradient descent iteration = 11
gd loss = 135270.4191912329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135250.7935821642
gradient descent iteration = 12
gd loss = 135250.7935821642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135231.5378047551
gradient descent iteration = 13
gd loss = 135231.5378047551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135212.6362938248
gradient descent iteration = 14
gd loss = 135212.6362938248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135194.0739388067
gradient descent iteration = 15
gd loss = 135194.0739388067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135175.8361146318
gradient descent iteration = 16
gd loss = 135175.8361146318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135157.9088607197
gradient descent iteration = 17
gd loss = 135157.9088607197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135140.2791500886
gradient descent iteration = 18
gd loss = 135140.2791500886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135122.9351234237
gradient descent iteration = 19
gd loss = 135122.9351234237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135105.8662381438
gradient descent iteration = 20
gd loss = 135105.8662381438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135089.063333777
gradient descent iteration = 21
gd loss = 135089.063333777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135072.5185241668
gradient descent iteration = 22
gd loss = 135072.5185241668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135056.224988241
gradient descent iteration = 23
gd loss = 135056.224988241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135040.1766746168
gradient descent iteration = 24
gd loss = 135040.1766746168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135024.3679450022
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 135024.3679450022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 135004.6223507918
gradient descent iteration = 1
gd loss = 135004.6223507918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134986.0066935977
gradient descent iteration = 2
gd loss = 134986.0066935977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134968.092803285
gradient descent iteration = 3
gd loss = 134968.092803285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134950.7423371643
gradient descent iteration = 4
gd loss = 134950.7423371643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134933.883085004
gradient descent iteration = 5
gd loss = 134933.883085004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134917.4652462709
gradient descent iteration = 6
gd loss = 134917.4652462709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134901.4500189172
gradient descent iteration = 7
gd loss = 134901.4500189172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134885.8053510961
gradient descent iteration = 8
gd loss = 134885.8053510961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134870.5038402879
gradient descent iteration = 9
gd loss = 134870.5038402879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134855.5216408781
gradient descent iteration = 10
gd loss = 134855.5216408781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134840.8377205834
gradient descent iteration = 11
gd loss = 134840.8377205834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134826.4333435365
gradient descent iteration = 12
gd loss = 134826.4333435365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134812.2917498245
gradient descent iteration = 13
gd loss = 134812.2917498245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134798.3978907736
gradient descent iteration = 14
gd loss = 134798.3978907736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134784.7382804588
gradient descent iteration = 15
gd loss = 134784.7382804588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134771.3009295627
gradient descent iteration = 16
gd loss = 134771.3009295627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134758.0750013177
gradient descent iteration = 17
gd loss = 134758.0750013177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134745.0506231876
gradient descent iteration = 18
gd loss = 134745.0506231876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134732.2187692589
gradient descent iteration = 19
gd loss = 134732.2187692589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134719.571154204
gradient descent iteration = 20
gd loss = 134719.571154204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134707.1001310522
gradient descent iteration = 21
gd loss = 134707.1001310522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134694.7985951237
gradient descent iteration = 22
gd loss = 134694.7985951237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134682.6599026963
gradient descent iteration = 23
gd loss = 134682.6599026963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134670.6777850974
gradient descent iteration = 24
gd loss = 134670.6777850974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134658.8462759396
Initial loss = 136293.2616740039
Final loss = 134658.8462759396
Deformation gradient control sequence optimization finished.
Animation interval 28 took 1317 seconds.
Full animation took 38777 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 29************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 134558.0294607606
initial norm = 1029.800573205573
convergence norm = 1.029800573205573
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 134558.0294607606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134471.1575837075
gradient descent iteration = 1
gd loss = 134471.1575837075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134407.389728747
gradient descent iteration = 2
gd loss = 134407.389728747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134360.818405535
gradient descent iteration = 3
gd loss = 134360.818405535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134325.9742411162
gradient descent iteration = 4
gd loss = 134325.9742411162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134297.8367960397
gradient descent iteration = 5
gd loss = 134297.8367960397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134272.5746888057
gradient descent iteration = 6
gd loss = 134272.5746888057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134248.6006913472
gradient descent iteration = 7
gd loss = 134248.6006913472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134225.5676404654
gradient descent iteration = 8
gd loss = 134225.5676404654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134203.4995875936
gradient descent iteration = 9
gd loss = 134203.4995875936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134182.7271192016
gradient descent iteration = 10
gd loss = 134182.7271192016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134162.1392834317
gradient descent iteration = 11
gd loss = 134162.1392834317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134141.9021933582
gradient descent iteration = 12
gd loss = 134141.9021933582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134121.2425796996
gradient descent iteration = 13
gd loss = 134121.2425796996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134100.6731860521
gradient descent iteration = 14
gd loss = 134100.6731860521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134080.1042792262
gradient descent iteration = 15
gd loss = 134080.1042792262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134059.7944068073
gradient descent iteration = 16
gd loss = 134059.7944068073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134039.7551581148
gradient descent iteration = 17
gd loss = 134039.7551581148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134020.1081248805
gradient descent iteration = 18
gd loss = 134020.1081248805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 134000.8616984598
gradient descent iteration = 19
gd loss = 134000.8616984598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133982.0503363041
gradient descent iteration = 20
gd loss = 133982.0503363041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133963.6526004073
gradient descent iteration = 21
gd loss = 133963.6526004073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133945.6430124881
gradient descent iteration = 22
gd loss = 133945.6430124881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133927.9852195238
gradient descent iteration = 23
gd loss = 133927.9852195238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133910.6349678126
gradient descent iteration = 24
gd loss = 133910.6349678126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133893.5667487755
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 133893.5667487755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133871.9741281719
gradient descent iteration = 1
gd loss = 133871.9741281719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133851.8758013787
gradient descent iteration = 2
gd loss = 133851.8758013787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133832.4066003167
gradient descent iteration = 3
gd loss = 133832.4066003167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133813.4199288629
gradient descent iteration = 4
gd loss = 133813.4199288629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133794.8587800706
gradient descent iteration = 5
gd loss = 133794.8587800706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133776.6864982242
gradient descent iteration = 6
gd loss = 133776.6864982242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133758.8738968497
gradient descent iteration = 7
gd loss = 133758.8738968497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133741.3962189145
gradient descent iteration = 8
gd loss = 133741.3962189145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133724.2317869803
gradient descent iteration = 9
gd loss = 133724.2317869803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133707.3613411787
gradient descent iteration = 10
gd loss = 133707.3613411787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133690.7674280827
gradient descent iteration = 11
gd loss = 133690.7674280827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133674.4340279508
gradient descent iteration = 12
gd loss = 133674.4340279508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133658.3463473242
gradient descent iteration = 13
gd loss = 133658.3463473242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133642.4907907396
gradient descent iteration = 14
gd loss = 133642.4907907396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133626.8549095401
gradient descent iteration = 15
gd loss = 133626.8549095401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133611.4273625367
gradient descent iteration = 16
gd loss = 133611.4273625367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133596.1978880484
gradient descent iteration = 17
gd loss = 133596.1978880484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133581.1572386308
gradient descent iteration = 18
gd loss = 133581.1572386308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133566.2971103757
gradient descent iteration = 19
gd loss = 133566.2971103757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133551.610076481
gradient descent iteration = 20
gd loss = 133551.610076481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133537.0895110513
gradient descent iteration = 21
gd loss = 133537.0895110513
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133522.7295160029
gradient descent iteration = 22
gd loss = 133522.7295160029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133508.5248046183
gradient descent iteration = 23
gd loss = 133508.5248046183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133494.4706011956
gradient descent iteration = 24
gd loss = 133494.4706011956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133480.5625247519
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 133480.5625247519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133461.8865950047
gradient descent iteration = 1
gd loss = 133461.8865950047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133444.2422987294
gradient descent iteration = 2
gd loss = 133444.2422987294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133427.2865654093
gradient descent iteration = 3
gd loss = 133427.2865654093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133410.8889934718
gradient descent iteration = 4
gd loss = 133410.8889934718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133394.9709709864
gradient descent iteration = 5
gd loss = 133394.9709709864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133379.4751678138
gradient descent iteration = 6
gd loss = 133379.4751678138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133364.3563177406
gradient descent iteration = 7
gd loss = 133364.3563177406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133349.5771786335
gradient descent iteration = 8
gd loss = 133349.5771786335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133335.1063672882
gradient descent iteration = 9
gd loss = 133335.1063672882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133320.9174900645
gradient descent iteration = 10
gd loss = 133320.9174900645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133306.9906927139
gradient descent iteration = 11
gd loss = 133306.9906927139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133293.311454481
gradient descent iteration = 12
gd loss = 133293.311454481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133279.8666351893
gradient descent iteration = 13
gd loss = 133279.8666351893
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133266.6443539211
gradient descent iteration = 14
gd loss = 133266.6443539211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133253.6340969503
gradient descent iteration = 15
gd loss = 133253.6340969503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133240.8270287542
gradient descent iteration = 16
gd loss = 133240.8270287542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133228.2161639065
gradient descent iteration = 17
gd loss = 133228.2161639065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133215.7964075219
gradient descent iteration = 18
gd loss = 133215.7964075219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133203.5643772316
gradient descent iteration = 19
gd loss = 133203.5643772316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133191.5182124697
gradient descent iteration = 20
gd loss = 133191.5182124697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133179.6572193466
gradient descent iteration = 21
gd loss = 133179.6572193466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133167.981359593
gradient descent iteration = 22
gd loss = 133167.981359593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133156.4908027493
gradient descent iteration = 23
gd loss = 133156.4908027493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133145.1880440857
gradient descent iteration = 24
gd loss = 133145.1880440857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 133134.0783369646
Initial loss = 134558.0294607606
Final loss = 133134.0783369646
Deformation gradient control sequence optimization finished.
Animation interval 29 took 1316 seconds.
Full animation took 40094 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 30************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 133038.6270761781
initial norm = 936.2739878826261
convergence norm = 0.9362739878826262
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 133038.6270761781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132960.4047466847
gradient descent iteration = 1
gd loss = 132960.4047466847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132906.959367444
gradient descent iteration = 2
gd loss = 132906.959367444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132869.3829132923
gradient descent iteration = 3
gd loss = 132869.3829132923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132841.0310204138
gradient descent iteration = 4
gd loss = 132841.0310204138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132816.6185880948
gradient descent iteration = 5
gd loss = 132816.6185880948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132793.3508026124
gradient descent iteration = 6
gd loss = 132793.3508026124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132770.4846352932
gradient descent iteration = 7
gd loss = 132770.4846352932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132747.8156758401
gradient descent iteration = 8
gd loss = 132747.8156758401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132725.2944667655
gradient descent iteration = 9
gd loss = 132725.2944667655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132702.9449606569
gradient descent iteration = 10
gd loss = 132702.9449606569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132680.8369006538
gradient descent iteration = 11
gd loss = 132680.8369006538
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132659.0408133813
gradient descent iteration = 12
gd loss = 132659.0408133813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132637.6077172482
gradient descent iteration = 13
gd loss = 132637.6077172482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132616.5385947529
gradient descent iteration = 14
gd loss = 132616.5385947529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132595.8211386307
gradient descent iteration = 15
gd loss = 132595.8211386307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132575.4436909116
gradient descent iteration = 16
gd loss = 132575.4436909116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132555.4547883264
gradient descent iteration = 17
gd loss = 132555.4547883264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132536.017424816
gradient descent iteration = 18
gd loss = 132536.017424816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132517.5299422242
gradient descent iteration = 19
gd loss = 132517.5299422242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132500.6539969305
gradient descent iteration = 20
gd loss = 132500.6539969305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132484.5659742701
gradient descent iteration = 21
gd loss = 132484.5659742701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132469.0580945388
gradient descent iteration = 22
gd loss = 132469.0580945388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132452.7637968031
gradient descent iteration = 23
gd loss = 132452.7637968031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132436.6894611466
gradient descent iteration = 24
gd loss = 132436.6894611466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132420.6081636449
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 132420.6081636449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132402.0567842348
gradient descent iteration = 1
gd loss = 132402.0567842348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132384.7560688
gradient descent iteration = 2
gd loss = 132384.7560688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132367.8162503095
gradient descent iteration = 3
gd loss = 132367.8162503095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132351.1215445178
gradient descent iteration = 4
gd loss = 132351.1215445178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132334.6351801985
gradient descent iteration = 5
gd loss = 132334.6351801985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132318.3382943681
gradient descent iteration = 6
gd loss = 132318.3382943681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132302.2200394589
gradient descent iteration = 7
gd loss = 132302.2200394589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132286.2747903482
gradient descent iteration = 8
gd loss = 132286.2747903482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132270.5008428576
gradient descent iteration = 9
gd loss = 132270.5008428576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132254.8995263272
gradient descent iteration = 10
gd loss = 132254.8995263272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132239.4744458237
gradient descent iteration = 11
gd loss = 132239.4744458237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132224.2306635834
gradient descent iteration = 12
gd loss = 132224.2306635834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132209.1738542558
gradient descent iteration = 13
gd loss = 132209.1738542558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132194.3095105705
gradient descent iteration = 14
gd loss = 132194.3095105705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132179.6423478303
gradient descent iteration = 15
gd loss = 132179.6423478303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132165.1759135095
gradient descent iteration = 16
gd loss = 132165.1759135095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132150.9119526695
gradient descent iteration = 17
gd loss = 132150.9119526695
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132136.8504167995
gradient descent iteration = 18
gd loss = 132136.8504167995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132122.9896694887
gradient descent iteration = 19
gd loss = 132122.9896694887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132109.3268123615
gradient descent iteration = 20
gd loss = 132109.3268123615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132095.858482972
gradient descent iteration = 21
gd loss = 132095.858482972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132082.602691247
gradient descent iteration = 22
gd loss = 132082.602691247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132070.5865530949
gradient descent iteration = 23
gd loss = 132070.5865530949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132058.3165228201
gradient descent iteration = 24
gd loss = 132058.3165228201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132044.7989484637
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 132044.7989484637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132026.7043677076
gradient descent iteration = 1
gd loss = 132026.7043677076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 132009.6372455745
gradient descent iteration = 2
gd loss = 132009.6372455745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131993.3315579354
gradient descent iteration = 3
gd loss = 131993.3315579354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131977.6550236635
gradient descent iteration = 4
gd loss = 131977.6550236635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131962.525635647
gradient descent iteration = 5
gd loss = 131962.525635647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131947.8851897578
gradient descent iteration = 6
gd loss = 131947.8851897578
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131933.6890015319
gradient descent iteration = 7
gd loss = 131933.6890015319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131919.9019533368
gradient descent iteration = 8
gd loss = 131919.9019533368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131906.4943824823
gradient descent iteration = 9
gd loss = 131906.4943824823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131893.4397138346
gradient descent iteration = 10
gd loss = 131893.4397138346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131880.7138578477
gradient descent iteration = 11
gd loss = 131880.7138578477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131868.2950673855
gradient descent iteration = 12
gd loss = 131868.2950673855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131856.1631628282
gradient descent iteration = 13
gd loss = 131856.1631628282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131844.2996687508
gradient descent iteration = 14
gd loss = 131844.2996687508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131832.6876220151
gradient descent iteration = 15
gd loss = 131832.6876220151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131821.3111712809
gradient descent iteration = 16
gd loss = 131821.3111712809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131810.1555452872
gradient descent iteration = 17
gd loss = 131810.1555452872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131799.2069674422
gradient descent iteration = 18
gd loss = 131799.2069674422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131788.4526451153
gradient descent iteration = 19
gd loss = 131788.4526451153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131777.8807343013
gradient descent iteration = 20
gd loss = 131777.8807343013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131767.4802549542
gradient descent iteration = 21
gd loss = 131767.4802549542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131757.2409078252
gradient descent iteration = 22
gd loss = 131757.2409078252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131747.1530285529
gradient descent iteration = 23
gd loss = 131747.1530285529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131737.2075614895
gradient descent iteration = 24
gd loss = 131737.2075614895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131727.3960305298
Initial loss = 133038.6270761781
Final loss = 131727.3960305298
Deformation gradient control sequence optimization finished.
Animation interval 30 took 1315 seconds.
Full animation took 41410 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 31************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 131753.5222298029
initial norm = 1103.914026252094
convergence norm = 1.103914026252094
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 131753.5222298029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131658.8272706592
gradient descent iteration = 1
gd loss = 131658.8272706592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131590.82969184
gradient descent iteration = 2
gd loss = 131590.82969184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131542.3285800221
gradient descent iteration = 3
gd loss = 131542.3285800221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131507.0857936679
gradient descent iteration = 4
gd loss = 131507.0857936679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131480.3333941243
gradient descent iteration = 5
gd loss = 131480.3333941243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131457.6617393813
gradient descent iteration = 6
gd loss = 131457.6617393813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131436.5789546084
gradient descent iteration = 7
gd loss = 131436.5789546084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131416.2490043623
gradient descent iteration = 8
gd loss = 131416.2490043623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131396.4163778722
gradient descent iteration = 9
gd loss = 131396.4163778722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131376.995344816
gradient descent iteration = 10
gd loss = 131376.995344816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131357.9547121294
gradient descent iteration = 11
gd loss = 131357.9547121294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131339.3168156145
gradient descent iteration = 12
gd loss = 131339.3168156145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131321.1463589692
gradient descent iteration = 13
gd loss = 131321.1463589692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131303.6798294974
gradient descent iteration = 14
gd loss = 131303.6798294974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131287.459114182
gradient descent iteration = 15
gd loss = 131287.459114182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131273.3169878125
gradient descent iteration = 16
gd loss = 131273.3169878125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131261.1019527019
gradient descent iteration = 17
gd loss = 131261.1019527019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131249.2044427688
gradient descent iteration = 18
gd loss = 131249.2044427688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131237.7069397263
gradient descent iteration = 19
gd loss = 131237.7069397263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131226.191712981
gradient descent iteration = 20
gd loss = 131226.191712981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131215.0112498192
gradient descent iteration = 21
gd loss = 131215.0112498192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131203.880440199
gradient descent iteration = 22
gd loss = 131203.880440199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131192.9852485102
gradient descent iteration = 23
gd loss = 131192.9852485102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131182.1542247685
gradient descent iteration = 24
gd loss = 131182.1542247685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131171.4836462817
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 131171.4836462817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131156.5425587768
gradient descent iteration = 1
gd loss = 131156.5425587768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131145.4516745042
gradient descent iteration = 2
gd loss = 131145.4516745042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131134.994040025
gradient descent iteration = 3
gd loss = 131134.994040025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131124.7758122825
gradient descent iteration = 4
gd loss = 131124.7758122825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131114.7246697611
gradient descent iteration = 5
gd loss = 131114.7246697611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131104.8132654766
gradient descent iteration = 6
gd loss = 131104.8132654766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131095.0234369667
gradient descent iteration = 7
gd loss = 131095.0234369667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131085.3404687707
gradient descent iteration = 8
gd loss = 131085.3404687707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131075.7519719495
gradient descent iteration = 9
gd loss = 131075.7519719495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131066.247422064
gradient descent iteration = 10
gd loss = 131066.247422064
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131056.8176737192
gradient descent iteration = 11
gd loss = 131056.8176737192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131047.4547476674
gradient descent iteration = 12
gd loss = 131047.4547476674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131038.1516921841
gradient descent iteration = 13
gd loss = 131038.1516921841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131028.9024889762
gradient descent iteration = 14
gd loss = 131028.9024889762
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131019.7019873977
gradient descent iteration = 15
gd loss = 131019.7019873977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131010.5458576522
gradient descent iteration = 16
gd loss = 131010.5458576522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 131001.4305640224
gradient descent iteration = 17
gd loss = 131001.4305640224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130992.3533446161
gradient descent iteration = 18
gd loss = 130992.3533446161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130983.3121888994
gradient descent iteration = 19
gd loss = 130983.3121888994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130974.3058078642
gradient descent iteration = 20
gd loss = 130974.3058078642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130965.3336056648
gradient descent iteration = 21
gd loss = 130965.3336056648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130956.3956248961
gradient descent iteration = 22
gd loss = 130956.3956248961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130947.4924935978
gradient descent iteration = 23
gd loss = 130947.4924935978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130938.625351409
gradient descent iteration = 24
gd loss = 130938.625351409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130929.7957672965
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 130929.7957672965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130918.6409707103
gradient descent iteration = 1
gd loss = 130918.6409707103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130908.1485268229
gradient descent iteration = 2
gd loss = 130908.1485268229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130898.080948271
gradient descent iteration = 3
gd loss = 130898.080948271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130888.3343581587
gradient descent iteration = 4
gd loss = 130888.3343581587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130878.8497649935
gradient descent iteration = 5
gd loss = 130878.8497649935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130869.5885837748
gradient descent iteration = 6
gd loss = 130869.5885837748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130860.5237148076
gradient descent iteration = 7
gd loss = 130860.5237148076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130851.635410692
gradient descent iteration = 8
gd loss = 130851.635410692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130842.908897794
gradient descent iteration = 9
gd loss = 130842.908897794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130834.3330140279
gradient descent iteration = 10
gd loss = 130834.3330140279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130825.8992521142
gradient descent iteration = 11
gd loss = 130825.8992521142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130817.6010191688
gradient descent iteration = 12
gd loss = 130817.6010191688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130809.4330994914
gradient descent iteration = 13
gd loss = 130809.4330994914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130801.3912706147
gradient descent iteration = 14
gd loss = 130801.3912706147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130793.472003036
gradient descent iteration = 15
gd loss = 130793.472003036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130785.6722448152
gradient descent iteration = 16
gd loss = 130785.6722448152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130777.9892694807
gradient descent iteration = 17
gd loss = 130777.9892694807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130770.42058036
gradient descent iteration = 18
gd loss = 130770.42058036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130762.9638356757
gradient descent iteration = 19
gd loss = 130762.9638356757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130755.6167847914
gradient descent iteration = 20
gd loss = 130755.6167847914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130748.3772145561
gradient descent iteration = 21
gd loss = 130748.3772145561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130741.2429545007
gradient descent iteration = 22
gd loss = 130741.2429545007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130734.2118503598
gradient descent iteration = 23
gd loss = 130734.2118503598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130727.2817350979
gradient descent iteration = 24
gd loss = 130727.2817350979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130720.4504267005
Initial loss = 131753.5222298029
Final loss = 130720.4504267005
Deformation gradient control sequence optimization finished.
Animation interval 31 took 1316 seconds.
Full animation took 42726 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 32************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 130722.3590494292
initial norm = 763.1179624982229
convergence norm = 0.7631179624982229
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 130722.3590494292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130658.3695758619
gradient descent iteration = 1
gd loss = 130658.3695758619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130613.6646452177
gradient descent iteration = 2
gd loss = 130613.6646452177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130582.0356602464
gradient descent iteration = 3
gd loss = 130582.0356602464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130557.3769603073
gradient descent iteration = 4
gd loss = 130557.3769603073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130535.0608961394
gradient descent iteration = 5
gd loss = 130535.0608961394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130513.6170840972
gradient descent iteration = 6
gd loss = 130513.6170840972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130492.6458026361
gradient descent iteration = 7
gd loss = 130492.6458026361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130471.9784580403
gradient descent iteration = 8
gd loss = 130471.9784580403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130451.5390784511
gradient descent iteration = 9
gd loss = 130451.5390784511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130431.2897459744
gradient descent iteration = 10
gd loss = 130431.2897459744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130411.2679669192
gradient descent iteration = 11
gd loss = 130411.2679669192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130391.5883025595
gradient descent iteration = 12
gd loss = 130391.5883025595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130372.470587587
gradient descent iteration = 13
gd loss = 130372.470587587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130354.2211271465
gradient descent iteration = 14
gd loss = 130354.2211271465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130337.5569727515
gradient descent iteration = 15
gd loss = 130337.5569727515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130323.7885752838
gradient descent iteration = 16
gd loss = 130323.7885752838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130310.3542480532
gradient descent iteration = 17
gd loss = 130310.3542480532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130297.8099713119
gradient descent iteration = 18
gd loss = 130297.8099713119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130284.8633500131
gradient descent iteration = 19
gd loss = 130284.8633500131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130272.5632851569
gradient descent iteration = 20
gd loss = 130272.5632851569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130260.4111567238
gradient descent iteration = 21
gd loss = 130260.4111567238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130248.6326607415
gradient descent iteration = 22
gd loss = 130248.6326607415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130236.9799683722
gradient descent iteration = 23
gd loss = 130236.9799683722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130225.5680666612
gradient descent iteration = 24
gd loss = 130225.5680666612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130214.2746693256
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 130214.2746693256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130200.3618906983
gradient descent iteration = 1
gd loss = 130200.3618906983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130188.5953517221
gradient descent iteration = 2
gd loss = 130188.5953517221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130177.3545458443
gradient descent iteration = 3
gd loss = 130177.3545458443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130166.4274088018
gradient descent iteration = 4
gd loss = 130166.4274088018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130155.7635710873
gradient descent iteration = 5
gd loss = 130155.7635710873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130145.3396953798
gradient descent iteration = 6
gd loss = 130145.3396953798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130135.1395275448
gradient descent iteration = 7
gd loss = 130135.1395275448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130125.1497567707
gradient descent iteration = 8
gd loss = 130125.1497567707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130115.35879715
gradient descent iteration = 9
gd loss = 130115.35879715
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130105.7561663963
gradient descent iteration = 10
gd loss = 130105.7561663963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130096.3321982757
gradient descent iteration = 11
gd loss = 130096.3321982757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130087.0778826472
gradient descent iteration = 12
gd loss = 130087.0778826472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130077.984772645
gradient descent iteration = 13
gd loss = 130077.984772645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130069.0449211292
gradient descent iteration = 14
gd loss = 130069.0449211292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130060.2508417789
gradient descent iteration = 15
gd loss = 130060.2508417789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130051.595479453
gradient descent iteration = 16
gd loss = 130051.595479453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130043.072196029
gradient descent iteration = 17
gd loss = 130043.072196029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130034.6747858142
gradient descent iteration = 18
gd loss = 130034.6747858142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130026.3974259041
gradient descent iteration = 19
gd loss = 130026.3974259041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130018.2346284344
gradient descent iteration = 20
gd loss = 130018.2346284344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130010.1812249018
gradient descent iteration = 21
gd loss = 130010.1812249018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 130002.2323482865
gradient descent iteration = 22
gd loss = 130002.2323482865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129994.383417318
gradient descent iteration = 23
gd loss = 129994.383417318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129986.6301224247
gradient descent iteration = 24
gd loss = 129986.6301224247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129978.968408324
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 129978.968408324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129967.6745197515
gradient descent iteration = 1
gd loss = 129967.6745197515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129957.1126678362
gradient descent iteration = 2
gd loss = 129957.1126678362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129947.0468044294
gradient descent iteration = 3
gd loss = 129947.0468044294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129937.3813608941
gradient descent iteration = 4
gd loss = 129937.3813608941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129928.0604882589
gradient descent iteration = 5
gd loss = 129928.0604882589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129919.044850594
gradient descent iteration = 6
gd loss = 129919.044850594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129910.3041939013
gradient descent iteration = 7
gd loss = 129910.3041939013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129901.8140892215
gradient descent iteration = 8
gd loss = 129901.8140892215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129893.5542278924
gradient descent iteration = 9
gd loss = 129893.5542278924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129885.5073722081
gradient descent iteration = 10
gd loss = 129885.5073722081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129877.6586520537
gradient descent iteration = 11
gd loss = 129877.6586520537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129869.9950703017
gradient descent iteration = 12
gd loss = 129869.9950703017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129862.5051418908
gradient descent iteration = 13
gd loss = 129862.5051418908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129855.1786266354
gradient descent iteration = 14
gd loss = 129855.1786266354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129848.0063273867
gradient descent iteration = 15
gd loss = 129848.0063273867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129840.9799339427
gradient descent iteration = 16
gd loss = 129840.9799339427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129834.0918952354
gradient descent iteration = 17
gd loss = 129834.0918952354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129827.3353200171
gradient descent iteration = 18
gd loss = 129827.3353200171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129820.7038977661
gradient descent iteration = 19
gd loss = 129820.7038977661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129814.1918294805
gradient descent iteration = 20
gd loss = 129814.1918294805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129807.7937696717
gradient descent iteration = 21
gd loss = 129807.7937696717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129801.5047732838
gradient descent iteration = 22
gd loss = 129801.5047732838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129795.3202487704
gradient descent iteration = 23
gd loss = 129795.3202487704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129789.2359171238
gradient descent iteration = 24
gd loss = 129789.2359171238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129783.2477752894
Initial loss = 130722.3590494292
Final loss = 129783.2477752894
Deformation gradient control sequence optimization finished.
Animation interval 32 took 1315 seconds.
Full animation took 44041 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 33************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 129932.0240114478
initial norm = 1145.950496169958
convergence norm = 1.145950496169958
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 129932.0240114478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129836.3025795041
gradient descent iteration = 1
gd loss = 129836.3025795041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129773.2500003928
gradient descent iteration = 2
gd loss = 129773.2500003928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129732.9466058554
gradient descent iteration = 3
gd loss = 129732.9466058554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129705.1405197612
gradient descent iteration = 4
gd loss = 129705.1405197612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129683.8438177689
gradient descent iteration = 5
gd loss = 129683.8438177689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129664.7130280209
gradient descent iteration = 6
gd loss = 129664.7130280209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129646.3837128656
gradient descent iteration = 7
gd loss = 129646.3837128656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129628.5139283084
gradient descent iteration = 8
gd loss = 129628.5139283084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129611.0080190307
gradient descent iteration = 9
gd loss = 129611.0080190307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129593.9452574244
gradient descent iteration = 10
gd loss = 129593.9452574244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129577.7062284567
gradient descent iteration = 11
gd loss = 129577.7062284567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129563.5733706027
gradient descent iteration = 12
gd loss = 129563.5733706027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129552.7804083751
gradient descent iteration = 13
gd loss = 129552.7804083751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129541.5447833526
gradient descent iteration = 14
gd loss = 129541.5447833526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129531.0732756931
gradient descent iteration = 15
gd loss = 129531.0732756931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129520.4084129486
gradient descent iteration = 16
gd loss = 129520.4084129486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129510.2192505104
gradient descent iteration = 17
gd loss = 129510.2192505104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129500.0546244395
gradient descent iteration = 18
gd loss = 129500.0546244395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129490.1864343381
gradient descent iteration = 19
gd loss = 129490.1864343381
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129480.385005228
gradient descent iteration = 20
gd loss = 129480.385005228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129470.8042065759
gradient descent iteration = 21
gd loss = 129470.8042065759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129461.2943955377
gradient descent iteration = 22
gd loss = 129461.2943955377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129451.9619633467
gradient descent iteration = 23
gd loss = 129451.9619633467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129442.6930651613
gradient descent iteration = 24
gd loss = 129442.6930651613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129433.5708029462
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 129433.5708029462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129419.7031260422
gradient descent iteration = 1
gd loss = 129419.7031260422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129409.8890276902
gradient descent iteration = 2
gd loss = 129409.8890276902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129400.757954588
gradient descent iteration = 3
gd loss = 129400.757954588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129391.8988360398
gradient descent iteration = 4
gd loss = 129391.8988360398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129383.2414774843
gradient descent iteration = 5
gd loss = 129383.2414774843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129374.7639088536
gradient descent iteration = 6
gd loss = 129374.7639088536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129366.4533497547
gradient descent iteration = 7
gd loss = 129366.4533497547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129358.2998190446
gradient descent iteration = 8
gd loss = 129358.2998190446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129350.2947183795
gradient descent iteration = 9
gd loss = 129350.2947183795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129342.430364806
gradient descent iteration = 10
gd loss = 129342.430364806
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129334.6997666944
gradient descent iteration = 11
gd loss = 129334.6997666944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129327.0964913224
gradient descent iteration = 12
gd loss = 129327.0964913224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129319.6145759544
gradient descent iteration = 13
gd loss = 129319.6145759544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129312.2484631988
gradient descent iteration = 14
gd loss = 129312.2484631988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129304.9929630614
gradient descent iteration = 15
gd loss = 129304.9929630614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129297.8431971659
gradient descent iteration = 16
gd loss = 129297.8431971659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129290.7945536537
gradient descent iteration = 17
gd loss = 129290.7945536537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129283.8426636369
gradient descent iteration = 18
gd loss = 129283.8426636369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129276.9833821639
gradient descent iteration = 19
gd loss = 129276.9833821639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129270.2127688284
gradient descent iteration = 20
gd loss = 129270.2127688284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129263.5270693385
gradient descent iteration = 21
gd loss = 129263.5270693385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129256.9227008009
gradient descent iteration = 22
gd loss = 129256.9227008009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129250.3962344615
gradient descent iteration = 23
gd loss = 129250.3962344615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129243.9443791401
gradient descent iteration = 24
gd loss = 129243.9443791401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129237.5639692263
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 129237.5639692263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129228.5486769668
gradient descent iteration = 1
gd loss = 129228.5486769668
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129220.3142805861
gradient descent iteration = 2
gd loss = 129220.3142805861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129212.5285676377
gradient descent iteration = 3
gd loss = 129212.5285676377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129205.0784889282
gradient descent iteration = 4
gd loss = 129205.0784889282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129197.9089677634
gradient descent iteration = 5
gd loss = 129197.9089677634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129190.9844468678
gradient descent iteration = 6
gd loss = 129190.9844468678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129184.2782541234
gradient descent iteration = 7
gd loss = 129184.2782541234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129177.7689645838
gradient descent iteration = 8
gd loss = 129177.7689645838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129171.4387758575
gradient descent iteration = 9
gd loss = 129171.4387758575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129165.2725914024
gradient descent iteration = 10
gd loss = 129165.2725914024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129159.2574206424
gradient descent iteration = 11
gd loss = 129159.2574206424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129153.381955563
gradient descent iteration = 12
gd loss = 129153.381955563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129147.6362586909
gradient descent iteration = 13
gd loss = 129147.6362586909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129142.0115262413
gradient descent iteration = 14
gd loss = 129142.0115262413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129136.4999047979
gradient descent iteration = 15
gd loss = 129136.4999047979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129131.0943469275
gradient descent iteration = 16
gd loss = 129131.0943469275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129125.7884954841
gradient descent iteration = 17
gd loss = 129125.7884954841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129120.5765892227
gradient descent iteration = 18
gd loss = 129120.5765892227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129115.4533860757
gradient descent iteration = 19
gd loss = 129115.4533860757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129110.4140993093
gradient descent iteration = 20
gd loss = 129110.4140993093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129105.4543439656
gradient descent iteration = 21
gd loss = 129105.4543439656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129100.5701273523
gradient descent iteration = 22
gd loss = 129100.5701273523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129095.7578577495
gradient descent iteration = 23
gd loss = 129095.7578577495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129091.0142209081
gradient descent iteration = 24
gd loss = 129091.0142209081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129086.3361360241
Initial loss = 129932.0240114478
Final loss = 129086.3361360241
Deformation gradient control sequence optimization finished.
Animation interval 33 took 1316 seconds.
Full animation took 45357 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 34************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 129248.6220077074
initial norm = 881.4565677250639
convergence norm = 0.881456567725064
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 129248.6220077074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129202.1838161682
gradient descent iteration = 1
gd loss = 129202.1838161682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129173.8443403298
gradient descent iteration = 2
gd loss = 129173.8443403298
line search decrease found at ls_iter = 2, alpha = 0.025, loss = 129168.581850923
gradient descent iteration = 3
gd loss = 129168.581850923
line search decrease found at ls_iter = 0, alpha = 0.025, loss = 129163.4374924009
gradient descent iteration = 4
gd loss = 129163.4374924009
line search decrease found at ls_iter = 3, alpha = 0.003125, loss = 129155.9410444564
gradient descent iteration = 5
gd loss = 129155.9410444564
line search decrease found at ls_iter = 11, alpha = 1.52587890625e-06, loss = 129154.626996032
gradient descent iteration = 6
gd loss = 129154.626996032
line search decrease found at ls_iter = 2, alpha = 3.814697265625e-07, loss = 129154.6208416277
gradient descent iteration = 7
gd loss = 129154.6208416277
line search decrease found at ls_iter = 3, alpha = 4.76837158203125e-08, loss = 129154.6202102037
gradient descent iteration = 8
gd loss = 129154.6202102037
line search decrease found at ls_iter = 3, alpha = 5.960464477539063e-09, loss = 129154.6201888082
gradient descent iteration = 9
gd loss = 129154.6201888082
line search decrease found at ls_iter = 2, alpha = 1.490116119384766e-09, loss = 129154.620188791
gradient descent iteration = 10
gd loss = 129154.620188791
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201885995
gradient descent iteration = 11
gd loss = 129154.6201885995
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201884993
gradient descent iteration = 12
gd loss = 129154.6201884993
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201883234
gradient descent iteration = 13
gd loss = 129154.6201883234
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201882088
gradient descent iteration = 14
gd loss = 129154.6201882088
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201880443
gradient descent iteration = 15
gd loss = 129154.6201880443
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201879224
gradient descent iteration = 16
gd loss = 129154.6201879224
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201877645
gradient descent iteration = 17
gd loss = 129154.6201877645
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201876371
gradient descent iteration = 18
gd loss = 129154.6201876371
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201874831
gradient descent iteration = 19
gd loss = 129154.6201874831
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201873525
gradient descent iteration = 20
gd loss = 129154.6201873525
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201872011
gradient descent iteration = 21
gd loss = 129154.6201872011
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.620187068
gradient descent iteration = 22
gd loss = 129154.620187068
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201869195
gradient descent iteration = 23
gd loss = 129154.6201869195
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201867844
gradient descent iteration = 24
gd loss = 129154.6201867844
line search decrease found at ls_iter = 0, alpha = 1.490116119384766e-09, loss = 129154.6201866364
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 129154.6201866364
line search decrease found at ls_iter = 8, alpha = 0.000390625, loss = 129154.6106069924
gradient descent iteration = 1
gd loss = 129154.6106069924
line search decrease found at ls_iter = 0, alpha = 0.000390625, loss = 129153.6763719853
gradient descent iteration = 2
gd loss = 129153.6763719853
Line search unable to find a decrease in timestep (10), gd iteration (2)
Exiting gradient descent and moving to next control timestep.
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 130068.2726760675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129157.0173200139
gradient descent iteration = 1
gd loss = 129157.0173200139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129152.225566262
gradient descent iteration = 2
gd loss = 129152.225566262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129147.8621435088
gradient descent iteration = 3
gd loss = 129147.8621435088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129143.84242565
gradient descent iteration = 4
gd loss = 129143.84242565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129140.1009414365
gradient descent iteration = 5
gd loss = 129140.1009414365
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129136.5867949052
gradient descent iteration = 6
gd loss = 129136.5867949052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129133.2602208976
gradient descent iteration = 7
gd loss = 129133.2602208976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129130.0899861175
gradient descent iteration = 8
gd loss = 129130.0899861175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129127.0514220043
gradient descent iteration = 9
gd loss = 129127.0514220043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129124.1249313291
gradient descent iteration = 10
gd loss = 129124.1249313291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129121.2948496068
gradient descent iteration = 11
gd loss = 129121.2948496068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129118.5485747233
gradient descent iteration = 12
gd loss = 129118.5485747233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129115.8758995685
gradient descent iteration = 13
gd loss = 129115.8758995685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129113.2684984176
gradient descent iteration = 14
gd loss = 129113.2684984176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129110.7195303224
gradient descent iteration = 15
gd loss = 129110.7195303224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129108.2233317631
gradient descent iteration = 16
gd loss = 129108.2233317631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129105.7751775632
gradient descent iteration = 17
gd loss = 129105.7751775632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129103.3710942461
gradient descent iteration = 18
gd loss = 129103.3710942461
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129101.0077137535
gradient descent iteration = 19
gd loss = 129101.0077137535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129098.6821584496
gradient descent iteration = 20
gd loss = 129098.6821584496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129096.3919502871
gradient descent iteration = 21
gd loss = 129096.3919502871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129094.1349387323
gradient descent iteration = 22
gd loss = 129094.1349387323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129091.909243374
gradient descent iteration = 23
gd loss = 129091.909243374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129089.7132079795
gradient descent iteration = 24
gd loss = 129089.7132079795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129087.5453649267
Initial loss = 129248.6220077074
Final loss = 129087.5453649267
Deformation gradient control sequence optimization finished.
Animation interval 34 took 1025 seconds.
Full animation took 46383 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 35************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 129515.2831093394
initial norm = 886.8555598622834
convergence norm = 0.8868555598622834
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 129515.2831093394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129446.3855438906
gradient descent iteration = 1
gd loss = 129446.3855438906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129408.7901386724
gradient descent iteration = 2
gd loss = 129408.7901386724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129382.8630458354
gradient descent iteration = 3
gd loss = 129382.8630458354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129361.4078465191
gradient descent iteration = 4
gd loss = 129361.4078465191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129342.1349778593
gradient descent iteration = 5
gd loss = 129342.1349778593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129324.145131556
gradient descent iteration = 6
gd loss = 129324.145131556
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129307.0768298406
gradient descent iteration = 7
gd loss = 129307.0768298406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129291.0040787866
gradient descent iteration = 8
gd loss = 129291.0040787866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129276.8937548511
gradient descent iteration = 9
gd loss = 129276.8937548511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129265.596830589
gradient descent iteration = 10
gd loss = 129265.596830589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129255.2681316989
gradient descent iteration = 11
gd loss = 129255.2681316989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129245.0553545828
gradient descent iteration = 12
gd loss = 129245.0553545828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129235.0202594254
gradient descent iteration = 13
gd loss = 129235.0202594254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129225.2501650861
gradient descent iteration = 14
gd loss = 129225.2501650861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129215.615795153
gradient descent iteration = 15
gd loss = 129215.615795153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129206.1657495575
gradient descent iteration = 16
gd loss = 129206.1657495575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129196.7817294089
gradient descent iteration = 17
gd loss = 129196.7817294089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129187.5011853091
gradient descent iteration = 18
gd loss = 129187.5011853091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129178.2487073918
gradient descent iteration = 19
gd loss = 129178.2487073918
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129169.0554901567
gradient descent iteration = 20
gd loss = 129169.0554901567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129159.8816429223
gradient descent iteration = 21
gd loss = 129159.8816429223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129150.748326851
gradient descent iteration = 22
gd loss = 129150.748326851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129141.6420278048
gradient descent iteration = 23
gd loss = 129141.6420278048
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129132.572132985
gradient descent iteration = 24
gd loss = 129132.572132985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129123.5441112295
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 129123.5441112295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129111.6308453643
gradient descent iteration = 1
gd loss = 129111.6308453643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129102.3033731637
gradient descent iteration = 2
gd loss = 129102.3033731637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129093.4988768301
gradient descent iteration = 3
gd loss = 129093.4988768301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129084.9440777853
gradient descent iteration = 4
gd loss = 129084.9440777853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129076.5840825167
gradient descent iteration = 5
gd loss = 129076.5840825167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129068.3998526638
gradient descent iteration = 6
gd loss = 129068.3998526638
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129060.3807676116
gradient descent iteration = 7
gd loss = 129060.3807676116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129052.5189321286
gradient descent iteration = 8
gd loss = 129052.5189321286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129044.807557201
gradient descent iteration = 9
gd loss = 129044.807557201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129037.2403863215
gradient descent iteration = 10
gd loss = 129037.2403863215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129029.8114863097
gradient descent iteration = 11
gd loss = 129029.8114863097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129022.5154178914
gradient descent iteration = 12
gd loss = 129022.5154178914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129015.3472271804
gradient descent iteration = 13
gd loss = 129015.3472271804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129008.3018595283
gradient descent iteration = 14
gd loss = 129008.3018595283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129001.3742301238
gradient descent iteration = 15
gd loss = 129001.3742301238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128994.5593396256
gradient descent iteration = 16
gd loss = 128994.5593396256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128987.8523681234
gradient descent iteration = 17
gd loss = 128987.8523681234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128981.2487402455
gradient descent iteration = 18
gd loss = 128981.2487402455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128974.7441693669
gradient descent iteration = 19
gd loss = 128974.7441693669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128968.3346913242
gradient descent iteration = 20
gd loss = 128968.3346913242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128962.0166652289
gradient descent iteration = 21
gd loss = 128962.0166652289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128955.7867761898
gradient descent iteration = 22
gd loss = 128955.7867761898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128949.6420210169
gradient descent iteration = 23
gd loss = 128949.6420210169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128943.57967152
gradient descent iteration = 24
gd loss = 128943.57967152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128937.5972561811
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 128937.5972561811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128930.1690292696
gradient descent iteration = 1
gd loss = 128930.1690292696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128923.1486575159
gradient descent iteration = 2
gd loss = 128923.1486575159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128916.3950756162
gradient descent iteration = 3
gd loss = 128916.3950756162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128909.8553104317
gradient descent iteration = 4
gd loss = 128909.8553104317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128903.5003866814
gradient descent iteration = 5
gd loss = 128903.5003866814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128897.3107613722
gradient descent iteration = 6
gd loss = 128897.3107613722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128891.2717912
gradient descent iteration = 7
gd loss = 128891.2717912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128885.3718690786
gradient descent iteration = 8
gd loss = 128885.3718690786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128879.6014687582
gradient descent iteration = 9
gd loss = 128879.6014687582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128873.9525756682
gradient descent iteration = 10
gd loss = 128873.9525756682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128868.4183148266
gradient descent iteration = 11
gd loss = 128868.4183148266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128862.9926931743
gradient descent iteration = 12
gd loss = 128862.9926931743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128857.6704155435
gradient descent iteration = 13
gd loss = 128857.6704155435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128852.4467551707
gradient descent iteration = 14
gd loss = 128852.4467551707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128847.3174443832
gradient descent iteration = 15
gd loss = 128847.3174443832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128842.2785864399
gradient descent iteration = 16
gd loss = 128842.2785864399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128837.3266009262
gradient descent iteration = 17
gd loss = 128837.3266009262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128832.4581768388
gradient descent iteration = 18
gd loss = 128832.4581768388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128827.6702340895
gradient descent iteration = 19
gd loss = 128827.6702340895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128822.9598925098
gradient descent iteration = 20
gd loss = 128822.9598925098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128818.3244468739
gradient descent iteration = 21
gd loss = 128818.3244468739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128813.7613453669
gradient descent iteration = 22
gd loss = 128813.7613453669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128809.2681703434
gradient descent iteration = 23
gd loss = 128809.2681703434
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128804.8426258452
gradient descent iteration = 24
gd loss = 128804.8426258452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128800.4825276304
Initial loss = 129515.2831093394
Final loss = 128800.4825276304
Deformation gradient control sequence optimization finished.
Animation interval 35 took 1314 seconds.
Full animation took 47697 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 36************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 129375.6232943853
initial norm = 882.4407855083992
convergence norm = 0.8824407855083992
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 129375.6232943853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129299.3048890628
gradient descent iteration = 1
gd loss = 129299.3048890628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129242.9134584195
gradient descent iteration = 2
gd loss = 129242.9134584195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129202.090728512
gradient descent iteration = 3
gd loss = 129202.090728512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129173.1862521499
gradient descent iteration = 4
gd loss = 129173.1862521499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129151.5162943245
gradient descent iteration = 5
gd loss = 129151.5162943245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129132.2855174517
gradient descent iteration = 6
gd loss = 129132.2855174517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129113.674052302
gradient descent iteration = 7
gd loss = 129113.674052302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129095.7477729567
gradient descent iteration = 8
gd loss = 129095.7477729567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129078.7486152757
gradient descent iteration = 9
gd loss = 129078.7486152757
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129062.5342099442
gradient descent iteration = 10
gd loss = 129062.5342099442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129046.8836879837
gradient descent iteration = 11
gd loss = 129046.8836879837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129031.7102434847
gradient descent iteration = 12
gd loss = 129031.7102434847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129017.3784521469
gradient descent iteration = 13
gd loss = 129017.3784521469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129005.4308379182
gradient descent iteration = 14
gd loss = 129005.4308379182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128997.1762139123
gradient descent iteration = 15
gd loss = 128997.1762139123
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128988.7376543779
gradient descent iteration = 16
gd loss = 128988.7376543779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128980.5505410176
gradient descent iteration = 17
gd loss = 128980.5505410176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128972.4395764465
gradient descent iteration = 18
gd loss = 128972.4395764465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128964.4849955629
gradient descent iteration = 19
gd loss = 128964.4849955629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128956.6186533427
gradient descent iteration = 20
gd loss = 128956.6186533427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128948.8901666436
gradient descent iteration = 21
gd loss = 128948.8901666436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128941.2388475021
gradient descent iteration = 22
gd loss = 128941.2388475021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128933.7161254233
gradient descent iteration = 23
gd loss = 128933.7161254233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128926.2578492173
gradient descent iteration = 24
gd loss = 128926.2578492173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128918.9206689606
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 128918.9206689606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128908.2285629148
gradient descent iteration = 1
gd loss = 128908.2285629148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128900.4296032045
gradient descent iteration = 2
gd loss = 128900.4296032045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128893.1879054859
gradient descent iteration = 3
gd loss = 128893.1879054859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128886.1953344629
gradient descent iteration = 4
gd loss = 128886.1953344629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128879.3880777821
gradient descent iteration = 5
gd loss = 128879.3880777821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128872.7440964041
gradient descent iteration = 6
gd loss = 128872.7440964041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128866.251361032
gradient descent iteration = 7
gd loss = 128866.251361032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128859.9010282089
gradient descent iteration = 8
gd loss = 128859.9010282089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128853.6855385396
gradient descent iteration = 9
gd loss = 128853.6855385396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128847.5979684985
gradient descent iteration = 10
gd loss = 128847.5979684985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128841.6317581803
gradient descent iteration = 11
gd loss = 128841.6317581803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128835.7806860433
gradient descent iteration = 12
gd loss = 128835.7806860433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128830.0389014909
gradient descent iteration = 13
gd loss = 128830.0389014909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128824.400988492
gradient descent iteration = 14
gd loss = 128824.400988492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128818.8620328537
gradient descent iteration = 15
gd loss = 128818.8620328537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128813.4174921263
gradient descent iteration = 16
gd loss = 128813.4174921263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128808.0631376036
gradient descent iteration = 17
gd loss = 128808.0631376036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128802.7950319908
gradient descent iteration = 18
gd loss = 128802.7950319908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128797.6094950233
gradient descent iteration = 19
gd loss = 128797.6094950233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128792.5030132344
gradient descent iteration = 20
gd loss = 128792.5030132344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128787.4722100944
gradient descent iteration = 21
gd loss = 128787.4722100944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128782.5138210722
gradient descent iteration = 22
gd loss = 128782.5138210722
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128777.6246723339
gradient descent iteration = 23
gd loss = 128777.6246723339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128772.8016443259
gradient descent iteration = 24
gd loss = 128772.8016443259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128768.0416988718
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 128768.0416988718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128761.1963002352
gradient descent iteration = 1
gd loss = 128761.1963002352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128754.6162697419
gradient descent iteration = 2
gd loss = 128754.6162697419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128748.2177668639
gradient descent iteration = 3
gd loss = 128748.2177668639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128741.9620754057
gradient descent iteration = 4
gd loss = 128741.9620754057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128735.8278670132
gradient descent iteration = 5
gd loss = 128735.8278670132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128729.8037567177
gradient descent iteration = 6
gd loss = 128729.8037567177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128723.887797897
gradient descent iteration = 7
gd loss = 128723.887797897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128718.0877431407
gradient descent iteration = 8
gd loss = 128718.0877431407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128712.4121032366
gradient descent iteration = 9
gd loss = 128712.4121032366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128706.8670113015
gradient descent iteration = 10
gd loss = 128706.8670113015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128701.4558048263
gradient descent iteration = 11
gd loss = 128701.4558048263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128696.1791870067
gradient descent iteration = 12
gd loss = 128696.1791870067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128691.0356400165
gradient descent iteration = 13
gd loss = 128691.0356400165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128686.0220085298
gradient descent iteration = 14
gd loss = 128686.0220085298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128681.1340330991
gradient descent iteration = 15
gd loss = 128681.1340330991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128676.3667860718
gradient descent iteration = 16
gd loss = 128676.3667860718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128671.7150037899
gradient descent iteration = 17
gd loss = 128671.7150037899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128667.1733224088
gradient descent iteration = 18
gd loss = 128667.1733224088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128662.73643235
gradient descent iteration = 19
gd loss = 128662.73643235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128658.3991752604
gradient descent iteration = 20
gd loss = 128658.3991752604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128654.1566047682
gradient descent iteration = 21
gd loss = 128654.1566047682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128650.0040183093
gradient descent iteration = 22
gd loss = 128650.0040183093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128645.9369669557
gradient descent iteration = 23
gd loss = 128645.9369669557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128641.9512533697
gradient descent iteration = 24
gd loss = 128641.9512533697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128638.0429227432
Initial loss = 129375.6232943853
Final loss = 128638.0429227432
Deformation gradient control sequence optimization finished.
Animation interval 36 took 1314 seconds.
Full animation took 49012 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 37************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 129309.0491852886
initial norm = 1082.572550585597
convergence norm = 1.082572550585597
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 129309.0491852886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129220.7044142984
gradient descent iteration = 1
gd loss = 129220.7044142984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129167.3331994413
gradient descent iteration = 2
gd loss = 129167.3331994413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129136.0256871017
gradient descent iteration = 3
gd loss = 129136.0256871017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129113.0435090654
gradient descent iteration = 4
gd loss = 129113.0435090654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129093.7938318109
gradient descent iteration = 5
gd loss = 129093.7938318109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129076.6598650412
gradient descent iteration = 6
gd loss = 129076.6598650412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129061.8036741251
gradient descent iteration = 7
gd loss = 129061.8036741251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129050.2462617905
gradient descent iteration = 8
gd loss = 129050.2462617905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129041.0115491004
gradient descent iteration = 9
gd loss = 129041.0115491004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129031.8785437192
gradient descent iteration = 10
gd loss = 129031.8785437192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129023.1962748761
gradient descent iteration = 11
gd loss = 129023.1962748761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129014.6953368897
gradient descent iteration = 12
gd loss = 129014.6953368897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 129006.4778494023
gradient descent iteration = 13
gd loss = 129006.4778494023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128998.3738668514
gradient descent iteration = 14
gd loss = 128998.3738668514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128990.4781146916
gradient descent iteration = 15
gd loss = 128990.4781146916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128982.642604659
gradient descent iteration = 16
gd loss = 128982.642604659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128974.9685951397
gradient descent iteration = 17
gd loss = 128974.9685951397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128967.3188673419
gradient descent iteration = 18
gd loss = 128967.3188673419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128959.8011953768
gradient descent iteration = 19
gd loss = 128959.8011953768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128952.2852276342
gradient descent iteration = 20
gd loss = 128952.2852276342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128944.884627708
gradient descent iteration = 21
gd loss = 128944.884627708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128937.4735553121
gradient descent iteration = 22
gd loss = 128937.4735553121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128930.1706029708
gradient descent iteration = 23
gd loss = 128930.1706029708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128922.8523325953
gradient descent iteration = 24
gd loss = 128922.8523325953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128915.6408766279
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 128915.6408766279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128904.7661560847
gradient descent iteration = 1
gd loss = 128904.7661560847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128897.005030492
gradient descent iteration = 2
gd loss = 128897.005030492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128889.8399134057
gradient descent iteration = 3
gd loss = 128889.8399134057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128882.9484588723
gradient descent iteration = 4
gd loss = 128882.9484588723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128876.2619340354
gradient descent iteration = 5
gd loss = 128876.2619340354
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128869.75339113
gradient descent iteration = 6
gd loss = 128869.75339113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128863.4061576236
gradient descent iteration = 7
gd loss = 128863.4061576236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128857.2074463307
gradient descent iteration = 8
gd loss = 128857.2074463307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128851.146518936
gradient descent iteration = 9
gd loss = 128851.146518936
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128845.2139674669
gradient descent iteration = 10
gd loss = 128845.2139674669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128839.4013512652
gradient descent iteration = 11
gd loss = 128839.4013512652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128833.7010073575
gradient descent iteration = 12
gd loss = 128833.7010073575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128828.1059666541
gradient descent iteration = 13
gd loss = 128828.1059666541
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128822.6097812274
gradient descent iteration = 14
gd loss = 128822.6097812274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128817.2064246937
gradient descent iteration = 15
gd loss = 128817.2064246937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128811.8902343612
gradient descent iteration = 16
gd loss = 128811.8902343612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128806.6558630378
gradient descent iteration = 17
gd loss = 128806.6558630378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128801.4982380326
gradient descent iteration = 18
gd loss = 128801.4982380326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128796.4125314091
gradient descent iteration = 19
gd loss = 128796.4125314091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 128791.3941299025
gradient descent iteration = 20
gd loss = 128791.3941299025
