gd loss = 126553.9265878407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 126252.3043940617
gradient descent iteration = 12
gd loss = 126252.3043940617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125954.4015950585
gradient descent iteration = 13
gd loss = 125954.4015950585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125660.0948129704
gradient descent iteration = 14
gd loss = 125660.0948129704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125369.2667650711
gradient descent iteration = 15
gd loss = 125369.2667650711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 125081.8059206234
gradient descent iteration = 16
gd loss = 125081.8059206234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124797.6061745275
gradient descent iteration = 17
gd loss = 124797.6061745275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124516.5665368053
gradient descent iteration = 18
gd loss = 124516.5665368053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 124238.5908288285
gradient descent iteration = 19
gd loss = 124238.5908288285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123963.587384564
gradient descent iteration = 20
gd loss = 123963.587384564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123691.4688088527
gradient descent iteration = 21
gd loss = 123691.4688088527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123422.1517560116
gradient descent iteration = 22
gd loss = 123422.1517560116
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123155.5567052643
gradient descent iteration = 23
gd loss = 123155.5567052643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122891.6077360145
gradient descent iteration = 24
gd loss = 122891.6077360145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122630.2323217093
Initial loss = 154310.4114320421
Final loss = 122630.2323217093
Deformation gradient control sequence optimization finished.
Animation interval 2 took 1340 seconds.
Full animation took 4021 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 3************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 124005.4132616213
initial norm = 4821.277568020674
convergence norm = 4.821277568020674
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 124005.4132616213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123528.7333488221
gradient descent iteration = 1
gd loss = 123528.7333488221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 123062.3335228996
gradient descent iteration = 2
gd loss = 123062.3335228996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122605.8931442191
gradient descent iteration = 3
gd loss = 122605.8931442191
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 122159.059465582
gradient descent iteration = 4
gd loss = 122159.059465582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121721.4556552675
gradient descent iteration = 5
gd loss = 121721.4556552675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 121292.6838423295
gradient descent iteration = 6
gd loss = 121292.6838423295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120872.3280371167
gradient descent iteration = 7
gd loss = 120872.3280371167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120459.9575775794
gradient descent iteration = 8
gd loss = 120459.9575775794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 120055.1345453733
gradient descent iteration = 9
gd loss = 120055.1345453733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119657.4230809967
gradient descent iteration = 10
gd loss = 119657.4230809967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 119266.3977673033
gradient descent iteration = 11
gd loss = 119266.3977673033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118881.6492641131
gradient descent iteration = 12
gd loss = 118881.6492641131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118502.7875904121
gradient descent iteration = 13
gd loss = 118502.7875904121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 118129.4462234443
gradient descent iteration = 14
gd loss = 118129.4462234443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117761.2828638938
gradient descent iteration = 15
gd loss = 117761.2828638938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117397.981185545
gradient descent iteration = 16
gd loss = 117397.981185545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 117039.2505404964
gradient descent iteration = 17
gd loss = 117039.2505404964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116684.8245758007
gradient descent iteration = 18
gd loss = 116684.8245758007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 116334.4590914819
gradient descent iteration = 19
gd loss = 116334.4590914819
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115987.9310376872
gradient descent iteration = 20
gd loss = 115987.9310376872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115645.0375359329
gradient descent iteration = 21
gd loss = 115645.0375359329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 115305.5943595454
gradient descent iteration = 22
gd loss = 115305.5943595454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114969.4341027901
gradient descent iteration = 23
gd loss = 114969.4341027901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114636.4047618031
gradient descent iteration = 24
gd loss = 114636.4047618031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 114306.3679023462
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 114306.3679023462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113872.0013314655
gradient descent iteration = 1
gd loss = 113872.0013314655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113443.9245429859
gradient descent iteration = 2
gd loss = 113443.9245429859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 113021.9983905128
gradient descent iteration = 3
gd loss = 113021.9983905128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112606.0880704903
gradient descent iteration = 4
gd loss = 112606.0880704903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 112196.0627363449
gradient descent iteration = 5
gd loss = 112196.0627363449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111791.7953209511
gradient descent iteration = 6
gd loss = 111791.7953209511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111393.1625839033
gradient descent iteration = 7
gd loss = 111393.1625839033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 111000.0449532763
gradient descent iteration = 8
gd loss = 111000.0449532763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110612.3268742626
gradient descent iteration = 9
gd loss = 110612.3268742626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 110229.896669573
gradient descent iteration = 10
gd loss = 110229.896669573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109852.646047617
gradient descent iteration = 11
gd loss = 109852.646047617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109480.469941165
gradient descent iteration = 12
gd loss = 109480.469941165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 109113.2662417043
gradient descent iteration = 13
gd loss = 109113.2662417043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108750.9355614927
gradient descent iteration = 14
gd loss = 108750.9355614927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108393.3810834499
gradient descent iteration = 15
gd loss = 108393.3810834499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 108040.50887581
gradient descent iteration = 16
gd loss = 108040.50887581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 107692.2277063536
gradient descent iteration = 17
gd loss = 107692.2277063536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 107348.4485560934
gradient descent iteration = 18
gd loss = 107348.4485560934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 107009.0845960649
gradient descent iteration = 19
gd loss = 107009.0845960649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106674.0510039785
gradient descent iteration = 20
gd loss = 106674.0510039785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106343.264933312
gradient descent iteration = 21
gd loss = 106343.264933312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 106016.6455016033
gradient descent iteration = 22
gd loss = 106016.6455016033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105694.1136919593
gradient descent iteration = 23
gd loss = 105694.1136919593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105375.592119705
gradient descent iteration = 24
gd loss = 105375.592119705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 105061.0049084172
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 105061.0049084172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104753.2208462038
gradient descent iteration = 1
gd loss = 104753.2208462038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104451.0443773325
gradient descent iteration = 2
gd loss = 104451.0443773325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 104154.2270400298
gradient descent iteration = 3
gd loss = 104154.2270400298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103862.5367778745
gradient descent iteration = 4
gd loss = 103862.5367778745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103575.7566510986
gradient descent iteration = 5
gd loss = 103575.7566510986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103293.683582905
gradient descent iteration = 6
gd loss = 103293.683582905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 103016.1272991617
gradient descent iteration = 7
gd loss = 103016.1272991617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102742.9094098247
gradient descent iteration = 8
gd loss = 102742.9094098247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102473.8624680901
gradient descent iteration = 9
gd loss = 102473.8624680901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102208.8291045023
gradient descent iteration = 10
gd loss = 102208.8291045023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101947.661263009
gradient descent iteration = 11
gd loss = 101947.661263009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101690.2195589367
gradient descent iteration = 12
gd loss = 101690.2195589367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101436.3726644875
gradient descent iteration = 13
gd loss = 101436.3726644875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101185.9966556603
gradient descent iteration = 14
gd loss = 101185.9966556603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100938.9744791358
gradient descent iteration = 15
gd loss = 100938.9744791358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100695.195474992
gradient descent iteration = 16
gd loss = 100695.195474992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100454.5549338475
gradient descent iteration = 17
gd loss = 100454.5549338475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100216.9536549678
gradient descent iteration = 18
gd loss = 100216.9536549678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99982.29759532453
gradient descent iteration = 19
gd loss = 99982.29759532453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99750.4976491445
gradient descent iteration = 20
gd loss = 99750.4976491445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99521.46926430386
gradient descent iteration = 21
gd loss = 99521.46926430386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99295.13207564804
gradient descent iteration = 22
gd loss = 99295.13207564804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99071.40963631787
gradient descent iteration = 23
gd loss = 99071.40963631787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98850.22919439089
gradient descent iteration = 24
gd loss = 98850.22919439089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98631.52148333431
Initial loss = 124005.4132616213
Final loss = 98631.52148333431
Deformation gradient control sequence optimization finished.
Animation interval 3 took 1341 seconds.
Full animation took 5362 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 4************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 102583.8229049823
initial norm = 3254.274073483932
convergence norm = 3.254274073483932
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 102583.8229049823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 102261.6961079425
gradient descent iteration = 1
gd loss = 102261.6961079425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101945.7466057745
gradient descent iteration = 2
gd loss = 101945.7466057745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101635.5632809176
gradient descent iteration = 3
gd loss = 101635.5632809176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101330.7697910529
gradient descent iteration = 4
gd loss = 101330.7697910529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 101031.0213585058
gradient descent iteration = 5
gd loss = 101031.0213585058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100736.001878174
gradient descent iteration = 6
gd loss = 100736.001878174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100445.4215352312
gradient descent iteration = 7
gd loss = 100445.4215352312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 100159.0139827339
gradient descent iteration = 8
gd loss = 100159.0139827339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99876.53396729907
gradient descent iteration = 9
gd loss = 99876.53396729907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99597.75561335988
gradient descent iteration = 10
gd loss = 99597.75561335988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99322.47066723843
gradient descent iteration = 11
gd loss = 99322.47066723843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 99050.48707096752
gradient descent iteration = 12
gd loss = 99050.48707096752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98781.62795570474
gradient descent iteration = 13
gd loss = 98781.62795570474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98515.7304995203
gradient descent iteration = 14
gd loss = 98515.7304995203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 98252.64453365604
gradient descent iteration = 15
gd loss = 98252.64453365604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97992.23168330421
gradient descent iteration = 16
gd loss = 97992.23168330421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97734.364773651
gradient descent iteration = 17
gd loss = 97734.364773651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97478.92675421812
gradient descent iteration = 18
gd loss = 97478.92675421812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 97225.80962408644
gradient descent iteration = 19
gd loss = 97225.80962408644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96974.91367531933
gradient descent iteration = 20
gd loss = 96974.91367531933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96726.14689013835
gradient descent iteration = 21
gd loss = 96726.14689013835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96479.42406600203
gradient descent iteration = 22
gd loss = 96479.42406600203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 96234.6662326605
gradient descent iteration = 23
gd loss = 96234.6662326605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95991.80020862515
gradient descent iteration = 24
gd loss = 95991.80020862515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95750.75811657772
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 95750.75811657772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95395.77221431825
gradient descent iteration = 1
gd loss = 95395.77221431825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 95048.21193855732
gradient descent iteration = 2
gd loss = 95048.21193855732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94707.79684755557
gradient descent iteration = 3
gd loss = 94707.79684755557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94374.26116884014
gradient descent iteration = 4
gd loss = 94374.26116884014
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 94047.35268687306
gradient descent iteration = 5
gd loss = 94047.35268687306
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93726.83185490787
gradient descent iteration = 6
gd loss = 93726.83185490787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93412.47095302689
gradient descent iteration = 7
gd loss = 93412.47095302689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 93104.0530794645
gradient descent iteration = 8
gd loss = 93104.0530794645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92801.3713752263
gradient descent iteration = 9
gd loss = 92801.3713752263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92504.22841805899
gradient descent iteration = 10
gd loss = 92504.22841805899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 92212.43569178518
gradient descent iteration = 11
gd loss = 92212.43569178518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91925.81307869604
gradient descent iteration = 12
gd loss = 91925.81307869604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91644.18834714232
gradient descent iteration = 13
gd loss = 91644.18834714232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91367.39681296503
gradient descent iteration = 14
gd loss = 91367.39681296503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 91095.28064191328
gradient descent iteration = 15
gd loss = 91095.28064191328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90827.68838992593
gradient descent iteration = 16
gd loss = 90827.68838992593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90564.47471860881
gradient descent iteration = 17
gd loss = 90564.47471860881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90305.50006657775
gradient descent iteration = 18
gd loss = 90305.50006657775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 90050.63042475324
gradient descent iteration = 19
gd loss = 90050.63042475324
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89799.73702135276
gradient descent iteration = 20
gd loss = 89799.73702135276
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89552.69609749016
gradient descent iteration = 21
gd loss = 89552.69609749016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89309.38882145644
gradient descent iteration = 22
gd loss = 89309.38882145644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 89069.70146195027
gradient descent iteration = 23
gd loss = 89069.70146195027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88833.52516290885
gradient descent iteration = 24
gd loss = 88833.52516290885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88600.75549236751
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 88600.75549236751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88362.82357361294
gradient descent iteration = 1
gd loss = 88362.82357361294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 88129.31381545195
gradient descent iteration = 2
gd loss = 88129.31381545195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87900.04620559585
gradient descent iteration = 3
gd loss = 87900.04620559585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87674.85190769694
gradient descent iteration = 4
gd loss = 87674.85190769694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87453.57238234242
gradient descent iteration = 5
gd loss = 87453.57238234242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87236.05860034641
gradient descent iteration = 6
gd loss = 87236.05860034641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87022.1703209268
gradient descent iteration = 7
gd loss = 87022.1703209268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86811.77542653761
gradient descent iteration = 8
gd loss = 86811.77542653761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86604.74931135164
gradient descent iteration = 9
gd loss = 86604.74931135164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86400.97432785139
gradient descent iteration = 10
gd loss = 86400.97432785139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86200.33929776518
gradient descent iteration = 11
gd loss = 86200.33929776518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86002.73904604882
gradient descent iteration = 12
gd loss = 86002.73904604882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85808.07397721626
gradient descent iteration = 13
gd loss = 85808.07397721626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85616.24969233297
gradient descent iteration = 14
gd loss = 85616.24969233297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85427.17663275482
gradient descent iteration = 15
gd loss = 85427.17663275482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85240.7697531491
gradient descent iteration = 16
gd loss = 85240.7697531491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85056.94822739209
gradient descent iteration = 17
gd loss = 85056.94822739209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84875.63516241669
gradient descent iteration = 18
gd loss = 84875.63516241669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84696.7573333827
gradient descent iteration = 19
gd loss = 84696.7573333827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84520.24495326083
gradient descent iteration = 20
gd loss = 84520.24495326083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84346.03146453838
gradient descent iteration = 21
gd loss = 84346.03146453838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84174.05334816063
gradient descent iteration = 22
gd loss = 84174.05334816063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84004.24994055112
gradient descent iteration = 23
gd loss = 84004.24994055112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83836.56325501911
gradient descent iteration = 24
gd loss = 83836.56325501911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83670.93781605853
Initial loss = 102583.8229049823
Final loss = 83670.93781605853
Deformation gradient control sequence optimization finished.
Animation interval 4 took 1337 seconds.
Full animation took 6699 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 5************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 87475.90089349358
initial norm = 3004.870433559557
convergence norm = 3.004870433559557
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 87475.90089349358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 87182.28577892626
gradient descent iteration = 1
gd loss = 87182.28577892626
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86901.24974673759
gradient descent iteration = 2
gd loss = 86901.24974673759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86631.5000953031
gradient descent iteration = 3
gd loss = 86631.5000953031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86371.79597731978
gradient descent iteration = 4
gd loss = 86371.79597731978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 86120.98154580935
gradient descent iteration = 5
gd loss = 86120.98154580935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85878.00556831819
gradient descent iteration = 6
gd loss = 85878.00556831819
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85641.93210388938
gradient descent iteration = 7
gd loss = 85641.93210388938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85411.94275457699
gradient descent iteration = 8
gd loss = 85411.94275457699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 85187.330854713
gradient descent iteration = 9
gd loss = 85187.330854713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84967.49155814617
gradient descent iteration = 10
gd loss = 84967.49155814617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84751.9095430716
gradient descent iteration = 11
gd loss = 84751.9095430716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84540.14631931442
gradient descent iteration = 12
gd loss = 84540.14631931442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84331.82871308825
gradient descent iteration = 13
gd loss = 84331.82871308825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 84126.63902980193
gradient descent iteration = 14
gd loss = 84126.63902980193
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83924.30664105396
gradient descent iteration = 15
gd loss = 83924.30664105396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83724.6004119234
gradient descent iteration = 16
gd loss = 83724.6004119234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83527.32227941504
gradient descent iteration = 17
gd loss = 83527.32227941504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83332.30215575121
gradient descent iteration = 18
gd loss = 83332.30215575121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 83139.39358306205
gradient descent iteration = 19
gd loss = 83139.39358306205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82948.46982718837
gradient descent iteration = 20
gd loss = 82948.46982718837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82759.42084607735
gradient descent iteration = 21
gd loss = 82759.42084607735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82572.15063051775
gradient descent iteration = 22
gd loss = 82572.15063051775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82386.57505007439
gradient descent iteration = 23
gd loss = 82386.57505007439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82202.62010111932
gradient descent iteration = 24
gd loss = 82202.62010111932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 82020.2203592623
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 82020.2203592623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81762.42962140177
gradient descent iteration = 1
gd loss = 81762.42962140177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81511.49807676444
gradient descent iteration = 2
gd loss = 81511.49807676444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81266.99220129808
gradient descent iteration = 3
gd loss = 81266.99220129808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 81028.51816753732
gradient descent iteration = 4
gd loss = 81028.51816753732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80795.71770362451
gradient descent iteration = 5
gd loss = 80795.71770362451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80568.26413892591
gradient descent iteration = 6
gd loss = 80568.26413892591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80345.85907897781
gradient descent iteration = 7
gd loss = 80345.85907897781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 80128.22926330051
gradient descent iteration = 8
gd loss = 80128.22926330051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79915.12426265398
gradient descent iteration = 9
gd loss = 79915.12426265398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79706.31423449691
gradient descent iteration = 10
gd loss = 79706.31423449691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79501.58773621134
gradient descent iteration = 11
gd loss = 79501.58773621134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79300.74995154947
gradient descent iteration = 12
gd loss = 79300.74995154947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 79103.62098491947
gradient descent iteration = 13
gd loss = 79103.62098491947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78910.03420337883
gradient descent iteration = 14
gd loss = 78910.03420337883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78719.83519692508
gradient descent iteration = 15
gd loss = 78719.83519692508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78532.88080565017
gradient descent iteration = 16
gd loss = 78532.88080565017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78349.03819493279
gradient descent iteration = 17
gd loss = 78349.03819493279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 78168.18398110502
gradient descent iteration = 18
gd loss = 78168.18398110502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77990.20326590775
gradient descent iteration = 19
gd loss = 77990.20326590775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77814.98907881233
gradient descent iteration = 20
gd loss = 77814.98907881233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77642.44194149059
gradient descent iteration = 21
gd loss = 77642.44194149059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77472.46926612592
gradient descent iteration = 22
gd loss = 77472.46926612592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77304.98446170142
gradient descent iteration = 23
gd loss = 77304.98446170142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 77139.90635272107
gradient descent iteration = 24
gd loss = 77139.90635272107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76977.15871586198
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 76977.15871586198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76798.75079696834
gradient descent iteration = 1
gd loss = 76798.75079696834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76624.36807403775
gradient descent iteration = 2
gd loss = 76624.36807403775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76453.80433718987
gradient descent iteration = 3
gd loss = 76453.80433718987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76286.86875960673
gradient descent iteration = 4
gd loss = 76286.86875960673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 76123.38455046795
gradient descent iteration = 5
gd loss = 76123.38455046795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75963.1877257645
gradient descent iteration = 6
gd loss = 75963.1877257645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75806.12598869798
gradient descent iteration = 7
gd loss = 75806.12598869798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75652.05770916598
gradient descent iteration = 8
gd loss = 75652.05770916598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75500.85100224114
gradient descent iteration = 9
gd loss = 75500.85100224114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75352.38292023801
gradient descent iteration = 10
gd loss = 75352.38292023801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75206.53871863103
gradient descent iteration = 11
gd loss = 75206.53871863103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 75063.21118555387
gradient descent iteration = 12
gd loss = 75063.21118555387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74922.30000342563
gradient descent iteration = 13
gd loss = 74922.30000342563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74783.71116981555
gradient descent iteration = 14
gd loss = 74783.71116981555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74647.35652045687
gradient descent iteration = 15
gd loss = 74647.35652045687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74513.15329674877
gradient descent iteration = 16
gd loss = 74513.15329674877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74381.02369385964
gradient descent iteration = 17
gd loss = 74381.02369385964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74250.89445443235
gradient descent iteration = 18
gd loss = 74250.89445443235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74122.696514861
gradient descent iteration = 19
gd loss = 74122.696514861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73996.36469900266
gradient descent iteration = 20
gd loss = 73996.36469900266
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73871.83743528739
gradient descent iteration = 21
gd loss = 73871.83743528739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73749.05649021162
gradient descent iteration = 22
gd loss = 73749.05649021162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73627.96672945842
gradient descent iteration = 23
gd loss = 73627.96672945842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73508.51588562771
gradient descent iteration = 24
gd loss = 73508.51588562771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73390.65435865229
Initial loss = 87475.90089349358
Final loss = 73390.65435865229
Deformation gradient control sequence optimization finished.
Animation interval 5 took 1337 seconds.
Full animation took 8036 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 6************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 74424.73708196291
initial norm = 1852.404625399164
convergence norm = 1.852404625399164
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 74424.73708196291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74246.99387318382
gradient descent iteration = 1
gd loss = 74246.99387318382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 74081.23441507888
gradient descent iteration = 2
gd loss = 74081.23441507888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73923.58582638821
gradient descent iteration = 3
gd loss = 73923.58582638821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73771.08410274214
gradient descent iteration = 4
gd loss = 73771.08410274214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73621.99029932451
gradient descent iteration = 5
gd loss = 73621.99029932451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73475.39888167172
gradient descent iteration = 6
gd loss = 73475.39888167172
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73330.83854666905
gradient descent iteration = 7
gd loss = 73330.83854666905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73188.04241866573
gradient descent iteration = 8
gd loss = 73188.04241866573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 73046.83987768805
gradient descent iteration = 9
gd loss = 73046.83987768805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72907.10889504521
gradient descent iteration = 10
gd loss = 72907.10889504521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72768.75492877337
gradient descent iteration = 11
gd loss = 72768.75492877337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72631.7012836355
gradient descent iteration = 12
gd loss = 72631.7012836355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72495.88346007049
gradient descent iteration = 13
gd loss = 72495.88346007049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72361.24590254466
gradient descent iteration = 14
gd loss = 72361.24590254466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72227.74026224867
gradient descent iteration = 15
gd loss = 72227.74026224867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 72095.32454784002
gradient descent iteration = 16
gd loss = 72095.32454784002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71963.96193605837
gradient descent iteration = 17
gd loss = 71963.96193605837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71833.62009821444
gradient descent iteration = 18
gd loss = 71833.62009821444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71704.27072838001
gradient descent iteration = 19
gd loss = 71704.27072838001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71575.8889010131
gradient descent iteration = 20
gd loss = 71575.8889010131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71448.45261074985
gradient descent iteration = 21
gd loss = 71448.45261074985
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71321.94203428079
gradient descent iteration = 22
gd loss = 71321.94203428079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71196.33928612883
gradient descent iteration = 23
gd loss = 71196.33928612883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 71071.62829279751
gradient descent iteration = 24
gd loss = 71071.62829279751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70947.79442812502
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 70947.79442812502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70767.67330100961
gradient descent iteration = 1
gd loss = 70767.67330100961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70592.70173116724
gradient descent iteration = 2
gd loss = 70592.70173116724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70422.47710565316
gradient descent iteration = 3
gd loss = 70422.47710565316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70256.64927965854
gradient descent iteration = 4
gd loss = 70256.64927965854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 70094.91280554065
gradient descent iteration = 5
gd loss = 70094.91280554065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69937.00033883065
gradient descent iteration = 6
gd loss = 69937.00033883065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69782.67642968295
gradient descent iteration = 7
gd loss = 69782.67642968295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69631.73296066871
gradient descent iteration = 8
gd loss = 69631.73296066871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69483.98518711459
gradient descent iteration = 9
gd loss = 69483.98518711459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69339.26763603842
gradient descent iteration = 10
gd loss = 69339.26763603842
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69197.43122708783
gradient descent iteration = 11
gd loss = 69197.43122708783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 69058.34105251591
gradient descent iteration = 12
gd loss = 69058.34105251591
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68921.87450260938
gradient descent iteration = 13
gd loss = 68921.87450260938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68787.91941415334
gradient descent iteration = 14
gd loss = 68787.91941415334
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68656.37265951213
gradient descent iteration = 15
gd loss = 68656.37265951213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68527.13911957903
gradient descent iteration = 16
gd loss = 68527.13911957903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68400.1307556043
gradient descent iteration = 17
gd loss = 68400.1307556043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68275.26582468614
gradient descent iteration = 18
gd loss = 68275.26582468614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68152.46820308619
gradient descent iteration = 19
gd loss = 68152.46820308619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 68031.66687362238
gradient descent iteration = 20
gd loss = 68031.66687362238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67912.7955471345
gradient descent iteration = 21
gd loss = 67912.7955471345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67795.79207235122
gradient descent iteration = 22
gd loss = 67795.79207235122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67680.59792866744
gradient descent iteration = 23
gd loss = 67680.59792866744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67567.15798324622
gradient descent iteration = 24
gd loss = 67567.15798324622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67455.42004386673
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 67455.42004386673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67322.90083338035
gradient descent iteration = 1
gd loss = 67322.90083338035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67194.29063114709
gradient descent iteration = 2
gd loss = 67194.29063114709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 67069.29497777281
gradient descent iteration = 3
gd loss = 67069.29497777281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66947.65294977921
gradient descent iteration = 4
gd loss = 66947.65294977921
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66829.13269173351
gradient descent iteration = 5
gd loss = 66829.13269173351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66713.52748062283
gradient descent iteration = 6
gd loss = 66713.52748062283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66600.65230791846
gradient descent iteration = 7
gd loss = 66600.65230791846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66490.34103988313
gradient descent iteration = 8
gd loss = 66490.34103988313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66382.44399399853
gradient descent iteration = 9
gd loss = 66382.44399399853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66276.82585707789
gradient descent iteration = 10
gd loss = 66276.82585707789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66173.36390913396
gradient descent iteration = 11
gd loss = 66173.36390913396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 66071.94649167346
gradient descent iteration = 12
gd loss = 66071.94649167346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65972.47165615659
gradient descent iteration = 13
gd loss = 65972.47165615659
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65874.84602185241
gradient descent iteration = 14
gd loss = 65874.84602185241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65778.98392796429
gradient descent iteration = 15
gd loss = 65778.98392796429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65684.80666738299
gradient descent iteration = 16
gd loss = 65684.80666738299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65592.24171916375
gradient descent iteration = 17
gd loss = 65592.24171916375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65501.22199091686
gradient descent iteration = 18
gd loss = 65501.22199091686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65411.68527840732
gradient descent iteration = 19
gd loss = 65411.68527840732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65323.57389058491
gradient descent iteration = 20
gd loss = 65323.57389058491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65236.83407930617
gradient descent iteration = 21
gd loss = 65236.83407930617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65151.41561519849
gradient descent iteration = 22
gd loss = 65151.41561519849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65067.27156550481
gradient descent iteration = 23
gd loss = 65067.27156550481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64984.35807484879
gradient descent iteration = 24
gd loss = 64984.35807484879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64902.63396298029
Initial loss = 74424.73708196291
Final loss = 64902.63396298029
Deformation gradient control sequence optimization finished.
Animation interval 6 took 1357 seconds.
Full animation took 9394 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 7************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 65718.94777708864
initial norm = 1586.624103693755
convergence norm = 1.586624103693755
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 65718.94777708864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65567.32601515262
gradient descent iteration = 1
gd loss = 65567.32601515262
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65428.01583824059
gradient descent iteration = 2
gd loss = 65428.01583824059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65298.84577096027
gradient descent iteration = 3
gd loss = 65298.84577096027
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65177.74884328839
gradient descent iteration = 4
gd loss = 65177.74884328839
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 65062.90504366766
gradient descent iteration = 5
gd loss = 65062.90504366766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64952.82588359248
gradient descent iteration = 6
gd loss = 64952.82588359248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64846.36923272442
gradient descent iteration = 7
gd loss = 64846.36923272442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64742.70046343488
gradient descent iteration = 8
gd loss = 64742.70046343488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64641.22797928646
gradient descent iteration = 9
gd loss = 64641.22797928646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64541.53808259704
gradient descent iteration = 10
gd loss = 64541.53808259704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64443.3412126284
gradient descent iteration = 11
gd loss = 64443.3412126284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64346.43175695273
gradient descent iteration = 12
gd loss = 64346.43175695273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64250.66002375702
gradient descent iteration = 13
gd loss = 64250.66002375702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64155.91365622146
gradient descent iteration = 14
gd loss = 64155.91365622146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 64062.10558022207
gradient descent iteration = 15
gd loss = 64062.10558022207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63969.16695380662
gradient descent iteration = 16
gd loss = 63969.16695380662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63877.04190050108
gradient descent iteration = 17
gd loss = 63877.04190050108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63785.6842748437
gradient descent iteration = 18
gd loss = 63785.6842748437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63695.0556478393
gradient descent iteration = 19
gd loss = 63695.0556478393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63605.12340423527
gradient descent iteration = 20
gd loss = 63605.12340423527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63515.85988214221
gradient descent iteration = 21
gd loss = 63515.85988214221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63427.2415411211
gradient descent iteration = 22
gd loss = 63427.2415411211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63339.2476875175
gradient descent iteration = 23
gd loss = 63339.2476875175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63251.85996032898
gradient descent iteration = 24
gd loss = 63251.85996032898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63165.06197970935
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 63165.06197970935
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 63047.95266357102
gradient descent iteration = 1
gd loss = 63047.95266357102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62934.3937398282
gradient descent iteration = 2
gd loss = 62934.3937398282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62824.06433242423
gradient descent iteration = 3
gd loss = 62824.06433242423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62716.7002509481
gradient descent iteration = 4
gd loss = 62716.7002509481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62612.08041507705
gradient descent iteration = 5
gd loss = 62612.08041507705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62510.01687597134
gradient descent iteration = 6
gd loss = 62510.01687597134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62410.34757335085
gradient descent iteration = 7
gd loss = 62410.34757335085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62312.93098073285
gradient descent iteration = 8
gd loss = 62312.93098073285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62217.64248664529
gradient descent iteration = 9
gd loss = 62217.64248664529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62124.3711180372
gradient descent iteration = 10
gd loss = 62124.3711180372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 62033.01742446789
gradient descent iteration = 11
gd loss = 62033.01742446789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61943.49136774581
gradient descent iteration = 12
gd loss = 61943.49136774581
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61855.7105423575
gradient descent iteration = 13
gd loss = 61855.7105423575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61769.59906627201
gradient descent iteration = 14
gd loss = 61769.59906627201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61685.08690282625
gradient descent iteration = 15
gd loss = 61685.08690282625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61602.10901681866
gradient descent iteration = 16
gd loss = 61602.10901681866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61520.60474825121
gradient descent iteration = 17
gd loss = 61520.60474825121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61440.51752926976
gradient descent iteration = 18
gd loss = 61440.51752926976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61361.79434838623
gradient descent iteration = 19
gd loss = 61361.79434838623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61284.38532446708
gradient descent iteration = 20
gd loss = 61284.38532446708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61208.24346750484
gradient descent iteration = 21
gd loss = 61208.24346750484
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61133.32450991784
gradient descent iteration = 22
gd loss = 61133.32450991784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 61059.58662159846
gradient descent iteration = 23
gd loss = 61059.58662159846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60986.99022869536
gradient descent iteration = 24
gd loss = 60986.99022869536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60915.49783231318
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 60915.49783231318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60828.43521992789
gradient descent iteration = 1
gd loss = 60828.43521992789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60744.22482318982
gradient descent iteration = 2
gd loss = 60744.22482318982
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60662.60761766702
gradient descent iteration = 3
gd loss = 60662.60761766702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60583.36429455459
gradient descent iteration = 4
gd loss = 60583.36429455459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60506.30770983246
gradient descent iteration = 5
gd loss = 60506.30770983246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60431.27657187552
gradient descent iteration = 6
gd loss = 60431.27657187552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60358.13059207724
gradient descent iteration = 7
gd loss = 60358.13059207724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60286.7469824377
gradient descent iteration = 8
gd loss = 60286.7469824377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60217.01773458246
gradient descent iteration = 9
gd loss = 60217.01773458246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60148.84693838002
gradient descent iteration = 10
gd loss = 60148.84693838002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60082.14882252173
gradient descent iteration = 11
gd loss = 60082.14882252173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 60016.84639843625
gradient descent iteration = 12
gd loss = 60016.84639843625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59952.87017484881
gradient descent iteration = 13
gd loss = 59952.87017484881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59890.15700246515
gradient descent iteration = 14
gd loss = 59890.15700246515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59828.64920343496
gradient descent iteration = 15
gd loss = 59828.64920343496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59768.29387393739
gradient descent iteration = 16
gd loss = 59768.29387393739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59709.04232089731
gradient descent iteration = 17
gd loss = 59709.04232089731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59650.84959412954
gradient descent iteration = 18
gd loss = 59650.84959412954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59593.67406641007
gradient descent iteration = 19
gd loss = 59593.67406641007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59537.47706859233
gradient descent iteration = 20
gd loss = 59537.47706859233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59482.22255433118
gradient descent iteration = 21
gd loss = 59482.22255433118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59427.87683281195
gradient descent iteration = 22
gd loss = 59427.87683281195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59374.40833523629
gradient descent iteration = 23
gd loss = 59374.40833523629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59321.78741077301
gradient descent iteration = 24
gd loss = 59321.78741077301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59269.98613991819
Initial loss = 65718.94777708864
Final loss = 59269.98613991819
Deformation gradient control sequence optimization finished.
Animation interval 7 took 1401 seconds.
Full animation took 10796 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 8************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 59508.88613979731
initial norm = 1014.294834099529
convergence norm = 1.014294834099529
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 59508.88613979731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59411.90682676325
gradient descent iteration = 1
gd loss = 59411.90682676325
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59322.11094588174
gradient descent iteration = 2
gd loss = 59322.11094588174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59237.62056567278
gradient descent iteration = 3
gd loss = 59237.62056567278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59156.974839327
gradient descent iteration = 4
gd loss = 59156.974839327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59079.13019268416
gradient descent iteration = 5
gd loss = 59079.13019268416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 59003.38037696803
gradient descent iteration = 6
gd loss = 59003.38037696803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58929.2577768355
gradient descent iteration = 7
gd loss = 58929.2577768355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58856.45096327703
gradient descent iteration = 8
gd loss = 58856.45096327703
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58784.74730428897
gradient descent iteration = 9
gd loss = 58784.74730428897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58713.99629328707
gradient descent iteration = 10
gd loss = 58713.99629328707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58644.08701594841
gradient descent iteration = 11
gd loss = 58644.08701594841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58574.93416828466
gradient descent iteration = 12
gd loss = 58574.93416828466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58506.46948013603
gradient descent iteration = 13
gd loss = 58506.46948013603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58438.63688216973
gradient descent iteration = 14
gd loss = 58438.63688216973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58371.38975317377
gradient descent iteration = 15
gd loss = 58371.38975317377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58304.68786418848
gradient descent iteration = 16
gd loss = 58304.68786418848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58238.49560432522
gradient descent iteration = 17
gd loss = 58238.49560432522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58172.78165313498
gradient descent iteration = 18
gd loss = 58172.78165313498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58107.51830722515
gradient descent iteration = 19
gd loss = 58107.51830722515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 58042.68139149139
gradient descent iteration = 20
gd loss = 58042.68139149139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57978.24962047477
gradient descent iteration = 21
gd loss = 57978.24962047477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57914.20357482329
gradient descent iteration = 22
gd loss = 57914.20357482329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57850.52526697613
gradient descent iteration = 23
gd loss = 57850.52526697613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57787.19788139297
gradient descent iteration = 24
gd loss = 57787.19788139297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57724.20537583058
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 57724.20537583058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57648.82059630437
gradient descent iteration = 1
gd loss = 57648.82059630437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57575.83010657211
gradient descent iteration = 2
gd loss = 57575.83010657211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57504.96916461641
gradient descent iteration = 3
gd loss = 57504.96916461641
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57436.02567773789
gradient descent iteration = 4
gd loss = 57436.02567773789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57368.82574859877
gradient descent iteration = 5
gd loss = 57368.82574859877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57303.22410157586
gradient descent iteration = 6
gd loss = 57303.22410157586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57239.09782530435
gradient descent iteration = 7
gd loss = 57239.09782530435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57176.34125698587
gradient descent iteration = 8
gd loss = 57176.34125698587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57114.86253280967
gradient descent iteration = 9
gd loss = 57114.86253280967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 57054.58105232489
gradient descent iteration = 10
gd loss = 57054.58105232489
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56995.42551561453
gradient descent iteration = 11
gd loss = 56995.42551561453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56937.33227928393
gradient descent iteration = 12
gd loss = 56937.33227928393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56880.24426064586
gradient descent iteration = 13
gd loss = 56880.24426064586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56824.11002774897
gradient descent iteration = 14
gd loss = 56824.11002774897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56768.88271192413
gradient descent iteration = 15
gd loss = 56768.88271192413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56714.51930038826
gradient descent iteration = 16
gd loss = 56714.51930038826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56660.98023203127
gradient descent iteration = 17
gd loss = 56660.98023203127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56608.22880684995
gradient descent iteration = 18
gd loss = 56608.22880684995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56556.23096315833
gradient descent iteration = 19
gd loss = 56556.23096315833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56504.95528377783
gradient descent iteration = 20
gd loss = 56504.95528377783
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56454.37319920886
gradient descent iteration = 21
gd loss = 56454.37319920886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56404.45836521885
gradient descent iteration = 22
gd loss = 56404.45836521885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56355.18642426271
gradient descent iteration = 23
gd loss = 56355.18642426271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56306.53483960561
gradient descent iteration = 24
gd loss = 56306.53483960561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56258.48260386498
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 56258.48260386498
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56204.5113999811
gradient descent iteration = 1
gd loss = 56204.5113999811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56152.58637264129
gradient descent iteration = 2
gd loss = 56152.58637264129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56102.46237009313
gradient descent iteration = 3
gd loss = 56102.46237009313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56053.94608898854
gradient descent iteration = 4
gd loss = 56053.94608898854
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 56006.88189819724
gradient descent iteration = 5
gd loss = 56006.88189819724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55961.14191815029
gradient descent iteration = 6
gd loss = 55961.14191815029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55916.61913800377
gradient descent iteration = 7
gd loss = 55916.61913800377
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55873.22258416084
gradient descent iteration = 8
gd loss = 55873.22258416084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55830.87386865827
gradient descent iteration = 9
gd loss = 55830.87386865827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55789.50474383872
gradient descent iteration = 10
gd loss = 55789.50474383872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55749.055065938
gradient descent iteration = 11
gd loss = 55749.055065938
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55709.47137028084
gradient descent iteration = 12
gd loss = 55709.47137028084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55670.70581058965
gradient descent iteration = 13
gd loss = 55670.70581058965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55632.71522292565
gradient descent iteration = 14
gd loss = 55632.71522292565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55595.46043421463
gradient descent iteration = 15
gd loss = 55595.46043421463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55558.90571405289
gradient descent iteration = 16
gd loss = 55558.90571405289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55523.01832429333
gradient descent iteration = 17
gd loss = 55523.01832429333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55487.76814666309
gradient descent iteration = 18
gd loss = 55487.76814666309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55453.12738298313
gradient descent iteration = 19
gd loss = 55453.12738298313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55419.07030216706
gradient descent iteration = 20
gd loss = 55419.07030216706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55385.5730071986
gradient descent iteration = 21
gd loss = 55385.5730071986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55352.6132492293
gradient descent iteration = 22
gd loss = 55352.6132492293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55320.1702674923
gradient descent iteration = 23
gd loss = 55320.1702674923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55288.22463848194
gradient descent iteration = 24
gd loss = 55288.22463848194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 55256.75818253282
Initial loss = 59508.88613979731
Final loss = 55256.75818253282
Deformation gradient control sequence optimization finished.
Animation interval 8 took 1420 seconds.
Full animation took 12216 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 9************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 54988.62554499359
initial norm = 835.4920687621587
convergence norm = 0.8354920687621588
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 54988.62554499359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54910.58167859122
gradient descent iteration = 1
gd loss = 54910.58167859122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54841.05423293617
gradient descent iteration = 2
gd loss = 54841.05423293617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54777.11708872164
gradient descent iteration = 3
gd loss = 54777.11708872164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54716.57052982564
gradient descent iteration = 4
gd loss = 54716.57052982564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54658.03055032962
gradient descent iteration = 5
gd loss = 54658.03055032962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54600.70740458729
gradient descent iteration = 6
gd loss = 54600.70740458729
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54544.16013092922
gradient descent iteration = 7
gd loss = 54544.16013092922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54488.13518501098
gradient descent iteration = 8
gd loss = 54488.13518501098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54432.4800642605
gradient descent iteration = 9
gd loss = 54432.4800642605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54377.09861371004
gradient descent iteration = 10
gd loss = 54377.09861371004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54321.92841388733
gradient descent iteration = 11
gd loss = 54321.92841388733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54266.9338414029
gradient descent iteration = 12
gd loss = 54266.9338414029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54212.09725796737
gradient descent iteration = 13
gd loss = 54212.09725796737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54157.41329517082
gradient descent iteration = 14
gd loss = 54157.41329517082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54102.89206390927
gradient descent iteration = 15
gd loss = 54102.89206390927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 54048.56020479224
gradient descent iteration = 16
gd loss = 54048.56020479224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53994.45047996139
gradient descent iteration = 17
gd loss = 53994.45047996139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53940.59241597063
gradient descent iteration = 18
gd loss = 53940.59241597063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53887.00385334577
gradient descent iteration = 19
gd loss = 53887.00385334577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53833.6954379375
gradient descent iteration = 20
gd loss = 53833.6954379375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53780.66416687877
gradient descent iteration = 21
gd loss = 53780.66416687877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53727.90130049016
gradient descent iteration = 22
gd loss = 53727.90130049016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53675.40529351529
gradient descent iteration = 23
gd loss = 53675.40529351529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53623.17725396504
gradient descent iteration = 24
gd loss = 53623.17725396504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53571.23201781835
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 53571.23201781835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53526.55734473706
gradient descent iteration = 1
gd loss = 53526.55734473706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53483.26396624815
gradient descent iteration = 2
gd loss = 53483.26396624815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53441.21366880119
gradient descent iteration = 3
gd loss = 53441.21366880119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53400.29649454685
gradient descent iteration = 4
gd loss = 53400.29649454685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53360.42280180436
gradient descent iteration = 5
gd loss = 53360.42280180436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53321.51775190764
gradient descent iteration = 6
gd loss = 53321.51775190764
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53283.51756737173
gradient descent iteration = 7
gd loss = 53283.51756737173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53246.36687342274
gradient descent iteration = 8
gd loss = 53246.36687342274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53210.01688176751
gradient descent iteration = 9
gd loss = 53210.01688176751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53174.42403750122
gradient descent iteration = 10
gd loss = 53174.42403750122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53139.54915804526
gradient descent iteration = 11
gd loss = 53139.54915804526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53105.35677276265
gradient descent iteration = 12
gd loss = 53105.35677276265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53071.81446216606
gradient descent iteration = 13
gd loss = 53071.81446216606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53038.89244174996
gradient descent iteration = 14
gd loss = 53038.89244174996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 53006.56320793704
gradient descent iteration = 15
gd loss = 53006.56320793704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52974.80122647678
gradient descent iteration = 16
gd loss = 52974.80122647678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52943.58273640624
gradient descent iteration = 17
gd loss = 52943.58273640624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52912.88552495387
gradient descent iteration = 18
gd loss = 52912.88552495387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52882.68869833226
gradient descent iteration = 19
gd loss = 52882.68869833226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52852.97258979017
gradient descent iteration = 20
gd loss = 52852.97258979017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52823.71871321052
gradient descent iteration = 21
gd loss = 52823.71871321052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52794.90964198553
gradient descent iteration = 22
gd loss = 52794.90964198553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52766.52888232589
gradient descent iteration = 23
gd loss = 52766.52888232589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52738.56084037875
gradient descent iteration = 24
gd loss = 52738.56084037875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52710.99082107623
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 52710.99082107623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52680.93856662875
gradient descent iteration = 1
gd loss = 52680.93856662875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52652.05247697279
gradient descent iteration = 2
gd loss = 52652.05247697279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52624.16243447563
gradient descent iteration = 3
gd loss = 52624.16243447563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52597.14294823226
gradient descent iteration = 4
gd loss = 52597.14294823226
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52570.89848390409
gradient descent iteration = 5
gd loss = 52570.89848390409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52545.35411062824
gradient descent iteration = 6
gd loss = 52545.35411062824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52520.44942102493
gradient descent iteration = 7
gd loss = 52520.44942102493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52496.13450964443
gradient descent iteration = 8
gd loss = 52496.13450964443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52472.36727374477
gradient descent iteration = 9
gd loss = 52472.36727374477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52449.11156060899
gradient descent iteration = 10
gd loss = 52449.11156060899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52426.33586049829
gradient descent iteration = 11
gd loss = 52426.33586049829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52404.0123684829
gradient descent iteration = 12
gd loss = 52404.0123684829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52382.11629516781
gradient descent iteration = 13
gd loss = 52382.11629516781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52360.62534994823
gradient descent iteration = 14
gd loss = 52360.62534994823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52339.51933755318
gradient descent iteration = 15
gd loss = 52339.51933755318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52318.77984641919
gradient descent iteration = 16
gd loss = 52318.77984641919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52298.39000602776
gradient descent iteration = 17
gd loss = 52298.39000602776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52278.33428705845
gradient descent iteration = 18
gd loss = 52278.33428705845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52258.59833767412
gradient descent iteration = 19
gd loss = 52258.59833767412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52239.16884705951
gradient descent iteration = 20
gd loss = 52239.16884705951
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52220.03343210852
gradient descent iteration = 21
gd loss = 52220.03343210852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52201.18054054792
gradient descent iteration = 22
gd loss = 52201.18054054792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52182.59937167941
gradient descent iteration = 23
gd loss = 52182.59937167941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52164.27980145449
gradient descent iteration = 24
gd loss = 52164.27980145449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 52146.21231615372
Initial loss = 54988.62554499359
Final loss = 52146.21231615372
Deformation gradient control sequence optimization finished.
Animation interval 9 took 1408 seconds.
Full animation took 13625 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 10************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 51551.12893066464
initial norm = 792.5046079156999
convergence norm = 0.7925046079157
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 51551.12893066464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51477.9516342024
gradient descent iteration = 1
gd loss = 51477.9516342024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51414.96529834519
gradient descent iteration = 2
gd loss = 51414.96529834519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51359.65617940225
gradient descent iteration = 3
gd loss = 51359.65617940225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51309.82399534164
gradient descent iteration = 4
gd loss = 51309.82399534164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51263.78057426838
gradient descent iteration = 5
gd loss = 51263.78057426838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51220.35961846753
gradient descent iteration = 6
gd loss = 51220.35961846753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51178.80798710038
gradient descent iteration = 7
gd loss = 51178.80798710038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51138.65293124393
gradient descent iteration = 8
gd loss = 51138.65293124393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51099.59528965525
gradient descent iteration = 9
gd loss = 51099.59528965525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51061.43871512518
gradient descent iteration = 10
gd loss = 51061.43871512518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 51024.04761130126
gradient descent iteration = 11
gd loss = 51024.04761130126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50987.32338071696
gradient descent iteration = 12
gd loss = 50987.32338071696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50951.19110541135
gradient descent iteration = 13
gd loss = 50951.19110541135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50915.59185156986
gradient descent iteration = 14
gd loss = 50915.59185156986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50880.47806012516
gradient descent iteration = 15
gd loss = 50880.47806012516
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50845.81065986046
gradient descent iteration = 16
gd loss = 50845.81065986046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50811.55706665113
gradient descent iteration = 17
gd loss = 50811.55706665113
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50777.68975796008
gradient descent iteration = 18
gd loss = 50777.68975796008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50744.18524090065
gradient descent iteration = 19
gd loss = 50744.18524090065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50711.02319895442
gradient descent iteration = 20
gd loss = 50711.02319895442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50678.18589598879
gradient descent iteration = 21
gd loss = 50678.18589598879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50645.6576957499
gradient descent iteration = 22
gd loss = 50645.6576957499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50613.42467969889
gradient descent iteration = 23
gd loss = 50613.42467969889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50581.4744152876
gradient descent iteration = 24
gd loss = 50581.4744152876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50549.79568085529
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 50549.79568085529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50516.80611069316
gradient descent iteration = 1
gd loss = 50516.80611069316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50485.18847929441
gradient descent iteration = 2
gd loss = 50485.18847929441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50454.74201672828
gradient descent iteration = 3
gd loss = 50454.74201672828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50425.31731648605
gradient descent iteration = 4
gd loss = 50425.31731648605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50396.79837250945
gradient descent iteration = 5
gd loss = 50396.79837250945
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50369.0922968473
gradient descent iteration = 6
gd loss = 50369.0922968473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50342.12292356054
gradient descent iteration = 7
gd loss = 50342.12292356054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50315.82658485165
gradient descent iteration = 8
gd loss = 50315.82658485165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50290.14924159311
gradient descent iteration = 9
gd loss = 50290.14924159311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50265.04446208329
gradient descent iteration = 10
gd loss = 50265.04446208329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50240.47196899898
gradient descent iteration = 11
gd loss = 50240.47196899898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50216.3964252665
gradient descent iteration = 12
gd loss = 50216.3964252665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50192.78654657835
gradient descent iteration = 13
gd loss = 50192.78654657835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50169.61442209389
gradient descent iteration = 14
gd loss = 50169.61442209389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50146.85497578727
gradient descent iteration = 15
gd loss = 50146.85497578727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50124.48556859108
gradient descent iteration = 16
gd loss = 50124.48556859108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50102.48570447687
gradient descent iteration = 17
gd loss = 50102.48570447687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50080.83664415293
gradient descent iteration = 18
gd loss = 50080.83664415293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50059.52115451284
gradient descent iteration = 19
gd loss = 50059.52115451284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50038.5233149887
gradient descent iteration = 20
gd loss = 50038.5233149887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 50017.82834971654
gradient descent iteration = 21
gd loss = 50017.82834971654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49997.42250330625
gradient descent iteration = 22
gd loss = 49997.42250330625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49977.29293156569
gradient descent iteration = 23
gd loss = 49977.29293156569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49957.42760308134
gradient descent iteration = 24
gd loss = 49957.42760308134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49937.81522041532
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 49937.81522041532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49915.36728776969
gradient descent iteration = 1
gd loss = 49915.36728776969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49893.74815675686
gradient descent iteration = 2
gd loss = 49893.74815675686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49872.79243474919
gradient descent iteration = 3
gd loss = 49872.79243474919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49852.39862323241
gradient descent iteration = 4
gd loss = 49852.39862323241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49832.49714331755
gradient descent iteration = 5
gd loss = 49832.49714331755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49813.0359795348
gradient descent iteration = 6
gd loss = 49813.0359795348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49793.97379701096
gradient descent iteration = 7
gd loss = 49793.97379701096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49775.27639366448
gradient descent iteration = 8
gd loss = 49775.27639366448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49756.9147100576
gradient descent iteration = 9
gd loss = 49756.9147100576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49738.86360780495
gradient descent iteration = 10
gd loss = 49738.86360780495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49721.10107038044
gradient descent iteration = 11
gd loss = 49721.10107038044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49703.607643829
gradient descent iteration = 12
gd loss = 49703.607643829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49686.36602147471
gradient descent iteration = 13
gd loss = 49686.36602147471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49669.36072745972
gradient descent iteration = 14
gd loss = 49669.36072745972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49652.57786908976
gradient descent iteration = 15
gd loss = 49652.57786908976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49636.00492305106
gradient descent iteration = 16
gd loss = 49636.00492305106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49619.63055137926
gradient descent iteration = 17
gd loss = 49619.63055137926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49603.44446421046
gradient descent iteration = 18
gd loss = 49603.44446421046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49587.43728300035
gradient descent iteration = 19
gd loss = 49587.43728300035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49571.60076059202
gradient descent iteration = 20
gd loss = 49571.60076059202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49555.92814984143
gradient descent iteration = 21
gd loss = 49555.92814984143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49540.41323576133
gradient descent iteration = 22
gd loss = 49540.41323576133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49525.05003481467
gradient descent iteration = 23
gd loss = 49525.05003481467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49509.83275303694
gradient descent iteration = 24
gd loss = 49509.83275303694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 49494.75573027731
Initial loss = 51551.12893066464
Final loss = 49494.75573027731
Deformation gradient control sequence optimization finished.
Animation interval 10 took 1398 seconds.
Full animation took 15023 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 11************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 48872.70918080446
initial norm = 677.3885058456361
convergence norm = 0.6773885058456361
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 48872.70918080446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48812.10353340298
gradient descent iteration = 1
gd loss = 48812.10353340298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48762.65266983452
gradient descent iteration = 2
gd loss = 48762.65266983452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48720.67570812397
gradient descent iteration = 3
gd loss = 48720.67570812397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48683.60737352683
gradient descent iteration = 4
gd loss = 48683.60737352683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48649.82499604339
gradient descent iteration = 5
gd loss = 48649.82499604339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48618.29297215402
gradient descent iteration = 6
gd loss = 48618.29297215402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48588.36724701117
gradient descent iteration = 7
gd loss = 48588.36724701117
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48559.64312765269
gradient descent iteration = 8
gd loss = 48559.64312765269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48531.8532382565
gradient descent iteration = 9
gd loss = 48531.8532382565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48504.81125700598
gradient descent iteration = 10
gd loss = 48504.81125700598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48478.38214314139
gradient descent iteration = 11
gd loss = 48478.38214314139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48452.46539975631
gradient descent iteration = 12
gd loss = 48452.46539975631
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48426.98482807492
gradient descent iteration = 13
gd loss = 48426.98482807492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48401.88172683574
gradient descent iteration = 14
gd loss = 48401.88172683574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48377.11014441544
gradient descent iteration = 15
gd loss = 48377.11014441544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48352.63348725209
gradient descent iteration = 16
gd loss = 48352.63348725209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48328.42207943583
gradient descent iteration = 17
gd loss = 48328.42207943583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48304.45139564664
gradient descent iteration = 18
gd loss = 48304.45139564664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48280.70077551886
gradient descent iteration = 19
gd loss = 48280.70077551886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48257.15249717003
gradient descent iteration = 20
gd loss = 48257.15249717003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48233.79110407432
gradient descent iteration = 21
gd loss = 48233.79110407432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48210.60290922991
gradient descent iteration = 22
gd loss = 48210.60290922991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48187.57563216566
gradient descent iteration = 23
gd loss = 48187.57563216566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48164.69812955203
gradient descent iteration = 24
gd loss = 48164.69812955203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48141.96020200785
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 48141.96020200785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48116.67324695005
gradient descent iteration = 1
gd loss = 48116.67324695005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48092.40904827353
gradient descent iteration = 2
gd loss = 48092.40904827353
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48068.92558224665
gradient descent iteration = 3
gd loss = 48068.92558224665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48046.0803751198
gradient descent iteration = 4
gd loss = 48046.0803751198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48023.77317497258
gradient descent iteration = 5
gd loss = 48023.77317497258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 48001.92851192546
gradient descent iteration = 6
gd loss = 48001.92851192546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47980.48717715625
gradient descent iteration = 7
gd loss = 47980.48717715625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47959.40131090487
gradient descent iteration = 8
gd loss = 47959.40131090487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47938.63124143087
gradient descent iteration = 9
gd loss = 47938.63124143087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47918.14342489462
gradient descent iteration = 10
gd loss = 47918.14342489462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47897.90905576711
gradient descent iteration = 11
gd loss = 47897.90905576711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47877.90310750176
gradient descent iteration = 12
gd loss = 47877.90310750176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47858.10372765733
gradient descent iteration = 13
gd loss = 47858.10372765733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47838.49175961865
gradient descent iteration = 14
gd loss = 47838.49175961865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47819.05038935136
gradient descent iteration = 15
gd loss = 47819.05038935136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47799.7649478868
gradient descent iteration = 16
gd loss = 47799.7649478868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47780.62269796873
gradient descent iteration = 17
gd loss = 47780.62269796873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47761.61202766778
gradient descent iteration = 18
gd loss = 47761.61202766778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47742.72230830651
gradient descent iteration = 19
gd loss = 47742.72230830651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47723.944508119
gradient descent iteration = 20
gd loss = 47723.944508119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47705.27067850989
gradient descent iteration = 21
gd loss = 47705.27067850989
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47686.69435357754
gradient descent iteration = 22
gd loss = 47686.69435357754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47668.21109084908
gradient descent iteration = 23
gd loss = 47668.21109084908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47649.81870350859
gradient descent iteration = 24
gd loss = 47649.81870350859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47631.51755862188
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 47631.51755862188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47609.33470127016
gradient descent iteration = 1
gd loss = 47609.33470127016
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47587.87806182959
gradient descent iteration = 2
gd loss = 47587.87806182959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47566.91493277511
gradient descent iteration = 3
gd loss = 47566.91493277511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47546.30879446053
gradient descent iteration = 4
gd loss = 47546.30879446053
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47525.96533504927
gradient descent iteration = 5
gd loss = 47525.96533504927
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47505.81235435736
gradient descent iteration = 6
gd loss = 47505.81235435736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47485.79062878464
gradient descent iteration = 7
gd loss = 47485.79062878464
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47465.84918169587
gradient descent iteration = 8
gd loss = 47465.84918169587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47445.94259109154
gradient descent iteration = 9
gd loss = 47445.94259109154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47426.02939142719
gradient descent iteration = 10
gd loss = 47426.02939142719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47406.07096589242
gradient descent iteration = 11
gd loss = 47406.07096589242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47386.03012165766
gradient descent iteration = 12
gd loss = 47386.03012165766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47365.87123265725
gradient descent iteration = 13
gd loss = 47365.87123265725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47345.56072769194
gradient descent iteration = 14
gd loss = 47345.56072769194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47325.06705607563
gradient descent iteration = 15
gd loss = 47325.06705607563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47304.36118599612
gradient descent iteration = 16
gd loss = 47304.36118599612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47283.41738723537
gradient descent iteration = 17
gd loss = 47283.41738723537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47262.21436046773
gradient descent iteration = 18
gd loss = 47262.21436046773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47240.73663266035
gradient descent iteration = 19
gd loss = 47240.73663266035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47218.9743431525
gradient descent iteration = 20
gd loss = 47218.9743431525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47196.9243627
gradient descent iteration = 21
gd loss = 47196.9243627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47174.59579231941
gradient descent iteration = 22
gd loss = 47174.59579231941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47152.01412822915
gradient descent iteration = 23
gd loss = 47152.01412822915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47129.22485539219
gradient descent iteration = 24
gd loss = 47129.22485539219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47106.28787935156
Initial loss = 48872.70918080446
Final loss = 47106.28787935156
Deformation gradient control sequence optimization finished.
Animation interval 11 took 1389 seconds.
Full animation took 16413 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 12************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 46689.96578212531
initial norm = 799.4903148417224
convergence norm = 0.7994903148417224
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 46689.96578212531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46620.3678303397
gradient descent iteration = 1
gd loss = 46620.3678303397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46568.29736946409
gradient descent iteration = 2
gd loss = 46568.29736946409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46527.95614096926
gradient descent iteration = 3
gd loss = 46527.95614096926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46493.80393729409
gradient descent iteration = 4
gd loss = 46493.80393729409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46463.11108969807
gradient descent iteration = 5
gd loss = 46463.11108969807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46434.76356469718
gradient descent iteration = 6
gd loss = 46434.76356469718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46408.11249884028
gradient descent iteration = 7
gd loss = 46408.11249884028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46382.70648872373
gradient descent iteration = 8
gd loss = 46382.70648872373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46358.22067400002
gradient descent iteration = 9
gd loss = 46358.22067400002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46334.42219352948
gradient descent iteration = 10
gd loss = 46334.42219352948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46311.14522989846
gradient descent iteration = 11
gd loss = 46311.14522989846
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46288.27188832394
gradient descent iteration = 12
gd loss = 46288.27188832394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46265.71855393997
gradient descent iteration = 13
gd loss = 46265.71855393997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46243.4251088002
gradient descent iteration = 14
gd loss = 46243.4251088002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46221.3470959486
gradient descent iteration = 15
gd loss = 46221.3470959486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46199.45123105101
gradient descent iteration = 16
gd loss = 46199.45123105101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46177.71238644474
gradient descent iteration = 17
gd loss = 46177.71238644474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46156.11135755031
gradient descent iteration = 18
gd loss = 46156.11135755031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46134.63353327547
gradient descent iteration = 19
gd loss = 46134.63353327547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46113.26803062487
gradient descent iteration = 20
gd loss = 46113.26803062487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46092.00692141787
gradient descent iteration = 21
gd loss = 46092.00692141787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46070.84460403228
gradient descent iteration = 22
gd loss = 46070.84460403228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46049.77768998611
gradient descent iteration = 23
gd loss = 46049.77768998611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46028.8049624956
gradient descent iteration = 24
gd loss = 46028.8049624956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46007.92724512215
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 46007.92724512215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45983.67581071384
gradient descent iteration = 1
gd loss = 45983.67581071384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45960.89405814514
gradient descent iteration = 2
gd loss = 45960.89405814514
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45939.12858178008
gradient descent iteration = 3
gd loss = 45939.12858178008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45918.15688073643
gradient descent iteration = 4
gd loss = 45918.15688073643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45897.83242399828
gradient descent iteration = 5
gd loss = 45897.83242399828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45878.04640746536
gradient descent iteration = 6
gd loss = 45878.04640746536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45858.71176011952
gradient descent iteration = 7
gd loss = 45858.71176011952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45839.75503162001
gradient descent iteration = 8
gd loss = 45839.75503162001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45821.11169144705
gradient descent iteration = 9
gd loss = 45821.11169144705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45802.72318873271
gradient descent iteration = 10
gd loss = 45802.72318873271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45784.53511884961
gradient descent iteration = 11
gd loss = 45784.53511884961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45766.49603819384
gradient descent iteration = 12
gd loss = 45766.49603819384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45748.55645103292
gradient descent iteration = 13
gd loss = 45748.55645103292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45730.66817412159
gradient descent iteration = 14
gd loss = 45730.66817412159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45712.78398045871
gradient descent iteration = 15
gd loss = 45712.78398045871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45694.85763813959
gradient descent iteration = 16
gd loss = 45694.85763813959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45676.84430944946
gradient descent iteration = 17
gd loss = 45676.84430944946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45658.70141026772
gradient descent iteration = 18
gd loss = 45658.70141026772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45640.38993502696
gradient descent iteration = 19
gd loss = 45640.38993502696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45621.87655952895
gradient descent iteration = 20
gd loss = 45621.87655952895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45603.13619012079
gradient descent iteration = 21
gd loss = 45603.13619012079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45584.1552218662
gradient descent iteration = 22
gd loss = 45584.1552218662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45564.93556850096
gradient descent iteration = 23
gd loss = 45564.93556850096
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45545.49717500004
gradient descent iteration = 24
gd loss = 45545.49717500004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45525.87414464517
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 45525.87414464517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45501.93681025256
gradient descent iteration = 1
gd loss = 45501.93681025256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45479.98385182292
gradient descent iteration = 2
gd loss = 45479.98385182292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45459.58892029308
gradient descent iteration = 3
gd loss = 45459.58892029308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45440.46289493662
gradient descent iteration = 4
gd loss = 45440.46289493662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45422.3831798128
gradient descent iteration = 5
gd loss = 45422.3831798128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45405.17188778144
gradient descent iteration = 6
gd loss = 45405.17188778144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45388.68489986182
gradient descent iteration = 7
gd loss = 45388.68489986182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45372.80399858574
gradient descent iteration = 8
gd loss = 45372.80399858574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45357.43100678948
gradient descent iteration = 9
gd loss = 45357.43100678948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45342.48527597746
gradient descent iteration = 10
gd loss = 45342.48527597746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45327.90068860092
gradient descent iteration = 11
gd loss = 45327.90068860092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45313.62224376108
gradient descent iteration = 12
gd loss = 45313.62224376108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45299.60480713887
gradient descent iteration = 13
gd loss = 45299.60480713887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45285.81162863259
gradient descent iteration = 14
gd loss = 45285.81162863259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45272.21315301222
gradient descent iteration = 15
gd loss = 45272.21315301222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45258.78644706328
gradient descent iteration = 16
gd loss = 45258.78644706328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45245.51368004761
gradient descent iteration = 17
gd loss = 45245.51368004761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45232.38138809406
gradient descent iteration = 18
gd loss = 45232.38138809406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45219.37981262636
gradient descent iteration = 19
gd loss = 45219.37981262636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45206.50228301052
gradient descent iteration = 20
gd loss = 45206.50228301052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45193.74458458504
gradient descent iteration = 21
gd loss = 45193.74458458504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45181.10410259521
gradient descent iteration = 22
gd loss = 45181.10410259521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45168.57950222576
gradient descent iteration = 23
gd loss = 45168.57950222576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45156.17059126704
gradient descent iteration = 24
gd loss = 45156.17059126704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45143.87785334106
Initial loss = 46689.96578212531
Final loss = 45143.87785334106
Deformation gradient control sequence optimization finished.
Animation interval 12 took 1395 seconds.
Full animation took 17808 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 13************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 44983.61804006317
initial norm = 1047.598245567257
convergence norm = 1.047598245567257
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 44983.61804006317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44885.4944250523
gradient descent iteration = 1
gd loss = 44885.4944250523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44803.38939497844
gradient descent iteration = 2
gd loss = 44803.38939497844
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44741.56955930407
gradient descent iteration = 3
gd loss = 44741.56955930407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44699.88434934311
gradient descent iteration = 4
gd loss = 44699.88434934311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44668.93294592867
gradient descent iteration = 5
gd loss = 44668.93294592867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44641.89277827213
gradient descent iteration = 6
gd loss = 44641.89277827213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44617.41426186686
gradient descent iteration = 7
gd loss = 44617.41426186686
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44594.84907988417
gradient descent iteration = 8
gd loss = 44594.84907988417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44573.71854060017
gradient descent iteration = 9
gd loss = 44573.71854060017
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44553.66164522499
gradient descent iteration = 10
gd loss = 44553.66164522499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44534.4163858459
gradient descent iteration = 11
gd loss = 44534.4163858459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44515.79902308583
gradient descent iteration = 12
gd loss = 44515.79902308583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44497.69181121467
gradient descent iteration = 13
gd loss = 44497.69181121467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44480.02890995213
gradient descent iteration = 14
gd loss = 44480.02890995213
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44462.81847695405
gradient descent iteration = 15
gd loss = 44462.81847695405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44446.18603873646
gradient descent iteration = 16
gd loss = 44446.18603873646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44430.51761549328
gradient descent iteration = 17
gd loss = 44430.51761549328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44416.43388900089
gradient descent iteration = 18
gd loss = 44416.43388900089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44404.02625305824
gradient descent iteration = 19
gd loss = 44404.02625305824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44392.45266487208
gradient descent iteration = 20
gd loss = 44392.45266487208
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44381.11953043894
gradient descent iteration = 21
gd loss = 44381.11953043894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44370.0544822972
gradient descent iteration = 22
gd loss = 44370.0544822972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44359.14480061366
gradient descent iteration = 23
gd loss = 44359.14480061366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44348.47850102392
gradient descent iteration = 24
gd loss = 44348.47850102392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44337.94068648024
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 44337.94068648024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44313.0997886293
gradient descent iteration = 1
gd loss = 44313.0997886293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44292.59601135924
gradient descent iteration = 2
gd loss = 44292.59601135924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44273.03226204131
gradient descent iteration = 3
gd loss = 44273.03226204131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44254.01800327291
gradient descent iteration = 4
gd loss = 44254.01800327291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44235.43183987607
gradient descent iteration = 5
gd loss = 44235.43183987607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44217.21254232832
gradient descent iteration = 6
gd loss = 44217.21254232832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44199.32927625421
gradient descent iteration = 7
gd loss = 44199.32927625421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44181.77187965898
gradient descent iteration = 8
gd loss = 44181.77187965898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44164.54474322133
gradient descent iteration = 9
gd loss = 44164.54474322133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44147.65948619389
gradient descent iteration = 10
gd loss = 44147.65948619389
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44131.1286788224
gradient descent iteration = 11
gd loss = 44131.1286788224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44114.96399225811
gradient descent iteration = 12
gd loss = 44114.96399225811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44099.17499817766
gradient descent iteration = 13
gd loss = 44099.17499817766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44083.7678483812
gradient descent iteration = 14
gd loss = 44083.7678483812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44068.74602564051
gradient descent iteration = 15
gd loss = 44068.74602564051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44054.11003056543
gradient descent iteration = 16
gd loss = 44054.11003056543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44039.85705199899
gradient descent iteration = 17
gd loss = 44039.85705199899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44025.98149243545
gradient descent iteration = 18
gd loss = 44025.98149243545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44012.47518439275
gradient descent iteration = 19
gd loss = 44012.47518439275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43999.32713818482
gradient descent iteration = 20
gd loss = 43999.32713818482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43986.52541480958
gradient descent iteration = 21
gd loss = 43986.52541480958
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43974.05746338462
gradient descent iteration = 22
gd loss = 43974.05746338462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43961.91132311882
gradient descent iteration = 23
gd loss = 43961.91132311882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43950.07597190602
gradient descent iteration = 24
gd loss = 43950.07597190602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43938.54099329277
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 43938.54099329277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43925.78976426831
gradient descent iteration = 1
gd loss = 43925.78976426831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43913.69214948257
gradient descent iteration = 2
gd loss = 43913.69214948257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43902.09336830866
gradient descent iteration = 3
gd loss = 43902.09336830866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43890.91338308095
gradient descent iteration = 4
gd loss = 43890.91338308095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43880.10202637954
gradient descent iteration = 5
gd loss = 43880.10202637954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43869.62361426823
gradient descent iteration = 6
gd loss = 43869.62361426823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43859.45073098128
gradient descent iteration = 7
gd loss = 43859.45073098128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43849.56113170551
gradient descent iteration = 8
gd loss = 43849.56113170551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43839.93594048201
gradient descent iteration = 9
gd loss = 43839.93594048201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43830.5585641768
gradient descent iteration = 10
gd loss = 43830.5585641768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43821.4139896687
gradient descent iteration = 11
gd loss = 43821.4139896687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43812.48833763343
gradient descent iteration = 12
gd loss = 43812.48833763343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43803.76860690497
gradient descent iteration = 13
gd loss = 43803.76860690497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43795.24253194223
gradient descent iteration = 14
gd loss = 43795.24253194223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43786.89850939251
gradient descent iteration = 15
gd loss = 43786.89850939251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43778.7255736022
gradient descent iteration = 16
gd loss = 43778.7255736022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43770.71339148657
gradient descent iteration = 17
gd loss = 43770.71339148657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43762.85226334547
gradient descent iteration = 18
gd loss = 43762.85226334547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43755.13309455724
gradient descent iteration = 19
gd loss = 43755.13309455724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43747.54743129339
gradient descent iteration = 20
gd loss = 43747.54743129339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43740.08752104959
gradient descent iteration = 21
gd loss = 43740.08752104959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43732.74608242327
gradient descent iteration = 22
gd loss = 43732.74608242327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43725.51631827627
gradient descent iteration = 23
gd loss = 43725.51631827627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43718.39189981855
gradient descent iteration = 24
gd loss = 43718.39189981855
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43711.36691410329
Initial loss = 44983.61804006317
Final loss = 43711.36691410329
Deformation gradient control sequence optimization finished.
Animation interval 13 took 1387 seconds.
Full animation took 19196 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 14************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 43628.24096042
initial norm = 786.8967891568341
convergence norm = 0.7868967891568341
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 43628.24096042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43561.03300132739
gradient descent iteration = 1
gd loss = 43561.03300132739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43513.42316848782
gradient descent iteration = 2
gd loss = 43513.42316848782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43478.80545415411
gradient descent iteration = 3
gd loss = 43478.80545415411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43450.47538180342
gradient descent iteration = 4
gd loss = 43450.47538180342
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43425.72409628231
gradient descent iteration = 5
gd loss = 43425.72409628231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43403.55458206118
gradient descent iteration = 6
gd loss = 43403.55458206118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43383.23418433896
gradient descent iteration = 7
gd loss = 43383.23418433896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43364.19393017259
gradient descent iteration = 8
gd loss = 43364.19393017259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43346.02865402125
gradient descent iteration = 9
gd loss = 43346.02865402125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43328.47581659685
gradient descent iteration = 10
gd loss = 43328.47581659685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43311.3747242263
gradient descent iteration = 11
gd loss = 43311.3747242263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43294.62964952194
gradient descent iteration = 12
gd loss = 43294.62964952194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43278.18386629404
gradient descent iteration = 13
gd loss = 43278.18386629404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43262.00317388219
gradient descent iteration = 14
gd loss = 43262.00317388219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43246.0657727897
gradient descent iteration = 15
gd loss = 43246.0657727897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43230.35599042644
gradient descent iteration = 16
gd loss = 43230.35599042644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43214.86032760999
gradient descent iteration = 17
gd loss = 43214.86032760999
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43199.56492755112
gradient descent iteration = 18
gd loss = 43199.56492755112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43184.45400184575
gradient descent iteration = 19
gd loss = 43184.45400184575
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43169.50883432617
gradient descent iteration = 20
gd loss = 43169.50883432617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43154.70704859473
gradient descent iteration = 21
gd loss = 43154.70704859473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43140.02189878865
gradient descent iteration = 22
gd loss = 43140.02189878865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43125.42181239898
gradient descent iteration = 23
gd loss = 43125.42181239898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43110.86993026701
gradient descent iteration = 24
gd loss = 43110.86993026701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43096.32797459718
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 43096.32797459718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43065.04189301372
gradient descent iteration = 1
gd loss = 43065.04189301372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43038.03965468203
gradient descent iteration = 2
gd loss = 43038.03965468203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43014.29763489091
gradient descent iteration = 3
gd loss = 43014.29763489091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42993.28577211699
gradient descent iteration = 4
gd loss = 42993.28577211699
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42974.3872067976
gradient descent iteration = 5
gd loss = 42974.3872067976
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42957.07418130329
gradient descent iteration = 6
gd loss = 42957.07418130329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42940.95408225952
gradient descent iteration = 7
gd loss = 42940.95408225952
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42925.7451928364
gradient descent iteration = 8
gd loss = 42925.7451928364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42911.24843370907
gradient descent iteration = 9
gd loss = 42911.24843370907
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42897.32462673754
gradient descent iteration = 10
gd loss = 42897.32462673754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42883.87658581694
gradient descent iteration = 11
gd loss = 42883.87658581694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42870.8357680898
gradient descent iteration = 12
gd loss = 42870.8357680898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42858.15301848912
gradient descent iteration = 13
gd loss = 42858.15301848912
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42845.79183581352
gradient descent iteration = 14
gd loss = 42845.79183581352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42833.72394666902
gradient descent iteration = 15
gd loss = 42833.72394666902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42821.9266090608
gradient descent iteration = 16
gd loss = 42821.9266090608
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42810.38083287246
gradient descent iteration = 17
gd loss = 42810.38083287246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42799.07028274161
gradient descent iteration = 18
gd loss = 42799.07028274161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42787.98057623239
gradient descent iteration = 19
gd loss = 42787.98057623239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42777.09891480667
gradient descent iteration = 20
gd loss = 42777.09891480667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42766.41438305905
gradient descent iteration = 21
gd loss = 42766.41438305905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42755.91744472121
gradient descent iteration = 22
gd loss = 42755.91744472121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42745.59898682706
gradient descent iteration = 23
gd loss = 42745.59898682706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42735.45036356158
gradient descent iteration = 24
gd loss = 42735.45036356158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42725.46349575384
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 42725.46349575384
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42712.45003714056
gradient descent iteration = 1
gd loss = 42712.45003714056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42700.43773710747
gradient descent iteration = 2
gd loss = 42700.43773710747
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42689.06998501829
gradient descent iteration = 3
gd loss = 42689.06998501829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42678.20398538296
gradient descent iteration = 4
gd loss = 42678.20398538296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42667.74747598343
gradient descent iteration = 5
gd loss = 42667.74747598343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42657.6337862413
gradient descent iteration = 6
gd loss = 42657.6337862413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42647.81307956466
gradient descent iteration = 7
gd loss = 42647.81307956466
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42638.24747087288
gradient descent iteration = 8
gd loss = 42638.24747087288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42628.90776955965
gradient descent iteration = 9
gd loss = 42628.90776955965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42619.77143356168
gradient descent iteration = 10
gd loss = 42619.77143356168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42610.82088285178
gradient descent iteration = 11
gd loss = 42610.82088285178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42602.04230484465
gradient descent iteration = 12
gd loss = 42602.04230484465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42593.42484039006
gradient descent iteration = 13
gd loss = 42593.42484039006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42584.95980740678
gradient descent iteration = 14
gd loss = 42584.95980740678
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42576.64016614878
gradient descent iteration = 15
gd loss = 42576.64016614878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42568.46015029812
gradient descent iteration = 16
gd loss = 42568.46015029812
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42560.41487618086
gradient descent iteration = 17
gd loss = 42560.41487618086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42552.5000906257
gradient descent iteration = 18
gd loss = 42552.5000906257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42544.71194716079
gradient descent iteration = 19
gd loss = 42544.71194716079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42537.04683580789
gradient descent iteration = 20
gd loss = 42537.04683580789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42529.5012647487
gradient descent iteration = 21
gd loss = 42529.5012647487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42522.07178439566
gradient descent iteration = 22
gd loss = 42522.07178439566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42514.75494204452
gradient descent iteration = 23
gd loss = 42514.75494204452
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42507.54724337348
gradient descent iteration = 24
gd loss = 42507.54724337348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42500.44516065542
Initial loss = 43628.24096042
Final loss = 42500.44516065542
Deformation gradient control sequence optimization finished.
Animation interval 14 took 1394 seconds.
Full animation took 20590 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 15************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 42481.35217773341
initial norm = 565.9738503486176
convergence norm = 0.5659738503486176
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 42481.35217773341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42433.63967504364
gradient descent iteration = 1
gd loss = 42433.63967504364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42399.62813958896
gradient descent iteration = 2
gd loss = 42399.62813958896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42372.98057374348
gradient descent iteration = 3
gd loss = 42372.98057374348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42349.96479917054
gradient descent iteration = 4
gd loss = 42349.96479917054
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42329.41952300413
gradient descent iteration = 5
gd loss = 42329.41952300413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42310.67450427145
gradient descent iteration = 6
gd loss = 42310.67450427145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42293.20525464267
gradient descent iteration = 7
gd loss = 42293.20525464267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42276.62484383744
gradient descent iteration = 8
gd loss = 42276.62484383744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42260.66911417763
gradient descent iteration = 9
gd loss = 42260.66911417763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42245.16649294824
gradient descent iteration = 10
gd loss = 42245.16649294824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42230.00885203419
gradient descent iteration = 11
gd loss = 42230.00885203419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42215.12950277379
gradient descent iteration = 12
gd loss = 42215.12950277379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42200.48952797216
gradient descent iteration = 13
gd loss = 42200.48952797216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42186.06958054451
gradient descent iteration = 14
gd loss = 42186.06958054451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42171.86526315055
gradient descent iteration = 15
gd loss = 42171.86526315055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42157.88284905924
gradient descent iteration = 16
gd loss = 42157.88284905924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42144.13606414654
gradient descent iteration = 17
gd loss = 42144.13606414654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42130.64112929632
gradient descent iteration = 18
gd loss = 42130.64112929632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42117.41290040313
gradient descent iteration = 19
gd loss = 42117.41290040313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42104.45973890074
gradient descent iteration = 20
gd loss = 42104.45973890074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42091.78548788092
gradient descent iteration = 21
gd loss = 42091.78548788092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42079.39390254755
gradient descent iteration = 22
gd loss = 42079.39390254755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42067.32456052834
gradient descent iteration = 23
gd loss = 42067.32456052834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42055.7342438928
gradient descent iteration = 24
gd loss = 42055.7342438928
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42045.1100275817
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 42045.1100275817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42030.16174291896
gradient descent iteration = 1
gd loss = 42030.16174291896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42017.77986299508
gradient descent iteration = 2
gd loss = 42017.77986299508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42006.50108669217
gradient descent iteration = 3
gd loss = 42006.50108669217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41995.9271304962
gradient descent iteration = 4
gd loss = 41995.9271304962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41985.86562993941
gradient descent iteration = 5
gd loss = 41985.86562993941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41976.21374537439
gradient descent iteration = 6
gd loss = 41976.21374537439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41966.9022173652
gradient descent iteration = 7
gd loss = 41966.9022173652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41957.88778554216
gradient descent iteration = 8
gd loss = 41957.88778554216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41949.13549603771
gradient descent iteration = 9
gd loss = 41949.13549603771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41940.62156374204
gradient descent iteration = 10
gd loss = 41940.62156374204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41932.32440989656
gradient descent iteration = 11
gd loss = 41932.32440989656
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41924.22848887455
gradient descent iteration = 12
gd loss = 41924.22848887455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41916.31873045831
gradient descent iteration = 13
gd loss = 41916.31873045831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41908.58376435981
gradient descent iteration = 14
gd loss = 41908.58376435981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41901.01214007436
gradient descent iteration = 15
gd loss = 41901.01214007436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41893.59491918337
gradient descent iteration = 16
gd loss = 41893.59491918337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41886.32300877402
gradient descent iteration = 17
gd loss = 41886.32300877402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41879.18909243547
gradient descent iteration = 18
gd loss = 41879.18909243547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41872.18568943037
gradient descent iteration = 19
gd loss = 41872.18568943037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41865.30657990887
gradient descent iteration = 20
gd loss = 41865.30657990887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41858.54540748092
gradient descent iteration = 21
gd loss = 41858.54540748092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41851.89678350511
gradient descent iteration = 22
gd loss = 41851.89678350511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41845.35524259344
gradient descent iteration = 23
gd loss = 41845.35524259344
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41838.91606398184
gradient descent iteration = 24
gd loss = 41838.91606398184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41832.57448486335
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 41832.57448486335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41822.50726548841
gradient descent iteration = 1
gd loss = 41822.50726548841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41813.49919461909
gradient descent iteration = 2
gd loss = 41813.49919461909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41805.19751723674
gradient descent iteration = 3
gd loss = 41805.19751723674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41797.43302817101
gradient descent iteration = 4
gd loss = 41797.43302817101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41790.09310338802
gradient descent iteration = 5
gd loss = 41790.09310338802
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41783.09807608459
gradient descent iteration = 6
gd loss = 41783.09807608459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41776.38964968162
gradient descent iteration = 7
gd loss = 41776.38964968162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41769.92392841004
gradient descent iteration = 8
gd loss = 41769.92392841004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41763.66709220177
gradient descent iteration = 9
gd loss = 41763.66709220177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41757.59266900523
gradient descent iteration = 10
gd loss = 41757.59266900523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41751.67956202555
gradient descent iteration = 11
gd loss = 41751.67956202555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41745.91068405316
gradient descent iteration = 12
gd loss = 41745.91068405316
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41740.27199603577
gradient descent iteration = 13
gd loss = 41740.27199603577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41734.75182032072
gradient descent iteration = 14
gd loss = 41734.75182032072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41729.34032374502
gradient descent iteration = 15
gd loss = 41729.34032374502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41724.02912524671
gradient descent iteration = 16
gd loss = 41724.02912524671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41718.81099168774
gradient descent iteration = 17
gd loss = 41718.81099168774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41713.67962384202
gradient descent iteration = 18
gd loss = 41713.67962384202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41708.62949812383
gradient descent iteration = 19
gd loss = 41708.62949812383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41703.65573345627
gradient descent iteration = 20
gd loss = 41703.65573345627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41698.75398453294
gradient descent iteration = 21
gd loss = 41698.75398453294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41693.92035416437
gradient descent iteration = 22
gd loss = 41693.92035416437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41689.15132156605
gradient descent iteration = 23
gd loss = 41689.15132156605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41684.44369101518
gradient descent iteration = 24
gd loss = 41684.44369101518
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41679.79454626267
Initial loss = 42481.35217773341
Final loss = 41679.79454626267
Deformation gradient control sequence optimization finished.
Animation interval 15 took 1388 seconds.
Full animation took 21979 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 16************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41697.00380174368
initial norm = 500.1316906347017
convergence norm = 0.5001316906347016
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41697.00380174368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41655.73747319835
gradient descent iteration = 1
gd loss = 41655.73747319835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41625.79230499065
gradient descent iteration = 2
gd loss = 41625.79230499065
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41601.48720134929
gradient descent iteration = 3
gd loss = 41601.48720134929
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41581.22275263487
gradient descent iteration = 4
gd loss = 41581.22275263487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41564.09879495249
gradient descent iteration = 5
gd loss = 41564.09879495249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41549.27797905121
gradient descent iteration = 6
gd loss = 41549.27797905121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41536.03757295103
gradient descent iteration = 7
gd loss = 41536.03757295103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41523.82560012129
gradient descent iteration = 8
gd loss = 41523.82560012129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41512.28056830615
gradient descent iteration = 9
gd loss = 41512.28056830615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41501.19457097995
gradient descent iteration = 10
gd loss = 41501.19457097995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41490.45657513299
gradient descent iteration = 11
gd loss = 41490.45657513299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41480.02231859486
gradient descent iteration = 12
gd loss = 41480.02231859486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41469.99229480312
gradient descent iteration = 13
gd loss = 41469.99229480312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41461.07142503429
gradient descent iteration = 14
gd loss = 41461.07142503429
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41455.08363734878
gradient descent iteration = 15
gd loss = 41455.08363734878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41449.90701957527
gradient descent iteration = 16
gd loss = 41449.90701957527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41444.5218001739
gradient descent iteration = 17
gd loss = 41444.5218001739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41439.32495059732
gradient descent iteration = 18
gd loss = 41439.32495059732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41434.20032729779
gradient descent iteration = 19
gd loss = 41434.20032729779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41429.1341445212
gradient descent iteration = 20
gd loss = 41429.1341445212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41424.17837813154
gradient descent iteration = 21
gd loss = 41424.17837813154
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41419.25164960367
gradient descent iteration = 22
gd loss = 41419.25164960367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41414.43650417151
gradient descent iteration = 23
gd loss = 41414.43650417151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41409.63850195372
gradient descent iteration = 24
gd loss = 41409.63850195372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41404.9477588275
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 41404.9477588275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41396.94055801808
gradient descent iteration = 1
gd loss = 41396.94055801808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41391.35758972393
gradient descent iteration = 2
gd loss = 41391.35758972393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41386.27568025663
gradient descent iteration = 3
gd loss = 41386.27568025663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41381.44478384823
gradient descent iteration = 4
gd loss = 41381.44478384823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41376.7960021868
gradient descent iteration = 5
gd loss = 41376.7960021868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41372.29534245646
gradient descent iteration = 6
gd loss = 41372.29534245646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41367.92019080109
gradient descent iteration = 7
gd loss = 41367.92019080109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41363.65404671977
gradient descent iteration = 8
gd loss = 41363.65404671977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41359.48417093658
gradient descent iteration = 9
gd loss = 41359.48417093658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41355.40042622058
gradient descent iteration = 10
gd loss = 41355.40042622058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41351.39453596292
gradient descent iteration = 11
gd loss = 41351.39453596292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41347.45961423645
gradient descent iteration = 12
gd loss = 41347.45961423645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41343.58983210328
gradient descent iteration = 13
gd loss = 41343.58983210328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41339.78018075603
gradient descent iteration = 14
gd loss = 41339.78018075603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41336.02630001304
gradient descent iteration = 15
gd loss = 41336.02630001304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41332.32435007664
gradient descent iteration = 16
gd loss = 41332.32435007664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41328.67091402882
gradient descent iteration = 17
gd loss = 41328.67091402882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41325.06292117487
gradient descent iteration = 18
gd loss = 41325.06292117487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41321.49758597944
gradient descent iteration = 19
gd loss = 41321.49758597944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41317.9723590406
gradient descent iteration = 20
gd loss = 41317.9723590406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41314.48488707727
gradient descent iteration = 21
gd loss = 41314.48488707727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41311.03297934974
gradient descent iteration = 22
gd loss = 41311.03297934974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41307.61457993689
gradient descent iteration = 23
gd loss = 41307.61457993689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41304.22774424373
gradient descent iteration = 24
gd loss = 41304.22774424373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41300.87061669039
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 41300.87061669039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41295.13517841633
gradient descent iteration = 1
gd loss = 41295.13517841633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41289.81358297045
gradient descent iteration = 2
gd loss = 41289.81358297045
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41284.81366340902
gradient descent iteration = 3
gd loss = 41284.81366340902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41280.08504944562
gradient descent iteration = 4
gd loss = 41280.08504944562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41275.59044338283
gradient descent iteration = 5
gd loss = 41275.59044338283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41271.29946479024
gradient descent iteration = 6
gd loss = 41271.29946479024
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41267.18664935746
gradient descent iteration = 7
gd loss = 41267.18664935746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41263.23043409114
gradient descent iteration = 8
gd loss = 41263.23043409114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41259.41246450376
gradient descent iteration = 9
gd loss = 41259.41246450376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41255.71707083355
gradient descent iteration = 10
gd loss = 41255.71707083355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41252.13084775249
gradient descent iteration = 11
gd loss = 41252.13084775249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41248.64229587665
gradient descent iteration = 12
gd loss = 41248.64229587665
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41245.24152255469
gradient descent iteration = 13
gd loss = 41245.24152255469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41241.9199908372
gradient descent iteration = 14
gd loss = 41241.9199908372
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41238.67030896481
gradient descent iteration = 15
gd loss = 41238.67030896481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41235.48605435795
gradient descent iteration = 16
gd loss = 41235.48605435795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41232.36162581202
gradient descent iteration = 17
gd loss = 41232.36162581202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41229.29211994242
gradient descent iteration = 18
gd loss = 41229.29211994242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41226.27322762267
gradient descent iteration = 19
gd loss = 41226.27322762267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41223.30114704034
gradient descent iteration = 20
gd loss = 41223.30114704034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41220.37251070081
gradient descent iteration = 21
gd loss = 41220.37251070081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41217.48432381479
gradient descent iteration = 22
gd loss = 41217.48432381479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41214.63391222269
gradient descent iteration = 23
gd loss = 41214.63391222269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41211.81887926158
gradient descent iteration = 24
gd loss = 41211.81887926158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41209.03706882343
Initial loss = 41697.00380174368
Final loss = 41209.03706882343
Deformation gradient control sequence optimization finished.
Animation interval 16 took 1388 seconds.
Full animation took 23367 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 17************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41375.01434154816
initial norm = 570.9205572308151
convergence norm = 0.5709205572308151
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41375.01434154816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41329.43417881673
gradient descent iteration = 1
gd loss = 41329.43417881673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41300.09364423675
gradient descent iteration = 2
gd loss = 41300.09364423675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41276.53384568731
gradient descent iteration = 3
gd loss = 41276.53384568731
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41256.36742392535
gradient descent iteration = 4
gd loss = 41256.36742392535
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41238.84405547049
gradient descent iteration = 5
gd loss = 41238.84405547049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41223.33070486553
gradient descent iteration = 6
gd loss = 41223.33070486553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41209.29539177823
gradient descent iteration = 7
gd loss = 41209.29539177823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41196.33175982142
gradient descent iteration = 8
gd loss = 41196.33175982142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41184.15419815336
gradient descent iteration = 9
gd loss = 41184.15419815336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41172.57537819837
gradient descent iteration = 10
gd loss = 41172.57537819837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41161.47902866672
gradient descent iteration = 11
gd loss = 41161.47902866672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41150.84206754433
gradient descent iteration = 12
gd loss = 41150.84206754433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41140.87185628176
gradient descent iteration = 13
gd loss = 41140.87185628176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41132.56564612667
gradient descent iteration = 14
gd loss = 41132.56564612667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41126.85134849868
gradient descent iteration = 15
gd loss = 41126.85134849868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41121.37011056593
gradient descent iteration = 16
gd loss = 41121.37011056593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41116.04583127247
gradient descent iteration = 17
gd loss = 41116.04583127247
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41110.93290998499
gradient descent iteration = 18
gd loss = 41110.93290998499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41105.89501192798
gradient descent iteration = 19
gd loss = 41105.89501192798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41101.01858449617
gradient descent iteration = 20
gd loss = 41101.01858449617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41096.18679382841
gradient descent iteration = 21
gd loss = 41096.18679382841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41091.48813305858
gradient descent iteration = 22
gd loss = 41091.48813305858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41086.8197017475
gradient descent iteration = 23
gd loss = 41086.8197017475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41082.26635085251
gradient descent iteration = 24
gd loss = 41082.26635085251
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41077.73275538329
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 41077.73275538329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41068.13771084559
gradient descent iteration = 1
gd loss = 41068.13771084559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41062.33327313853
gradient descent iteration = 2
gd loss = 41062.33327313853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41057.20444647272
gradient descent iteration = 3
gd loss = 41057.20444647272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41052.37032028616
gradient descent iteration = 4
gd loss = 41052.37032028616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41047.74037956947
gradient descent iteration = 5
gd loss = 41047.74037956947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41043.2726633068
gradient descent iteration = 6
gd loss = 41043.2726633068
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41038.940598122
gradient descent iteration = 7
gd loss = 41038.940598122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41034.72476679661
gradient descent iteration = 8
gd loss = 41034.72476679661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41030.61020953562
gradient descent iteration = 9
gd loss = 41030.61020953562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41026.58495791881
gradient descent iteration = 10
gd loss = 41026.58495791881
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41022.63922723106
gradient descent iteration = 11
gd loss = 41022.63922723106
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41018.76487956987
gradient descent iteration = 12
gd loss = 41018.76487956987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41014.95506537565
gradient descent iteration = 13
gd loss = 41014.95506537565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41011.20396196432
gradient descent iteration = 14
gd loss = 41011.20396196432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41007.50658584692
gradient descent iteration = 15
gd loss = 41007.50658584692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41003.85864775564
gradient descent iteration = 16
gd loss = 41003.85864775564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41000.25644102825
gradient descent iteration = 17
gd loss = 41000.25644102825
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40996.69677766576
gradient descent iteration = 18
gd loss = 40996.69677766576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40993.17693148554
gradient descent iteration = 19
gd loss = 40993.17693148554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40989.69458454047
gradient descent iteration = 20
gd loss = 40989.69458454047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40986.2477860714
gradient descent iteration = 21
gd loss = 40986.2477860714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40982.83491826427
gradient descent iteration = 22
gd loss = 40982.83491826427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40979.45466703671
gradient descent iteration = 23
gd loss = 40979.45466703671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40976.10599473847
gradient descent iteration = 24
gd loss = 40976.10599473847
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40972.78811493547
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40972.78811493547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40968.27452380711
gradient descent iteration = 1
gd loss = 40968.27452380711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40964.08773413199
gradient descent iteration = 2
gd loss = 40964.08773413199
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40960.12798732169
gradient descent iteration = 3
gd loss = 40960.12798732169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40956.34829063067
gradient descent iteration = 4
gd loss = 40956.34829063067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40952.7182215515
gradient descent iteration = 5
gd loss = 40952.7182215515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40949.2153114901
gradient descent iteration = 6
gd loss = 40949.2153114901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40945.82209776201
gradient descent iteration = 7
gd loss = 40945.82209776201
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40942.52467543629
gradient descent iteration = 8
gd loss = 40942.52467543629
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40939.31179996674
gradient descent iteration = 9
gd loss = 40939.31179996674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40936.17426839841
gradient descent iteration = 10
gd loss = 40936.17426839841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40933.10447021784
gradient descent iteration = 11
gd loss = 40933.10447021784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40930.09605323432
gradient descent iteration = 12
gd loss = 40930.09605323432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40927.14366961828
gradient descent iteration = 13
gd loss = 40927.14366961828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40924.24277889204
gradient descent iteration = 14
gd loss = 40924.24277889204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40921.38949484796
gradient descent iteration = 15
gd loss = 40921.38949484796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40918.58046502973
gradient descent iteration = 16
gd loss = 40918.58046502973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40915.81277604506
gradient descent iteration = 17
gd loss = 40915.81277604506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40913.08387683013
gradient descent iteration = 18
gd loss = 40913.08387683013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40910.39151748097
gradient descent iteration = 19
gd loss = 40910.39151748097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40907.73369966179
gradient descent iteration = 20
gd loss = 40907.73369966179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40905.10863621145
gradient descent iteration = 21
gd loss = 40905.10863621145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40902.51471808278
gradient descent iteration = 22
gd loss = 40902.51471808278
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40899.95049155003
gradient descent iteration = 23
gd loss = 40899.95049155003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40897.41470487499
gradient descent iteration = 24
gd loss = 40897.41470487499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40894.90630915135
Initial loss = 41375.01434154816
Final loss = 40894.90630915135
Deformation gradient control sequence optimization finished.
Animation interval 17 took 1387 seconds.
Full animation took 24754 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 18************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41130.09953923792
initial norm = 491.8052403396193
convergence norm = 0.4918052403396193
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41130.09953923792
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41092.42827719598
gradient descent iteration = 1
gd loss = 41092.42827719598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41066.93555288926
gradient descent iteration = 2
gd loss = 41066.93555288926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41045.88038620438
gradient descent iteration = 3
gd loss = 41045.88038620438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41028.25873905592
gradient descent iteration = 4
gd loss = 41028.25873905592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41013.16110872923
gradient descent iteration = 5
gd loss = 41013.16110872923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40999.77734504037
gradient descent iteration = 6
gd loss = 40999.77734504037
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40987.62573651886
gradient descent iteration = 7
gd loss = 40987.62573651886
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40976.91308875532
gradient descent iteration = 8
gd loss = 40976.91308875532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40968.57793440268
gradient descent iteration = 9
gd loss = 40968.57793440268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40961.31769172467
gradient descent iteration = 10
gd loss = 40961.31769172467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40953.51903114966
gradient descent iteration = 11
gd loss = 40953.51903114966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40945.24410074807
gradient descent iteration = 12
gd loss = 40945.24410074807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40936.72357414788
gradient descent iteration = 13
gd loss = 40936.72357414788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40928.40056882465
gradient descent iteration = 14
gd loss = 40928.40056882465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40920.6343298104
gradient descent iteration = 15
gd loss = 40920.6343298104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40913.49641013511
gradient descent iteration = 16
gd loss = 40913.49641013511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40906.95365286827
gradient descent iteration = 17
gd loss = 40906.95365286827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40900.88511801424
gradient descent iteration = 18
gd loss = 40900.88511801424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40895.23076881129
gradient descent iteration = 19
gd loss = 40895.23076881129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40889.89460716031
gradient descent iteration = 20
gd loss = 40889.89460716031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40884.84789381892
gradient descent iteration = 21
gd loss = 40884.84789381892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40880.02266894586
gradient descent iteration = 22
gd loss = 40880.02266894586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40875.41178805548
gradient descent iteration = 23
gd loss = 40875.41178805548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40870.96299551497
gradient descent iteration = 24
gd loss = 40870.96299551497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40866.678847351
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 40866.678847351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40857.67364135737
gradient descent iteration = 1
gd loss = 40857.67364135737
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40851.5608710245
gradient descent iteration = 2
gd loss = 40851.5608710245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40846.20521175326
gradient descent iteration = 3
gd loss = 40846.20521175326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40841.26554573734
gradient descent iteration = 4
gd loss = 40841.26554573734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40836.63300155428
gradient descent iteration = 5
gd loss = 40836.63300155428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40832.24791376357
gradient descent iteration = 6
gd loss = 40832.24791376357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40828.06859124179
gradient descent iteration = 7
gd loss = 40828.06859124179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40824.0637891392
gradient descent iteration = 8
gd loss = 40824.0637891392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40820.20907264859
gradient descent iteration = 9
gd loss = 40820.20907264859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40816.48487586624
gradient descent iteration = 10
gd loss = 40816.48487586624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40812.87519176648
gradient descent iteration = 11
gd loss = 40812.87519176648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40809.36671526754
gradient descent iteration = 12
gd loss = 40809.36671526754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40805.94820439931
gradient descent iteration = 13
gd loss = 40805.94820439931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40802.61002761409
gradient descent iteration = 14
gd loss = 40802.61002761409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40799.34383047307
gradient descent iteration = 15
gd loss = 40799.34383047307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40796.14226516311
gradient descent iteration = 16
gd loss = 40796.14226516311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40792.99877961012
gradient descent iteration = 17
gd loss = 40792.99877961012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40789.90747444311
gradient descent iteration = 18
gd loss = 40789.90747444311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40786.86296952455
gradient descent iteration = 19
gd loss = 40786.86296952455
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40783.86028346261
gradient descent iteration = 20
gd loss = 40783.86028346261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40780.89473573732
gradient descent iteration = 21
gd loss = 40780.89473573732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40777.96186298454
gradient descent iteration = 22
gd loss = 40777.96186298454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40775.05734805255
gradient descent iteration = 23
gd loss = 40775.05734805255
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40772.17695551287
gradient descent iteration = 24
gd loss = 40772.17695551287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40769.31646649719
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40769.31646649719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40764.38705829679
gradient descent iteration = 1
gd loss = 40764.38705829679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40759.83361219775
gradient descent iteration = 2
gd loss = 40759.83361219775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40755.5411204396
gradient descent iteration = 3
gd loss = 40755.5411204396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40751.46088989358
gradient descent iteration = 4
gd loss = 40751.46088989358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40747.56271756214
gradient descent iteration = 5
gd loss = 40747.56271756214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40743.82396548647
gradient descent iteration = 6
gd loss = 40743.82396548647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40740.22632235118
gradient descent iteration = 7
gd loss = 40740.22632235118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40736.75447374448
gradient descent iteration = 8
gd loss = 40736.75447374448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40733.39537784254
gradient descent iteration = 9
gd loss = 40733.39537784254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40730.1377973845
gradient descent iteration = 10
gd loss = 40730.1377973845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40726.97196618165
gradient descent iteration = 11
gd loss = 40726.97196618165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40723.88933669378
gradient descent iteration = 12
gd loss = 40723.88933669378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40720.88238252111
gradient descent iteration = 13
gd loss = 40720.88238252111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40717.9444396296
gradient descent iteration = 14
gd loss = 40717.9444396296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40715.06957691866
gradient descent iteration = 15
gd loss = 40715.06957691866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40712.25248986103
gradient descent iteration = 16
gd loss = 40712.25248986103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40709.48841140232
gradient descent iteration = 17
gd loss = 40709.48841140232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40706.77303681146
gradient descent iteration = 18
gd loss = 40706.77303681146
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40704.10246016501
gradient descent iteration = 19
gd loss = 40704.10246016501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40701.47312026682
gradient descent iteration = 20
gd loss = 40701.47312026682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40698.88175450434
gradient descent iteration = 21
gd loss = 40698.88175450434
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40696.32535928003
gradient descent iteration = 22
gd loss = 40696.32535928003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40693.80115598672
gradient descent iteration = 23
gd loss = 40693.80115598672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40691.30656169214
gradient descent iteration = 24
gd loss = 40691.30656169214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40688.83916378194
Initial loss = 41130.09953923792
Final loss = 40688.83916378194
Deformation gradient control sequence optimization finished.
Animation interval 18 took 1389 seconds.
Full animation took 26144 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 19************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41073.60749741642
initial norm = 696.2664740607983
convergence norm = 0.6962664740607982
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41073.60749741642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41017.03519816268
gradient descent iteration = 1
gd loss = 41017.03519816268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40982.38099543145
gradient descent iteration = 2
gd loss = 40982.38099543145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40958.91747796451
gradient descent iteration = 3
gd loss = 40958.91747796451
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40939.44299975738
gradient descent iteration = 4
gd loss = 40939.44299975738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40922.85147336141
gradient descent iteration = 5
gd loss = 40922.85147336141
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40908.28248373647
gradient descent iteration = 6
gd loss = 40908.28248373647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40895.03149154814
gradient descent iteration = 7
gd loss = 40895.03149154814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40882.63272631291
gradient descent iteration = 8
gd loss = 40882.63272631291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40870.98716920683
gradient descent iteration = 9
gd loss = 40870.98716920683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40860.69462638734
gradient descent iteration = 10
gd loss = 40860.69462638734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40852.85507677189
gradient descent iteration = 11
gd loss = 40852.85507677189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40845.93138224044
gradient descent iteration = 12
gd loss = 40845.93138224044
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40839.03840782827
gradient descent iteration = 13
gd loss = 40839.03840782827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40832.27604284305
gradient descent iteration = 14
gd loss = 40832.27604284305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40825.65228210214
gradient descent iteration = 15
gd loss = 40825.65228210214
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40819.11015028643
gradient descent iteration = 16
gd loss = 40819.11015028643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40812.70456509835
gradient descent iteration = 17
gd loss = 40812.70456509835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40806.38081012593
gradient descent iteration = 18
gd loss = 40806.38081012593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40800.2067354784
gradient descent iteration = 19
gd loss = 40800.2067354784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40794.13217683273
gradient descent iteration = 20
gd loss = 40794.13217683273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40788.23454925098
gradient descent iteration = 21
gd loss = 40788.23454925098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40782.45739157179
gradient descent iteration = 22
gd loss = 40782.45739157179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40776.87362459277
gradient descent iteration = 23
gd loss = 40776.87362459277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40771.4119361176
gradient descent iteration = 24
gd loss = 40771.4119361176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40766.135295015
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 40766.135295015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40756.10410350261
gradient descent iteration = 1
gd loss = 40756.10410350261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40748.94066667911
gradient descent iteration = 2
gd loss = 40748.94066667911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40742.48177520312
gradient descent iteration = 3
gd loss = 40742.48177520312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40736.42478498501
gradient descent iteration = 4
gd loss = 40736.42478498501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40730.68333867788
gradient descent iteration = 5
gd loss = 40730.68333867788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40725.21046503277
gradient descent iteration = 6
gd loss = 40725.21046503277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40719.97202858557
gradient descent iteration = 7
gd loss = 40719.97202858557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40714.9412757361
gradient descent iteration = 8
gd loss = 40714.9412757361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40710.0963737312
gradient descent iteration = 9
gd loss = 40710.0963737312
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40705.4191609133
gradient descent iteration = 10
gd loss = 40705.4191609133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40700.89429971282
gradient descent iteration = 11
gd loss = 40700.89429971282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40696.50870694885
gradient descent iteration = 12
gd loss = 40696.50870694885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40692.25114638333
gradient descent iteration = 13
gd loss = 40692.25114638333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40688.11187355245
gradient descent iteration = 14
gd loss = 40688.11187355245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40684.08236173246
gradient descent iteration = 15
gd loss = 40684.08236173246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40680.15510722833
gradient descent iteration = 16
gd loss = 40680.15510722833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40676.32347634564
gradient descent iteration = 17
gd loss = 40676.32347634564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40672.58157125135
gradient descent iteration = 18
gd loss = 40672.58157125135
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40668.92410715284
gradient descent iteration = 19
gd loss = 40668.92410715284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40665.34636229637
gradient descent iteration = 20
gd loss = 40665.34636229637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40661.84419266107
gradient descent iteration = 21
gd loss = 40661.84419266107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40658.41382176532
gradient descent iteration = 22
gd loss = 40658.41382176532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40655.05174883669
gradient descent iteration = 23
gd loss = 40655.05174883669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40651.75472018798
gradient descent iteration = 24
gd loss = 40651.75472018798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40648.51970324104
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40648.51970324104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40642.43257434667
gradient descent iteration = 1
gd loss = 40642.43257434667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40636.84194140524
gradient descent iteration = 2
gd loss = 40636.84194140524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40631.57677447643
gradient descent iteration = 3
gd loss = 40631.57677447643
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40626.57528914425
gradient descent iteration = 4
gd loss = 40626.57528914425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40621.80371656249
gradient descent iteration = 5
gd loss = 40621.80371656249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40617.23758404038
gradient descent iteration = 6
gd loss = 40617.23758404038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40612.85682676177
gradient descent iteration = 7
gd loss = 40612.85682676177
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40608.64426772807
gradient descent iteration = 8
gd loss = 40608.64426772807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40604.58494176158
gradient descent iteration = 9
gd loss = 40604.58494176158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40600.66569445882
gradient descent iteration = 10
gd loss = 40600.66569445882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40596.87490201849
gradient descent iteration = 11
gd loss = 40596.87490201849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40593.20226947837
gradient descent iteration = 12
gd loss = 40593.20226947837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40589.63864940829
gradient descent iteration = 13
gd loss = 40589.63864940829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40586.17588760072
gradient descent iteration = 14
gd loss = 40586.17588760072
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40582.80668785412
gradient descent iteration = 15
gd loss = 40582.80668785412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40579.52450730539
gradient descent iteration = 16
gd loss = 40579.52450730539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40576.32346654369
gradient descent iteration = 17
gd loss = 40576.32346654369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40573.1982686239
gradient descent iteration = 18
gd loss = 40573.1982686239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40570.14412860721
gradient descent iteration = 19
gd loss = 40570.14412860721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40567.15671299755
gradient descent iteration = 20
gd loss = 40567.15671299755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40564.23208679287
gradient descent iteration = 21
gd loss = 40564.23208679287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40561.36666686468
gradient descent iteration = 22
gd loss = 40561.36666686468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40558.55718330998
gradient descent iteration = 23
gd loss = 40558.55718330998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40555.80064542878
gradient descent iteration = 24
gd loss = 40555.80064542878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40553.0943113934
Initial loss = 41073.60749741642
Final loss = 40553.0943113934
Deformation gradient control sequence optimization finished.
Animation interval 19 took 1393 seconds.
Full animation took 27538 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 20************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 40967.70625212984
initial norm = 400.7000447844568
convergence norm = 0.4007000447844568
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 40967.70625212984
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40935.04072953349
gradient descent iteration = 1
gd loss = 40935.04072953349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40910.50488851171
gradient descent iteration = 2
gd loss = 40910.50488851171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40890.909939299
gradient descent iteration = 3
gd loss = 40890.909939299
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40874.68112118835
gradient descent iteration = 4
gd loss = 40874.68112118835
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40860.71444268057
gradient descent iteration = 5
gd loss = 40860.71444268057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40848.15759069876
gradient descent iteration = 6
gd loss = 40848.15759069876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40836.44451626892
gradient descent iteration = 7
gd loss = 40836.44451626892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40825.28622082788
gradient descent iteration = 8
gd loss = 40825.28622082788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40814.6719310655
gradient descent iteration = 9
gd loss = 40814.6719310655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40805.41172327033
gradient descent iteration = 10
gd loss = 40805.41172327033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40800.04994597968
gradient descent iteration = 11
gd loss = 40800.04994597968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40794.59184418941
gradient descent iteration = 12
gd loss = 40794.59184418941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40789.58688997128
gradient descent iteration = 13
gd loss = 40789.58688997128
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40784.55516963995
gradient descent iteration = 14
gd loss = 40784.55516963995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40779.69999600431
gradient descent iteration = 15
gd loss = 40779.69999600431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40774.89221606118
gradient descent iteration = 16
gd loss = 40774.89221606118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40770.19105577244
gradient descent iteration = 17
gd loss = 40770.19105577244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40765.54865719501
gradient descent iteration = 18
gd loss = 40765.54865719501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40760.98682186077
gradient descent iteration = 19
gd loss = 40760.98682186077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40756.48087611999
gradient descent iteration = 20
gd loss = 40756.48087611999
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40752.04169417178
gradient descent iteration = 21
gd loss = 40752.04169417178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40747.65262118795
gradient descent iteration = 22
gd loss = 40747.65262118795
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40743.32086616833
gradient descent iteration = 23
gd loss = 40743.32086616833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40739.03339511814
gradient descent iteration = 24
gd loss = 40739.03339511814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40734.79589836751
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 40734.79589836751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40725.29720622223
gradient descent iteration = 1
gd loss = 40725.29720622223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40719.05900207131
gradient descent iteration = 2
gd loss = 40719.05900207131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40713.46705116564
gradient descent iteration = 3
gd loss = 40713.46705116564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40708.17184684804
gradient descent iteration = 4
gd loss = 40708.17184684804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40703.08927677207
gradient descent iteration = 5
gd loss = 40703.08927677207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40698.17993191078
gradient descent iteration = 6
gd loss = 40698.17993191078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40693.41729656222
gradient descent iteration = 7
gd loss = 40693.41729656222
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40688.78188777537
gradient descent iteration = 8
gd loss = 40688.78188777537
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40684.25873046515
gradient descent iteration = 9
gd loss = 40684.25873046515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40679.83612046397
gradient descent iteration = 10
gd loss = 40679.83612046397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40675.50478668544
gradient descent iteration = 11
gd loss = 40675.50478668544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40671.25734284584
gradient descent iteration = 12
gd loss = 40671.25734284584
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40667.08785783548
gradient descent iteration = 13
gd loss = 40667.08785783548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40662.99154343623
gradient descent iteration = 14
gd loss = 40662.99154343623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40658.96452556239
gradient descent iteration = 15
gd loss = 40658.96452556239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40655.00366122343
gradient descent iteration = 16
gd loss = 40655.00366122343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40651.10639110185
gradient descent iteration = 17
gd loss = 40651.10639110185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40647.27062116192
gradient descent iteration = 18
gd loss = 40647.27062116192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40643.49462551787
gradient descent iteration = 19
gd loss = 40643.49462551787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40639.77696374993
gradient descent iteration = 20
gd loss = 40639.77696374993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40636.11640929946
gradient descent iteration = 21
gd loss = 40636.11640929946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40632.5118888426
gradient descent iteration = 22
gd loss = 40632.5118888426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40628.9624351955
gradient descent iteration = 23
gd loss = 40628.9624351955
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40625.46715311525
gradient descent iteration = 24
gd loss = 40625.46715311525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40622.02519764492
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40622.02519764492
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40617.07728368232
gradient descent iteration = 1
gd loss = 40617.07728368232
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40612.47760785875
gradient descent iteration = 2
gd loss = 40612.47760785875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40608.11026532039
gradient descent iteration = 3
gd loss = 40608.11026532039
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40603.9245314391
gradient descent iteration = 4
gd loss = 40603.9245314391
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40599.8910641651
gradient descent iteration = 5
gd loss = 40599.8910641651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40595.98955633346
gradient descent iteration = 6
gd loss = 40595.98955633346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40592.20466196403
gradient descent iteration = 7
gd loss = 40592.20466196403
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40588.5243091532
gradient descent iteration = 8
gd loss = 40588.5243091532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40584.93881081967
gradient descent iteration = 9
gd loss = 40584.93881081967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40581.44030328056
gradient descent iteration = 10
gd loss = 40581.44030328056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40578.02235154799
gradient descent iteration = 11
gd loss = 40578.02235154799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40574.67965470203
gradient descent iteration = 12
gd loss = 40574.67965470203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40571.40781812587
gradient descent iteration = 13
gd loss = 40571.40781812587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40568.20317332503
gradient descent iteration = 14
gd loss = 40568.20317332503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40565.06263303308
gradient descent iteration = 15
gd loss = 40565.06263303308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40561.98357580895
gradient descent iteration = 16
gd loss = 40561.98357580895
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40558.96390833284
gradient descent iteration = 17
gd loss = 40558.96390833284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40556.002270786
gradient descent iteration = 18
gd loss = 40556.002270786
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40553.09747651897
gradient descent iteration = 19
gd loss = 40553.09747651897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40550.24834516644
gradient descent iteration = 20
gd loss = 40550.24834516644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40547.45367279969
gradient descent iteration = 21
gd loss = 40547.45367279969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40544.71222196674
gradient descent iteration = 22
gd loss = 40544.71222196674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40542.02270563321
gradient descent iteration = 23
gd loss = 40542.02270563321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40539.38384016891
gradient descent iteration = 24
gd loss = 40539.38384016891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40536.79432356751
Initial loss = 40967.70625212984
Final loss = 40536.79432356751
Deformation gradient control sequence optimization finished.
Animation interval 20 took 1391 seconds.
Full animation took 28929 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 21************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41038.03839071088
initial norm = 607.8814302588275
convergence norm = 0.6078814302588276
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41038.03839071088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40990.31566679501
gradient descent iteration = 1
gd loss = 40990.31566679501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40962.09985708338
gradient descent iteration = 2
gd loss = 40962.09985708338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40941.37718897196
gradient descent iteration = 3
gd loss = 40941.37718897196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40924.65415743444
gradient descent iteration = 4
gd loss = 40924.65415743444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40910.6879156137
gradient descent iteration = 5
gd loss = 40910.6879156137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40898.53497449525
gradient descent iteration = 6
gd loss = 40898.53497449525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40887.51419150837
gradient descent iteration = 7
gd loss = 40887.51419150837
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40877.35364108052
gradient descent iteration = 8
gd loss = 40877.35364108052
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40868.4757318849
gradient descent iteration = 9
gd loss = 40868.4757318849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40861.84374968694
gradient descent iteration = 10
gd loss = 40861.84374968694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40856.48034860252
gradient descent iteration = 11
gd loss = 40856.48034860252
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40851.54151006919
gradient descent iteration = 12
gd loss = 40851.54151006919
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40846.71143702853
gradient descent iteration = 13
gd loss = 40846.71143702853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40842.13056045856
gradient descent iteration = 14
gd loss = 40842.13056045856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40837.69743388545
gradient descent iteration = 15
gd loss = 40837.69743388545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40833.52265478482
gradient descent iteration = 16
gd loss = 40833.52265478482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40829.59732004419
gradient descent iteration = 17
gd loss = 40829.59732004419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40825.97421192007
gradient descent iteration = 18
gd loss = 40825.97421192007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40822.56077344459
gradient descent iteration = 19
gd loss = 40822.56077344459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40819.27314033502
gradient descent iteration = 20
gd loss = 40819.27314033502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40816.03955521994
gradient descent iteration = 21
gd loss = 40816.03955521994
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40812.86800798267
gradient descent iteration = 22
gd loss = 40812.86800798267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40809.72618899954
gradient descent iteration = 23
gd loss = 40809.72618899954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40806.6491478137
gradient descent iteration = 24
gd loss = 40806.6491478137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40803.59275622671
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 40803.59275622671
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40795.46063477168
gradient descent iteration = 1
gd loss = 40795.46063477168
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40790.86345747692
gradient descent iteration = 2
gd loss = 40790.86345747692
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40786.89956909888
gradient descent iteration = 3
gd loss = 40786.89956909888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40783.19451622738
gradient descent iteration = 4
gd loss = 40783.19451622738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40779.67002452599
gradient descent iteration = 5
gd loss = 40779.67002452599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40776.29298518544
gradient descent iteration = 6
gd loss = 40776.29298518544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40773.04140082937
gradient descent iteration = 7
gd loss = 40773.04140082937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40769.89886275709
gradient descent iteration = 8
gd loss = 40769.89886275709
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40766.85244693756
gradient descent iteration = 9
gd loss = 40766.85244693756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40763.89174997179
gradient descent iteration = 10
gd loss = 40763.89174997179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40761.00823354727
gradient descent iteration = 11
gd loss = 40761.00823354727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40758.19479295336
gradient descent iteration = 12
gd loss = 40758.19479295336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40755.44544276508
gradient descent iteration = 13
gd loss = 40755.44544276508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40752.7550875449
gradient descent iteration = 14
gd loss = 40752.7550875449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40750.11934639176
gradient descent iteration = 15
gd loss = 40750.11934639176
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40747.53441949258
gradient descent iteration = 16
gd loss = 40747.53441949258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40744.99698467595
gradient descent iteration = 17
gd loss = 40744.99698467595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40742.50411623558
gradient descent iteration = 18
gd loss = 40742.50411623558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40740.05322034666
gradient descent iteration = 19
gd loss = 40740.05322034666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40737.64198315972
gradient descent iteration = 20
gd loss = 40737.64198315972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40735.26832879565
gradient descent iteration = 21
gd loss = 40735.26832879565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40732.93038493166
gradient descent iteration = 22
gd loss = 40732.93038493166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40730.62645451697
gradient descent iteration = 23
gd loss = 40730.62645451697
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40728.35499225585
gradient descent iteration = 24
gd loss = 40728.35499225585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40726.11458497824
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40726.11458497824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40723.06504578818
gradient descent iteration = 1
gd loss = 40723.06504578818
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40720.2779898532
gradient descent iteration = 2
gd loss = 40720.2779898532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40717.66367256467
gradient descent iteration = 3
gd loss = 40717.66367256467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40715.18087766892
gradient descent iteration = 4
gd loss = 40715.18087766892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40712.80544237634
gradient descent iteration = 5
gd loss = 40712.80544237634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40710.52066834721
gradient descent iteration = 6
gd loss = 40710.52066834721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40708.31395758218
gradient descent iteration = 7
gd loss = 40708.31395758218
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40706.1753751993
gradient descent iteration = 8
gd loss = 40706.1753751993
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40704.09689287801
gradient descent iteration = 9
gd loss = 40704.09689287801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40702.07191983284
gradient descent iteration = 10
gd loss = 40702.07191983284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40700.09498079505
gradient descent iteration = 11
gd loss = 40700.09498079505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40698.1614820548
gradient descent iteration = 12
gd loss = 40698.1614820548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40696.26753572565
gradient descent iteration = 13
gd loss = 40696.26753572565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40694.40982484567
gradient descent iteration = 14
gd loss = 40694.40982484567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40692.58549837887
gradient descent iteration = 15
gd loss = 40692.58549837887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40690.79208853986
gradient descent iteration = 16
gd loss = 40690.79208853986
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40689.0274451095
gradient descent iteration = 17
gd loss = 40689.0274451095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40687.28968278799
gradient descent iteration = 18
gd loss = 40687.28968278799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40685.5771386801
gradient descent iteration = 19
gd loss = 40685.5771386801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40683.88833771923
gradient descent iteration = 20
gd loss = 40683.88833771923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40682.22196440726
gradient descent iteration = 21
gd loss = 40682.22196440726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40680.5768395374
gradient descent iteration = 22
gd loss = 40680.5768395374
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40678.95190077782
gradient descent iteration = 23
gd loss = 40678.95190077782
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40677.34618676756
gradient descent iteration = 24
gd loss = 40677.34618676756
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40675.75882370565
Initial loss = 41038.03839071088
Final loss = 40675.75882370565
Deformation gradient control sequence optimization finished.
Animation interval 21 took 1401 seconds.
Full animation took 30331 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 22************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41256.38094777254
initial norm = 406.2687166422164
convergence norm = 0.4062687166422164
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41256.38094777254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41224.50112995126
gradient descent iteration = 1
gd loss = 41224.50112995126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41201.91350739398
gradient descent iteration = 2
gd loss = 41201.91350739398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41184.62738139069
gradient descent iteration = 3
gd loss = 41184.62738139069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41170.81989871261
gradient descent iteration = 4
gd loss = 41170.81989871261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41159.24011372033
gradient descent iteration = 5
gd loss = 41159.24011372033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41149.32448216188
gradient descent iteration = 6
gd loss = 41149.32448216188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41143.06150210519
gradient descent iteration = 7
gd loss = 41143.06150210519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41140.24153897378
gradient descent iteration = 8
gd loss = 41140.24153897378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41135.1659110602
gradient descent iteration = 9
gd loss = 41135.1659110602
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41131.69035470785
gradient descent iteration = 10
gd loss = 41131.69035470785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41127.42977747029
gradient descent iteration = 11
gd loss = 41127.42977747029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41123.80206979225
gradient descent iteration = 12
gd loss = 41123.80206979225
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41119.91490036667
gradient descent iteration = 13
gd loss = 41119.91490036667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41116.30249512658
gradient descent iteration = 14
gd loss = 41116.30249512658
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41112.62574134445
gradient descent iteration = 15
gd loss = 41112.62574134445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41109.08060373081
gradient descent iteration = 16
gd loss = 41109.08060373081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41105.54359527727
gradient descent iteration = 17
gd loss = 41105.54359527727
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41102.07830622295
gradient descent iteration = 18
gd loss = 41102.07830622295
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41098.64620351558
gradient descent iteration = 19
gd loss = 41098.64620351558
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41095.26047245898
gradient descent iteration = 20
gd loss = 41095.26047245898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41091.91397937289
gradient descent iteration = 21
gd loss = 41091.91397937289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41088.6040621807
gradient descent iteration = 22
gd loss = 41088.6040621807
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41085.33158546189
gradient descent iteration = 23
gd loss = 41085.33158546189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41082.0932558557
gradient descent iteration = 24
gd loss = 41082.0932558557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41078.88830118698
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 41078.88830118698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41069.65916460042
gradient descent iteration = 1
gd loss = 41069.65916460042
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41064.8430035811
gradient descent iteration = 2
gd loss = 41064.8430035811
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41060.76759608753
gradient descent iteration = 3
gd loss = 41060.76759608753
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41056.96332162481
gradient descent iteration = 4
gd loss = 41056.96332162481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41053.33638091149
gradient descent iteration = 5
gd loss = 41053.33638091149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41049.8496003635
gradient descent iteration = 6
gd loss = 41049.8496003635
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41046.48093294062
gradient descent iteration = 7
gd loss = 41046.48093294062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41043.21474974406
gradient descent iteration = 8
gd loss = 41043.21474974406
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41040.03928082216
gradient descent iteration = 9
gd loss = 41040.03928082216
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41036.94526355364
gradient descent iteration = 10
gd loss = 41036.94526355364
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41033.92519987181
gradient descent iteration = 11
gd loss = 41033.92519987181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41030.9728691746
gradient descent iteration = 12
gd loss = 41030.9728691746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41028.08301015235
gradient descent iteration = 13
gd loss = 41028.08301015235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41025.25109930219
gradient descent iteration = 14
gd loss = 41025.25109930219
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41022.47319337576
gradient descent iteration = 15
gd loss = 41022.47319337576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41019.74581821079
gradient descent iteration = 16
gd loss = 41019.74581821079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41017.06588601434
gradient descent iteration = 17
gd loss = 41017.06588601434
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41014.43063240368
gradient descent iteration = 18
gd loss = 41014.43063240368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41011.83756638171
gradient descent iteration = 19
gd loss = 41011.83756638171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41009.28443269774
gradient descent iteration = 20
gd loss = 41009.28443269774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41006.76918416971
gradient descent iteration = 21
gd loss = 41006.76918416971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41004.28995685194
gradient descent iteration = 22
gd loss = 41004.28995685194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41001.84504896545
gradient descent iteration = 23
gd loss = 41001.84504896545
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40999.43290509809
gradient descent iteration = 24
gd loss = 40999.43290509809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40997.05209994573
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 40997.05209994573
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40993.43519114965
gradient descent iteration = 1
gd loss = 40993.43519114965
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40990.07833458263
gradient descent iteration = 2
gd loss = 40990.07833458263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40986.90170016392
gradient descent iteration = 3
gd loss = 40986.90170016392
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40983.8672791798
gradient descent iteration = 4
gd loss = 40983.8672791798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40980.95217589869
gradient descent iteration = 5
gd loss = 40980.95217589869
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40978.14036313523
gradient descent iteration = 6
gd loss = 40978.14036313523
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40975.41966570071
gradient descent iteration = 7
gd loss = 40975.41966570071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40972.78044504662
gradient descent iteration = 8
gd loss = 40972.78044504662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40970.2148838548
gradient descent iteration = 9
gd loss = 40970.2148838548
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40967.71653248348
gradient descent iteration = 10
gd loss = 40967.71653248348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40965.27999500035
gradient descent iteration = 11
gd loss = 40965.27999500035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40962.90070048506
gradient descent iteration = 12
gd loss = 40962.90070048506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40960.57473172282
gradient descent iteration = 13
gd loss = 40960.57473172282
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40958.29869415144
gradient descent iteration = 14
gd loss = 40958.29869415144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40956.06961572394
gradient descent iteration = 15
gd loss = 40956.06961572394
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40953.88486937183
gradient descent iteration = 16
gd loss = 40953.88486937183
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40951.74211217018
gradient descent iteration = 17
gd loss = 40951.74211217018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40949.63923731196
gradient descent iteration = 18
gd loss = 40949.63923731196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40947.57433607817
gradient descent iteration = 19
gd loss = 40947.57433607817
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40945.54566753713
gradient descent iteration = 20
gd loss = 40945.54566753713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40943.55163424857
gradient descent iteration = 21
gd loss = 40943.55163424857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40941.59076259085
gradient descent iteration = 22
gd loss = 40941.59076259085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40939.66168672431
gradient descent iteration = 23
gd loss = 40939.66168672431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40937.76313536173
gradient descent iteration = 24
gd loss = 40937.76313536173
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 40935.89392079576
Initial loss = 41256.38094777254
Final loss = 40935.89392079576
Deformation gradient control sequence optimization finished.
Animation interval 22 took 1393 seconds.
Full animation took 31724 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 23************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41583.57535754778
initial norm = 483.1664177535982
convergence norm = 0.4831664177535982
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41583.57535754778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41547.86672196067
gradient descent iteration = 1
gd loss = 41547.86672196067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41524.30693040733
gradient descent iteration = 2
gd loss = 41524.30693040733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41506.31310082673
gradient descent iteration = 3
gd loss = 41506.31310082673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41492.03019912245
gradient descent iteration = 4
gd loss = 41492.03019912245
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41480.34657752472
gradient descent iteration = 5
gd loss = 41480.34657752472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41471.54227720689
gradient descent iteration = 6
gd loss = 41471.54227720689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41467.72566728867
gradient descent iteration = 7
gd loss = 41467.72566728867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41462.64954531975
gradient descent iteration = 8
gd loss = 41462.64954531975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41458.70288805361
gradient descent iteration = 9
gd loss = 41458.70288805361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41454.34569099004
gradient descent iteration = 10
gd loss = 41454.34569099004
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41450.47690927186
gradient descent iteration = 11
gd loss = 41450.47690927186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41446.49808585619
gradient descent iteration = 12
gd loss = 41446.49808585619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41442.77863681194
gradient descent iteration = 13
gd loss = 41442.77863681194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41439.04317782712
gradient descent iteration = 14
gd loss = 41439.04317782712
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41435.47711185443
gradient descent iteration = 15
gd loss = 41435.47711185443
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41431.92227066111
gradient descent iteration = 16
gd loss = 41431.92227066111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41428.49698175528
gradient descent iteration = 17
gd loss = 41428.49698175528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41425.08719306289
gradient descent iteration = 18
gd loss = 41425.08719306289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41421.78705499131
gradient descent iteration = 19
gd loss = 41421.78705499131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41418.49873102905
gradient descent iteration = 20
gd loss = 41418.49873102905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41415.30888068015
gradient descent iteration = 21
gd loss = 41415.30888068015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41412.12455377875
gradient descent iteration = 22
gd loss = 41412.12455377875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41409.03183789021
gradient descent iteration = 23
gd loss = 41409.03183789021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41405.93754259001
gradient descent iteration = 24
gd loss = 41405.93754259001
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41402.93058470914
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 41402.93058470914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41394.96019103924
gradient descent iteration = 1
gd loss = 41394.96019103924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41390.45045549758
gradient descent iteration = 2
gd loss = 41390.45045549758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41386.64087382636
gradient descent iteration = 3
gd loss = 41386.64087382636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41383.12571339319
gradient descent iteration = 4
gd loss = 41383.12571339319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41379.80821049894
gradient descent iteration = 5
gd loss = 41379.80821049894
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41376.64647615979
gradient descent iteration = 6
gd loss = 41376.64647615979
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41373.61355522152
gradient descent iteration = 7
gd loss = 41373.61355522152
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41370.68990162088
gradient descent iteration = 8
gd loss = 41370.68990162088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41367.8604246953
gradient descent iteration = 9
gd loss = 41367.8604246953
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41365.11315642769
gradient descent iteration = 10
gd loss = 41365.11315642769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41362.43838294189
gradient descent iteration = 11
gd loss = 41362.43838294189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41359.8280912434
gradient descent iteration = 12
gd loss = 41359.8280912434
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41357.27557474164
gradient descent iteration = 13
gd loss = 41357.27557474164
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41354.77515085459
gradient descent iteration = 14
gd loss = 41354.77515085459
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41352.32194974579
gradient descent iteration = 15
gd loss = 41352.32194974579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41349.91175463822
gradient descent iteration = 16
gd loss = 41349.91175463822
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41347.54087924301
gradient descent iteration = 17
gd loss = 41347.54087924301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41345.20607126258
gradient descent iteration = 18
gd loss = 41345.20607126258
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41342.90443564271
gradient descent iteration = 19
gd loss = 41342.90443564271
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41340.63337278074
gradient descent iteration = 20
gd loss = 41340.63337278074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41338.3905281203
gradient descent iteration = 21
gd loss = 41338.3905281203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41336.1737506422
gradient descent iteration = 22
gd loss = 41336.1737506422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41333.98105816301
gradient descent iteration = 23
gd loss = 41333.98105816301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41331.8106079137
gradient descent iteration = 24
gd loss = 41331.8106079137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41329.6606715143
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 41329.6606715143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41326.90031237198
gradient descent iteration = 1
gd loss = 41326.90031237198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41324.38338722174
gradient descent iteration = 2
gd loss = 41324.38338722174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41322.03138629228
gradient descent iteration = 3
gd loss = 41322.03138629228
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41319.80515668619
gradient descent iteration = 4
gd loss = 41319.80515668619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41317.68016384174
gradient descent iteration = 5
gd loss = 41317.68016384174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41315.63894938759
gradient descent iteration = 6
gd loss = 41315.63894938759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41313.66828992662
gradient descent iteration = 7
gd loss = 41313.66828992662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41311.75784544878
gradient descent iteration = 8
gd loss = 41311.75784544878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41309.89937705554
gradient descent iteration = 9
gd loss = 41309.89937705554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41308.08623261949
gradient descent iteration = 10
gd loss = 41308.08623261949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41306.31298325107
gradient descent iteration = 11
gd loss = 41306.31298325107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41304.57515619487
gradient descent iteration = 12
gd loss = 41304.57515619487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41302.86903401415
gradient descent iteration = 13
gd loss = 41302.86903401415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41301.19150125906
gradient descent iteration = 14
gd loss = 41301.19150125906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41299.53992599691
gradient descent iteration = 15
gd loss = 41299.53992599691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41297.91206771704
gradient descent iteration = 16
gd loss = 41297.91206771704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41296.30600509315
gradient descent iteration = 17
gd loss = 41296.30600509315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41294.72007873441
gradient descent iteration = 18
gd loss = 41294.72007873441
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41293.15284560517
gradient descent iteration = 19
gd loss = 41293.15284560517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41291.6030424889
gradient descent iteration = 20
gd loss = 41291.6030424889
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41290.06955652382
gradient descent iteration = 21
gd loss = 41290.06955652382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41288.55140125491
gradient descent iteration = 22
gd loss = 41288.55140125491
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41287.04769710496
gradient descent iteration = 23
gd loss = 41287.04769710496
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41285.55765535962
gradient descent iteration = 24
gd loss = 41285.55765535962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41284.08056497899
Initial loss = 41583.57535754778
Final loss = 41284.08056497899
Deformation gradient control sequence optimization finished.
Animation interval 23 took 1390 seconds.
Full animation took 33115 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 24************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 41957.5657641192
initial norm = 349.0756756668696
convergence norm = 0.3490756756668696
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 41957.5657641192
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41929.37075882179
gradient descent iteration = 1
gd loss = 41929.37075882179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41907.42396300728
gradient descent iteration = 2
gd loss = 41907.42396300728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41889.47249597217
gradient descent iteration = 3
gd loss = 41889.47249597217
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41874.20246931734
gradient descent iteration = 4
gd loss = 41874.20246931734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41861.11788682763
gradient descent iteration = 5
gd loss = 41861.11788682763
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41849.91573628568
gradient descent iteration = 6
gd loss = 41849.91573628568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41840.33100455335
gradient descent iteration = 7
gd loss = 41840.33100455335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41832.08628630281
gradient descent iteration = 8
gd loss = 41832.08628630281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41826.09848333234
gradient descent iteration = 9
gd loss = 41826.09848333234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41820.99039631305
gradient descent iteration = 10
gd loss = 41820.99039631305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41815.95462368445
gradient descent iteration = 11
gd loss = 41815.95462368445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41811.1926646816
gradient descent iteration = 12
gd loss = 41811.1926646816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41806.58110718308
gradient descent iteration = 13
gd loss = 41806.58110718308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41802.2334397103
gradient descent iteration = 14
gd loss = 41802.2334397103
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41798.13376797742
gradient descent iteration = 15
gd loss = 41798.13376797742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41794.39636800463
gradient descent iteration = 16
gd loss = 41794.39636800463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41790.90525174853
gradient descent iteration = 17
gd loss = 41790.90525174853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41787.5743006779
gradient descent iteration = 18
gd loss = 41787.5743006779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41784.2895310973
gradient descent iteration = 19
gd loss = 41784.2895310973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41781.05292130766
gradient descent iteration = 20
gd loss = 41781.05292130766
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41777.86030550856
gradient descent iteration = 21
gd loss = 41777.86030550856
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41774.69720764529
gradient descent iteration = 22
gd loss = 41774.69720764529
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41771.58848524728
gradient descent iteration = 23
gd loss = 41771.58848524728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41768.49657888932
gradient descent iteration = 24
gd loss = 41768.49657888932
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41765.4634380651
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 41765.4634380651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41757.05479588063
gradient descent iteration = 1
gd loss = 41757.05479588063
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41752.12585207304
gradient descent iteration = 2
gd loss = 41752.12585207304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41747.95161889771
gradient descent iteration = 3
gd loss = 41747.95161889771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41744.09364796471
gradient descent iteration = 4
gd loss = 41744.09364796471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41740.4449184768
gradient descent iteration = 5
gd loss = 41740.4449184768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41736.96064144663
gradient descent iteration = 6
gd loss = 41736.96064144663
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41733.61260024824
gradient descent iteration = 7
gd loss = 41733.61260024824
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41730.38054138534
gradient descent iteration = 8
gd loss = 41730.38054138534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41727.24887955534
gradient descent iteration = 9
gd loss = 41727.24887955534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41724.20530181924
gradient descent iteration = 10
gd loss = 41724.20530181924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41721.23984647301
gradient descent iteration = 11
gd loss = 41721.23984647301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41718.34432880211
gradient descent iteration = 12
gd loss = 41718.34432880211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41715.51192841386
gradient descent iteration = 13
gd loss = 41715.51192841386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41712.7368964987
gradient descent iteration = 14
gd loss = 41712.7368964987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41710.01433723628
gradient descent iteration = 15
gd loss = 41710.01433723628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41707.34004338189
gradient descent iteration = 16
gd loss = 41707.34004338189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41704.71036991013
gradient descent iteration = 17
gd loss = 41704.71036991013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41702.12213508468
gradient descent iteration = 18
gd loss = 41702.12213508468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41699.57254199326
gradient descent iteration = 19
gd loss = 41699.57254199326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41697.05911719775
gradient descent iteration = 20
gd loss = 41697.05911719775
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41694.57966110335
gradient descent iteration = 21
gd loss = 41694.57966110335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41692.13220781169
gradient descent iteration = 22
gd loss = 41692.13220781169
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41689.71499228368
gradient descent iteration = 23
gd loss = 41689.71499228368
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41687.32642090209
gradient descent iteration = 24
gd loss = 41687.32642090209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41684.96504896721
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 41684.96504896721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41680.83204427649
gradient descent iteration = 1
gd loss = 41680.83204427649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41677.05799212436
gradient descent iteration = 2
gd loss = 41677.05799212436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41673.53283946127
gradient descent iteration = 3
gd loss = 41673.53283946127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41670.20633718086
gradient descent iteration = 4
gd loss = 41670.20633718086
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41667.04663195292
gradient descent iteration = 5
gd loss = 41667.04663195292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41664.0302838779
gradient descent iteration = 6
gd loss = 41664.0302838779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41661.13888634482
gradient descent iteration = 7
gd loss = 41661.13888634482
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41658.35750107366
gradient descent iteration = 8
gd loss = 41658.35750107366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41655.67375395675
gradient descent iteration = 9
gd loss = 41655.67375395675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41653.07724845055
gradient descent iteration = 10
gd loss = 41653.07724845055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41650.55915282544
gradient descent iteration = 11
gd loss = 41650.55915282544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41648.11189655995
gradient descent iteration = 12
gd loss = 41648.11189655995
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41645.72894033724
gradient descent iteration = 13
gd loss = 41645.72894033724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41643.40459766774
gradient descent iteration = 14
gd loss = 41643.40459766774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41641.1338942012
gradient descent iteration = 15
gd loss = 41641.1338942012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41638.91245520711
gradient descent iteration = 16
gd loss = 41638.91245520711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41636.73641444463
gradient descent iteration = 17
gd loss = 41636.73641444463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41634.60233973195
gradient descent iteration = 18
gd loss = 41634.60233973195
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41632.50717150352
gradient descent iteration = 19
gd loss = 41632.50717150352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41630.44817114589
gradient descent iteration = 20
gd loss = 41630.44817114589
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41628.42287812454
gradient descent iteration = 21
gd loss = 41628.42287812454
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41626.42907385025
gradient descent iteration = 22
gd loss = 41626.42907385025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41624.46475099321
gradient descent iteration = 23
gd loss = 41624.46475099321
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41622.52808736302
gradient descent iteration = 24
gd loss = 41622.52808736302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41620.61742354139
Initial loss = 41957.5657641192
Final loss = 41620.61742354139
Deformation gradient control sequence optimization finished.
Animation interval 24 took 1393 seconds.
Full animation took 34509 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 25************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 42342.55578484711
initial norm = 347.1308837287449
convergence norm = 0.3471308837287449
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 42342.55578484711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42314.2136866885
gradient descent iteration = 1
gd loss = 42314.2136866885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42292.96518514594
gradient descent iteration = 2
gd loss = 42292.96518514594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42276.29650868711
gradient descent iteration = 3
gd loss = 42276.29650868711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42262.64215698616
gradient descent iteration = 4
gd loss = 42262.64215698616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42250.79232207974
gradient descent iteration = 5
gd loss = 42250.79232207974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42240.23216410233
gradient descent iteration = 6
gd loss = 42240.23216410233
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42232.18593870477
gradient descent iteration = 7
gd loss = 42232.18593870477
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42227.74754125012
gradient descent iteration = 8
gd loss = 42227.74754125012
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42222.14865376277
gradient descent iteration = 9
gd loss = 42222.14865376277
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42217.2642798067
gradient descent iteration = 10
gd loss = 42217.2642798067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42212.22997717305
gradient descent iteration = 11
gd loss = 42212.22997717305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42207.3597727858
gradient descent iteration = 12
gd loss = 42207.3597727858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42202.55861136947
gradient descent iteration = 13
gd loss = 42202.55861136947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42197.78543803286
gradient descent iteration = 14
gd loss = 42197.78543803286
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42193.12526328456
gradient descent iteration = 15
gd loss = 42193.12526328456
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42188.45266042937
gradient descent iteration = 16
gd loss = 42188.45266042937
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42183.8978137444
gradient descent iteration = 17
gd loss = 42183.8978137444
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42179.31600711676
gradient descent iteration = 18
gd loss = 42179.31600711676
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42174.84876992393
gradient descent iteration = 19
gd loss = 42174.84876992393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42170.34851929917
gradient descent iteration = 20
gd loss = 42170.34851929917
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42165.95881519194
gradient descent iteration = 21
gd loss = 42165.95881519194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42161.53342104788
gradient descent iteration = 22
gd loss = 42161.53342104788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42157.21499681973
gradient descent iteration = 23
gd loss = 42157.21499681973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42152.85974186138
gradient descent iteration = 24
gd loss = 42152.85974186138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42148.60817425637
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 42148.60817425637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42138.80072194586
gradient descent iteration = 1
gd loss = 42138.80072194586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42132.41817315418
gradient descent iteration = 2
gd loss = 42132.41817315418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42126.82417080902
gradient descent iteration = 3
gd loss = 42126.82417080902
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42121.58580861981
gradient descent iteration = 4
gd loss = 42121.58580861981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42116.58914236841
gradient descent iteration = 5
gd loss = 42116.58914236841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42111.78361726026
gradient descent iteration = 6
gd loss = 42111.78361726026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42107.13702707768
gradient descent iteration = 7
gd loss = 42107.13702707768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42102.62608401841
gradient descent iteration = 8
gd loss = 42102.62608401841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42098.23262421559
gradient descent iteration = 9
gd loss = 42098.23262421559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42093.94196330883
gradient descent iteration = 10
gd loss = 42093.94196330883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42089.74188344093
gradient descent iteration = 11
gd loss = 42089.74188344093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42085.62202254293
gradient descent iteration = 12
gd loss = 42085.62202254293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42081.5734566553
gradient descent iteration = 13
gd loss = 42081.5734566553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42077.58841447705
gradient descent iteration = 14
gd loss = 42077.58841447705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42073.66007159596
gradient descent iteration = 15
gd loss = 42073.66007159596
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42069.78240206349
gradient descent iteration = 16
gd loss = 42069.78240206349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42065.95006750841
gradient descent iteration = 17
gd loss = 42065.95006750841
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42062.1583308733
gradient descent iteration = 18
gd loss = 42062.1583308733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42058.4029961038
gradient descent iteration = 19
gd loss = 42058.4029961038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42054.68035993744
gradient descent iteration = 20
gd loss = 42054.68035993744
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42050.98717238646
gradient descent iteration = 21
gd loss = 42050.98717238646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42047.32060540738
gradient descent iteration = 22
gd loss = 42047.32060540738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42043.67822439774
gradient descent iteration = 23
gd loss = 42043.67822439774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42040.05796786301
gradient descent iteration = 24
gd loss = 42040.05796786301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42036.45812729085
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 42036.45812729085
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42031.03220318949
gradient descent iteration = 1
gd loss = 42031.03220318949
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42026.09172773137
gradient descent iteration = 2
gd loss = 42026.09172773137
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42021.45000482419
gradient descent iteration = 3
gd loss = 42021.45000482419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42017.03377643159
gradient descent iteration = 4
gd loss = 42017.03377643159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42012.79939192446
gradient descent iteration = 5
gd loss = 42012.79939192446
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42008.71628499826
gradient descent iteration = 6
gd loss = 42008.71628499826
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42004.76165569088
gradient descent iteration = 7
gd loss = 42004.76165569088
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42000.91794659934
gradient descent iteration = 8
gd loss = 42000.91794659934
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41997.17136235143
gradient descent iteration = 9
gd loss = 41997.17136235143
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41993.51090446828
gradient descent iteration = 10
gd loss = 41993.51090446828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41989.92770599431
gradient descent iteration = 11
gd loss = 41989.92770599431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41986.4145557098
gradient descent iteration = 12
gd loss = 41986.4145557098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41982.96555614487
gradient descent iteration = 13
gd loss = 41982.96555614487
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41979.57586367532
gradient descent iteration = 14
gd loss = 41979.57586367532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41976.24147469402
gradient descent iteration = 15
gd loss = 41976.24147469402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41972.95906675301
gradient descent iteration = 16
gd loss = 41972.95906675301
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41969.72586922015
gradient descent iteration = 17
gd loss = 41969.72586922015
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41966.53955388625
gradient descent iteration = 18
gd loss = 41966.53955388625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41963.39816323202
gradient descent iteration = 19
gd loss = 41963.39816323202
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41960.30004571035
gradient descent iteration = 20
gd loss = 41960.30004571035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41957.24379849221
gradient descent iteration = 21
gd loss = 41957.24379849221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41954.22821943089
gradient descent iteration = 22
gd loss = 41954.22821943089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41951.2522660089
gradient descent iteration = 23
gd loss = 41951.2522660089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41948.31502043148
gradient descent iteration = 24
gd loss = 41948.31502043148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 41945.41566038581
Initial loss = 42342.55578484711
Final loss = 41945.41566038581
Deformation gradient control sequence optimization finished.
Animation interval 25 took 1379 seconds.
Full animation took 35888 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 26************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 42671.08215307793
initial norm = 338.973029359577
convergence norm = 0.338973029359577
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 42671.08215307793
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42642.41871117315
gradient descent iteration = 1
gd loss = 42642.41871117315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42619.46073569151
gradient descent iteration = 2
gd loss = 42619.46073569151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42600.48776670871
gradient descent iteration = 3
gd loss = 42600.48776670871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42584.26129017077
gradient descent iteration = 4
gd loss = 42584.26129017077
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42569.81062536281
gradient descent iteration = 5
gd loss = 42569.81062536281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42556.48691188388
gradient descent iteration = 6
gd loss = 42556.48691188388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42543.94116315796
gradient descent iteration = 7
gd loss = 42543.94116315796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42532.1185149026
gradient descent iteration = 8
gd loss = 42532.1185149026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42521.68018390849
gradient descent iteration = 9
gd loss = 42521.68018390849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42514.72343839613
gradient descent iteration = 10
gd loss = 42514.72343839613
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42509.03246135318
gradient descent iteration = 11
gd loss = 42509.03246135318
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42503.03857760736
gradient descent iteration = 12
gd loss = 42503.03857760736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42497.33906953967
gradient descent iteration = 13
gd loss = 42497.33906953967
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42491.76416802061
gradient descent iteration = 14
gd loss = 42491.76416802061
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42486.26005008743
gradient descent iteration = 15
gd loss = 42486.26005008743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42480.94771097133
gradient descent iteration = 16
gd loss = 42480.94771097133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42475.65067645362
gradient descent iteration = 17
gd loss = 42475.65067645362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42470.55564570369
gradient descent iteration = 18
gd loss = 42470.55564570369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42465.45605992073
gradient descent iteration = 19
gd loss = 42465.45605992073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42460.560795887
gradient descent iteration = 20
gd loss = 42460.560795887
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42455.65059980249
gradient descent iteration = 21
gd loss = 42455.65059980249
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42450.9459824961
gradient descent iteration = 22
gd loss = 42450.9459824961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42446.21842078399
gradient descent iteration = 23
gd loss = 42446.21842078399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42441.69675627062
gradient descent iteration = 24
gd loss = 42441.69675627062
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42437.14405943771
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 42437.14405943771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42426.87042883
gradient descent iteration = 1
gd loss = 42426.87042883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42420.53633516355
gradient descent iteration = 2
gd loss = 42420.53633516355
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42415.02348616362
gradient descent iteration = 3
gd loss = 42415.02348616362
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42409.87812533534
gradient descent iteration = 4
gd loss = 42409.87812533534
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42404.99059599207
gradient descent iteration = 5
gd loss = 42404.99059599207
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42400.31178858424
gradient descent iteration = 6
gd loss = 42400.31178858424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42395.81120636445
gradient descent iteration = 7
gd loss = 42395.81120636445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42391.46681296022
gradient descent iteration = 8
gd loss = 42391.46681296022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42387.26165807305
gradient descent iteration = 9
gd loss = 42387.26165807305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42383.18213410586
gradient descent iteration = 10
gd loss = 42383.18213410586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42379.21702188114
gradient descent iteration = 11
gd loss = 42379.21702188114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42375.35687710212
gradient descent iteration = 12
gd loss = 42375.35687710212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42371.59362380568
gradient descent iteration = 13
gd loss = 42371.59362380568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42367.9202659313
gradient descent iteration = 14
gd loss = 42367.9202659313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42364.33067693373
gradient descent iteration = 15
gd loss = 42364.33067693373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42360.81944091674
gradient descent iteration = 16
gd loss = 42360.81944091674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42357.38173114644
gradient descent iteration = 17
gd loss = 42357.38173114644
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42354.01321653992
gradient descent iteration = 18
gd loss = 42354.01321653992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42350.70999248163
gradient descent iteration = 19
gd loss = 42350.70999248163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42347.4685140189
gradient descent iteration = 20
gd loss = 42347.4685140189
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42344.28554239059
gradient descent iteration = 21
gd loss = 42344.28554239059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42341.15810670186
gradient descent iteration = 22
gd loss = 42341.15810670186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42338.0834727071
gradient descent iteration = 23
gd loss = 42338.0834727071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42335.05911508311
gradient descent iteration = 24
gd loss = 42335.05911508311
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42332.08269502808
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 42332.08269502808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42327.24335722139
gradient descent iteration = 1
gd loss = 42327.24335722139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42322.87902413711
gradient descent iteration = 2
gd loss = 42322.87902413711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42318.81507216716
gradient descent iteration = 3
gd loss = 42318.81507216716
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42314.97870209948
gradient descent iteration = 4
gd loss = 42314.97870209948
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42311.32628991398
gradient descent iteration = 5
gd loss = 42311.32628991398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42307.82749171476
gradient descent iteration = 6
gd loss = 42307.82749171476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42304.45982852366
gradient descent iteration = 7
gd loss = 42304.45982852366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42301.20606134223
gradient descent iteration = 8
gd loss = 42301.20606134223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42298.05264387557
gradient descent iteration = 9
gd loss = 42298.05264387557
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42294.98872573089
gradient descent iteration = 10
gd loss = 42294.98872573089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42292.00547024026
gradient descent iteration = 11
gd loss = 42292.00547024026
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42289.09556917335
gradient descent iteration = 12
gd loss = 42289.09556917335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42286.25289151198
gradient descent iteration = 13
gd loss = 42286.25289151198
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42283.47222511789
gradient descent iteration = 14
gd loss = 42283.47222511789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42280.74908415708
gradient descent iteration = 15
gd loss = 42280.74908415708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42278.07956397528
gradient descent iteration = 16
gd loss = 42278.07956397528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42275.46023059725
gradient descent iteration = 17
gd loss = 42275.46023059725
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42272.88803532707
gradient descent iteration = 18
gd loss = 42272.88803532707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42270.36024848438
gradient descent iteration = 19
gd loss = 42270.36024848438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42267.87440862508
gradient descent iteration = 20
gd loss = 42267.87440862508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42265.42828181673
gradient descent iteration = 21
gd loss = 42265.42828181673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42263.01982901419
gradient descent iteration = 22
gd loss = 42263.01982901419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42260.64717973751
gradient descent iteration = 23
gd loss = 42260.64717973751
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42258.30861064866
gradient descent iteration = 24
gd loss = 42258.30861064866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42256.00252794541
Initial loss = 42671.08215307793
Final loss = 42256.00252794541
Deformation gradient control sequence optimization finished.
Animation interval 26 took 1340 seconds.
Full animation took 37229 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 27************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 43033.8673660433
initial norm = 375.1283194442977
convergence norm = 0.3751283194442978
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 43033.8673660433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43004.6169934922
gradient descent iteration = 1
gd loss = 43004.6169934922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42982.44427535494
gradient descent iteration = 2
gd loss = 42982.44427535494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42965.03539007642
gradient descent iteration = 3
gd loss = 42965.03539007642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42950.95216013305
gradient descent iteration = 4
gd loss = 42950.95216013305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42938.98560727279
gradient descent iteration = 5
gd loss = 42938.98560727279
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42929.1469147082
gradient descent iteration = 6
gd loss = 42929.1469147082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42923.66612589105
gradient descent iteration = 7
gd loss = 42923.66612589105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42918.56286592292
gradient descent iteration = 8
gd loss = 42918.56286592292
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42913.36416943395
gradient descent iteration = 9
gd loss = 42913.36416943395
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42908.46355678119
gradient descent iteration = 10
gd loss = 42908.46355678119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42903.51759248335
gradient descent iteration = 11
gd loss = 42903.51759248335
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42898.79188448268
gradient descent iteration = 12
gd loss = 42898.79188448268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42894.02130747931
gradient descent iteration = 13
gd loss = 42894.02130747931
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42889.44511927194
gradient descent iteration = 14
gd loss = 42889.44511927194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42884.81958732648
gradient descent iteration = 15
gd loss = 42884.81958732648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42880.38194863347
gradient descent iteration = 16
gd loss = 42880.38194863347
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42875.89349758308
gradient descent iteration = 17
gd loss = 42875.89349758308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42871.59466999748
gradient descent iteration = 18
gd loss = 42871.59466999748
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42867.2467480433
gradient descent iteration = 19
gd loss = 42867.2467480433
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42863.09328501662
gradient descent iteration = 20
gd loss = 42863.09328501662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42858.89207966187
gradient descent iteration = 21
gd loss = 42858.89207966187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42854.88761970511
gradient descent iteration = 22
gd loss = 42854.88761970511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42850.83418076605
gradient descent iteration = 23
gd loss = 42850.83418076605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42846.97656950345
gradient descent iteration = 24
gd loss = 42846.97656950345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42843.06571085911
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 42843.06571085911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42833.31057816654
gradient descent iteration = 1
gd loss = 42833.31057816654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42827.58738725828
gradient descent iteration = 2
gd loss = 42827.58738725828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42822.63725221507
gradient descent iteration = 3
gd loss = 42822.63725221507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42818.03160213341
gradient descent iteration = 4
gd loss = 42818.03160213341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42813.66842422224
gradient descent iteration = 5
gd loss = 42813.66842422224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42809.50032609237
gradient descent iteration = 6
gd loss = 42809.50032609237
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42805.49721618315
gradient descent iteration = 7
gd loss = 42805.49721618315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42801.63733455091
gradient descent iteration = 8
gd loss = 42801.63733455091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42797.90400455507
gradient descent iteration = 9
gd loss = 42797.90400455507
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42794.28391738634
gradient descent iteration = 10
gd loss = 42794.28391738634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42790.76615622408
gradient descent iteration = 11
gd loss = 42790.76615622408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42787.34157663522
gradient descent iteration = 12
gd loss = 42787.34157663522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42784.00239604864
gradient descent iteration = 13
gd loss = 42784.00239604864
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42780.74190474426
gradient descent iteration = 14
gd loss = 42780.74190474426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42777.55426024873
gradient descent iteration = 15
gd loss = 42777.55426024873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42774.43433422229
gradient descent iteration = 16
gd loss = 42774.43433422229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42771.37759377564
gradient descent iteration = 17
gd loss = 42771.37759377564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42768.3800085425
gradient descent iteration = 18
gd loss = 42768.3800085425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42765.4379764732
gradient descent iteration = 19
gd loss = 42765.4379764732
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42762.54826362149
gradient descent iteration = 20
gd loss = 42762.54826362149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42759.70795461323
gradient descent iteration = 21
gd loss = 42759.70795461323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42756.91441140522
gradient descent iteration = 22
gd loss = 42756.91441140522
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42754.16523862755
gradient descent iteration = 23
gd loss = 42754.16523862755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42751.45825351046
gradient descent iteration = 24
gd loss = 42751.45825351046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42748.79146039408
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 42748.79146039408
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42744.01003762212
gradient descent iteration = 1
gd loss = 42744.01003762212
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42739.71775956066
gradient descent iteration = 2
gd loss = 42739.71775956066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42735.7475305662
gradient descent iteration = 3
gd loss = 42735.7475305662
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42732.02109747962
gradient descent iteration = 4
gd loss = 42732.02109747962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42728.49124546165
gradient descent iteration = 5
gd loss = 42728.49124546165
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42725.12549248544
gradient descent iteration = 6
gd loss = 42725.12549248544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42721.89985041714
gradient descent iteration = 7
gd loss = 42721.89985041714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42718.79584070648
gradient descent iteration = 8
gd loss = 42718.79584070648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42715.79882463704
gradient descent iteration = 9
gd loss = 42715.79882463704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42712.89696451174
gradient descent iteration = 10
gd loss = 42712.89696451174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42710.08053008554
gradient descent iteration = 11
gd loss = 42710.08053008554
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42707.34141178413
gradient descent iteration = 12
gd loss = 42707.34141178413
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42704.67276783032
gradient descent iteration = 13
gd loss = 42704.67276783032
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42702.0687623227
gradient descent iteration = 14
gd loss = 42702.0687623227
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42699.52436746174
gradient descent iteration = 15
gd loss = 42699.52436746174
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42697.03521195089
gradient descent iteration = 16
gd loss = 42697.03521195089
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42694.5974633673
gradient descent iteration = 17
gd loss = 42694.5974633673
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42692.2077359914
gradient descent iteration = 18
gd loss = 42692.2077359914
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42689.86301783861
gradient descent iteration = 19
gd loss = 42689.86301783861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42687.56061239701
gradient descent iteration = 20
gd loss = 42687.56061239701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42685.2980914488
gradient descent iteration = 21
gd loss = 42685.2980914488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42683.07325686768
gradient descent iteration = 22
gd loss = 42683.07325686768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42680.88410935649
gradient descent iteration = 23
gd loss = 42680.88410935649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42678.72882266899
gradient descent iteration = 24
gd loss = 42678.72882266899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 42676.60572211252
Initial loss = 43033.8673660433
Final loss = 42676.60572211252
Deformation gradient control sequence optimization finished.
Animation interval 27 took 1337 seconds.
Full animation took 38567 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 28************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 43479.12357908954
initial norm = 338.4607546598513
convergence norm = 0.3384607546598513
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 43479.12357908954
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43452.63872147728
gradient descent iteration = 1
gd loss = 43452.63872147728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43433.26612843182
gradient descent iteration = 2
gd loss = 43433.26612843182
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43418.37121968006
gradient descent iteration = 3
gd loss = 43418.37121968006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43406.44740848571
gradient descent iteration = 4
gd loss = 43406.44740848571
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43397.41801218539
gradient descent iteration = 5
gd loss = 43397.41801218539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43393.03679301845
gradient descent iteration = 6
gd loss = 43393.03679301845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43388.20591571421
gradient descent iteration = 7
gd loss = 43388.20591571421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43383.95964544568
gradient descent iteration = 8
gd loss = 43383.95964544568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43379.65263602457
gradient descent iteration = 9
gd loss = 43379.65263602457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43375.63850857647
gradient descent iteration = 10
gd loss = 43375.63850857647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43371.6372609145
gradient descent iteration = 11
gd loss = 43371.6372609145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43367.82040010585
gradient descent iteration = 12
gd loss = 43367.82040010585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43364.03115293734
gradient descent iteration = 13
gd loss = 43364.03115293734
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43360.37968501094
gradient descent iteration = 14
gd loss = 43360.37968501094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43356.75345841875
gradient descent iteration = 15
gd loss = 43356.75345841875
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43353.24220078473
gradient descent iteration = 16
gd loss = 43353.24220078473
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43349.74898806614
gradient descent iteration = 17
gd loss = 43349.74898806614
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43346.35827673383
gradient descent iteration = 18
gd loss = 43346.35827673383
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43342.97747551605
gradient descent iteration = 19
gd loss = 43342.97747551605
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43339.69174952011
gradient descent iteration = 20
gd loss = 43339.69174952011
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43336.40807434043
gradient descent iteration = 21
gd loss = 43336.40807434043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43333.21478734723
gradient descent iteration = 22
gd loss = 43333.21478734723
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43330.0162913294
gradient descent iteration = 23
gd loss = 43330.0162913294
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43326.90513807369
gradient descent iteration = 24
gd loss = 43326.90513807369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43323.7821449655
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 43323.7821449655
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43314.51009900122
gradient descent iteration = 1
gd loss = 43314.51009900122
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43309.60200940879
gradient descent iteration = 2
gd loss = 43309.60200940879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43305.4288323906
gradient descent iteration = 3
gd loss = 43305.4288323906
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43301.55004342075
gradient descent iteration = 4
gd loss = 43301.55004342075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43297.86901377805
gradient descent iteration = 5
gd loss = 43297.86901377805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43294.34289702959
gradient descent iteration = 6
gd loss = 43294.34289702959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43290.94519953179
gradient descent iteration = 7
gd loss = 43290.94519953179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43287.65711779577
gradient descent iteration = 8
gd loss = 43287.65711779577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43284.46448680606
gradient descent iteration = 9
gd loss = 43284.46448680606
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43281.35619942924
gradient descent iteration = 10
gd loss = 43281.35619942924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43278.3233142587
gradient descent iteration = 11
gd loss = 43278.3233142587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43275.35848773423
gradient descent iteration = 12
gd loss = 43275.35848773423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43272.4555957424
gradient descent iteration = 13
gd loss = 43272.4555957424
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43269.60946741475
gradient descent iteration = 14
gd loss = 43269.60946741475
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43266.81569138933
gradient descent iteration = 15
gd loss = 43266.81569138933
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43264.0704706996
gradient descent iteration = 16
gd loss = 43264.0704706996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43261.37051186566
gradient descent iteration = 17
gd loss = 43261.37051186566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43258.71293809367
gradient descent iteration = 18
gd loss = 43258.71293809367
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43256.09522071733
gradient descent iteration = 19
gd loss = 43256.09522071733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43253.51512479144
gradient descent iteration = 20
gd loss = 43253.51512479144
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43250.97066450601
gradient descent iteration = 21
gd loss = 43250.97066450601
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43248.46006660981
gradient descent iteration = 22
gd loss = 43248.46006660981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43245.9817404821
gradient descent iteration = 23
gd loss = 43245.9817404821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43243.53425300882
gradient descent iteration = 24
gd loss = 43243.53425300882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43241.11630728978
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 43241.11630728978
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43237.49131315138
gradient descent iteration = 1
gd loss = 43237.49131315138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43234.17579959468
gradient descent iteration = 2
gd loss = 43234.17579959468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43231.06091509739
gradient descent iteration = 3
gd loss = 43231.06091509739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43228.09465863501
gradient descent iteration = 4
gd loss = 43228.09465863501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43225.24603873597
gradient descent iteration = 5
gd loss = 43225.24603873597
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43222.49417645139
gradient descent iteration = 6
gd loss = 43222.49417645139
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43219.82405418521
gradient descent iteration = 7
gd loss = 43219.82405418521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43217.22446716129
gradient descent iteration = 8
gd loss = 43217.22446716129
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43214.68685976488
gradient descent iteration = 9
gd loss = 43214.68685976488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43212.20458709843
gradient descent iteration = 10
gd loss = 43212.20458709843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43209.77241243821
gradient descent iteration = 11
gd loss = 43209.77241243821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43207.38615173147
gradient descent iteration = 12
gd loss = 43207.38615173147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43205.04241585969
gradient descent iteration = 13
gd loss = 43205.04241585969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43202.73842145448
gradient descent iteration = 14
gd loss = 43202.73842145448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43200.47185031773
gradient descent iteration = 15
gd loss = 43200.47185031773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43198.24074357888
gradient descent iteration = 16
gd loss = 43198.24074357888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43196.04342177285
gradient descent iteration = 17
gd loss = 43196.04342177285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43193.87842410607
gradient descent iteration = 18
gd loss = 43193.87842410607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43191.74446206056
gradient descent iteration = 19
gd loss = 43191.74446206056
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43189.64038376706
gradient descent iteration = 20
gd loss = 43189.64038376706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43187.56514451058
gradient descent iteration = 21
gd loss = 43187.56514451058
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43185.51777646549
gradient descent iteration = 22
gd loss = 43185.51777646549
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43183.49737899851
gradient descent iteration = 23
gd loss = 43183.49737899851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43181.50311267779
gradient descent iteration = 24
gd loss = 43181.50311267779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43179.53418818175
Initial loss = 43479.12357908954
Final loss = 43179.53418818175
Deformation gradient control sequence optimization finished.
Animation interval 28 took 1332 seconds.
Full animation took 39899 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 29************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 43997.47378878832
initial norm = 345.0827894291381
convergence norm = 0.3450827894291381
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 43997.47378878832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43971.67067746899
gradient descent iteration = 1
gd loss = 43971.67067746899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43952.159007352
gradient descent iteration = 2
gd loss = 43952.159007352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43936.98530583369
gradient descent iteration = 3
gd loss = 43936.98530583369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43925.23778857736
gradient descent iteration = 4
gd loss = 43925.23778857736
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43917.67156898289
gradient descent iteration = 5
gd loss = 43917.67156898289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43913.09747977738
gradient descent iteration = 6
gd loss = 43913.09747977738
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43907.49265225186
gradient descent iteration = 7
gd loss = 43907.49265225186
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43902.8457818098
gradient descent iteration = 8
gd loss = 43902.8457818098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43897.87939168041
gradient descent iteration = 9
gd loss = 43897.87939168041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43893.35178839458
gradient descent iteration = 10
gd loss = 43893.35178839458
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43888.65608483552
gradient descent iteration = 11
gd loss = 43888.65608483552
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43884.24928392153
gradient descent iteration = 12
gd loss = 43884.24928392153
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43879.70206192112
gradient descent iteration = 13
gd loss = 43879.70206192112
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43875.39408371913
gradient descent iteration = 14
gd loss = 43875.39408371913
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43870.94595563791
gradient descent iteration = 15
gd loss = 43870.94595563791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43866.72069241336
gradient descent iteration = 16
gd loss = 43866.72069241336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43862.35159672767
gradient descent iteration = 17
gd loss = 43862.35159672767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43858.20182031755
gradient descent iteration = 18
gd loss = 43858.20182031755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43853.90557832892
gradient descent iteration = 19
gd loss = 43853.90557832892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43849.83017420711
gradient descent iteration = 20
gd loss = 43849.83017420711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43845.60658110215
gradient descent iteration = 21
gd loss = 43845.60658110215
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43841.60660581922
gradient descent iteration = 22
gd loss = 43841.60660581922
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43837.45642615402
gradient descent iteration = 23
gd loss = 43837.45642615402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43833.53195064876
gradient descent iteration = 24
gd loss = 43833.53195064876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43829.4542021607
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 43829.4542021607
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43819.83526543099
gradient descent iteration = 1
gd loss = 43819.83526543099
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43813.97234300883
gradient descent iteration = 2
gd loss = 43813.97234300883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43808.90312392628
gradient descent iteration = 3
gd loss = 43808.90312392628
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43804.15674641528
gradient descent iteration = 4
gd loss = 43804.15674641528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43799.62349170025
gradient descent iteration = 5
gd loss = 43799.62349170025
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43795.25812046151
gradient descent iteration = 6
gd loss = 43795.25812046151
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43791.0340924019
gradient descent iteration = 7
gd loss = 43791.0340924019
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43786.93272892664
gradient descent iteration = 8
gd loss = 43786.93272892664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43782.93998710863
gradient descent iteration = 9
gd loss = 43782.93998710863
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43779.04481934749
gradient descent iteration = 10
gd loss = 43779.04481934749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43775.23831735687
gradient descent iteration = 11
gd loss = 43775.23831735687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43771.51315215755
gradient descent iteration = 12
gd loss = 43771.51315215755
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43767.8632046108
gradient descent iteration = 13
gd loss = 43767.8632046108
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43764.28329784666
gradient descent iteration = 14
gd loss = 43764.28329784666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43760.76899963481
gradient descent iteration = 15
gd loss = 43760.76899963481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43757.3164704471
gradient descent iteration = 16
gd loss = 43757.3164704471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43753.92234510161
gradient descent iteration = 17
gd loss = 43753.92234510161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43750.58363943622
gradient descent iteration = 18
gd loss = 43750.58363943622
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43747.2976765018
gradient descent iteration = 19
gd loss = 43747.2976765018
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43744.06202818987
gradient descent iteration = 20
gd loss = 43744.06202818987
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43740.87446963332
gradient descent iteration = 21
gd loss = 43740.87446963332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43737.73294508472
gradient descent iteration = 22
gd loss = 43737.73294508472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43734.63555210574
gradient descent iteration = 23
gd loss = 43734.63555210574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43731.58051858511
gradient descent iteration = 24
gd loss = 43731.58051858511
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43728.56617353411
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 43728.56617353411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43723.68636610897
gradient descent iteration = 1
gd loss = 43723.68636610897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43719.17798955827
gradient descent iteration = 2
gd loss = 43719.17798955827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43714.91365747435
gradient descent iteration = 3
gd loss = 43714.91365747435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43710.83531920397
gradient descent iteration = 4
gd loss = 43710.83531920397
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43706.90921458457
gradient descent iteration = 5
gd loss = 43706.90921458457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43703.11286509701
gradient descent iteration = 6
gd loss = 43703.11286509701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43699.42993535923
gradient descent iteration = 7
gd loss = 43699.42993535923
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43695.84801453415
gradient descent iteration = 8
gd loss = 43695.84801453415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43692.35741250651
gradient descent iteration = 9
gd loss = 43692.35741250651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43688.9504244378
gradient descent iteration = 10
gd loss = 43688.9504244378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43685.62082689317
gradient descent iteration = 11
gd loss = 43685.62082689317
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43682.36350828905
gradient descent iteration = 12
gd loss = 43682.36350828905
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43679.17421245603
gradient descent iteration = 13
gd loss = 43679.17421245603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43676.04933862268
gradient descent iteration = 14
gd loss = 43676.04933862268
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43672.98578860616
gradient descent iteration = 15
gd loss = 43672.98578860616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43669.98085813264
gradient descent iteration = 16
gd loss = 43669.98085813264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43667.03214589254
gradient descent iteration = 17
gd loss = 43667.03214589254
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43664.13748287947
gradient descent iteration = 18
gd loss = 43664.13748287947
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43661.29488177832
gradient descent iteration = 19
gd loss = 43661.29488177832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43658.50250000798
gradient descent iteration = 20
gd loss = 43658.50250000798
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43655.75860970562
gradient descent iteration = 21
gd loss = 43655.75860970562
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43653.0615740393
gradient descent iteration = 22
gd loss = 43653.0615740393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43650.40983257983
gradient descent iteration = 23
gd loss = 43650.40983257983
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43647.8018886568
gradient descent iteration = 24
gd loss = 43647.8018886568
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43645.23629948613
Initial loss = 43997.47378878832
Final loss = 43645.23629948613
Deformation gradient control sequence optimization finished.
Animation interval 29 took 1330 seconds.
Full animation took 41230 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 30************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 44446.87115105688
initial norm = 321.1532585796046
convergence norm = 0.3211532585796046
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 44446.87115105688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44421.33801531179
gradient descent iteration = 1
gd loss = 44421.33801531179
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44401.17815307745
gradient descent iteration = 2
gd loss = 44401.17815307745
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44384.56574309422
gradient descent iteration = 3
gd loss = 44384.56574309422
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44370.4506937528
gradient descent iteration = 4
gd loss = 44370.4506937528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44358.53591953904
gradient descent iteration = 5
gd loss = 44358.53591953904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44349.73995121373
gradient descent iteration = 6
gd loss = 44349.73995121373
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44342.58456422157
gradient descent iteration = 7
gd loss = 44342.58456422157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44335.41660902891
gradient descent iteration = 8
gd loss = 44335.41660902891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44328.37161905781
gradient descent iteration = 9
gd loss = 44328.37161905781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44321.57619581358
gradient descent iteration = 10
gd loss = 44321.57619581358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44314.76430060677
gradient descent iteration = 11
gd loss = 44314.76430060677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44308.22746811654
gradient descent iteration = 12
gd loss = 44308.22746811654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44301.6630587521
gradient descent iteration = 13
gd loss = 44301.6630587521
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44295.38165462074
gradient descent iteration = 14
gd loss = 44295.38165462074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44289.06463287125
gradient descent iteration = 15
gd loss = 44289.06463287125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44283.02420584167
gradient descent iteration = 16
gd loss = 44283.02420584167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44276.92970938767
gradient descent iteration = 17
gd loss = 44276.92970938767
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44271.10065704166
gradient descent iteration = 18
gd loss = 44271.10065704166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44265.20057250185
gradient descent iteration = 19
gd loss = 44265.20057250185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44259.56165808281
gradient descent iteration = 20
gd loss = 44259.56165808281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44253.84238256772
gradient descent iteration = 21
gd loss = 44253.84238256772
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44248.38673409809
gradient descent iteration = 22
gd loss = 44248.38673409809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44242.84604797587
gradient descent iteration = 23
gd loss = 44242.84604797587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44237.57348736882
gradient descent iteration = 24
gd loss = 44237.57348736882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44232.21128202508
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 44232.21128202508
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44220.9687730343
gradient descent iteration = 1
gd loss = 44220.9687730343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44213.8351572981
gradient descent iteration = 2
gd loss = 44213.8351572981
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44207.51617789701
gradient descent iteration = 3
gd loss = 44207.51617789701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44201.57091520082
gradient descent iteration = 4
gd loss = 44201.57091520082
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44195.89120971008
gradient descent iteration = 5
gd loss = 44195.89120971008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44190.42631504612
gradient descent iteration = 6
gd loss = 44190.42631504612
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44185.14435910465
gradient descent iteration = 7
gd loss = 44185.14435910465
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44180.02249215784
gradient descent iteration = 8
gd loss = 44180.02249215784
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44175.04337409579
gradient descent iteration = 9
gd loss = 44175.04337409579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44170.19331831832
gradient descent iteration = 10
gd loss = 44170.19331831832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44165.46122980503
gradient descent iteration = 11
gd loss = 44165.46122980503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44160.83793225114
gradient descent iteration = 12
gd loss = 44160.83793225114
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44156.31571966882
gradient descent iteration = 13
gd loss = 44156.31571966882
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44151.88803427536
gradient descent iteration = 14
gd loss = 44151.88803427536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44147.54923216502
gradient descent iteration = 15
gd loss = 44147.54923216502
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44143.29439371845
gradient descent iteration = 16
gd loss = 44143.29439371845
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44139.11918947773
gradient descent iteration = 17
gd loss = 44139.11918947773
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44135.01977332885
gradient descent iteration = 18
gd loss = 44135.01977332885
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44130.99269048943
gradient descent iteration = 19
gd loss = 44130.99269048943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44127.03480628167
gradient descent iteration = 20
gd loss = 44127.03480628167
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44123.14325443307
gradient descent iteration = 21
gd loss = 44123.14325443307
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44119.31539354305
gradient descent iteration = 22
gd loss = 44119.31539354305
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44115.54877213888
gradient descent iteration = 23
gd loss = 44115.54877213888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44111.84109869197
gradient descent iteration = 24
gd loss = 44111.84109869197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44108.19022236211
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 44108.19022236211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44100.32485304388
gradient descent iteration = 1
gd loss = 44100.32485304388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44093.14117648586
gradient descent iteration = 2
gd loss = 44093.14117648586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44086.41903480669
gradient descent iteration = 3
gd loss = 44086.41903480669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44080.05839336567
gradient descent iteration = 4
gd loss = 44080.05839336567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44074.00113547059
gradient descent iteration = 5
gd loss = 44074.00113547059
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44068.20775999238
gradient descent iteration = 6
gd loss = 44068.20775999238
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44062.64877249752
gradient descent iteration = 7
gd loss = 44062.64877249752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44057.30087606653
gradient descent iteration = 8
gd loss = 44057.30087606653
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44052.14499669834
gradient descent iteration = 9
gd loss = 44052.14499669834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44047.1651300493
gradient descent iteration = 10
gd loss = 44047.1651300493
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44042.34759965359
gradient descent iteration = 11
gd loss = 44042.34759965359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44037.68055301386
gradient descent iteration = 12
gd loss = 44037.68055301386
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44033.15360152497
gradient descent iteration = 13
gd loss = 44033.15360152497
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44028.75755437361
gradient descent iteration = 14
gd loss = 44028.75755437361
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44024.48421505296
gradient descent iteration = 15
gd loss = 44024.48421505296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44020.32622611407
gradient descent iteration = 16
gd loss = 44020.32622611407
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44016.27694608038
gradient descent iteration = 17
gd loss = 44016.27694608038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44012.33034545041
gradient descent iteration = 18
gd loss = 44012.33034545041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44008.48092423791
gradient descent iteration = 19
gd loss = 44008.48092423791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44004.72364422645
gradient descent iteration = 20
gd loss = 44004.72364422645
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44001.05387297896
gradient descent iteration = 21
gd loss = 44001.05387297896
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43997.46733672717
gradient descent iteration = 22
gd loss = 43997.46733672717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43993.96007988138
gradient descent iteration = 23
gd loss = 43993.96007988138
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43990.52842987287
gradient descent iteration = 24
gd loss = 43990.52842987287
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 43987.16896826617
Initial loss = 44446.87115105688
Final loss = 43987.16896826617
Deformation gradient control sequence optimization finished.
Animation interval 30 took 1333 seconds.
Full animation took 42563 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 31************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 44795.14009265789
initial norm = 335.6677503172118
convergence norm = 0.3356677503172118
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 44795.14009265789
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44767.46487729654
gradient descent iteration = 1
gd loss = 44767.46487729654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44746.33191749838
gradient descent iteration = 2
gd loss = 44746.33191749838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44728.98478629506
gradient descent iteration = 3
gd loss = 44728.98478629506
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44714.11542467687
gradient descent iteration = 4
gd loss = 44714.11542467687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44700.76000859211
gradient descent iteration = 5
gd loss = 44700.76000859211
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44688.33280067774
gradient descent iteration = 6
gd loss = 44688.33280067774
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44676.55556173358
gradient descent iteration = 7
gd loss = 44676.55556173358
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44665.51094268411
gradient descent iteration = 8
gd loss = 44665.51094268411
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44656.52948386585
gradient descent iteration = 9
gd loss = 44656.52948386585
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44651.71463477805
gradient descent iteration = 10
gd loss = 44651.71463477805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44645.84373852566
gradient descent iteration = 11
gd loss = 44645.84373852566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44640.78215845066
gradient descent iteration = 12
gd loss = 44640.78215845066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44635.41517678926
gradient descent iteration = 13
gd loss = 44635.41517678926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44630.47596140532
gradient descent iteration = 14
gd loss = 44630.47596140532
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44625.38251721148
gradient descent iteration = 15
gd loss = 44625.38251721148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44620.62373915761
gradient descent iteration = 16
gd loss = 44620.62373915761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44615.73676359107
gradient descent iteration = 17
gd loss = 44615.73676359107
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44611.15704162319
gradient descent iteration = 18
gd loss = 44611.15704162319
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44606.44675571599
gradient descent iteration = 19
gd loss = 44606.44675571599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44602.03366181126
gradient descent iteration = 20
gd loss = 44602.03366181126
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44597.4813107196
gradient descent iteration = 21
gd loss = 44597.4813107196
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44593.22151009733
gradient descent iteration = 22
gd loss = 44593.22151009733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44588.81276211531
gradient descent iteration = 23
gd loss = 44588.81276211531
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44584.69403750326
gradient descent iteration = 24
gd loss = 44584.69403750326
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44580.41697740369
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 44580.41697740369
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44569.64568057593
gradient descent iteration = 1
gd loss = 44569.64568057593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44562.91767963401
gradient descent iteration = 2
gd loss = 44562.91767963401
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44557.03517051478
gradient descent iteration = 3
gd loss = 44557.03517051478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44551.55909998648
gradient descent iteration = 4
gd loss = 44551.55909998648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44546.37895905711
gradient descent iteration = 5
gd loss = 44546.37895905711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44541.44168735022
gradient descent iteration = 6
gd loss = 44541.44168735022
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44536.7131355555
gradient descent iteration = 7
gd loss = 44536.7131355555
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44532.16826092681
gradient descent iteration = 8
gd loss = 44532.16826092681
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44527.78760105561
gradient descent iteration = 9
gd loss = 44527.78760105561
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44523.55539973718
gradient descent iteration = 10
gd loss = 44523.55539973718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44519.45855424707
gradient descent iteration = 11
gd loss = 44519.45855424707
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44515.48593925901
gradient descent iteration = 12
gd loss = 44515.48593925901
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44511.62795752256
gradient descent iteration = 13
gd loss = 44511.62795752256
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44507.87622184253
gradient descent iteration = 14
gd loss = 44507.87622184253
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44504.22332476964
gradient descent iteration = 15
gd loss = 44504.22332476964
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44500.66266646348
gradient descent iteration = 16
gd loss = 44500.66266646348
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44497.18832312385
gradient descent iteration = 17
gd loss = 44497.18832312385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44493.79494684409
gradient descent iteration = 18
gd loss = 44493.79494684409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44490.47768607517
gradient descent iteration = 19
gd loss = 44490.47768607517
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44487.23212137543
gradient descent iteration = 20
gd loss = 44487.23212137543
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44484.05421284551
gradient descent iteration = 21
gd loss = 44484.05421284551
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44480.94025648968
gradient descent iteration = 22
gd loss = 44480.94025648968
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44477.88684737469
gradient descent iteration = 23
gd loss = 44477.88684737469
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44474.89084801336
gradient descent iteration = 24
gd loss = 44474.89084801336
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44471.94936120075
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 44471.94936120075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44467.54115532274
gradient descent iteration = 1
gd loss = 44467.54115532274
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44463.5876370428
gradient descent iteration = 2
gd loss = 44463.5876370428
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44459.9382791771
gradient descent iteration = 3
gd loss = 44459.9382791771
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44456.51702262776
gradient descent iteration = 4
gd loss = 44456.51702262776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44453.27782904046
gradient descent iteration = 5
gd loss = 44453.27782904046
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44450.18942995102
gradient descent iteration = 6
gd loss = 44450.18942995102
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44447.22901854147
gradient descent iteration = 7
gd loss = 44447.22901854147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44444.37920202263
gradient descent iteration = 8
gd loss = 44444.37920202263
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44441.62632186721
gradient descent iteration = 9
gd loss = 44441.62632186721
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44438.95942435387
gradient descent iteration = 10
gd loss = 44438.95942435387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44436.36957867975
gradient descent iteration = 11
gd loss = 44436.36957867975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44433.84940126398
gradient descent iteration = 12
gd loss = 44433.84940126398
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44431.39271273474
gradient descent iteration = 13
gd loss = 44431.39271273474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44428.99428404337
gradient descent iteration = 14
gd loss = 44428.99428404337
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44426.64964177649
gradient descent iteration = 15
gd loss = 44426.64964177649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44424.3549082598
gradient descent iteration = 16
gd loss = 44424.3549082598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44422.10670197687
gradient descent iteration = 17
gd loss = 44422.10670197687
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44419.90205655275
gradient descent iteration = 18
gd loss = 44419.90205655275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44417.73835052471
gradient descent iteration = 19
gd loss = 44417.73835052471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44415.61325066035
gradient descent iteration = 20
gd loss = 44415.61325066035
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44413.52466759404
gradient descent iteration = 21
gd loss = 44413.52466759404
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44411.470720385
gradient descent iteration = 22
gd loss = 44411.470720385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44409.44970767908
gradient descent iteration = 23
gd loss = 44409.44970767908
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44407.46008267224
gradient descent iteration = 24
gd loss = 44407.46008267224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44405.50043236095
Initial loss = 44795.14009265789
Final loss = 44405.50043236095
Deformation gradient control sequence optimization finished.
Animation interval 31 took 1333 seconds.
Full animation took 43896 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 32************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 45226.78107258713
initial norm = 327.7919768231664
convergence norm = 0.3277919768231664
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 45226.78107258713
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45199.9112831823
gradient descent iteration = 1
gd loss = 45199.9112831823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45179.99072299904
gradient descent iteration = 2
gd loss = 45179.99072299904
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45164.16264437691
gradient descent iteration = 3
gd loss = 45164.16264437691
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45150.89463808679
gradient descent iteration = 4
gd loss = 45150.89463808679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45139.02296014962
gradient descent iteration = 5
gd loss = 45139.02296014962
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45128.64712588701
gradient descent iteration = 6
gd loss = 45128.64712588701
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45122.01492645672
gradient descent iteration = 7
gd loss = 45122.01492645672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45116.31797614647
gradient descent iteration = 8
gd loss = 45116.31797614647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45110.39162077735
gradient descent iteration = 9
gd loss = 45110.39162077735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45104.53372495121
gradient descent iteration = 10
gd loss = 45104.53372495121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45098.93989574234
gradient descent iteration = 11
gd loss = 45098.93989574234
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45093.1981937956
gradient descent iteration = 12
gd loss = 45093.1981937956
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45087.81522734657
gradient descent iteration = 13
gd loss = 45087.81522734657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45082.24628263029
gradient descent iteration = 14
gd loss = 45082.24628263029
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45077.0455463623
gradient descent iteration = 15
gd loss = 45077.0455463623
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45071.65879370111
gradient descent iteration = 16
gd loss = 45071.65879370111
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45066.63175166539
gradient descent iteration = 17
gd loss = 45066.63175166539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45061.42385714095
gradient descent iteration = 18
gd loss = 45061.42385714095
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45056.56917105158
gradient descent iteration = 19
gd loss = 45056.56917105158
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45051.53426658765
gradient descent iteration = 20
gd loss = 45051.53426658765
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45046.8478141694
gradient descent iteration = 21
gd loss = 45046.8478141694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45041.97524142038
gradient descent iteration = 22
gd loss = 45041.97524142038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45037.44480959357
gradient descent iteration = 23
gd loss = 45037.44480959357
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45032.71444158426
gradient descent iteration = 24
gd loss = 45032.71444158426
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45028.31670052281
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 45028.31670052281
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45017.03547958708
gradient descent iteration = 1
gd loss = 45017.03547958708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45010.06991249924
gradient descent iteration = 2
gd loss = 45010.06991249924
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45003.94575923915
gradient descent iteration = 3
gd loss = 45003.94575923915
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44998.26348864946
gradient descent iteration = 4
gd loss = 44998.26348864946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44992.91816518876
gradient descent iteration = 5
gd loss = 44992.91816518876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44987.85199147476
gradient descent iteration = 6
gd loss = 44987.85199147476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44983.02314600815
gradient descent iteration = 7
gd loss = 44983.02314600815
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44978.39918506743
gradient descent iteration = 8
gd loss = 44978.39918506743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44973.95405946091
gradient descent iteration = 9
gd loss = 44973.95405946091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44969.66649345843
gradient descent iteration = 10
gd loss = 44969.66649345843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44965.51890301969
gradient descent iteration = 11
gd loss = 44965.51890301969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44961.49667027598
gradient descent iteration = 12
gd loss = 44961.49667027598
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44957.58761391743
gradient descent iteration = 13
gd loss = 44957.58761391743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44953.78156251409
gradient descent iteration = 14
gd loss = 44953.78156251409
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44950.06994519421
gradient descent iteration = 15
gd loss = 44950.06994519421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44946.44561104679
gradient descent iteration = 16
gd loss = 44946.44561104679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44942.90267318297
gradient descent iteration = 17
gd loss = 44942.90267318297
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44939.43631654499
gradient descent iteration = 18
gd loss = 44939.43631654499
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44936.04262026304
gradient descent iteration = 19
gd loss = 44936.04262026304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44932.71839682134
gradient descent iteration = 20
gd loss = 44932.71839682134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44929.46104542741
gradient descent iteration = 21
gd loss = 44929.46104542741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44926.26841155916
gradient descent iteration = 22
gd loss = 44926.26841155916
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44923.13865360898
gradient descent iteration = 23
gd loss = 44923.13865360898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44920.07014753633
gradient descent iteration = 24
gd loss = 44920.07014753633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44917.0613892197
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 44917.0613892197
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44912.02998717624
gradient descent iteration = 1
gd loss = 44912.02998717624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44907.48394950877
gradient descent iteration = 2
gd loss = 44907.48394950877
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44903.26327032677
gradient descent iteration = 3
gd loss = 44903.26327032677
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44899.29389909423
gradient descent iteration = 4
gd loss = 44899.29389909423
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44895.53351756788
gradient descent iteration = 5
gd loss = 44895.53351756788
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44891.95353796862
gradient descent iteration = 6
gd loss = 44891.95353796862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44888.53246910944
gradient descent iteration = 7
gd loss = 44888.53246910944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44885.25313217563
gradient descent iteration = 8
gd loss = 44885.25313217563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44882.10130432094
gradient descent iteration = 9
gd loss = 44882.10130432094
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44879.06495436724
gradient descent iteration = 10
gd loss = 44879.06495436724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44876.1337578041
gradient descent iteration = 11
gd loss = 44876.1337578041
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44873.29876098861
gradient descent iteration = 12
gd loss = 44873.29876098861
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44870.55213394244
gradient descent iteration = 13
gd loss = 44870.55213394244
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44867.88698133104
gradient descent iteration = 14
gd loss = 44867.88698133104
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44865.29719400147
gradient descent iteration = 15
gd loss = 44865.29719400147
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44862.7773303124
gradient descent iteration = 16
gd loss = 44862.7773303124
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44860.32252071998
gradient descent iteration = 17
gd loss = 44860.32252071998
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44857.92838884857
gradient descent iteration = 18
gd loss = 44857.92838884857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44855.59098574087
gradient descent iteration = 19
gd loss = 44855.59098574087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44853.30673493468
gradient descent iteration = 20
gd loss = 44853.30673493468
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44851.07238610836
gradient descent iteration = 21
gd loss = 44851.07238610836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44848.88497428814
gradient descent iteration = 22
gd loss = 44848.88497428814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44846.74178561853
gradient descent iteration = 23
gd loss = 44846.74178561853
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44844.64032929457
gradient descent iteration = 24
gd loss = 44844.64032929457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 44842.57831497081
Initial loss = 45226.78107258713
Final loss = 44842.57831497081
Deformation gradient control sequence optimization finished.
Animation interval 32 took 1330 seconds.
Full animation took 45227 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 33************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 45678.63542363706
initial norm = 336.479090487136
convergence norm = 0.336479090487136
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 45678.63542363706
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45652.40683440074
gradient descent iteration = 1
gd loss = 45652.40683440074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45633.23962079809
gradient descent iteration = 2
gd loss = 45633.23962079809
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45618.34861352996
gradient descent iteration = 3
gd loss = 45618.34861352996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45606.51868207453
gradient descent iteration = 4
gd loss = 45606.51868207453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45598.20232534743
gradient descent iteration = 5
gd loss = 45598.20232534743
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45593.84681030314
gradient descent iteration = 6
gd loss = 45593.84681030314
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45588.20066895858
gradient descent iteration = 7
gd loss = 45588.20066895858
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45583.23553478181
gradient descent iteration = 8
gd loss = 45583.23553478181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45578.22951909248
gradient descent iteration = 9
gd loss = 45578.22951909248
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45573.13061814696
gradient descent iteration = 10
gd loss = 45573.13061814696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45568.29296892988
gradient descent iteration = 11
gd loss = 45568.29296892988
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45563.15670675378
gradient descent iteration = 12
gd loss = 45563.15670675378
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45558.34801719418
gradient descent iteration = 13
gd loss = 45558.34801719418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45553.19100995505
gradient descent iteration = 14
gd loss = 45553.19100995505
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45548.37200309442
gradient descent iteration = 15
gd loss = 45548.37200309442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45543.20622061594
gradient descent iteration = 16
gd loss = 45543.20622061594
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45538.37879009971
gradient descent iteration = 17
gd loss = 45538.37879009971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45533.22470002911
gradient descent iteration = 18
gd loss = 45533.22470002911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45528.40844187667
gradient descent iteration = 19
gd loss = 45528.40844187667
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45523.2910368485
gradient descent iteration = 20
gd loss = 45523.2910368485
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45518.51013638437
gradient descent iteration = 21
gd loss = 45518.51013638437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45513.45330096308
gradient descent iteration = 22
gd loss = 45513.45330096308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45508.73021539009
gradient descent iteration = 23
gd loss = 45508.73021539009
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45503.75451641474
gradient descent iteration = 24
gd loss = 45503.75451641474
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45499.10895892768
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 45499.10895892768
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45487.46542698079
gradient descent iteration = 1
gd loss = 45487.46542698079
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45479.47800831185
gradient descent iteration = 2
gd loss = 45479.47800831185
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45472.41432454718
gradient descent iteration = 3
gd loss = 45472.41432454718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45465.84201369696
gradient descent iteration = 4
gd loss = 45465.84201369696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45459.65079658067
gradient descent iteration = 5
gd loss = 45459.65079658067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45453.79044705813
gradient descent iteration = 6
gd loss = 45453.79044705813
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45448.22513911524
gradient descent iteration = 7
gd loss = 45448.22513911524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45442.9262316075
gradient descent iteration = 8
gd loss = 45442.9262316075
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45437.8690155272
gradient descent iteration = 9
gd loss = 45437.8690155272
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45433.03150273187
gradient descent iteration = 10
gd loss = 45433.03150273187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45428.39385490159
gradient descent iteration = 11
gd loss = 45428.39385490159
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45423.93803176749
gradient descent iteration = 12
gd loss = 45423.93803176749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45419.64767739586
gradient descent iteration = 13
gd loss = 45419.64767739586
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45415.50796745221
gradient descent iteration = 14
gd loss = 45415.50796745221
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45411.50547050642
gradient descent iteration = 15
gd loss = 45411.50547050642
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45407.62801503666
gradient descent iteration = 16
gd loss = 45407.62801503666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45403.86456988209
gradient descent iteration = 17
gd loss = 45403.86456988209
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45400.20512272637
gradient descent iteration = 18
gd loss = 45400.20512272637
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45396.6405851865
gradient descent iteration = 19
gd loss = 45396.6405851865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45393.16269582078
gradient descent iteration = 20
gd loss = 45393.16269582078
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45389.76394197814
gradient descent iteration = 21
gd loss = 45389.76394197814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45386.43748592851
gradient descent iteration = 22
gd loss = 45386.43748592851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45383.1770973472
gradient descent iteration = 23
gd loss = 45383.1770973472
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45379.97709446579
gradient descent iteration = 24
gd loss = 45379.97709446579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45376.83229103181
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 45376.83229103181
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45371.62720713034
gradient descent iteration = 1
gd loss = 45371.62720713034
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45366.68141729647
gradient descent iteration = 2
gd loss = 45366.68141729647
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45361.8962665574
gradient descent iteration = 3
gd loss = 45361.8962665574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45357.2483550503
gradient descent iteration = 4
gd loss = 45357.2483550503
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45352.73552963204
gradient descent iteration = 5
gd loss = 45352.73552963204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45348.36174287718
gradient descent iteration = 6
gd loss = 45348.36174287718
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45344.13157748264
gradient descent iteration = 7
gd loss = 45344.13157748264
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45340.04800505974
gradient descent iteration = 8
gd loss = 45340.04800505974
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45336.11159305664
gradient descent iteration = 9
gd loss = 45336.11159305664
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45332.32047353333
gradient descent iteration = 10
gd loss = 45332.32047353333
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45328.67070141067
gradient descent iteration = 11
gd loss = 45328.67070141067
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45325.1567704486
gradient descent iteration = 12
gd loss = 45325.1567704486
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45321.77212286834
gradient descent iteration = 13
gd loss = 45321.77212286834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45318.5095979494
gradient descent iteration = 14
gd loss = 45318.5095979494
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45315.36182804903
gradient descent iteration = 15
gd loss = 45315.36182804903
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45312.32149375425
gradient descent iteration = 16
gd loss = 45312.32149375425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45309.38149535587
gradient descent iteration = 17
gd loss = 45309.38149535587
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45306.53506493427
gradient descent iteration = 18
gd loss = 45306.53506493427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45303.77582739399
gradient descent iteration = 19
gd loss = 45303.77582739399
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45301.09783398698
gradient descent iteration = 20
gd loss = 45301.09783398698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45298.49556995223
gradient descent iteration = 21
gd loss = 45298.49556995223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45295.96391592588
gradient descent iteration = 22
gd loss = 45295.96391592588
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45293.49811772435
gradient descent iteration = 23
gd loss = 45293.49811772435
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45291.09379012187
gradient descent iteration = 24
gd loss = 45291.09379012187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45288.74690868396
Initial loss = 45678.63542363706
Final loss = 45288.74690868396
Deformation gradient control sequence optimization finished.
Animation interval 33 took 1332 seconds.
Full animation took 46559 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 34************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 46112.00791216526
initial norm = 379.1877709392619
convergence norm = 0.3791877709392619
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 46112.00791216526
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46085.23558996848
gradient descent iteration = 1
gd loss = 46085.23558996848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46065.31111458565
gradient descent iteration = 2
gd loss = 46065.31111458565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46049.11161247599
gradient descent iteration = 3
gd loss = 46049.11161247599
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46035.40617123611
gradient descent iteration = 4
gd loss = 46035.40617123611
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46023.8602230445
gradient descent iteration = 5
gd loss = 46023.8602230445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46015.01603560769
gradient descent iteration = 6
gd loss = 46015.01603560769
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46008.43631103008
gradient descent iteration = 7
gd loss = 46008.43631103008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46001.88132277002
gradient descent iteration = 8
gd loss = 46001.88132277002
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45995.70462532878
gradient descent iteration = 9
gd loss = 45995.70462532878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45989.59672596654
gradient descent iteration = 10
gd loss = 45989.59672596654
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45983.76334029463
gradient descent iteration = 11
gd loss = 45983.76334029463
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45977.97357947652
gradient descent iteration = 12
gd loss = 45977.97357947652
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45972.39718039661
gradient descent iteration = 13
gd loss = 45972.39718039661
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45966.84623760163
gradient descent iteration = 14
gd loss = 45966.84623760163
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45961.45796981564
gradient descent iteration = 15
gd loss = 45961.45796981564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45956.08254837808
gradient descent iteration = 16
gd loss = 45956.08254837808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45950.82164970996
gradient descent iteration = 17
gd loss = 45950.82164970996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45945.56428879331
gradient descent iteration = 18
gd loss = 45945.56428879331
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45940.36722424033
gradient descent iteration = 19
gd loss = 45940.36722424033
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45935.15109982865
gradient descent iteration = 20
gd loss = 45935.15109982865
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45929.92932011761
gradient descent iteration = 21
gd loss = 45929.92932011761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45924.68625226708
gradient descent iteration = 22
gd loss = 45924.68625226708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45919.43241917327
gradient descent iteration = 23
gd loss = 45919.43241917327
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45914.22341835366
gradient descent iteration = 24
gd loss = 45914.22341835366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45909.07972309634
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 45909.07972309634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45897.51733626036
gradient descent iteration = 1
gd loss = 45897.51733626036
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45890.15873757448
gradient descent iteration = 2
gd loss = 45890.15873757448
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45883.67530362669
gradient descent iteration = 3
gd loss = 45883.67530362669
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45877.62948164828
gradient descent iteration = 4
gd loss = 45877.62948164828
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45871.91147945741
gradient descent iteration = 5
gd loss = 45871.91147945741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45866.46961031625
gradient descent iteration = 6
gd loss = 45866.46961031625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45861.26744961746
gradient descent iteration = 7
gd loss = 45861.26744961746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45856.27616719119
gradient descent iteration = 8
gd loss = 45856.27616719119
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45851.4715605852
gradient descent iteration = 9
gd loss = 45851.4715605852
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45846.83292005121
gradient descent iteration = 10
gd loss = 45846.83292005121
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45842.34211434393
gradient descent iteration = 11
gd loss = 45842.34211434393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45837.98279397166
gradient descent iteration = 12
gd loss = 45837.98279397166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45833.73953872866
gradient descent iteration = 13
gd loss = 45833.73953872866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45829.59646467495
gradient descent iteration = 14
gd loss = 45829.59646467495
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45825.53458158013
gradient descent iteration = 15
gd loss = 45825.53458158013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45821.52755634754
gradient descent iteration = 16
gd loss = 45821.52755634754
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45821.28345260479
gradient descent iteration = 17
gd loss = 45821.28345260479
line search decrease found at ls_iter = 5, alpha = 0.003125, loss = 45820.52437669074
gradient descent iteration = 18
gd loss = 45820.52437669074
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45820.40153569463
gradient descent iteration = 19
gd loss = 45820.40153569463
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45820.27889214925
gradient descent iteration = 20
gd loss = 45820.27889214925
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45820.15643804783
gradient descent iteration = 21
gd loss = 45820.15643804783
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45820.03416600666
gradient descent iteration = 22
gd loss = 45820.03416600666
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45819.91206921276
gradient descent iteration = 23
gd loss = 45819.91206921276
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45819.79014139014
gradient descent iteration = 24
gd loss = 45819.79014139014
line search decrease found at ls_iter = 0, alpha = 0.003125, loss = 45819.66837673023
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 45819.66837673023
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45814.15696597371
gradient descent iteration = 1
gd loss = 45814.15696597371
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45809.12564212898
gradient descent iteration = 2
gd loss = 45809.12564212898
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45804.40824276187
gradient descent iteration = 3
gd loss = 45804.40824276187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45799.92966314091
gradient descent iteration = 4
gd loss = 45799.92966314091
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45795.64646694831
gradient descent iteration = 5
gd loss = 45795.64646694831
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45791.52947636184
gradient descent iteration = 6
gd loss = 45791.52947636184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45787.55720567752
gradient descent iteration = 7
gd loss = 45787.55720567752
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45783.71294442298
gradient descent iteration = 8
gd loss = 45783.71294442298
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45779.98325852449
gradient descent iteration = 9
gd loss = 45779.98325852449
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45776.35710472313
gradient descent iteration = 10
gd loss = 45776.35710472313
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45772.82525414133
gradient descent iteration = 11
gd loss = 45772.82525414133
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45769.37989301339
gradient descent iteration = 12
gd loss = 45769.37989301339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45766.01433402646
gradient descent iteration = 13
gd loss = 45766.01433402646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45762.7228012708
gradient descent iteration = 14
gd loss = 45762.7228012708
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45759.50026502759
gradient descent iteration = 15
gd loss = 45759.50026502759
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45756.34231290405
gradient descent iteration = 16
gd loss = 45756.34231290405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45753.24504842427
gradient descent iteration = 17
gd loss = 45753.24504842427
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45750.20500995519
gradient descent iteration = 18
gd loss = 45750.20500995519
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45747.21910503285
gradient descent iteration = 19
gd loss = 45747.21910503285
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45744.28455410304
gradient descent iteration = 20
gd loss = 45744.28455410304
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45741.39884286134
gradient descent iteration = 21
gd loss = 45741.39884286134
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45738.55969173651
gradient descent iteration = 22
gd loss = 45738.55969173651
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45735.76502592583
gradient descent iteration = 23
gd loss = 45735.76502592583
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45733.01294518419
gradient descent iteration = 24
gd loss = 45733.01294518419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 45730.30168838782
Initial loss = 46112.00791216526
Final loss = 45730.30168838782
Deformation gradient control sequence optimization finished.
Animation interval 34 took 1337 seconds.
Full animation took 47897 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 35************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 46565.79925592891
initial norm = 438.7979420978996
convergence norm = 0.4387979420978996
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 46565.79925592891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46535.24820892728
gradient descent iteration = 1
gd loss = 46535.24820892728
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46514.88931331803
gradient descent iteration = 2
gd loss = 46514.88931331803
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46498.73138023582
gradient descent iteration = 3
gd loss = 46498.73138023582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46485.20522549366
gradient descent iteration = 4
gd loss = 46485.20522549366
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46473.34795979098
gradient descent iteration = 5
gd loss = 46473.34795979098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46463.67378377832
gradient descent iteration = 6
gd loss = 46463.67378377832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46458.60090844356
gradient descent iteration = 7
gd loss = 46458.60090844356
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46452.9547455488
gradient descent iteration = 8
gd loss = 46452.9547455488
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46447.77505593416
gradient descent iteration = 9
gd loss = 46447.77505593416
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46442.50917545779
gradient descent iteration = 10
gd loss = 46442.50917545779
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46437.43605452259
gradient descent iteration = 11
gd loss = 46437.43605452259
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46432.35458280415
gradient descent iteration = 12
gd loss = 46432.35458280415
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46427.3750747969
gradient descent iteration = 13
gd loss = 46427.3750747969
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46422.39236241975
gradient descent iteration = 14
gd loss = 46422.39236241975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46417.47014378504
gradient descent iteration = 15
gd loss = 46417.47014378504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46412.53377556349
gradient descent iteration = 16
gd loss = 46412.53377556349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46407.63513665265
gradient descent iteration = 17
gd loss = 46407.63513665265
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46402.71202590576
gradient descent iteration = 18
gd loss = 46402.71202590576
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46397.81344112118
gradient descent iteration = 19
gd loss = 46397.81344112118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46392.88143280567
gradient descent iteration = 20
gd loss = 46392.88143280567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46387.96655124375
gradient descent iteration = 21
gd loss = 46387.96655124375
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46383.01189927539
gradient descent iteration = 22
gd loss = 46383.01189927539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46378.07094531069
gradient descent iteration = 23
gd loss = 46378.07094531069
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46373.08622746442
gradient descent iteration = 24
gd loss = 46373.08622746442
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46368.114514648
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 46368.114514648
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46357.27305181437
gradient descent iteration = 1
gd loss = 46357.27305181437
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46350.04119164008
gradient descent iteration = 2
gd loss = 46350.04119164008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46343.52160062302
gradient descent iteration = 3
gd loss = 46343.52160062302
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46337.30321538308
gradient descent iteration = 4
gd loss = 46337.30321538308
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46331.30415287341
gradient descent iteration = 5
gd loss = 46331.30415287341
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46325.49758119288
gradient descent iteration = 6
gd loss = 46325.49758119288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46319.87041891741
gradient descent iteration = 7
gd loss = 46319.87041891741
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46314.41391229595
gradient descent iteration = 8
gd loss = 46314.41391229595
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46309.12107842432
gradient descent iteration = 9
gd loss = 46309.12107842432
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46303.98552086859
gradient descent iteration = 10
gd loss = 46303.98552086859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46299.00099041414
gradient descent iteration = 11
gd loss = 46299.00099041414
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46294.16121138269
gradient descent iteration = 12
gd loss = 46294.16121138269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46289.45986501636
gradient descent iteration = 13
gd loss = 46289.45986501636
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46284.89062951184
gradient descent iteration = 14
gd loss = 46284.89062951184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46280.44723850705
gradient descent iteration = 15
gd loss = 46280.44723850705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46276.12353587476
gradient descent iteration = 16
gd loss = 46276.12353587476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46271.91352085296
gradient descent iteration = 17
gd loss = 46271.91352085296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46267.8113817275
gradient descent iteration = 18
gd loss = 46267.8113817275
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46263.81151680997
gradient descent iteration = 19
gd loss = 46263.81151680997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46259.90854776733
gradient descent iteration = 20
gd loss = 46259.90854776733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46256.09732836674
gradient descent iteration = 21
gd loss = 46256.09732836674
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46252.37294511883
gradient descent iteration = 22
gd loss = 46252.37294511883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46248.73071377823
gradient descent iteration = 23
gd loss = 46248.73071377823
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46245.16617232973
gradient descent iteration = 24
gd loss = 46245.16617232973
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46241.67507469421
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 46241.67507469421
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46236.61462050476
gradient descent iteration = 1
gd loss = 46236.61462050476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46232.08226734941
gradient descent iteration = 2
gd loss = 46232.08226734941
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46227.82915055528
gradient descent iteration = 3
gd loss = 46227.82915055528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46223.7771776992
gradient descent iteration = 4
gd loss = 46223.7771776992
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46219.88787026876
gradient descent iteration = 5
gd loss = 46219.88787026876
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46216.13655534132
gradient descent iteration = 6
gd loss = 46216.13655534132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46212.50508370574
gradient descent iteration = 7
gd loss = 46212.50508370574
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46208.97910984559
gradient descent iteration = 8
gd loss = 46208.97910984559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46205.54683573702
gradient descent iteration = 9
gd loss = 46205.54683573702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46202.19835529246
gradient descent iteration = 10
gd loss = 46202.19835529246
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46198.92519865849
gradient descent iteration = 11
gd loss = 46198.92519865849
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46195.72005039359
gradient descent iteration = 12
gd loss = 46195.72005039359
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46192.57653046043
gradient descent iteration = 13
gd loss = 46192.57653046043
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46189.48901198553
gradient descent iteration = 14
gd loss = 46189.48901198553
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46186.45254867388
gradient descent iteration = 15
gd loss = 46186.45254867388
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46183.46258109797
gradient descent iteration = 16
gd loss = 46183.46258109797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46180.51515880283
gradient descent iteration = 17
gd loss = 46180.51515880283
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46177.60666689527
gradient descent iteration = 18
gd loss = 46177.60666689527
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46174.73381948132
gradient descent iteration = 19
gd loss = 46174.73381948132
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46171.8936253524
gradient descent iteration = 20
gd loss = 46171.8936253524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46169.08335849702
gradient descent iteration = 21
gd loss = 46169.08335849702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46166.30052940323
gradient descent iteration = 22
gd loss = 46166.30052940323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46163.54287826379
gradient descent iteration = 23
gd loss = 46163.54287826379
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46160.80839378467
gradient descent iteration = 24
gd loss = 46160.80839378467
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46158.09526995917
Initial loss = 46565.79925592891
Final loss = 46158.09526995917
Deformation gradient control sequence optimization finished.
Animation interval 35 took 1330 seconds.
Full animation took 49227 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 36************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 46986.82125919296
initial norm = 461.5409442623531
convergence norm = 0.4615409442623531
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 46986.82125919296
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46953.54045728007
gradient descent iteration = 1
gd loss = 46953.54045728007
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46932.49639193343
gradient descent iteration = 2
gd loss = 46932.49639193343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46916.73812082162
gradient descent iteration = 3
gd loss = 46916.73812082162
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46903.95394414836
gradient descent iteration = 4
gd loss = 46903.95394414836
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46893.14639087515
gradient descent iteration = 5
gd loss = 46893.14639087515
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46886.42956989666
gradient descent iteration = 6
gd loss = 46886.42956989666
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46882.33350441453
gradient descent iteration = 7
gd loss = 46882.33350441453
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46876.66155070236
gradient descent iteration = 8
gd loss = 46876.66155070236
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46872.07937841073
gradient descent iteration = 9
gd loss = 46872.07937841073
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46867.01424292879
gradient descent iteration = 10
gd loss = 46867.01424292879
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46862.37897891615
gradient descent iteration = 11
gd loss = 46862.37897891615
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46857.58329697805
gradient descent iteration = 12
gd loss = 46857.58329697805
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46853.01498357136
gradient descent iteration = 13
gd loss = 46853.01498357136
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46848.38598235
gradient descent iteration = 14
gd loss = 46848.38598235
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46843.91756632787
gradient descent iteration = 15
gd loss = 46843.91756632787
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46839.42019137478
gradient descent iteration = 16
gd loss = 46839.42019137478
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46835.05939117051
gradient descent iteration = 17
gd loss = 46835.05939117051
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46830.67867740329
gradient descent iteration = 18
gd loss = 46830.67867740329
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46826.4236205231
gradient descent iteration = 19
gd loss = 46826.4236205231
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46822.14845993618
gradient descent iteration = 20
gd loss = 46822.14845993618
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46817.99048365963
gradient descent iteration = 21
gd loss = 46817.99048365963
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46813.80634043267
gradient descent iteration = 22
gd loss = 46813.80634043267
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46809.72858278704
gradient descent iteration = 23
gd loss = 46809.72858278704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46805.61275686926
gradient descent iteration = 24
gd loss = 46805.61275686926
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46801.58656697439
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 46801.58656697439
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46792.53954812339
gradient descent iteration = 1
gd loss = 46792.53954812339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46787.51056163564
gradient descent iteration = 2
gd loss = 46787.51056163564
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46783.0887563639
gradient descent iteration = 3
gd loss = 46783.0887563639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46778.85953688694
gradient descent iteration = 4
gd loss = 46778.85953688694
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46774.74041100639
gradient descent iteration = 5
gd loss = 46774.74041100639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46770.69652911704
gradient descent iteration = 6
gd loss = 46770.69652911704
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46766.70410223975
gradient descent iteration = 7
gd loss = 46766.70410223975
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46762.74329612688
gradient descent iteration = 8
gd loss = 46762.74329612688
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46758.79642447884
gradient descent iteration = 9
gd loss = 46758.79642447884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46754.84692152092
gradient descent iteration = 10
gd loss = 46754.84692152092
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46750.87890163827
gradient descent iteration = 11
gd loss = 46750.87890163827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46746.87679879175
gradient descent iteration = 12
gd loss = 46746.87679879175
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46742.82515535996
gradient descent iteration = 13
gd loss = 46742.82515535996
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46738.70864883634
gradient descent iteration = 14
gd loss = 46738.70864883634
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46734.51234639349
gradient descent iteration = 15
gd loss = 46734.51234639349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46730.22249905425
gradient descent iteration = 16
gd loss = 46730.22249905425
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46725.8288407625
gradient descent iteration = 17
gd loss = 46725.8288407625
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46721.32618198187
gradient descent iteration = 18
gd loss = 46721.32618198187
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46716.71610439512
gradient descent iteration = 19
gd loss = 46716.71610439512
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46712.01025407777
gradient descent iteration = 20
gd loss = 46712.01025407777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46707.23642519457
gradient descent iteration = 21
gd loss = 46707.23642519457
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46702.44029593833
gradient descent iteration = 22
gd loss = 46702.44029593833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46697.67266295785
gradient descent iteration = 23
gd loss = 46697.67266295785
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46692.9758229483
gradient descent iteration = 24
gd loss = 46692.9758229483
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46688.37289149733
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 46688.37289149733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46683.11607714005
gradient descent iteration = 1
gd loss = 46683.11607714005
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46678.26325701157
gradient descent iteration = 2
gd loss = 46678.26325701157
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46673.71161393603
gradient descent iteration = 3
gd loss = 46673.71161393603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46669.41986381592
gradient descent iteration = 4
gd loss = 46669.41986381592
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46665.36177573528
gradient descent iteration = 5
gd loss = 46665.36177573528
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46661.5152988991
gradient descent iteration = 6
gd loss = 46661.5152988991
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46657.86006504006
gradient descent iteration = 7
gd loss = 46657.86006504006
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46654.37704446702
gradient descent iteration = 8
gd loss = 46654.37704446702
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46651.0486725431
gradient descent iteration = 9
gd loss = 46651.0486725431
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46647.85897626184
gradient descent iteration = 10
gd loss = 46647.85897626184
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46644.79360280776
gradient descent iteration = 11
gd loss = 46644.79360280776
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46641.83975626074
gradient descent iteration = 12
gd loss = 46641.83975626074
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46638.98608613345
gradient descent iteration = 13
gd loss = 46638.98608613345
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46636.22255823509
gradient descent iteration = 14
gd loss = 46636.22255823509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46633.54032780412
gradient descent iteration = 15
gd loss = 46633.54032780412
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46630.93162248028
gradient descent iteration = 16
gd loss = 46630.93162248028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46628.38963821675
gradient descent iteration = 17
gd loss = 46628.38963821675
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46625.90844200632
gradient descent iteration = 18
gd loss = 46625.90844200632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46623.48285860525
gradient descent iteration = 19
gd loss = 46623.48285860525
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46621.10836754536
gradient descent iteration = 20
gd loss = 46621.10836754536
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46618.78100876911
gradient descent iteration = 21
gd loss = 46618.78100876911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46616.49729919339
gradient descent iteration = 22
gd loss = 46616.49729919339
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46614.25416125242
gradient descent iteration = 23
gd loss = 46614.25416125242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46612.04887815711
gradient descent iteration = 24
gd loss = 46612.04887815711
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 46609.87904073023
Initial loss = 46986.82125919296
Final loss = 46609.87904073023
Deformation gradient control sequence optimization finished.
Animation interval 36 took 1332 seconds.
Full animation took 50560 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 37************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 47437.42612468857
initial norm = 546.8505705531963
convergence norm = 0.5468505705531964
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 47437.42612468857
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47393.54986486081
gradient descent iteration = 1
gd loss = 47393.54986486081
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47363.54974939101
gradient descent iteration = 2
gd loss = 47363.54974939101
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47341.49633370309
gradient descent iteration = 3
gd loss = 47341.49633370309
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47324.10007820149
gradient descent iteration = 4
gd loss = 47324.10007820149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47309.32957417405
gradient descent iteration = 5
gd loss = 47309.32957417405
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47296.05764697224
gradient descent iteration = 6
gd loss = 47296.05764697224
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47284.46862132884
gradient descent iteration = 7
gd loss = 47284.46862132884
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47276.41076048127
gradient descent iteration = 8
gd loss = 47276.41076048127
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47269.82264908241
gradient descent iteration = 9
gd loss = 47269.82264908241
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47262.79393255569
gradient descent iteration = 10
gd loss = 47262.79393255569
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47256.12136813418
gradient descent iteration = 11
gd loss = 47256.12136813418
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47249.40582639843
gradient descent iteration = 12
gd loss = 47249.40582639843
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47242.84488331291
gradient descent iteration = 13
gd loss = 47242.84488331291
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47236.2787390243
gradient descent iteration = 14
gd loss = 47236.2787390243
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47229.8175510657
gradient descent iteration = 15
gd loss = 47229.8175510657
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47223.33977254376
gradient descent iteration = 16
gd loss = 47223.33977254376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47216.94060188868
gradient descent iteration = 17
gd loss = 47216.94060188868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47210.51182315542
gradient descent iteration = 18
gd loss = 47210.51182315542
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47204.14969747343
gradient descent iteration = 19
gd loss = 47204.14969747343
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47197.75502412683
gradient descent iteration = 20
gd loss = 47197.75502412683
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47191.42834489323
gradient descent iteration = 21
gd loss = 47191.42834489323
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47185.07985954577
gradient descent iteration = 22
gd loss = 47185.07985954577
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47178.80468110419
gradient descent iteration = 23
gd loss = 47178.80468110419
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47172.51498286161
gradient descent iteration = 24
gd loss = 47172.51498286161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47166.29769746946
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 47166.29769746946
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47157.45527490909
gradient descent iteration = 1
gd loss = 47157.45527490909
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47152.29551904242
gradient descent iteration = 2
gd loss = 47152.29551904242
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47147.75096931891
gradient descent iteration = 3
gd loss = 47147.75096931891
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47143.43748799288
gradient descent iteration = 4
gd loss = 47143.43748799288
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47139.28064042188
gradient descent iteration = 5
gd loss = 47139.28064042188
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47135.25205055735
gradient descent iteration = 6
gd loss = 47135.25205055735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47131.33485233544
gradient descent iteration = 7
gd loss = 47131.33485233544
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47127.51680634205
gradient descent iteration = 8
gd loss = 47127.51680634205
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47123.78834970966
gradient descent iteration = 9
gd loss = 47123.78834970966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47120.14163100447
gradient descent iteration = 10
gd loss = 47120.14163100447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47116.56998713109
gradient descent iteration = 11
gd loss = 47116.56998713109
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47113.06761894698
gradient descent iteration = 12
gd loss = 47113.06761894698
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47109.62937456646
gradient descent iteration = 13
gd loss = 47109.62937456646
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47106.25061136008
gradient descent iteration = 14
gd loss = 47106.25061136008
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47102.92709643685
gradient descent iteration = 15
gd loss = 47102.92709643685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47099.65493602714
gradient descent iteration = 16
gd loss = 47099.65493602714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47096.43052604565
gradient descent iteration = 17
gd loss = 47096.43052604565
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47093.25051093566
gradient descent iteration = 18
gd loss = 47093.25051093566
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47090.11175256888
gradient descent iteration = 19
gd loss = 47090.11175256888
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47087.01130673567
gradient descent iteration = 20
gd loss = 47087.01130673567
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47083.9463992524
gradient descent iteration = 21
gd loss = 47083.9463992524
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47080.91440450801
gradient descent iteration = 22
gd loss = 47080.91440450801
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47077.91282512098
gradient descent iteration = 23
gd loss = 47077.91282512098
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47074.93927488796
gradient descent iteration = 24
gd loss = 47074.93927488796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47071.99146195682
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 47071.99146195682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47067.92618868402
gradient descent iteration = 1
gd loss = 47067.92618868402
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47064.21239985777
gradient descent iteration = 2
gd loss = 47064.21239985777
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47060.70478277284
gradient descent iteration = 3
gd loss = 47060.70478277284
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47057.34657393504
gradient descent iteration = 4
gd loss = 47057.34657393504
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47054.10842749859
gradient descent iteration = 5
gd loss = 47054.10842749859
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47050.97158885616
gradient descent iteration = 6
gd loss = 47050.97158885616
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47047.9224057049
gradient descent iteration = 7
gd loss = 47047.9224057049
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47044.95019887346
gradient descent iteration = 8
gd loss = 47044.95019887346
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47042.04625759897
gradient descent iteration = 9
gd loss = 47042.04625759897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47039.20329669087
gradient descent iteration = 10
gd loss = 47039.20329669087
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47036.41520294778
gradient descent iteration = 11
gd loss = 47036.41520294778
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47033.67673106257
gradient descent iteration = 12
gd loss = 47033.67673106257
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47030.98329819131
gradient descent iteration = 13
gd loss = 47030.98329819131
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47028.33085722382
gradient descent iteration = 14
gd loss = 47028.33085722382
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47025.71581880582
gradient descent iteration = 15
gd loss = 47025.71581880582
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47023.13498936848
gradient descent iteration = 16
gd loss = 47023.13498936848
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47020.58550161303
gradient descent iteration = 17
gd loss = 47020.58550161303
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47018.06477210097
gradient descent iteration = 18
gd loss = 47018.06477210097
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47015.57052191559
gradient descent iteration = 19
gd loss = 47015.57052191559
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47013.10092246204
gradient descent iteration = 20
gd loss = 47013.10092246204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47010.6544383799
gradient descent iteration = 21
gd loss = 47010.6544383799
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47008.22974938624
gradient descent iteration = 22
gd loss = 47008.22974938624
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47005.82573003693
gradient descent iteration = 23
gd loss = 47005.82573003693
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47003.44143294338
gradient descent iteration = 24
gd loss = 47003.44143294338
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47001.07607636162
Initial loss = 47437.42612468857
Final loss = 47001.07607636162
Deformation gradient control sequence optimization finished.
Animation interval 37 took 1335 seconds.
Full animation took 51895 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 38************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 47738.65493785148
initial norm = 512.6464982492786
convergence norm = 0.5126464982492785
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 47738.65493785148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47696.26864362619
gradient descent iteration = 1
gd loss = 47696.26864362619
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47665.49480083229
gradient descent iteration = 2
gd loss = 47665.49480083229
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47641.83229145627
gradient descent iteration = 3
gd loss = 47641.83229145627
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47622.62401281604
gradient descent iteration = 4
gd loss = 47622.62401281604
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47606.21826923834
gradient descent iteration = 5
gd loss = 47606.21826923834
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47591.53150223833
gradient descent iteration = 6
gd loss = 47591.53150223833
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47577.98041422672
gradient descent iteration = 7
gd loss = 47577.98041422672
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47565.48163897376
gradient descent iteration = 8
gd loss = 47565.48163897376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47555.06444247547
gradient descent iteration = 9
gd loss = 47555.06444247547
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47548.41557770911
gradient descent iteration = 10
gd loss = 47548.41557770911
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47541.83056130055
gradient descent iteration = 11
gd loss = 47541.83056130055
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47535.38512904161
gradient descent iteration = 12
gd loss = 47535.38512904161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47529.04636503417
gradient descent iteration = 13
gd loss = 47529.04636503417
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47522.76593315142
gradient descent iteration = 14
gd loss = 47522.76593315142
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47516.5417740509
gradient descent iteration = 15
gd loss = 47516.5417740509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47510.31884333873
gradient descent iteration = 16
gd loss = 47510.31884333873
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47504.10207541148
gradient descent iteration = 17
gd loss = 47504.10207541148
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47497.83339739866
gradient descent iteration = 18
gd loss = 47497.83339739866
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47491.52057726632
gradient descent iteration = 19
gd loss = 47491.52057726632
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47485.10619195972
gradient descent iteration = 20
gd loss = 47485.10619195972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47478.59857148892
gradient descent iteration = 21
gd loss = 47478.59857148892
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47471.93315000166
gradient descent iteration = 22
gd loss = 47471.93315000166
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47465.10977142161
gradient descent iteration = 23
gd loss = 47465.10977142161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47458.04793016445
gradient descent iteration = 24
gd loss = 47458.04793016445
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47450.72615808393
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 47450.72615808393
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47439.81917638396
gradient descent iteration = 1
gd loss = 47439.81917638396
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47432.28573600862
gradient descent iteration = 2
gd loss = 47432.28573600862
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47425.25934171814
gradient descent iteration = 3
gd loss = 47425.25934171814
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47418.39796877797
gradient descent iteration = 4
gd loss = 47418.39796877797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47411.62925368438
gradient descent iteration = 5
gd loss = 47411.62925368438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47404.92303885758
gradient descent iteration = 6
gd loss = 47404.92303885758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47398.26430106003
gradient descent iteration = 7
gd loss = 47398.26430106003
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47391.6489282328
gradient descent iteration = 8
gd loss = 47391.6489282328
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47385.07888694471
gradient descent iteration = 9
gd loss = 47385.07888694471
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47378.55867502293
gradient descent iteration = 10
gd loss = 47378.55867502293
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47372.09270362733
gradient descent iteration = 11
gd loss = 47372.09270362733
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47365.68306850735
gradient descent iteration = 12
gd loss = 47365.68306850735
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47359.32789850897
gradient descent iteration = 13
gd loss = 47359.32789850897
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47353.02039902705
gradient descent iteration = 14
gd loss = 47353.02039902705
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47346.74825530742
gradient descent iteration = 15
gd loss = 47346.74825530742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47340.49385101689
gradient descent iteration = 16
gd loss = 47340.49385101689
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47334.23225516436
gradient descent iteration = 17
gd loss = 47334.23225516436
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47327.9270069943
gradient descent iteration = 18
gd loss = 47327.9270069943
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47321.53725776352
gradient descent iteration = 19
gd loss = 47321.53725776352
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47315.04365897871
gradient descent iteration = 20
gd loss = 47315.04365897871
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47308.46089040203
gradient descent iteration = 21
gd loss = 47308.46089040203
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47301.8317070546
gradient descent iteration = 22
gd loss = 47301.8317070546
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47295.22908794966
gradient descent iteration = 23
gd loss = 47295.22908794966
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47288.74089805649
gradient descent iteration = 24
gd loss = 47288.74089805649
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47282.43652153038
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 47282.43652153038
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47275.92355291944
gradient descent iteration = 1
gd loss = 47275.92355291944
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47270.01841575827
gradient descent iteration = 2
gd loss = 47270.01841575827
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47264.4894150796
gradient descent iteration = 3
gd loss = 47264.4894150796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47259.24339660639
gradient descent iteration = 4
gd loss = 47259.24339660639
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47254.23019507149
gradient descent iteration = 5
gd loss = 47254.23019507149
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47249.41607798883
gradient descent iteration = 6
gd loss = 47249.41607798883
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47244.77549415714
gradient descent iteration = 7
gd loss = 47244.77549415714
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47240.28797561084
gradient descent iteration = 8
gd loss = 47240.28797561084
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47235.93672778462
gradient descent iteration = 9
gd loss = 47235.93672778462
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47231.70782574458
gradient descent iteration = 10
gd loss = 47231.70782574458
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47227.58951415066
gradient descent iteration = 11
gd loss = 47227.58951415066
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47223.57176790076
gradient descent iteration = 12
gd loss = 47223.57176790076
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47219.64597130791
gradient descent iteration = 13
gd loss = 47219.64597130791
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47215.80467326682
gradient descent iteration = 14
gd loss = 47215.80467326682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47212.04138864838
gradient descent iteration = 15
gd loss = 47212.04138864838
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47208.35043976899
gradient descent iteration = 16
gd loss = 47208.35043976899
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47204.72683121821
gradient descent iteration = 17
gd loss = 47204.72683121821
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47201.16615284387
gradient descent iteration = 18
gd loss = 47201.16615284387
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47197.66451382797
gradient descent iteration = 19
gd loss = 47197.66451382797
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47194.21845612971
gradient descent iteration = 20
gd loss = 47194.21845612971
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47190.82488660746
gradient descent iteration = 21
gd loss = 47190.82488660746
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47187.48102910194
gradient descent iteration = 22
gd loss = 47187.48102910194
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47184.18439031385
gradient descent iteration = 23
gd loss = 47184.18439031385
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47180.93277035476
gradient descent iteration = 24
gd loss = 47180.93277035476
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47177.72429862266
Initial loss = 47738.65493785148
Final loss = 47177.72429862266
Deformation gradient control sequence optimization finished.
Animation interval 38 took 1331 seconds.
Full animation took 53227 seconds so far.
**********OPTIMIZING ANIMATION INTERVAL: 39************
Optimizing control sequence with simulation parameters:
num_steps = 30
dt = 0.008333333333333333
drag = 0.5
f_ext = 0 0 0
initial loss = 47921.24119125972
initial norm = 683.5892231336975
convergence norm = 0.6835892231336975
Optimizing for timestep: 0
gradient descent iteration = 0
gd loss = 47921.24119125972
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47862.73278696749
gradient descent iteration = 1
gd loss = 47862.73278696749
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47818.72019558719
gradient descent iteration = 2
gd loss = 47818.72019558719
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47784.34994142794
gradient descent iteration = 3
gd loss = 47784.34994142794
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47756.53664018105
gradient descent iteration = 4
gd loss = 47756.53664018105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47732.84845739028
gradient descent iteration = 5
gd loss = 47732.84845739028
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47711.67351009829
gradient descent iteration = 6
gd loss = 47711.67351009829
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47692.00721020057
gradient descent iteration = 7
gd loss = 47692.00721020057
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47673.08750159071
gradient descent iteration = 8
gd loss = 47673.08750159071
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47654.33090887125
gradient descent iteration = 9
gd loss = 47654.33090887125
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47635.96672755724
gradient descent iteration = 10
gd loss = 47635.96672755724
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47618.48449635742
gradient descent iteration = 11
gd loss = 47618.48449635742
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47600.87510364161
gradient descent iteration = 12
gd loss = 47600.87510364161
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47582.5901723717
gradient descent iteration = 13
gd loss = 47582.5901723717
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47565.843598261
gradient descent iteration = 14
gd loss = 47565.843598261
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47550.53454277878
gradient descent iteration = 15
gd loss = 47550.53454277878
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47535.83213845093
gradient descent iteration = 16
gd loss = 47535.83213845093
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47521.68874491481
gradient descent iteration = 17
gd loss = 47521.68874491481
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47509.04275736145
gradient descent iteration = 18
gd loss = 47509.04275736145
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47498.77791329563
gradient descent iteration = 19
gd loss = 47498.77791329563
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47489.60272052315
gradient descent iteration = 20
gd loss = 47489.60272052315
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47480.65774204758
gradient descent iteration = 21
gd loss = 47480.65774204758
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47472.08437277083
gradient descent iteration = 22
gd loss = 47472.08437277083
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47463.65040833816
gradient descent iteration = 23
gd loss = 47463.65040833816
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47455.43742864851
gradient descent iteration = 24
gd loss = 47455.43742864851
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47447.24787271633
Optimizing for timestep: 10
gradient descent iteration = 0
gd loss = 47447.24787271633
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47437.1065381867
gradient descent iteration = 1
gd loss = 47437.1065381867
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47430.3436674204
gradient descent iteration = 2
gd loss = 47430.3436674204
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47424.1489323959
gradient descent iteration = 3
gd loss = 47424.1489323959
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47418.21284757868
gradient descent iteration = 4
gd loss = 47418.21284757868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47412.47563126178
gradient descent iteration = 5
gd loss = 47412.47563126178
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47406.91031423239
gradient descent iteration = 6
gd loss = 47406.91031423239
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47401.49845004021
gradient descent iteration = 7
gd loss = 47401.49845004021
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47396.22600966832
gradient descent iteration = 8
gd loss = 47396.22600966832
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47391.08178255509
gradient descent iteration = 9
gd loss = 47391.08178255509
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47386.05653633997
gradient descent iteration = 10
gd loss = 47386.05653633997
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47381.14246921105
gradient descent iteration = 11
gd loss = 47381.14246921105
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47376.3328578269
gradient descent iteration = 12
gd loss = 47376.3328578269
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47371.62180539679
gradient descent iteration = 13
gd loss = 47371.62180539679
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47367.00406516501
gradient descent iteration = 14
gd loss = 47367.00406516501
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47362.47491263593
gradient descent iteration = 15
gd loss = 47362.47491263593
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47358.03005168617
gradient descent iteration = 16
gd loss = 47358.03005168617
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47353.66554037223
gradient descent iteration = 17
gd loss = 47353.66554037223
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47349.3777369351
gradient descent iteration = 18
gd loss = 47349.3777369351
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47345.1632597868
gradient descent iteration = 19
gd loss = 47345.1632597868
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47341.01895650781
gradient descent iteration = 20
gd loss = 47341.01895650781
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47336.94187674479
gradient descent iteration = 21
gd loss = 47336.94187674479
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47332.92924933872
gradient descent iteration = 22
gd loss = 47332.92924933872
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47328.97846372961
gradient descent iteration = 23
gd loss = 47328.97846372961
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47325.08705352031
gradient descent iteration = 24
gd loss = 47325.08705352031
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47321.25268214796
Optimizing for timestep: 20
gradient descent iteration = 0
gd loss = 47321.25268214796
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47315.75430418579
gradient descent iteration = 1
gd loss = 47315.75430418579
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47310.93539242118
gradient descent iteration = 2
gd loss = 47310.93539242118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47306.44703405349
gradient descent iteration = 3
gd loss = 47306.44703405349
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47302.17928703171
gradient descent iteration = 4
gd loss = 47302.17928703171
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47298.08571172447
gradient descent iteration = 5
gd loss = 47298.08571172447
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47294.13992750118
gradient descent iteration = 6
gd loss = 47294.13992750118
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47290.32359375808
gradient descent iteration = 7
gd loss = 47290.32359375808
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47286.62257434685
gradient descent iteration = 8
gd loss = 47286.62257434685
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47283.02543159273
gradient descent iteration = 9
gd loss = 47283.02543159273
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47279.52266951289
gradient descent iteration = 10
gd loss = 47279.52266951289
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47276.10629003603
gradient descent iteration = 11
gd loss = 47276.10629003603
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47272.76955282376
gradient descent iteration = 12
gd loss = 47272.76955282376
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47269.50666962726
gradient descent iteration = 13
gd loss = 47269.50666962726
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47266.31257983804
gradient descent iteration = 14
gd loss = 47266.31257983804
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47263.18284530682
gradient descent iteration = 15
gd loss = 47263.18284530682
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47260.11355645761
gradient descent iteration = 16
gd loss = 47260.11355645761
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47257.10122190977
gradient descent iteration = 17
gd loss = 47257.10122190977
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47254.14270875539
gradient descent iteration = 18
gd loss = 47254.14270875539
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47251.23517758332
gradient descent iteration = 19
gd loss = 47251.23517758332
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47248.3760333739
gradient descent iteration = 20
gd loss = 47248.3760333739
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47245.56289901013
gradient descent iteration = 21
gd loss = 47245.56289901013
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47242.79359419047
gradient descent iteration = 22
gd loss = 47242.79359419047
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47240.06611107438
gradient descent iteration = 23
gd loss = 47240.06611107438
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47237.37859543696
gradient descent iteration = 24
gd loss = 47237.37859543696
line search decrease found at ls_iter = 0, alpha = 0.1, loss = 47234.72934259722
Initial loss = 47921.24119125972
Final loss = 47234.72934259722
Deformation gradient control sequence optimization finished.
Animation interval 39 took 1331 seconds.
Full animation took 54558 seconds so far.
